[
    {
        "sentence": "We propose the usage of Convolutional Long Short-Term Memory (ConvLSTM) model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 1,
        "paper_id": 0,
        "paragraph_info": "*Abstract*\u2014Recently, air pollution is one of the most concerns for big cities. Predicting air quality for any regions and at any time is a critical requirement of urban citizens. However, air pollution prediction for the whole city is a challenging problem. The reason is, there are many spatiotemporal factors affecting air pollution throughout the city. Collecting as many of them could help us to forecast air pollution better. In this research, we present many spatiotemporal datasets collected over Seoul city in Korea, which is currently much suffered by air pollution problem as well. These datasets include air pollution data, meteorological data, traffic volume, average driving speed, and air pollution indexes of external areas which are known to impact Seoul's air pollution. To the best of our knowledge, traffic volume and average driving speed data are two new datasets in air pollution research. In addition, recent research in air pollution has tried to build models to interpolate and predict air pollution in the city. Nevertheless, they mostly focused on predicting air quality in discrete locations or used hand-crafted spatial and temporal features. In this paper, we propose the usage of Convolutional Long Short-Term Memory (ConvLSTM) model [\\[16\\]](#page-7-0), a combination of Convolutional Neural Networks and Long Short-Term Memory, which automatically manipulates both the spatial and temporal features of the data. Specially, we introduce how to transform the air pollution data into sequences of images which leverages the using of ConvLSTM model to interpolate and predict air quality for the entire city at the same time. We prove that our approach is suitable for spatiotemporal air pollution problems and also outperforms other related research.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5930238962173462,
            -1.7292288541793823
        ],
        "MSU_id": 10
    },
    {
        "sentence": "ConvLSTM is a combination of Convolutional Neural Networks and Long Short-Term Memory.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 1,
        "paper_id": 0,
        "paragraph_info": "*Abstract*\u2014Recently, air pollution is one of the most concerns for big cities. Predicting air quality for any regions and at any time is a critical requirement of urban citizens. However, air pollution prediction for the whole city is a challenging problem. The reason is, there are many spatiotemporal factors affecting air pollution throughout the city. Collecting as many of them could help us to forecast air pollution better. In this research, we present many spatiotemporal datasets collected over Seoul city in Korea, which is currently much suffered by air pollution problem as well. These datasets include air pollution data, meteorological data, traffic volume, average driving speed, and air pollution indexes of external areas which are known to impact Seoul's air pollution. To the best of our knowledge, traffic volume and average driving speed data are two new datasets in air pollution research. In addition, recent research in air pollution has tried to build models to interpolate and predict air pollution in the city. Nevertheless, they mostly focused on predicting air quality in discrete locations or used hand-crafted spatial and temporal features. In this paper, we propose the usage of Convolutional Long Short-Term Memory (ConvLSTM) model [\\[16\\]](#page-7-0), a combination of Convolutional Neural Networks and Long Short-Term Memory, which automatically manipulates both the spatial and temporal features of the data. Specially, we introduce how to transform the air pollution data into sequences of images which leverages the using of ConvLSTM model to interpolate and predict air quality for the entire city at the same time. We prove that our approach is suitable for spatiotemporal air pollution problems and also outperforms other related research.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5452337265014648,
            -1.7433747053146362
        ],
        "MSU_id": 11
    },
    {
        "sentence": "ConvLSTM automatically manipulates both the spatial and temporal features of the data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 1,
        "paper_id": 0,
        "paragraph_info": "*Abstract*\u2014Recently, air pollution is one of the most concerns for big cities. Predicting air quality for any regions and at any time is a critical requirement of urban citizens. However, air pollution prediction for the whole city is a challenging problem. The reason is, there are many spatiotemporal factors affecting air pollution throughout the city. Collecting as many of them could help us to forecast air pollution better. In this research, we present many spatiotemporal datasets collected over Seoul city in Korea, which is currently much suffered by air pollution problem as well. These datasets include air pollution data, meteorological data, traffic volume, average driving speed, and air pollution indexes of external areas which are known to impact Seoul's air pollution. To the best of our knowledge, traffic volume and average driving speed data are two new datasets in air pollution research. In addition, recent research in air pollution has tried to build models to interpolate and predict air pollution in the city. Nevertheless, they mostly focused on predicting air quality in discrete locations or used hand-crafted spatial and temporal features. In this paper, we propose the usage of Convolutional Long Short-Term Memory (ConvLSTM) model [\\[16\\]](#page-7-0), a combination of Convolutional Neural Networks and Long Short-Term Memory, which automatically manipulates both the spatial and temporal features of the data. Specially, we introduce how to transform the air pollution data into sequences of images which leverages the using of ConvLSTM model to interpolate and predict air quality for the entire city at the same time. We prove that our approach is suitable for spatiotemporal air pollution problems and also outperforms other related research.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9247393608093262,
            -1.3151410818099976
        ],
        "MSU_id": 12
    },
    {
        "sentence": "We introduce how to transform the air pollution data into sequences of images.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 1,
        "paper_id": 0,
        "paragraph_info": "*Abstract*\u2014Recently, air pollution is one of the most concerns for big cities. Predicting air quality for any regions and at any time is a critical requirement of urban citizens. However, air pollution prediction for the whole city is a challenging problem. The reason is, there are many spatiotemporal factors affecting air pollution throughout the city. Collecting as many of them could help us to forecast air pollution better. In this research, we present many spatiotemporal datasets collected over Seoul city in Korea, which is currently much suffered by air pollution problem as well. These datasets include air pollution data, meteorological data, traffic volume, average driving speed, and air pollution indexes of external areas which are known to impact Seoul's air pollution. To the best of our knowledge, traffic volume and average driving speed data are two new datasets in air pollution research. In addition, recent research in air pollution has tried to build models to interpolate and predict air pollution in the city. Nevertheless, they mostly focused on predicting air quality in discrete locations or used hand-crafted spatial and temporal features. In this paper, we propose the usage of Convolutional Long Short-Term Memory (ConvLSTM) model [\\[16\\]](#page-7-0), a combination of Convolutional Neural Networks and Long Short-Term Memory, which automatically manipulates both the spatial and temporal features of the data. Specially, we introduce how to transform the air pollution data into sequences of images which leverages the using of ConvLSTM model to interpolate and predict air quality for the entire city at the same time. We prove that our approach is suitable for spatiotemporal air pollution problems and also outperforms other related research.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.1160013675689697,
            -1.1360082626342773
        ],
        "MSU_id": 13
    },
    {
        "sentence": "This transformation leverages the usage of ConvLSTM model to interpolate and predict air quality for the entire city at the same time.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 1,
        "paper_id": 0,
        "paragraph_info": "*Abstract*\u2014Recently, air pollution is one of the most concerns for big cities. Predicting air quality for any regions and at any time is a critical requirement of urban citizens. However, air pollution prediction for the whole city is a challenging problem. The reason is, there are many spatiotemporal factors affecting air pollution throughout the city. Collecting as many of them could help us to forecast air pollution better. In this research, we present many spatiotemporal datasets collected over Seoul city in Korea, which is currently much suffered by air pollution problem as well. These datasets include air pollution data, meteorological data, traffic volume, average driving speed, and air pollution indexes of external areas which are known to impact Seoul's air pollution. To the best of our knowledge, traffic volume and average driving speed data are two new datasets in air pollution research. In addition, recent research in air pollution has tried to build models to interpolate and predict air pollution in the city. Nevertheless, they mostly focused on predicting air quality in discrete locations or used hand-crafted spatial and temporal features. In this paper, we propose the usage of Convolutional Long Short-Term Memory (ConvLSTM) model [\\[16\\]](#page-7-0), a combination of Convolutional Neural Networks and Long Short-Term Memory, which automatically manipulates both the spatial and temporal features of the data. Specially, we introduce how to transform the air pollution data into sequences of images which leverages the using of ConvLSTM model to interpolate and predict air quality for the entire city at the same time. We prove that our approach is suitable for spatiotemporal air pollution problems and also outperforms other related research.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5651977062225342,
            -1.8258875608444214
        ],
        "MSU_id": 14
    },
    {
        "sentence": "Many countries have constructed air pollution monitoring stations inside major cities.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 3,
        "paper_id": 0,
        "paragraph_info": "Outdoor air pollution is now threatening seriously to human health and life in big cities [\\[8\\]](#page-7-1). Many countries have constructed air pollution monitoring stations inside major cities to observe air pollutants such as PM2.5, PM10, CO, NO2, and SO2 [\\[18\\]](#page-7-2). The sources for air pollution can be from industry, people lives, vehicles, or natural sources (such as wildfires, sand storms). As a result, air pollution is affected by many complicated factors and predicting air pollution is a hard problem.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9875071048736572,
            -1.2011617422103882
        ],
        "MSU_id": 24
    },
    {
        "sentence": "Air pollution monitoring stations are used to observe air pollutants such as PM2.5, PM10, CO, NO2, and SO2.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 3,
        "paper_id": 0,
        "paragraph_info": "Outdoor air pollution is now threatening seriously to human health and life in big cities [\\[8\\]](#page-7-1). Many countries have constructed air pollution monitoring stations inside major cities to observe air pollutants such as PM2.5, PM10, CO, NO2, and SO2 [\\[18\\]](#page-7-2). The sources for air pollution can be from industry, people lives, vehicles, or natural sources (such as wildfires, sand storms). As a result, air pollution is affected by many complicated factors and predicting air pollution is a hard problem.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9859867095947266,
            -1.7718992233276367
        ],
        "MSU_id": 25
    },
    {
        "sentence": "Air quality monitoring stations provide measurements of air pollution at their located points.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 7,
        "paper_id": 0,
        "paragraph_info": "form. The temperature, humidity, raining of different areas are dissimilar and the wind speed, wind direction make air pollution varies from locations to locations. Another critical reason for air pollution is traffic density and traffic congestion. The area with more traffic volume or frequent traffic jam will have ambient air quality worse. One indication of the traffic jam is the average driving speed on each road, in which a low average speed means there might be traffic congestion. The air quality monitoring stations could help us to have a measurement of air pollution at and around their located points but not for the whole city. For example, in Seoul, only less than 40 monitoring stations are covering the area of 600 km2. Consequently, we need to interpolate and predict air pollution in areas that do not have observation stations nearby. While we can not build air quality monitoring stations for all regions in a city, we can use aforementioned air pollution impact factors collected for other locations throughout the city to interpolate and forecast air pollution in the citywide scale. In fig. 1, we show the overall picture for our addressing research which tries to solve the air pollution interpolation and prediction for the entire city based on many air pollution related sources. In the next section, we will introduce the collected spatiotemporal datasets, specific to Seoul city in Korea, to help build better air pollution prediction models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7253453731536865,
            -1.8298569917678833
        ],
        "MSU_id": 42
    },
    {
        "sentence": "We can use air pollution impact factors collected from other locations to interpolate and forecast air pollution citywide.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 7,
        "paper_id": 0,
        "paragraph_info": "form. The temperature, humidity, raining of different areas are dissimilar and the wind speed, wind direction make air pollution varies from locations to locations. Another critical reason for air pollution is traffic density and traffic congestion. The area with more traffic volume or frequent traffic jam will have ambient air quality worse. One indication of the traffic jam is the average driving speed on each road, in which a low average speed means there might be traffic congestion. The air quality monitoring stations could help us to have a measurement of air pollution at and around their located points but not for the whole city. For example, in Seoul, only less than 40 monitoring stations are covering the area of 600 km2. Consequently, we need to interpolate and predict air pollution in areas that do not have observation stations nearby. While we can not build air quality monitoring stations for all regions in a city, we can use aforementioned air pollution impact factors collected for other locations throughout the city to interpolate and forecast air pollution in the citywide scale. In fig. 1, we show the overall picture for our addressing research which tries to solve the air pollution interpolation and prediction for the entire city based on many air pollution related sources. In the next section, we will introduce the collected spatiotemporal datasets, specific to Seoul city in Korea, to help build better air pollution prediction models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7541813850402832,
            -1.6093045473098755
        ],
        "MSU_id": 47
    },
    {
        "sentence": "In the next section, we will introduce the collected spatiotemporal datasets specific to Seoul city in Korea.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 7,
        "paper_id": 0,
        "paragraph_info": "form. The temperature, humidity, raining of different areas are dissimilar and the wind speed, wind direction make air pollution varies from locations to locations. Another critical reason for air pollution is traffic density and traffic congestion. The area with more traffic volume or frequent traffic jam will have ambient air quality worse. One indication of the traffic jam is the average driving speed on each road, in which a low average speed means there might be traffic congestion. The air quality monitoring stations could help us to have a measurement of air pollution at and around their located points but not for the whole city. For example, in Seoul, only less than 40 monitoring stations are covering the area of 600 km2. Consequently, we need to interpolate and predict air pollution in areas that do not have observation stations nearby. While we can not build air quality monitoring stations for all regions in a city, we can use aforementioned air pollution impact factors collected for other locations throughout the city to interpolate and forecast air pollution in the citywide scale. In fig. 1, we show the overall picture for our addressing research which tries to solve the air pollution interpolation and prediction for the entire city based on many air pollution related sources. In the next section, we will introduce the collected spatiotemporal datasets, specific to Seoul city in Korea, to help build better air pollution prediction models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.0631906986236572,
            -1.7265137434005737
        ],
        "MSU_id": 49
    },
    {
        "sentence": "We have gathered air pollution data from 3 areas in China like Beijing, Shanghai, and Shandong.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 8,
        "paper_id": 0,
        "paragraph_info": "This section introduces the collected spatiotemporal datasets for citywide air pollution interpolation and prediction. The period of data is 3 years, from 2015 to 2017. In summary, we already recovered hourly air pollution data of 39 monitoring stations, hourly meteorological data of 28 observation stations, hourly traffic volume data for about 145 main roads, and hourly average driving speed in more than 4000 speedsurveying points in Seoul. Moreover, a recent report from [\\[14\\]](#page-7-6) has shown the influence of external air pollution sources from China's cities to Seoul. To mimic these effects, we have gathered air pollution of 3 areas in China like Beijing, Shanghai, and Shandong, which affect Seoul's air quality, also from 2015 to 2017.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9670038223266602,
            -1.5585006475448608
        ],
        "MSU_id": 57
    },
    {
        "sentence": "The traffic volume is collected hourly by vehicle detector devices at survey points in the road.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 9,
        "paper_id": 0,
        "paragraph_info": "The hourly air pollution and meteorological datasets are quite common in recent research about air pollution predicting. The traffic volume and average driving speed data are new datasets within all known air pollution related research. The traffic volume is collected hourly by vehicle detector devices at survey points in the road. They have both the inflow and outflow directions along the survey roads. The average driving speed data is also collected hourly and by the speed checkpoints. In fig. 2, we plot the locations of all traffic volume and vehicle speed survey points in the Seoul city's map. As we can observe, the traffic volume survey points and speed checkpoints are dense and cover quite well the area of Seoul city compared with the air pollution monitoring stations (in markers). Table I also represents some statistic analysis of these 2 datasets. In Table I, turns/hr is the number of vehicles running across a survey point in an hour.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.2596697807312012,
            -0.6234619617462158
        ],
        "MSU_id": 61
    },
    {
        "sentence": "The traffic volume data includes both the inflow and outflow directions along the survey roads.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 9,
        "paper_id": 0,
        "paragraph_info": "The hourly air pollution and meteorological datasets are quite common in recent research about air pollution predicting. The traffic volume and average driving speed data are new datasets within all known air pollution related research. The traffic volume is collected hourly by vehicle detector devices at survey points in the road. They have both the inflow and outflow directions along the survey roads. The average driving speed data is also collected hourly and by the speed checkpoints. In fig. 2, we plot the locations of all traffic volume and vehicle speed survey points in the Seoul city's map. As we can observe, the traffic volume survey points and speed checkpoints are dense and cover quite well the area of Seoul city compared with the air pollution monitoring stations (in markers). Table I also represents some statistic analysis of these 2 datasets. In Table I, turns/hr is the number of vehicles running across a survey point in an hour.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.1393216848373413,
            -1.0301480293273926
        ],
        "MSU_id": 62
    },
    {
        "sentence": "The average driving speed data is also collected hourly and by the speed checkpoints.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 9,
        "paper_id": 0,
        "paragraph_info": "The hourly air pollution and meteorological datasets are quite common in recent research about air pollution predicting. The traffic volume and average driving speed data are new datasets within all known air pollution related research. The traffic volume is collected hourly by vehicle detector devices at survey points in the road. They have both the inflow and outflow directions along the survey roads. The average driving speed data is also collected hourly and by the speed checkpoints. In fig. 2, we plot the locations of all traffic volume and vehicle speed survey points in the Seoul city's map. As we can observe, the traffic volume survey points and speed checkpoints are dense and cover quite well the area of Seoul city compared with the air pollution monitoring stations (in markers). Table I also represents some statistic analysis of these 2 datasets. In Table I, turns/hr is the number of vehicles running across a survey point in an hour.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8324987888336182,
            -1.0240494012832642
        ],
        "MSU_id": 63
    },
    {
        "sentence": "We propose to use a recent model named Convolutional Long Short-term Memory (ConvLSTM).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 12,
        "paper_id": 0,
        "paragraph_info": "Based on the observation that air pollution changes in spatiotemporal form, we propose to use a recent model named Convolutional Long Short-term Memory (ConvLSTM) by [\\[16\\]](#page-7-0). This model was proved to be superior in processing both spatial and temporal features of the input data. We also confirm in this paper that by transforming air pollution data into sequences of images, a ConvLSTM model is the best suitable for the air pollution interpolation and prediction problem, outperforms other baselines based on recurrent neural network (RNN) or convolutional neural network (CNN). Furthermore, ConvLSTM model helps us to learn the spatial and temporal features of input data at the same time and automatically, surpassing recent research that much relied on hand-crafted spatiotemporal features. We will present in some next sections how we construct the input data to fit with ConvLSTM model and how to use it efficiently in air pollution relating problems.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5652756690979004,
            -1.7802507877349854
        ],
        "MSU_id": 72
    },
    {
        "sentence": "We present our proposed model for citywide air pollution Interpolation and Prediction based on Spatiotemporal Deep Learning.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 13,
        "paper_id": 0,
        "paragraph_info": "In this section, we present our proposed model for citywide air pollution Interpolation and Prediction based on Spatiotemporal Deep Learning. Firstly, we briefly talk about CNN and LSTM models, which are proved is working efficiently with spatial and temporal data. Next, we propose the usage of ConvLSTM model [\\[16\\]](#page-7-0) and claim its suitability for spatiotemporal air pollution problem. Finally, in the last part, we show the complete Spatiotemporal Deep Learning model for our cityscale Air Pollution Interpolation and Prediction.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.799349308013916,
            -1.8465520143508911
        ],
        "MSU_id": 79
    },
    {
        "sentence": "We propose the usage of the ConvLSTM model and claim its suitability for the spatiotemporal air pollution problem.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 13,
        "paper_id": 0,
        "paragraph_info": "In this section, we present our proposed model for citywide air pollution Interpolation and Prediction based on Spatiotemporal Deep Learning. Firstly, we briefly talk about CNN and LSTM models, which are proved is working efficiently with spatial and temporal data. Next, we propose the usage of ConvLSTM model [\\[16\\]](#page-7-0) and claim its suitability for spatiotemporal air pollution problem. Finally, in the last part, we show the complete Spatiotemporal Deep Learning model for our cityscale Air Pollution Interpolation and Prediction.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9166516065597534,
            -1.567921757698059
        ],
        "MSU_id": 81
    },
    {
        "sentence": "We show the complete Spatiotemporal Deep Learning model for our cityscale Air Pollution Interpolation and Prediction.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 13,
        "paper_id": 0,
        "paragraph_info": "In this section, we present our proposed model for citywide air pollution Interpolation and Prediction based on Spatiotemporal Deep Learning. Firstly, we briefly talk about CNN and LSTM models, which are proved is working efficiently with spatial and temporal data. Next, we propose the usage of ConvLSTM model [\\[16\\]](#page-7-0) and claim its suitability for spatiotemporal air pollution problem. Finally, in the last part, we show the complete Spatiotemporal Deep Learning model for our cityscale Air Pollution Interpolation and Prediction.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7991318702697754,
            -1.9213906526565552
        ],
        "MSU_id": 82
    },
    {
        "sentence": "A CNN model typically consists of one or many Convolutional layers.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 14,
        "paper_id": 0,
        "paragraph_info": "CNN is one of the most successful Deep Learning algorithms, especially in image classification, object detection. A CNN model typically consists of one or many Convolutional layers to extract the spatial relationship between input image's pixels. As a result, a CNN model can identify spatial patterns of the input such as edges, shading changes, shapes, objects, and so on. The input to a CNN is usually an image with 3 dimensions: width, height, and depth (or channel). If the image channel is 3 then we have a Red-Green-Blue (RGB) image. Alternatively, if the channel is 1, we have a gray-scale image.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4733721017837524,
            -1.9803920984268188
        ],
        "MSU_id": 85
    },
    {
        "sentence": "Convolutional layers extract the spatial relationship between input image's pixels.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 14,
        "paper_id": 0,
        "paragraph_info": "CNN is one of the most successful Deep Learning algorithms, especially in image classification, object detection. A CNN model typically consists of one or many Convolutional layers to extract the spatial relationship between input image's pixels. As a result, a CNN model can identify spatial patterns of the input such as edges, shading changes, shapes, objects, and so on. The input to a CNN is usually an image with 3 dimensions: width, height, and depth (or channel). If the image channel is 3 then we have a Red-Green-Blue (RGB) image. Alternatively, if the channel is 1, we have a gray-scale image.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.309668779373169,
            -1.569353461265564
        ],
        "MSU_id": 86
    },
    {
        "sentence": "At any time t, the input to an LSTM cell is the actual data input at time t, x<sup>t</sup>, and the hidden state from the previous cell ht-1.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 15,
        "paper_id": 0,
        "paragraph_info": "LSTM is a special kind of Recurrent Neural Network (RNN), which recently works as a standard Deep Learning algorithm for sequence predicting problems like speech recognition, language translation, to name a few. The architecture of an LSTM layer is following [\\[4\\]](#page-7-7) and illustrated in fig. 3. At any time t, the input to an LSTM cell is the actual data input at time t, x<sup>t</sup> , and the hidden state from previous cell ht-1. An LSTM cell uses some \"gate\" mechanisms such as forget gate, input gate and output gate to decide which part of the information will be output from the cell state and which information will be stored. Following are the equations which represent the transformation from input to output of an LSTM cell. f<sup>t</sup> is the output of the forget gate, W<sup>f</sup> and b<sup>f</sup> are corresponding weights and biases. \\* is the matrix-vector multiplication.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.547199010848999,
            -1.8940134048461914
        ],
        "MSU_id": 94
    },
    {
        "sentence": "An LSTM cell uses gate mechanisms such as forget gate, input gate, and output gate to decide which part of the information will be output from the cell state and which information will be stored.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 15,
        "paper_id": 0,
        "paragraph_info": "LSTM is a special kind of Recurrent Neural Network (RNN), which recently works as a standard Deep Learning algorithm for sequence predicting problems like speech recognition, language translation, to name a few. The architecture of an LSTM layer is following [\\[4\\]](#page-7-7) and illustrated in fig. 3. At any time t, the input to an LSTM cell is the actual data input at time t, x<sup>t</sup> , and the hidden state from previous cell ht-1. An LSTM cell uses some \"gate\" mechanisms such as forget gate, input gate and output gate to decide which part of the information will be output from the cell state and which information will be stored. Following are the equations which represent the transformation from input to output of an LSTM cell. f<sup>t</sup> is the output of the forget gate, W<sup>f</sup> and b<sup>f</sup> are corresponding weights and biases. \\* is the matrix-vector multiplication.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.335216999053955,
            -1.87464439868927
        ],
        "MSU_id": 95
    },
    {
        "sentence": "The equations represent the transformation from input to output of an LSTM cell.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 15,
        "paper_id": 0,
        "paragraph_info": "LSTM is a special kind of Recurrent Neural Network (RNN), which recently works as a standard Deep Learning algorithm for sequence predicting problems like speech recognition, language translation, to name a few. The architecture of an LSTM layer is following [\\[4\\]](#page-7-7) and illustrated in fig. 3. At any time t, the input to an LSTM cell is the actual data input at time t, x<sup>t</sup> , and the hidden state from previous cell ht-1. An LSTM cell uses some \"gate\" mechanisms such as forget gate, input gate and output gate to decide which part of the information will be output from the cell state and which information will be stored. Following are the equations which represent the transformation from input to output of an LSTM cell. f<sup>t</sup> is the output of the forget gate, W<sup>f</sup> and b<sup>f</sup> are corresponding weights and biases. \\* is the matrix-vector multiplication.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.3532252311706543,
            -1.8704776763916016
        ],
        "MSU_id": 96
    },
    {
        "sentence": "f<sup>t</sup> is the output of the forget gate, W<sup>f</sup> and b<sup>f</sup> are corresponding weights and biases.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 15,
        "paper_id": 0,
        "paragraph_info": "LSTM is a special kind of Recurrent Neural Network (RNN), which recently works as a standard Deep Learning algorithm for sequence predicting problems like speech recognition, language translation, to name a few. The architecture of an LSTM layer is following [\\[4\\]](#page-7-7) and illustrated in fig. 3. At any time t, the input to an LSTM cell is the actual data input at time t, x<sup>t</sup> , and the hidden state from previous cell ht-1. An LSTM cell uses some \"gate\" mechanisms such as forget gate, input gate and output gate to decide which part of the information will be output from the cell state and which information will be stored. Following are the equations which represent the transformation from input to output of an LSTM cell. f<sup>t</sup> is the output of the forget gate, W<sup>f</sup> and b<sup>f</sup> are corresponding weights and biases. \\* is the matrix-vector multiplication.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.169589638710022,
            -1.7207356691360474
        ],
        "MSU_id": 97
    },
    {
        "sentence": "For a higher dimensional input such as 2D or 3D tensors data, we can easily extend these transformations by replacing matrix-vector multiplication operator with matrix-matrix multiplication.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 19,
        "paper_id": 0,
        "paragraph_info": "The equations from (1) to (6) are commonly applied for 1 dimensional (1D) time series input data. For a higher dimensional input such as 2D or 3D tensors data, we can easily extend these transformations by replacing matrix-vector multiplication operator with matrix-matrix multiplication. This is called fully connected LSTM (FC-LSTM) model. Nevertheless, in [\\[16\\]](#page-7-0), the authors claimed that FC-LSTM model is not efficient for spatiotemporal based data because of its poor ability in spatial learning. For the next subsection, we will describe how a new variant of LSTM model like ConvLSTM model could be fit well to our tackling problem.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.2170125246047974,
            -1.9230517148971558
        ],
        "MSU_id": 105
    },
    {
        "sentence": "To efficiently predict air pollution anywhere, we need a model that leverages spatial features.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 20,
        "paper_id": 0,
        "paragraph_info": "As presented in the sections above, urban air pollution has both spatial and temporal characteristics. Therefore, to efficiently predict air pollution anywhere (interpolation) and at any time (forecasting), we need a model that leverages both spatial and temporal features.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6216161251068115,
            -1.8108576536178589
        ],
        "MSU_id": 110
    },
    {
        "sentence": "To efficiently predict air pollution at any time, we need a model that leverages temporal features.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 20,
        "paper_id": 0,
        "paragraph_info": "As presented in the sections above, urban air pollution has both spatial and temporal characteristics. Therefore, to efficiently predict air pollution anywhere (interpolation) and at any time (forecasting), we need a model that leverages both spatial and temporal features.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.817518949508667,
            -1.7270492315292358
        ],
        "MSU_id": 111
    },
    {
        "sentence": "The Convolutional LSTM Network tries to catch spatial features to improve predictions on spatiotemporal problems.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 21,
        "paper_id": 0,
        "paragraph_info": "In 2015, X. Shi et al. proposed a model for precipitation forecasting named Convolutional LSTM Network, which was an extension of FC-LSTM model but tried to catch spatial features to have a better prediction on a spatiotemporal problem. As our air pollution problem is also spatiotemporally based, we propose to use ConvLSTM for interpolating and predicting air quality in the entire city and claim that this model gives superior performance compared with other solutions.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6528583765029907,
            -1.8848282098770142
        ],
        "MSU_id": 114
    },
    {
        "sentence": "We propose to use ConvLSTM for interpolating and predicting air quality in the entire city.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 21,
        "paper_id": 0,
        "paragraph_info": "In 2015, X. Shi et al. proposed a model for precipitation forecasting named Convolutional LSTM Network, which was an extension of FC-LSTM model but tried to catch spatial features to have a better prediction on a spatiotemporal problem. As our air pollution problem is also spatiotemporally based, we propose to use ConvLSTM for interpolating and predicting air quality in the entire city and claim that this model gives superior performance compared with other solutions.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8460519313812256,
            -1.5695689916610718
        ],
        "MSU_id": 115
    },
    {
        "sentence": "Shi et al. proposed to replace the fully connected operators by convolutional structures in both the input-to-state and state-to-state transitions of the ConvLSTM model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 22,
        "paper_id": 0,
        "paragraph_info": "To address the spatiotemporal problem, in ConvLSTM model, Shi et al. proposed to replace the fully connected operators by convolutional structures in both the input-tostate and state-to-state transitions. All the inputs X1,, X<sup>t</sup> , cell outputs C1,, C<sup>t</sup> , hidden states H1,, H<sup>t</sup> , and gates i<sup>t</sup> , f<sup>t</sup> , o<sup>t</sup> of the ConvLSTM are 3D tensors whose last two dimensions are spatial dimensions. The equations for ConvLSTM are shown from (7) to (11) with \\* is now the convolutional operator and",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.513287901878357,
            -1.811470866203308
        ],
        "MSU_id": 117
    },
    {
        "sentence": "Shi et al. suggested using a structure consisting of two networks for the prediction problem.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 24,
        "paper_id": 0,
        "paragraph_info": "For the prediction problem, Shi et al. suggested using the structure shown in fig. 4, which consists of two networks, an encoding, and a forecasting network. The initial states and cell outputs of the forecasting network are replicated from the last state of the encoding network. Both networks are formed by stacking several ConvLSTM layers. Since the prediction target has the same dimension as the input, to generate the final prediction, all the states in the forecasting network are concatenated and fed into a 1x1 convolution layer.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.3210268020629883,
            -1.3256968259811401
        ],
        "MSU_id": 121
    },
    {
        "sentence": "The two networks are an encoding network and a forecasting network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 24,
        "paper_id": 0,
        "paragraph_info": "For the prediction problem, Shi et al. suggested using the structure shown in fig. 4, which consists of two networks, an encoding, and a forecasting network. The initial states and cell outputs of the forecasting network are replicated from the last state of the encoding network. Both networks are formed by stacking several ConvLSTM layers. Since the prediction target has the same dimension as the input, to generate the final prediction, all the states in the forecasting network are concatenated and fed into a 1x1 convolution layer.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.2349092960357666,
            -1.8446210622787476
        ],
        "MSU_id": 122
    },
    {
        "sentence": "The initial states and cell outputs of the forecasting network are replicated from the last state of the encoding network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 24,
        "paper_id": 0,
        "paragraph_info": "For the prediction problem, Shi et al. suggested using the structure shown in fig. 4, which consists of two networks, an encoding, and a forecasting network. The initial states and cell outputs of the forecasting network are replicated from the last state of the encoding network. Both networks are formed by stacking several ConvLSTM layers. Since the prediction target has the same dimension as the input, to generate the final prediction, all the states in the forecasting network are concatenated and fed into a 1x1 convolution layer.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.8244533538818359,
            -1.9788833856582642
        ],
        "MSU_id": 123
    },
    {
        "sentence": "Both networks are formed by stacking several ConvLSTM layers.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 24,
        "paper_id": 0,
        "paragraph_info": "For the prediction problem, Shi et al. suggested using the structure shown in fig. 4, which consists of two networks, an encoding, and a forecasting network. The initial states and cell outputs of the forecasting network are replicated from the last state of the encoding network. Both networks are formed by stacking several ConvLSTM layers. Since the prediction target has the same dimension as the input, to generate the final prediction, all the states in the forecasting network are concatenated and fed into a 1x1 convolution layer.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6718472242355347,
            -1.5651792287826538
        ],
        "MSU_id": 124
    },
    {
        "sentence": "To generate the final prediction, all the states in the forecasting network are concatenated and fed into a 1x1 convolution layer.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 24,
        "paper_id": 0,
        "paragraph_info": "For the prediction problem, Shi et al. suggested using the structure shown in fig. 4, which consists of two networks, an encoding, and a forecasting network. The initial states and cell outputs of the forecasting network are replicated from the last state of the encoding network. Both networks are formed by stacking several ConvLSTM layers. Since the prediction target has the same dimension as the input, to generate the final prediction, all the states in the forecasting network are concatenated and fed into a 1x1 convolution layer.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5597957372665405,
            -1.880581259727478
        ],
        "MSU_id": 126
    },
    {
        "type": "figure",
        "para_id": 26,
        "paper_id": 0,
        "paragraph_info": "_page_2_Figure_17.jpeg",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5911555290222168,
            -1.7082314491271973
        ],
        "MSU_id": 127,
        "sentence": "The image illustrates the Encoding-Forecasting ConvLSTM structure used for spatiotemporal sequence prediction, showing the flow from input through encoding and forecasting networks to generate predictions.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "To leverage the ConvLSTM model, we divide the city's covering rectangle into a grid of width x height size.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 27,
        "paper_id": 0,
        "paragraph_info": "We need to interpolate and predict air pollution for Everywhere in a city. To leverage the ConvLSTM model, we divide the city's covering rectangle into a grid of width x height size and assign collected air pollution data into grid-cells. The value in a cell is the aggregated value of all assigned stations values at a timestamp t. Thus, at any time t, we have a grayscale image of dimension width x height representing for the entire city. The pixel values are the aggregated air pollution values at that time.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6176637411117554,
            -1.4465588331222534
        ],
        "MSU_id": 130
    },
    {
        "sentence": "We assign collected air pollution data into grid-cells.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 27,
        "paper_id": 0,
        "paragraph_info": "We need to interpolate and predict air pollution for Everywhere in a city. To leverage the ConvLSTM model, we divide the city's covering rectangle into a grid of width x height size and assign collected air pollution data into grid-cells. The value in a cell is the aggregated value of all assigned stations values at a timestamp t. Thus, at any time t, we have a grayscale image of dimension width x height representing for the entire city. The pixel values are the aggregated air pollution values at that time.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9289937019348145,
            -1.3447185754776
        ],
        "MSU_id": 131
    },
    {
        "sentence": "The value in a cell is the aggregated value of all assigned stations values at a timestamp t.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 27,
        "paper_id": 0,
        "paragraph_info": "We need to interpolate and predict air pollution for Everywhere in a city. To leverage the ConvLSTM model, we divide the city's covering rectangle into a grid of width x height size and assign collected air pollution data into grid-cells. The value in a cell is the aggregated value of all assigned stations values at a timestamp t. Thus, at any time t, we have a grayscale image of dimension width x height representing for the entire city. The pixel values are the aggregated air pollution values at that time.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.3875322937965393,
            -1.9175828695297241
        ],
        "MSU_id": 132
    },
    {
        "sentence": "We make a 32x32 grid for the Seoul city case study.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5737906694412231,
            0.5875942707061768
        ],
        "MSU_id": 135
    },
    {
        "sentence": "We need to predict the missing values via interpolating.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.338260293006897,
            -1.8563276529312134
        ],
        "MSU_id": 139
    },
    {
        "sentence": "We transform meteorological data into the grid map as air pollution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6728191375732422,
            -1.4301553964614868
        ],
        "MSU_id": 141
    },
    {
        "sentence": "We assign weather observation stations into the corresponding grid-cells and average values for meteorological data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.7154352068901062,
            -1.5737327337265015
        ],
        "MSU_id": 142
    },
    {
        "sentence": "Survey points geolocations are used to allocate traffic volume and driving speed to the grid cells.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.430584192276001,
            -1.1751344203948975
        ],
        "MSU_id": 143
    },
    {
        "sentence": "Traffic volume and speed are aggregated for the grid cells.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5153781175613403,
            -1.2687554359436035
        ],
        "MSU_id": 144
    },
    {
        "sentence": "External air pollution sources are embedded into the grid-map via a pre-training mechanism.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8069112300872803,
            -1.3494526147842407
        ],
        "MSU_id": 145
    },
    {
        "sentence": "We apply the ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 28,
        "paper_id": 0,
        "paragraph_info": "Regarding the Seoul city case study, we make a 32x32 grid, which means each grid dimension has the distance approximate 1 km in the real scale. Consequently, we have many sequences of \"images\" which represent for the air pollution in the city by time slices. The pixel with zero value means there is no air pollution monitoring station at that grid cell. We need to predict the missing values via interpolating. As aforementioned, the air pollution in a city depends on many factors like meteorology, traffic volume, average driving speed or external air pollution sources. We also transform these data into the grid map as air pollution. For meteorological data, we assign the weather observation stations into the corresponding grid-cells and average values like in air pollution case. For traffic volume and driving speed, the survey points geolocations are used to allocate them to the cell, and the traffic volume and speed are also aggregated. With external air pollution sources, because they cannot be assigned directly to the grid, we embed them into grid-map via pre-training mechanism. Fig. 5 illustrates how we construct the gray-scale images of air pollution and the spatiotemporal data for the Seoul city. We can see that, despite air pollution \"images\" are very sparse, other spatiotemporal data make dense images which motivate us to apply ConvLSTM model for these image sequences to interpolate and predict air pollution for the whole city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8218297958374023,
            -1.6140531301498413
        ],
        "MSU_id": 148
    },
    {
        "sentence": "We use gray-scale images as 2D input tensors with MxN dimension.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.0505396127700806,
            -1.898121953010559
        ],
        "MSU_id": 152
    },
    {
        "sentence": "The input tensors are a combination of air pollution and other influential factors values at the same location.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.1216256618499756,
            -1.9234682321548462
        ],
        "MSU_id": 153
    },
    {
        "sentence": "Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.28034988045692444,
            -1.6785880327224731
        ],
        "MSU_id": 154
    },
    {
        "sentence": "$R_a$ is the air pollution domain.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.4223938286304474,
            -1.1980525255203247
        ],
        "MSU_id": 155
    },
    {
        "sentence": "$P_a$ is the range of air pollution values.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.0333728790283203,
            -0.6307306289672852
        ],
        "MSU_id": 156
    },
    {
        "sentence": "$X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.4112156331539154,
            -1.6686958074569702
        ],
        "MSU_id": 157
    },
    {
        "sentence": "$X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.046334981918335,
            -1.750552773475647
        ],
        "MSU_id": 158
    },
    {
        "sentence": "$X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.11610434949398041,
            -1.9337199926376343
        ],
        "MSU_id": 159
    },
    {
        "sentence": "$X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.6156115531921387,
            -1.6942591667175293
        ],
        "MSU_id": 160
    },
    {
        "sentence": "$R_m$, $R_t$, $R_s$, and $R_e$ are the meteorological, traffic, speed and external air pollution domain, respectively.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.411881685256958,
            -1.781667709350586
        ],
        "MSU_id": 161
    },
    {
        "sentence": "$P_a$, $P_t$, $P_m$, and $P_e$ are the corresponding meteorological, traffic, speed and external air pollution range of values.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6912767887115479,
            -1.7332534790039062
        ],
        "MSU_id": 162
    },
    {
        "sentence": "The input tensor $X$ of the model is a concatenation of all described input tensors: $X = X_a + X_m + X_t + X_s + X_e$.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.131921410560608,
            -1.9416736364364624
        ],
        "MSU_id": 163
    },
    {
        "sentence": "In which + is a vector concatenation operator.",
        "category": "Method",
        "rank": 2,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5680480003356934,
            -1.7366783618927002
        ],
        "MSU_id": 164
    },
    {
        "sentence": "If we want to forecast for K hours ahead, the equation will be following.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 31,
        "paper_id": 0,
        "paragraph_info": "To apply ConvLSTM model for our problem, we use gray-scale images as 2D input tensors with MxN dimension. The input tensors are not only air pollution values but the combination of air pollution and other influential factors values at the same location. Denotes  $X_a \\in R_a^{P_a x M x N}$  is the air pollution input tensor, where  $R_a$  is the air pollution domain,  $P_a$  is the range of air pollution values. Similarly,  $X_m \\in {R_m}^{P_m x M x N}$  is the meteorological input tensor,  $X_t \\in {R_t}^{{P_t} x M x N}$  is the transportation traffic input tensor,  $X_s \\in R_s^{\\stackrel{\\cdot}{P}_s x M x N}$  is the vehicles average speed input tensor, and  $X_e \\in R_e^{P_e x M x N}$  is the external air pollution input tensor. In which  $R_m$ ,  $R_t$ ,  $R_s$ , and  $R_e$  are the meteorological, traffic, speed and external air pollution domain, respectively, and  $P_a$ ,  $P_t$ ,  $P_m$ , and  $P_e$  are the corresponding meteorological, traffic, speed and external air pollution range of values. Then the input tensor  $X$  of the model is a concatenation of all described input tensors:  $X = X_a + X_m + X_t + X_s + X_e$ , in  $which + is a vector concatenation operator. Therefore, with our$ interpolation and prediction problem, if we want to forecast for K hours ahead, the equation will be following.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.42273014783859253,
            -1.968671441078186
        ],
        "MSU_id": 165
    },
    {
        "sentence": "The complete model is shown in fig. 6 with 1 encoder network and 1 forecasting (decoder) network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 32,
        "paper_id": 0,
        "paragraph_info": "In (12),  $K = 1$  is our interpolation and  $K > 1$  is the prediction problem. The complete model is shown in fig. 6 with 1 encoder network and 1 forecasting (decoder) network. Both 2 networks are stacks of many ConvLSTM layers. The output of the forecasting network is then fed into a  $1x1$  convolution layer to produce the final output.  $1 \\times 1$  convolution is called a feature pooling technique where it allows to sum pooling the features across the depth channel while still keeps the spatial characteristic of the feature map. Using  $1x1$  convolution at the last layer before the output layer, we can transform the ConvLSTM networks output volume into the final output with the same 2D dimension. The output also has the grid-based form like the input, and we can use it to determine air quality's values everywhere in the city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.460840106010437,
            -1.972659945487976
        ],
        "MSU_id": 167
    },
    {
        "sentence": "Both networks are stacks of many ConvLSTM layers.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 32,
        "paper_id": 0,
        "paragraph_info": "In (12),  $K = 1$  is our interpolation and  $K > 1$  is the prediction problem. The complete model is shown in fig. 6 with 1 encoder network and 1 forecasting (decoder) network. Both 2 networks are stacks of many ConvLSTM layers. The output of the forecasting network is then fed into a  $1x1$  convolution layer to produce the final output.  $1 \\times 1$  convolution is called a feature pooling technique where it allows to sum pooling the features across the depth channel while still keeps the spatial characteristic of the feature map. Using  $1x1$  convolution at the last layer before the output layer, we can transform the ConvLSTM networks output volume into the final output with the same 2D dimension. The output also has the grid-based form like the input, and we can use it to determine air quality's values everywhere in the city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.750393033027649,
            -1.5082687139511108
        ],
        "MSU_id": 168
    },
    {
        "sentence": "The output of the forecasting network is then fed into a $1x1$ convolution layer to produce the final output.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 32,
        "paper_id": 0,
        "paragraph_info": "In (12),  $K = 1$  is our interpolation and  $K > 1$  is the prediction problem. The complete model is shown in fig. 6 with 1 encoder network and 1 forecasting (decoder) network. Both 2 networks are stacks of many ConvLSTM layers. The output of the forecasting network is then fed into a  $1x1$  convolution layer to produce the final output.  $1 \\times 1$  convolution is called a feature pooling technique where it allows to sum pooling the features across the depth channel while still keeps the spatial characteristic of the feature map. Using  $1x1$  convolution at the last layer before the output layer, we can transform the ConvLSTM networks output volume into the final output with the same 2D dimension. The output also has the grid-based form like the input, and we can use it to determine air quality's values everywhere in the city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.640944004058838,
            -1.8704379796981812
        ],
        "MSU_id": 169
    },
    {
        "sentence": "Using $1x1$ convolution at the last layer before the output layer, we can transform the ConvLSTM networks output volume into the final output with the same 2D dimension.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 32,
        "paper_id": 0,
        "paragraph_info": "In (12),  $K = 1$  is our interpolation and  $K > 1$  is the prediction problem. The complete model is shown in fig. 6 with 1 encoder network and 1 forecasting (decoder) network. Both 2 networks are stacks of many ConvLSTM layers. The output of the forecasting network is then fed into a  $1x1$  convolution layer to produce the final output.  $1 \\times 1$  convolution is called a feature pooling technique where it allows to sum pooling the features across the depth channel while still keeps the spatial characteristic of the feature map. Using  $1x1$  convolution at the last layer before the output layer, we can transform the ConvLSTM networks output volume into the final output with the same 2D dimension. The output also has the grid-based form like the input, and we can use it to determine air quality's values everywhere in the city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4654752016067505,
            -1.8582749366760254
        ],
        "MSU_id": 172
    },
    {
        "type": "figure",
        "para_id": 34,
        "paper_id": 0,
        "paragraph_info": "_page_3_Figure_7.jpeg",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8652570247650146,
            -1.7719866037368774
        ],
        "MSU_id": 175,
        "sentence": "The image illustrates a Spatiotemporal Deep Learning model using a ConvLSTM Network for citywide air pollution interpolation and prediction.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "The Spatiotemporal Deep Learning model is used for interpolating air pollution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 34,
        "paper_id": 0,
        "paragraph_info": "Fig. 6. The Spatiotemporal Deep Learning model for Interpolating and Predicting air pollution in a Citywide scale.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8446407318115234,
            -2.045165538787842
        ],
        "MSU_id": 176
    },
    {
        "sentence": "The Spatiotemporal Deep Learning model is used for predicting air pollution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 34,
        "paper_id": 0,
        "paragraph_info": "Fig. 6. The Spatiotemporal Deep Learning model for Interpolating and Predicting air pollution in a Citywide scale.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8108103275299072,
            -2.010065793991089
        ],
        "MSU_id": 177
    },
    {
        "sentence": "The authors divided the studying city into a grid and tried to interpolate the air pollution in grid-cells where there are no monitoring stations.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 35,
        "paper_id": 0,
        "paragraph_info": "Among recent research about interpolating and predicting air pollution at the same time, Deep Air Learning (DAL) model by  $[15]$  is the most relevant model to our approach. The authors also divided the studying city (in their case was Beijing) into the grid and tried to interpolate the air pollution in grid-cells where have no monitoring stations. Beside the interpolation capability, the authors claimed that their model was able to predict air pollution in some time ahead. The most relevant part of their research to ours is that they leveraged the using of spatial and temporal features of the input data in a unified way. Nevertheless, they still used hand-crafted spatiotemporal features for their model. On the other hand, we use ConvLSTM networks, which automatically explore the relationship of the spatial and temporal features while training with the spatiotemporal input data.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9193755388259888,
            -1.217838168144226
        ],
        "MSU_id": 180
    },
    {
        "sentence": "They still used hand-crafted spatiotemporal features for their model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 35,
        "paper_id": 0,
        "paragraph_info": "Among recent research about interpolating and predicting air pollution at the same time, Deep Air Learning (DAL) model by  $[15]$  is the most relevant model to our approach. The authors also divided the studying city (in their case was Beijing) into the grid and tried to interpolate the air pollution in grid-cells where have no monitoring stations. Beside the interpolation capability, the authors claimed that their model was able to predict air pollution in some time ahead. The most relevant part of their research to ours is that they leveraged the using of spatial and temporal features of the input data in a unified way. Nevertheless, they still used hand-crafted spatiotemporal features for their model. On the other hand, we use ConvLSTM networks, which automatically explore the relationship of the spatial and temporal features while training with the spatiotemporal input data.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.879162073135376,
            -0.344725102186203
        ],
        "MSU_id": 183
    },
    {
        "sentence": "We use ConvLSTM networks, which automatically explore the relationship of the spatial and temporal features while training with the spatiotemporal input data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 35,
        "paper_id": 0,
        "paragraph_info": "Among recent research about interpolating and predicting air pollution at the same time, Deep Air Learning (DAL) model by  $[15]$  is the most relevant model to our approach. The authors also divided the studying city (in their case was Beijing) into the grid and tried to interpolate the air pollution in grid-cells where have no monitoring stations. Beside the interpolation capability, the authors claimed that their model was able to predict air pollution in some time ahead. The most relevant part of their research to ours is that they leveraged the using of spatial and temporal features of the input data in a unified way. Nevertheless, they still used hand-crafted spatiotemporal features for their model. On the other hand, we use ConvLSTM networks, which automatically explore the relationship of the spatial and temporal features while training with the spatiotemporal input data.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8478620052337646,
            -1.2959638833999634
        ],
        "MSU_id": 184
    },
    {
        "sentence": "They proposed a spatiotemporal semisupervised neural network in the DAL model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 36,
        "paper_id": 0,
        "paragraph_info": "In the DAL model, they proposed a spatiotemporal semisupervised neural network as shown in fig. 7. The authors stated that the information contained in unlabeled examples could be utilized to better exploit the geometric structure of the data, especially for the spatiotemporal data of nearby neighborhoods. Based on this characteristic, they presented a  $\\hat{X}^{\\text{m}}_{t}$  method that embeds spatiotemporal semi-supervised learning in the output layer of the neural network by minimizing the loss function between the nearby observations over the labeled and unlabeled training set, which they called spatiotemporal loss. The nearby features were chosen manually as 2 for both spatial and temporal neighbors as in their paper.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7648248672485352,
            -1.748723030090332
        ],
        "MSU_id": 185
    },
    {
        "sentence": "They presented a method that embeds spatiotemporal semi-supervised learning in the output layer of the neural network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 36,
        "paper_id": 0,
        "paragraph_info": "In the DAL model, they proposed a spatiotemporal semisupervised neural network as shown in fig. 7. The authors stated that the information contained in unlabeled examples could be utilized to better exploit the geometric structure of the data, especially for the spatiotemporal data of nearby neighborhoods. Based on this characteristic, they presented a  $\\hat{X}^{\\text{m}}_{t}$  method that embeds spatiotemporal semi-supervised learning in the output layer of the neural network by minimizing the loss function between the nearby observations over the labeled and unlabeled training set, which they called spatiotemporal loss. The nearby features were chosen manually as 2 for both spatial and temporal neighbors as in their paper.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5965250730514526,
            -1.8593536615371704
        ],
        "MSU_id": 187
    },
    {
        "sentence": "The method minimizes the loss function between the nearby observations over the labeled and unlabeled training set.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 36,
        "paper_id": 0,
        "paragraph_info": "In the DAL model, they proposed a spatiotemporal semisupervised neural network as shown in fig. 7. The authors stated that the information contained in unlabeled examples could be utilized to better exploit the geometric structure of the data, especially for the spatiotemporal data of nearby neighborhoods. Based on this characteristic, they presented a  $\\hat{X}^{\\text{m}}_{t}$  method that embeds spatiotemporal semi-supervised learning in the output layer of the neural network by minimizing the loss function between the nearby observations over the labeled and unlabeled training set, which they called spatiotemporal loss. The nearby features were chosen manually as 2 for both spatial and temporal neighbors as in their paper.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4575825929641724,
            -1.9557198286056519
        ],
        "MSU_id": 188
    },
    {
        "sentence": "The nearby features were chosen manually as 2 for both spatial and temporal neighbors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 36,
        "paper_id": 0,
        "paragraph_info": "In the DAL model, they proposed a spatiotemporal semisupervised neural network as shown in fig. 7. The authors stated that the information contained in unlabeled examples could be utilized to better exploit the geometric structure of the data, especially for the spatiotemporal data of nearby neighborhoods. Based on this characteristic, they presented a  $\\hat{X}^{\\text{m}}_{t}$  method that embeds spatiotemporal semi-supervised learning in the output layer of the neural network by minimizing the loss function between the nearby observations over the labeled and unlabeled training set, which they called spatiotemporal loss. The nearby features were chosen manually as 2 for both spatial and temporal neighbors as in their paper.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.8643235564231873,
            -1.8222488164901733
        ],
        "MSU_id": 190
    },
    {
        "type": "figure",
        "para_id": 38,
        "paper_id": 0,
        "paragraph_info": "_page_4_Figure_0.jpeg",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8589260578155518,
            -1.460905909538269
        ],
        "MSU_id": 191,
        "sentence": "The image illustrates the structure of a spatiotemporal semi-supervised neural network within the DAL model, highlighting spatial and temporal neighborhood connections.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "They used a pre-trained auto-encoder for input data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 39,
        "paper_id": 0,
        "paragraph_info": "To make this model as our baseline comparison, we reimplemented it for the datasets from Seoul city. In [\\[15\\]](#page-7-8), they used a pre-trained auto-encoder for input data and then tuned with their proposed spatiotemporal loss. We also trained an auto-encoder with 4 layers and used the pre-trained model for the next phase training. We implemented DAL for both interpolation and prediction tasks.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.257904291152954,
            -2.041074752807617
        ],
        "MSU_id": 194
    },
    {
        "sentence": "They tuned the model with their proposed spatiotemporal loss.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 39,
        "paper_id": 0,
        "paragraph_info": "To make this model as our baseline comparison, we reimplemented it for the datasets from Seoul city. In [\\[15\\]](#page-7-8), they used a pre-trained auto-encoder for input data and then tuned with their proposed spatiotemporal loss. We also trained an auto-encoder with 4 layers and used the pre-trained model for the next phase training. We implemented DAL for both interpolation and prediction tasks.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.6606613993644714,
            -2.107933521270752
        ],
        "MSU_id": 195
    },
    {
        "sentence": "We trained an auto-encoder with 4 layers.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 39,
        "paper_id": 0,
        "paragraph_info": "To make this model as our baseline comparison, we reimplemented it for the datasets from Seoul city. In [\\[15\\]](#page-7-8), they used a pre-trained auto-encoder for input data and then tuned with their proposed spatiotemporal loss. We also trained an auto-encoder with 4 layers and used the pre-trained model for the next phase training. We implemented DAL for both interpolation and prediction tasks.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.1227564811706543,
            -2.132648468017578
        ],
        "MSU_id": 196
    },
    {
        "sentence": "We used the pre-trained model for the next phase training.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 39,
        "paper_id": 0,
        "paragraph_info": "To make this model as our baseline comparison, we reimplemented it for the datasets from Seoul city. In [\\[15\\]](#page-7-8), they used a pre-trained auto-encoder for input data and then tuned with their proposed spatiotemporal loss. We also trained an auto-encoder with 4 layers and used the pre-trained model for the next phase training. We implemented DAL for both interpolation and prediction tasks.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.0673154592514038,
            -2.063802480697632
        ],
        "MSU_id": 197
    },
    {
        "sentence": "We implemented DAL for both interpolation and prediction tasks.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 39,
        "paper_id": 0,
        "paragraph_info": "To make this model as our baseline comparison, we reimplemented it for the datasets from Seoul city. In [\\[15\\]](#page-7-8), they used a pre-trained auto-encoder for input data and then tuned with their proposed spatiotemporal loss. We also trained an auto-encoder with 4 layers and used the pre-trained model for the next phase training. We implemented DAL for both interpolation and prediction tasks.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5894443988800049,
            -1.7749320268630981
        ],
        "MSU_id": 198
    },
    {
        "sentence": "We describe how we pre-process the collected datasets for our experiments.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 40,
        "paper_id": 0,
        "paragraph_info": "In this section, we describe how we pre-process the collected datasets for our experiments. We can refer to fig. 5 to see the results of these transformation.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.38162875175476074,
            -0.5843954086303711
        ],
        "MSU_id": 199
    },
    {
        "sentence": "We save 6 datasets of air pollution input.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 41,
        "paper_id": 0,
        "paragraph_info": "The air pollution data has 6 air pollutants for each row, which are SO2, CO, O3, NO2, PM10, and PM25. Because each type of air pollutants has a different distribution, we save 6 datasets of air pollution input and train different models for each dataset with the same model architecture. For all experiments in this paper, we use PM2.5 pollutant to demonstrate our proposed model and its results. The gridbased air pollution data is then normalized to the range [0-1] by using Min-Max normalization.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.3401254415512085,
            -1.901720404624939
        ],
        "MSU_id": 204
    },
    {
        "sentence": "We train different models for each dataset with the same model architecture.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 41,
        "paper_id": 0,
        "paragraph_info": "The air pollution data has 6 air pollutants for each row, which are SO2, CO, O3, NO2, PM10, and PM25. Because each type of air pollutants has a different distribution, we save 6 datasets of air pollution input and train different models for each dataset with the same model architecture. For all experiments in this paper, we use PM2.5 pollutant to demonstrate our proposed model and its results. The gridbased air pollution data is then normalized to the range [0-1] by using Min-Max normalization.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.0890387296676636,
            -2.07859468460083
        ],
        "MSU_id": 205
    },
    {
        "sentence": "The grid-based air pollution data is normalized to the range [0-1] by using Min-Max normalization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 41,
        "paper_id": 0,
        "paragraph_info": "The air pollution data has 6 air pollutants for each row, which are SO2, CO, O3, NO2, PM10, and PM25. Because each type of air pollutants has a different distribution, we save 6 datasets of air pollution input and train different models for each dataset with the same model architecture. For all experiments in this paper, we use PM2.5 pollutant to demonstrate our proposed model and its results. The gridbased air pollution data is then normalized to the range [0-1] by using Min-Max normalization.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.018385410308838,
            -1.2531050443649292
        ],
        "MSU_id": 207
    },
    {
        "sentence": "To assign meteorological data into the grid cell, we aggregate the value of 5 numeric features including temperature, wind speed, air pressure, and humidity.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 42,
        "paper_id": 0,
        "paragraph_info": "Regarding meteorological data, we have 7 values like temperature, wind speed, wind direction, rainfall, lowest air pressure, highest air pressure, and humidity. To assign meteorological data into the grid cell, we aggregate the value of 5 numeric features including temperature, wind speed, air pressure, and humidity. Wind direction is a categorical feature such as North, South, West-North, and so on. Relating to wind direction, we did not average but chose one of the values if many stations are belonging to a grid cell. We tried to fill the missing meteorological values by the nearest neighbor interpolation method. The chosen interpolation method was acceptable thanks to [\\[2\\]](#page-7-9), the meteorological conditions do not change much in a range of 50 km. The resulting data is then normalized to the range [0-1] by using Min-Max normalization except for wind direction data, which is encoded by One-Hot Encoding.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.313751220703125,
            -2.0080206394195557
        ],
        "MSU_id": 209
    },
    {
        "sentence": "We did not average wind direction but chose one of the values if many stations belong to a grid cell.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 42,
        "paper_id": 0,
        "paragraph_info": "Regarding meteorological data, we have 7 values like temperature, wind speed, wind direction, rainfall, lowest air pressure, highest air pressure, and humidity. To assign meteorological data into the grid cell, we aggregate the value of 5 numeric features including temperature, wind speed, air pressure, and humidity. Wind direction is a categorical feature such as North, South, West-North, and so on. Relating to wind direction, we did not average but chose one of the values if many stations are belonging to a grid cell. We tried to fill the missing meteorological values by the nearest neighbor interpolation method. The chosen interpolation method was acceptable thanks to [\\[2\\]](#page-7-9), the meteorological conditions do not change much in a range of 50 km. The resulting data is then normalized to the range [0-1] by using Min-Max normalization except for wind direction data, which is encoded by One-Hot Encoding.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.09730613231658936,
            -1.6895830631256104
        ],
        "MSU_id": 211
    },
    {
        "sentence": "We tried to fill the missing meteorological values by the nearest neighbor interpolation method.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 42,
        "paper_id": 0,
        "paragraph_info": "Regarding meteorological data, we have 7 values like temperature, wind speed, wind direction, rainfall, lowest air pressure, highest air pressure, and humidity. To assign meteorological data into the grid cell, we aggregate the value of 5 numeric features including temperature, wind speed, air pressure, and humidity. Wind direction is a categorical feature such as North, South, West-North, and so on. Relating to wind direction, we did not average but chose one of the values if many stations are belonging to a grid cell. We tried to fill the missing meteorological values by the nearest neighbor interpolation method. The chosen interpolation method was acceptable thanks to [\\[2\\]](#page-7-9), the meteorological conditions do not change much in a range of 50 km. The resulting data is then normalized to the range [0-1] by using Min-Max normalization except for wind direction data, which is encoded by One-Hot Encoding.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.8483892679214478,
            -1.8376121520996094
        ],
        "MSU_id": 212
    },
    {
        "sentence": "The resulting data is then normalized to the range [0-1] by using Min-Max normalization except for wind direction data, which is encoded by One-Hot Encoding.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 42,
        "paper_id": 0,
        "paragraph_info": "Regarding meteorological data, we have 7 values like temperature, wind speed, wind direction, rainfall, lowest air pressure, highest air pressure, and humidity. To assign meteorological data into the grid cell, we aggregate the value of 5 numeric features including temperature, wind speed, air pressure, and humidity. Wind direction is a categorical feature such as North, South, West-North, and so on. Relating to wind direction, we did not average but chose one of the values if many stations are belonging to a grid cell. We tried to fill the missing meteorological values by the nearest neighbor interpolation method. The chosen interpolation method was acceptable thanks to [\\[2\\]](#page-7-9), the meteorological conditions do not change much in a range of 50 km. The resulting data is then normalized to the range [0-1] by using Min-Max normalization except for wind direction data, which is encoded by One-Hot Encoding.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.787143588066101,
            -1.493202567100525
        ],
        "MSU_id": 214
    },
    {
        "sentence": "The geometric coordinates of each survey point for traffic mass and speed are used to determine its cell position in the grid-map.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 43,
        "paper_id": 0,
        "paragraph_info": "The grid-based transformation for traffic volume and average driving speed is similar to air pollution. The geometric coordinates of each survey point for traffic mass and speed are used to determine its cell position in the grid-map. The data is also normalized to the range [0-1] with Min-Max normalization.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.222367763519287,
            -0.6757784485816956
        ],
        "MSU_id": 216
    },
    {
        "sentence": "The data is normalized to the range [0-1] with Min-Max normalization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 43,
        "paper_id": 0,
        "paragraph_info": "The grid-based transformation for traffic volume and average driving speed is similar to air pollution. The geometric coordinates of each survey point for traffic mass and speed are used to determine its cell position in the grid-map. The data is also normalized to the range [0-1] with Min-Max normalization.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9738770723342896,
            -1.1797064542770386
        ],
        "MSU_id": 217
    },
    {
        "sentence": "We use an additional neural network to embed their spatiotemporal effects with Seoul air pollution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 44,
        "paper_id": 0,
        "paragraph_info": "The external air pollution of 3 areas in China is kept untouched cause we use an additional neural network to embed their spatiotemporal effects with Seoul air pollution as mentioned in previous section.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.938570499420166,
            -1.7655781507492065
        ],
        "MSU_id": 219
    },
    {
        "sentence": "This splitting mechanism ensures the training and test set have the same distribution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 45,
        "paper_id": 0,
        "paragraph_info": "For experiments and evaluations, we split the input dataset into the training set of 2 years, 2015 and 2016, and the test set is the year 2017. This splitting mechanism, choosing the training set is 2 years, and test set is the remaining year, ensures the training and test set have the same distribution and still make our model to have a good generalization. Regarding the forecasting task, we chose to predict for 12 hours ahead. That means we can predict from 1 to 12 hours in the future.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.20519353449344635,
            -2.0983800888061523
        ],
        "MSU_id": 222
    },
    {
        "sentence": "We chose to predict for 12 hours ahead.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 45,
        "paper_id": 0,
        "paragraph_info": "For experiments and evaluations, we split the input dataset into the training set of 2 years, 2015 and 2016, and the test set is the year 2017. This splitting mechanism, choosing the training set is 2 years, and test set is the remaining year, ensures the training and test set have the same distribution and still make our model to have a good generalization. Regarding the forecasting task, we chose to predict for 12 hours ahead. That means we can predict from 1 to 12 hours in the future.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            1.050934076309204,
            -1.9800411462783813
        ],
        "MSU_id": 224
    },
    {
        "sentence": "We use Tensorflow framework from Google to build ConvLSTM layers.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 46,
        "paper_id": 0,
        "paragraph_info": "We use Tensorflow framework from Google to build ConvLSTM layers [\\[1\\]](#page-7-10). If not explicitly stated, all experiments in this paper use the learning rate is 0.001, the batch size is 128, training steps are 200, L2 regularization with beta value is 0.01 and the dropout ratio is 0.5. The metric for the test sets result is the root mean squared error (RMSE) between the actual air pollution values and the predicted/interpolated values. This is a common metric used in the regression problem like this. RMSE is only calculated for the grid-cells that are assigned monitoring stations. If RMSE is smaller then the models performance is better.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6701350212097168,
            -1.7101730108261108
        ],
        "MSU_id": 226
    },
    {
        "sentence": "All experiments in this paper use a learning rate of 0.001.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 46,
        "paper_id": 0,
        "paragraph_info": "We use Tensorflow framework from Google to build ConvLSTM layers [\\[1\\]](#page-7-10). If not explicitly stated, all experiments in this paper use the learning rate is 0.001, the batch size is 128, training steps are 200, L2 regularization with beta value is 0.01 and the dropout ratio is 0.5. The metric for the test sets result is the root mean squared error (RMSE) between the actual air pollution values and the predicted/interpolated values. This is a common metric used in the regression problem like this. RMSE is only calculated for the grid-cells that are assigned monitoring stations. If RMSE is smaller then the models performance is better.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4597597122192383,
            -1.3401798009872437
        ],
        "MSU_id": 227
    },
    {
        "sentence": "All experiments in this paper use a batch size of 128.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 46,
        "paper_id": 0,
        "paragraph_info": "We use Tensorflow framework from Google to build ConvLSTM layers [\\[1\\]](#page-7-10). If not explicitly stated, all experiments in this paper use the learning rate is 0.001, the batch size is 128, training steps are 200, L2 regularization with beta value is 0.01 and the dropout ratio is 0.5. The metric for the test sets result is the root mean squared error (RMSE) between the actual air pollution values and the predicted/interpolated values. This is a common metric used in the regression problem like this. RMSE is only calculated for the grid-cells that are assigned monitoring stations. If RMSE is smaller then the models performance is better.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.6867272853851318,
            -0.23204216361045837
        ],
        "MSU_id": 228
    },
    {
        "sentence": "All experiments in this paper use 200 training steps.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 46,
        "paper_id": 0,
        "paragraph_info": "We use Tensorflow framework from Google to build ConvLSTM layers [\\[1\\]](#page-7-10). If not explicitly stated, all experiments in this paper use the learning rate is 0.001, the batch size is 128, training steps are 200, L2 regularization with beta value is 0.01 and the dropout ratio is 0.5. The metric for the test sets result is the root mean squared error (RMSE) between the actual air pollution values and the predicted/interpolated values. This is a common metric used in the regression problem like this. RMSE is only calculated for the grid-cells that are assigned monitoring stations. If RMSE is smaller then the models performance is better.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.7139419317245483,
            -0.9406339526176453
        ],
        "MSU_id": 229
    },
    {
        "sentence": "All experiments in this paper use L2 regularization with a beta value of 0.01.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 46,
        "paper_id": 0,
        "paragraph_info": "We use Tensorflow framework from Google to build ConvLSTM layers [\\[1\\]](#page-7-10). If not explicitly stated, all experiments in this paper use the learning rate is 0.001, the batch size is 128, training steps are 200, L2 regularization with beta value is 0.01 and the dropout ratio is 0.5. The metric for the test sets result is the root mean squared error (RMSE) between the actual air pollution values and the predicted/interpolated values. This is a common metric used in the regression problem like this. RMSE is only calculated for the grid-cells that are assigned monitoring stations. If RMSE is smaller then the models performance is better.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4014555215835571,
            -1.7721871137619019
        ],
        "MSU_id": 230
    },
    {
        "sentence": "All experiments in this paper use a dropout ratio of 0.5.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 46,
        "paper_id": 0,
        "paragraph_info": "We use Tensorflow framework from Google to build ConvLSTM layers [\\[1\\]](#page-7-10). If not explicitly stated, all experiments in this paper use the learning rate is 0.001, the batch size is 128, training steps are 200, L2 regularization with beta value is 0.01 and the dropout ratio is 0.5. The metric for the test sets result is the root mean squared error (RMSE) between the actual air pollution values and the predicted/interpolated values. This is a common metric used in the regression problem like this. RMSE is only calculated for the grid-cells that are assigned monitoring stations. If RMSE is smaller then the models performance is better.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.8191391825675964,
            -1.5874930620193481
        ],
        "MSU_id": 231
    },
    {
        "sentence": "RMSE is only calculated for the grid-cells that are assigned monitoring stations.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 46,
        "paper_id": 0,
        "paragraph_info": "We use Tensorflow framework from Google to build ConvLSTM layers [\\[1\\]](#page-7-10). If not explicitly stated, all experiments in this paper use the learning rate is 0.001, the batch size is 128, training steps are 200, L2 regularization with beta value is 0.01 and the dropout ratio is 0.5. The metric for the test sets result is the root mean squared error (RMSE) between the actual air pollution values and the predicted/interpolated values. This is a common metric used in the regression problem like this. RMSE is only calculated for the grid-cells that are assigned monitoring stations. If RMSE is smaller then the models performance is better.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.21932053565979,
            -1.7779877185821533
        ],
        "MSU_id": 233
    },
    {
        "sentence": "We implement DAL interpolation with the output time lag is 1 hour ahead.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 47,
        "paper_id": 0,
        "paragraph_info": "We implement DAL interpolation with the output time lag is 1 hour ahead. The number of Auto-Encoder weights for each layer is 2000. After training Auto-Encoder model and save to a checkpoint, we restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training. For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values but we tried to make 2 large tensors by concatenating all actual and all predicted values. Then we only need 1 computation to compute the loss for spatial or temporal neighbors. The final loss is the combination of labeled loss, weighted spatiotemporal loss of all labeled and unlabeled data. The RMSE result in the test set is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.6379468441009521,
            -2.0408341884613037
        ],
        "MSU_id": 236
    },
    {
        "sentence": "The number of Auto-Encoder weights for each layer is 2000.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 47,
        "paper_id": 0,
        "paragraph_info": "We implement DAL interpolation with the output time lag is 1 hour ahead. The number of Auto-Encoder weights for each layer is 2000. After training Auto-Encoder model and save to a checkpoint, we restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training. For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values but we tried to make 2 large tensors by concatenating all actual and all predicted values. Then we only need 1 computation to compute the loss for spatial or temporal neighbors. The final loss is the combination of labeled loss, weighted spatiotemporal loss of all labeled and unlabeled data. The RMSE result in the test set is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.1643537282943726,
            -2.090254783630371
        ],
        "MSU_id": 237
    },
    {
        "sentence": "After training the Auto-Encoder model, we save it to a checkpoint.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 47,
        "paper_id": 0,
        "paragraph_info": "We implement DAL interpolation with the output time lag is 1 hour ahead. The number of Auto-Encoder weights for each layer is 2000. After training Auto-Encoder model and save to a checkpoint, we restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training. For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values but we tried to make 2 large tensors by concatenating all actual and all predicted values. Then we only need 1 computation to compute the loss for spatial or temporal neighbors. The final loss is the combination of labeled loss, weighted spatiotemporal loss of all labeled and unlabeled data. The RMSE result in the test set is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.5907222628593445,
            -2.198068141937256
        ],
        "MSU_id": 238
    },
    {
        "sentence": "We restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 47,
        "paper_id": 0,
        "paragraph_info": "We implement DAL interpolation with the output time lag is 1 hour ahead. The number of Auto-Encoder weights for each layer is 2000. After training Auto-Encoder model and save to a checkpoint, we restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training. For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values but we tried to make 2 large tensors by concatenating all actual and all predicted values. Then we only need 1 computation to compute the loss for spatial or temporal neighbors. The final loss is the combination of labeled loss, weighted spatiotemporal loss of all labeled and unlabeled data. The RMSE result in the test set is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.55901300907135,
            -1.7920337915420532
        ],
        "MSU_id": 239
    },
    {
        "sentence": "For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 47,
        "paper_id": 0,
        "paragraph_info": "We implement DAL interpolation with the output time lag is 1 hour ahead. The number of Auto-Encoder weights for each layer is 2000. After training Auto-Encoder model and save to a checkpoint, we restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training. For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values but we tried to make 2 large tensors by concatenating all actual and all predicted values. Then we only need 1 computation to compute the loss for spatial or temporal neighbors. The final loss is the combination of labeled loss, weighted spatiotemporal loss of all labeled and unlabeled data. The RMSE result in the test set is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5180362462997437,
            -1.819700002670288
        ],
        "MSU_id": 240
    },
    {
        "sentence": "We tried to make 2 large tensors by concatenating all actual and all predicted values.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 47,
        "paper_id": 0,
        "paragraph_info": "We implement DAL interpolation with the output time lag is 1 hour ahead. The number of Auto-Encoder weights for each layer is 2000. After training Auto-Encoder model and save to a checkpoint, we restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training. For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values but we tried to make 2 large tensors by concatenating all actual and all predicted values. Then we only need 1 computation to compute the loss for spatial or temporal neighbors. The final loss is the combination of labeled loss, weighted spatiotemporal loss of all labeled and unlabeled data. The RMSE result in the test set is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.7836326956748962,
            -2.0552282333374023
        ],
        "MSU_id": 241
    },
    {
        "sentence": "We only need 1 computation to compute the loss for spatial or temporal neighbors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 47,
        "paper_id": 0,
        "paragraph_info": "We implement DAL interpolation with the output time lag is 1 hour ahead. The number of Auto-Encoder weights for each layer is 2000. After training Auto-Encoder model and save to a checkpoint, we restore the pre-trained checkpoint for spatiotemporal semi-supervised regression model training. For the spatial and temporal loss, we did not compute the loss separately for each pair of actual and prediction values but we tried to make 2 large tensors by concatenating all actual and all predicted values. Then we only need 1 computation to compute the loss for spatial or temporal neighbors. The final loss is the combination of labeled loss, weighted spatiotemporal loss of all labeled and unlabeled data. The RMSE result in the test set is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5067334175109863,
            -1.8357943296432495
        ],
        "MSU_id": 242
    },
    {
        "sentence": "The implementation of ConvLSTM interpolation model is similar with 1 hour ahead for interpolating function.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 48,
        "paper_id": 0,
        "paragraph_info": "The implementation of ConvLSTM interpolation model is similar with 1 hour ahead for interpolating function. The number of layers for the interpolation model is 1 encoder and 1 decoder (prediction) layer with the output channels are 64. The kernel size chosen for all layers is 3x3. We performed 2 experiments, ConvLSTM model with only labeled data loss and ConvLSTM model with both labeled and unlabeled data spatiotemporal loss as introduced in DAL model. The result is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4712483882904053,
            -1.9433857202529907
        ],
        "MSU_id": 245
    },
    {
        "sentence": "The number of layers for the interpolation model is 1 encoder and 1 decoder (prediction) layer.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 48,
        "paper_id": 0,
        "paragraph_info": "The implementation of ConvLSTM interpolation model is similar with 1 hour ahead for interpolating function. The number of layers for the interpolation model is 1 encoder and 1 decoder (prediction) layer with the output channels are 64. The kernel size chosen for all layers is 3x3. We performed 2 experiments, ConvLSTM model with only labeled data loss and ConvLSTM model with both labeled and unlabeled data spatiotemporal loss as introduced in DAL model. The result is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.257399559020996,
            -2.0553016662597656
        ],
        "MSU_id": 246
    },
    {
        "sentence": "The output channels for the interpolation model are 64.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 48,
        "paper_id": 0,
        "paragraph_info": "The implementation of ConvLSTM interpolation model is similar with 1 hour ahead for interpolating function. The number of layers for the interpolation model is 1 encoder and 1 decoder (prediction) layer with the output channels are 64. The kernel size chosen for all layers is 3x3. We performed 2 experiments, ConvLSTM model with only labeled data loss and ConvLSTM model with both labeled and unlabeled data spatiotemporal loss as introduced in DAL model. The result is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.13982093334198,
            -2.0744197368621826
        ],
        "MSU_id": 247
    },
    {
        "sentence": "The kernel size chosen for all layers is 3x3.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 48,
        "paper_id": 0,
        "paragraph_info": "The implementation of ConvLSTM interpolation model is similar with 1 hour ahead for interpolating function. The number of layers for the interpolation model is 1 encoder and 1 decoder (prediction) layer with the output channels are 64. The kernel size chosen for all layers is 3x3. We performed 2 experiments, ConvLSTM model with only labeled data loss and ConvLSTM model with both labeled and unlabeled data spatiotemporal loss as introduced in DAL model. The result is shown in Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.3801996111869812,
            -1.3174270391464233
        ],
        "MSU_id": 248
    },
    {
        "sentence": "We implemented 2 other models based on Stacked FC-LSTM and CNN Encoder-Decoder.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 49,
        "paper_id": 0,
        "paragraph_info": "Besides DAL model as the competitive baseline, we implemented 2 other models based on Stacked FC-LSTM and CNN Encoder-Decoder to evaluate how our proposed design better in both spatial and temporal exploration, respectively. With Stacked FC-LSTM model (or FC-LSTM for short), we use the input as the gray-scale images of 32x32 size. We picked the number of hidden units for an LSTM cell is 2000 and stacked 3 LSTM cells to increase the models capacity. The output of LSTM cells is then flowed through a fully connected neural network (FCNN) to produce the final output. Regarding CNN Encoder-Decoder model, we applied an Encoder-Decoder network with the encoder is a convolutional layer and decoder is a deconvolution layer similar to [\\[25\\]](#page-7-11). To be comparable with ConvLSTM, we also used 1 encoder and 1 decoder layer with the same parameters (3x3 filter size and 64 output channels). The RMSE of CNN Encoder-Decoder and FC-LSTM model in the test set can be seen from Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6345939636230469,
            -1.8215367794036865
        ],
        "MSU_id": 251
    },
    {
        "sentence": "We use the input as the gray-scale images of 32x32 size for the Stacked FC-LSTM model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 49,
        "paper_id": 0,
        "paragraph_info": "Besides DAL model as the competitive baseline, we implemented 2 other models based on Stacked FC-LSTM and CNN Encoder-Decoder to evaluate how our proposed design better in both spatial and temporal exploration, respectively. With Stacked FC-LSTM model (or FC-LSTM for short), we use the input as the gray-scale images of 32x32 size. We picked the number of hidden units for an LSTM cell is 2000 and stacked 3 LSTM cells to increase the models capacity. The output of LSTM cells is then flowed through a fully connected neural network (FCNN) to produce the final output. Regarding CNN Encoder-Decoder model, we applied an Encoder-Decoder network with the encoder is a convolutional layer and decoder is a deconvolution layer similar to [\\[25\\]](#page-7-11). To be comparable with ConvLSTM, we also used 1 encoder and 1 decoder layer with the same parameters (3x3 filter size and 64 output channels). The RMSE of CNN Encoder-Decoder and FC-LSTM model in the test set can be seen from Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.683617353439331,
            -1.9260636568069458
        ],
        "MSU_id": 253
    },
    {
        "sentence": "We picked the number of hidden units for an LSTM cell as 2000 and stacked 3 LSTM cells to increase the model's capacity.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 49,
        "paper_id": 0,
        "paragraph_info": "Besides DAL model as the competitive baseline, we implemented 2 other models based on Stacked FC-LSTM and CNN Encoder-Decoder to evaluate how our proposed design better in both spatial and temporal exploration, respectively. With Stacked FC-LSTM model (or FC-LSTM for short), we use the input as the gray-scale images of 32x32 size. We picked the number of hidden units for an LSTM cell is 2000 and stacked 3 LSTM cells to increase the models capacity. The output of LSTM cells is then flowed through a fully connected neural network (FCNN) to produce the final output. Regarding CNN Encoder-Decoder model, we applied an Encoder-Decoder network with the encoder is a convolutional layer and decoder is a deconvolution layer similar to [\\[25\\]](#page-7-11). To be comparable with ConvLSTM, we also used 1 encoder and 1 decoder layer with the same parameters (3x3 filter size and 64 output channels). The RMSE of CNN Encoder-Decoder and FC-LSTM model in the test set can be seen from Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5620039701461792,
            -1.9784613847732544
        ],
        "MSU_id": 254
    },
    {
        "sentence": "The output of LSTM cells is then flowed through a fully connected neural network (FCNN) to produce the final output.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 49,
        "paper_id": 0,
        "paragraph_info": "Besides DAL model as the competitive baseline, we implemented 2 other models based on Stacked FC-LSTM and CNN Encoder-Decoder to evaluate how our proposed design better in both spatial and temporal exploration, respectively. With Stacked FC-LSTM model (or FC-LSTM for short), we use the input as the gray-scale images of 32x32 size. We picked the number of hidden units for an LSTM cell is 2000 and stacked 3 LSTM cells to increase the models capacity. The output of LSTM cells is then flowed through a fully connected neural network (FCNN) to produce the final output. Regarding CNN Encoder-Decoder model, we applied an Encoder-Decoder network with the encoder is a convolutional layer and decoder is a deconvolution layer similar to [\\[25\\]](#page-7-11). To be comparable with ConvLSTM, we also used 1 encoder and 1 decoder layer with the same parameters (3x3 filter size and 64 output channels). The RMSE of CNN Encoder-Decoder and FC-LSTM model in the test set can be seen from Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.3959044218063354,
            -2.0546157360076904
        ],
        "MSU_id": 255
    },
    {
        "sentence": "We applied an Encoder-Decoder network with the encoder as a convolutional layer and decoder as a deconvolution layer for the CNN Encoder-Decoder model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 49,
        "paper_id": 0,
        "paragraph_info": "Besides DAL model as the competitive baseline, we implemented 2 other models based on Stacked FC-LSTM and CNN Encoder-Decoder to evaluate how our proposed design better in both spatial and temporal exploration, respectively. With Stacked FC-LSTM model (or FC-LSTM for short), we use the input as the gray-scale images of 32x32 size. We picked the number of hidden units for an LSTM cell is 2000 and stacked 3 LSTM cells to increase the models capacity. The output of LSTM cells is then flowed through a fully connected neural network (FCNN) to produce the final output. Regarding CNN Encoder-Decoder model, we applied an Encoder-Decoder network with the encoder is a convolutional layer and decoder is a deconvolution layer similar to [\\[25\\]](#page-7-11). To be comparable with ConvLSTM, we also used 1 encoder and 1 decoder layer with the same parameters (3x3 filter size and 64 output channels). The RMSE of CNN Encoder-Decoder and FC-LSTM model in the test set can be seen from Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.3523170948028564,
            -1.9255315065383911
        ],
        "MSU_id": 256
    },
    {
        "sentence": "We used 1 encoder and 1 decoder layer with the same parameters (3x3 filter size and 64 output channels) to be comparable with ConvLSTM.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 49,
        "paper_id": 0,
        "paragraph_info": "Besides DAL model as the competitive baseline, we implemented 2 other models based on Stacked FC-LSTM and CNN Encoder-Decoder to evaluate how our proposed design better in both spatial and temporal exploration, respectively. With Stacked FC-LSTM model (or FC-LSTM for short), we use the input as the gray-scale images of 32x32 size. We picked the number of hidden units for an LSTM cell is 2000 and stacked 3 LSTM cells to increase the models capacity. The output of LSTM cells is then flowed through a fully connected neural network (FCNN) to produce the final output. Regarding CNN Encoder-Decoder model, we applied an Encoder-Decoder network with the encoder is a convolutional layer and decoder is a deconvolution layer similar to [\\[25\\]](#page-7-11). To be comparable with ConvLSTM, we also used 1 encoder and 1 decoder layer with the same parameters (3x3 filter size and 64 output channels). The RMSE of CNN Encoder-Decoder and FC-LSTM model in the test set can be seen from Table II.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4039784669876099,
            -1.8289867639541626
        ],
        "MSU_id": 257
    },
    {
        "sentence": "We describe how to assess this result efficiently.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 52,
        "paper_id": 0,
        "paragraph_info": "*1) More Interpolation Evaluation:* The most critical evaluation for this part is to evaluate the citywide air pollution Interpolation. It means how well the predicted output image reflects the air pollution of the whole city. In this part, we describe how to asset this result efficiently.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.5247948169708252,
            0.03615403175354004
        ],
        "MSU_id": 265
    },
    {
        "sentence": "We suggest testing the variance of the interpolated values.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 53,
        "paper_id": 0,
        "paragraph_info": "The RMSE values shown in Table II are useful for quantitative evaluation but they are hard to show the quality of interpolated results for the whole city. In fig. 8, we plot the output images of DAL, ConvLSTM, CNN Encoder-Decoder, and FC-LSTM model to see the distribution of air pollution interpolated values. Intuitively, FC-LSTM model shows the worst output with all the grid-cells except the existing monitoring stations have the same value. The reason is FC-LSTM networks do not learn the spatial features well, and thus do not give good interpolation output. For the remaining 3 models, ConvLSTM and DAL show pretty good air pollution interpolation compared with the CNN Encoder-Decoder model. To prove that ConvLSTM model produces better air pollution interpolated values over other baselines, we compare it with the actual air pollution values distribution. Here, we suggest testing the variance of the interpolated values.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.5785383582115173,
            -1.6401678323745728
        ],
        "MSU_id": 273
    },
    {
        "sentence": "We calculate the variance of actual air pollution values and the interpolated results.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 54,
        "paper_id": 0,
        "paragraph_info": "Variance is the expectation of the squared deviation of a distribution from its mean. A high variance indicates that the data points are very spread out from the mean and other points. While a small variance states that the data points tend to be close to each other. We calculate the variance of actual air pollution values and the interpolated results, repeat for 10 interpolated time steps and draw to a graph in fig. 9. We can witness that the variance of interpolation values of ConvLSTM model is the closest to the variance of actual air pollution values. It means ConvLSTM interpolation model outcomes DAL and other baseline models in producing better interpolated values.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.752461552619934,
            -1.7742382287979126
        ],
        "MSU_id": 277
    },
    {
        "sentence": "We repeat the calculation for 10 interpolated time steps.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 54,
        "paper_id": 0,
        "paragraph_info": "Variance is the expectation of the squared deviation of a distribution from its mean. A high variance indicates that the data points are very spread out from the mean and other points. While a small variance states that the data points tend to be close to each other. We calculate the variance of actual air pollution values and the interpolated results, repeat for 10 interpolated time steps and draw to a graph in fig. 9. We can witness that the variance of interpolation values of ConvLSTM model is the closest to the variance of actual air pollution values. It means ConvLSTM interpolation model outcomes DAL and other baseline models in producing better interpolated values.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.629051685333252,
            -1.6486804485321045
        ],
        "MSU_id": 278
    },
    {
        "sentence": "We draw the results to a graph in fig. 9.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 54,
        "paper_id": 0,
        "paragraph_info": "Variance is the expectation of the squared deviation of a distribution from its mean. A high variance indicates that the data points are very spread out from the mean and other points. While a small variance states that the data points tend to be close to each other. We calculate the variance of actual air pollution values and the interpolated results, repeat for 10 interpolated time steps and draw to a graph in fig. 9. We can witness that the variance of interpolation values of ConvLSTM model is the closest to the variance of actual air pollution values. It means ConvLSTM interpolation model outcomes DAL and other baseline models in producing better interpolated values.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7694177627563477,
            0.46442726254463196
        ],
        "MSU_id": 279
    },
    {
        "sentence": "We implement the experiments with several models: ConvLSTM, ConvLSTM + Met, ConvLSTM + Traffic, ConvLSTM + Speed, ConvLSTM + External, and ConvLSTM + All.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 59,
        "paper_id": 0,
        "paragraph_info": "*2) Interpolation with air pollution influence factors:* In this section, we show the experiments results of air pollution interpolating along with spatiotemporal air pollution impact factors like meteorology, traffic volume, driving average speed, and external air pollution sources. We implement the experiments with following models: ConvLSTM (ConvLSTM with only air pollution data), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and traffic volume data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table III shows the RMSE in the test set of pure ConvLSTM and other combination models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7015719413757324,
            -1.464553713798523
        ],
        "MSU_id": 291
    },
    {
        "sentence": "ConvLSTM uses only air pollution data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 59,
        "paper_id": 0,
        "paragraph_info": "*2) Interpolation with air pollution influence factors:* In this section, we show the experiments results of air pollution interpolating along with spatiotemporal air pollution impact factors like meteorology, traffic volume, driving average speed, and external air pollution sources. We implement the experiments with following models: ConvLSTM (ConvLSTM with only air pollution data), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and traffic volume data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table III shows the RMSE in the test set of pure ConvLSTM and other combination models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.982998251914978,
            -1.7140158414840698
        ],
        "MSU_id": 292
    },
    {
        "sentence": "ConvLSTM + Met uses air pollution and meteorological data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 59,
        "paper_id": 0,
        "paragraph_info": "*2) Interpolation with air pollution influence factors:* In this section, we show the experiments results of air pollution interpolating along with spatiotemporal air pollution impact factors like meteorology, traffic volume, driving average speed, and external air pollution sources. We implement the experiments with following models: ConvLSTM (ConvLSTM with only air pollution data), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and traffic volume data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table III shows the RMSE in the test set of pure ConvLSTM and other combination models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.032552480697632,
            -1.6171985864639282
        ],
        "MSU_id": 293
    },
    {
        "sentence": "ConvLSTM + Traffic uses air pollution and traffic volume data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 59,
        "paper_id": 0,
        "paragraph_info": "*2) Interpolation with air pollution influence factors:* In this section, we show the experiments results of air pollution interpolating along with spatiotemporal air pollution impact factors like meteorology, traffic volume, driving average speed, and external air pollution sources. We implement the experiments with following models: ConvLSTM (ConvLSTM with only air pollution data), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and traffic volume data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table III shows the RMSE in the test set of pure ConvLSTM and other combination models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.034444570541382,
            -1.6072674989700317
        ],
        "MSU_id": 294
    },
    {
        "sentence": "ConvLSTM + Speed uses air pollution and vehicles average speed data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 59,
        "paper_id": 0,
        "paragraph_info": "*2) Interpolation with air pollution influence factors:* In this section, we show the experiments results of air pollution interpolating along with spatiotemporal air pollution impact factors like meteorology, traffic volume, driving average speed, and external air pollution sources. We implement the experiments with following models: ConvLSTM (ConvLSTM with only air pollution data), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and traffic volume data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table III shows the RMSE in the test set of pure ConvLSTM and other combination models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.0464022159576416,
            -1.5863295793533325
        ],
        "MSU_id": 295
    },
    {
        "sentence": "ConvLSTM + External uses air pollution and external air pollution data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 59,
        "paper_id": 0,
        "paragraph_info": "*2) Interpolation with air pollution influence factors:* In this section, we show the experiments results of air pollution interpolating along with spatiotemporal air pollution impact factors like meteorology, traffic volume, driving average speed, and external air pollution sources. We implement the experiments with following models: ConvLSTM (ConvLSTM with only air pollution data), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and traffic volume data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table III shows the RMSE in the test set of pure ConvLSTM and other combination models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.101079225540161,
            -1.6458076238632202
        ],
        "MSU_id": 296
    },
    {
        "sentence": "ConvLSTM + All uses air pollution and all related factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 59,
        "paper_id": 0,
        "paragraph_info": "*2) Interpolation with air pollution influence factors:* In this section, we show the experiments results of air pollution interpolating along with spatiotemporal air pollution impact factors like meteorology, traffic volume, driving average speed, and external air pollution sources. We implement the experiments with following models: ConvLSTM (ConvLSTM with only air pollution data), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and traffic volume data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table III shows the RMSE in the test set of pure ConvLSTM and other combination models.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.982816457748413,
            -1.5194780826568604
        ],
        "MSU_id": 297
    },
    {
        "sentence": "We propose to evaluate how other spatiotemporal factors affect the air pollution interpolations efficiency.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 61,
        "paper_id": 0,
        "paragraph_info": "To evaluate how other spatiotemporal factors affect the air pollution interpolations efficiency, we propose to use the fol-",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8928872346878052,
            -1.7219570875167847
        ],
        "MSU_id": 304
    },
    {
        "sentence": "We removed one of the existing air pollution values from input data while keeping the values of other impacted spatiotemporal data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 63,
        "paper_id": 0,
        "paragraph_info": "lowing test: removing one of the existing air pollution values from input data but still keep the values of other impacted spatiotemporal data and then check the regression error of the interpolated air pollution value with the existing one. If the error is small then we can infer that other spatiotemporal data has a remarkable effect on air pollution interpolation. To measure the error, we alternately set the air pollution value of each existed input pixel to zero, keep other data of that pixel unchanged, running the trained model on this modified input data and calculate RMSE between the inferred value with the actual pixel value of the same position. The final error is the mean of all errors after doing this procedure with all existing air pollution values. We call this error spRMSE, which means the RMSE caused by spatiotemporal factors. The experiments results are shown in Table III. We can notice that ConvLSTM + Speed model has a better spRMSE than ConvLSTM in spite it has worse overall RMSE; which indicates the driving average speed affects air pollution in spatiotemporal form. ConvLSTM + All model has the best spRMSE, proves that we can improve the citywide interpolation with more spatiotemporal data.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4519188404083252,
            -1.9394091367721558
        ],
        "MSU_id": 306
    },
    {
        "sentence": "To measure the error, we alternately set the air pollution value of each existing input pixel to zero while keeping other data of that pixel unchanged.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 63,
        "paper_id": 0,
        "paragraph_info": "lowing test: removing one of the existing air pollution values from input data but still keep the values of other impacted spatiotemporal data and then check the regression error of the interpolated air pollution value with the existing one. If the error is small then we can infer that other spatiotemporal data has a remarkable effect on air pollution interpolation. To measure the error, we alternately set the air pollution value of each existed input pixel to zero, keep other data of that pixel unchanged, running the trained model on this modified input data and calculate RMSE between the inferred value with the actual pixel value of the same position. The final error is the mean of all errors after doing this procedure with all existing air pollution values. We call this error spRMSE, which means the RMSE caused by spatiotemporal factors. The experiments results are shown in Table III. We can notice that ConvLSTM + Speed model has a better spRMSE than ConvLSTM in spite it has worse overall RMSE; which indicates the driving average speed affects air pollution in spatiotemporal form. ConvLSTM + All model has the best spRMSE, proves that we can improve the citywide interpolation with more spatiotemporal data.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.7169137597084045,
            -2.0898218154907227
        ],
        "MSU_id": 309
    },
    {
        "sentence": "We ran the trained model on this modified input data and calculated RMSE between the inferred value and the actual pixel value of the same position.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 63,
        "paper_id": 0,
        "paragraph_info": "lowing test: removing one of the existing air pollution values from input data but still keep the values of other impacted spatiotemporal data and then check the regression error of the interpolated air pollution value with the existing one. If the error is small then we can infer that other spatiotemporal data has a remarkable effect on air pollution interpolation. To measure the error, we alternately set the air pollution value of each existed input pixel to zero, keep other data of that pixel unchanged, running the trained model on this modified input data and calculate RMSE between the inferred value with the actual pixel value of the same position. The final error is the mean of all errors after doing this procedure with all existing air pollution values. We call this error spRMSE, which means the RMSE caused by spatiotemporal factors. The experiments results are shown in Table III. We can notice that ConvLSTM + Speed model has a better spRMSE than ConvLSTM in spite it has worse overall RMSE; which indicates the driving average speed affects air pollution in spatiotemporal form. ConvLSTM + All model has the best spRMSE, proves that we can improve the citywide interpolation with more spatiotemporal data.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.2716106176376343,
            -1.964053988456726
        ],
        "MSU_id": 310
    },
    {
        "sentence": "The input time steps for the baseline model are 24 hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 64,
        "paper_id": 0,
        "paragraph_info": "The baseline model for Air pollution forecasting is also a DAL forecasting model. This model has the same structure as the DAL model for interpolation but the input time steps are 24 hours and the prediction time lags are 12 hours. We still pre-train an Auto-Encoder and then use it to train the prediction model. The spatial loss is computed by summing up the spatial loss for each 12 output image frames. The temporal loss is also the sum of the loss between 1 image slice with 2 neighbor image slices of the output (the DAL paper chose temporal neighbor size is 2). The final loss is the total of labeled loss and spatiotemporal loss.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.24489937722682953,
            -1.8528372049331665
        ],
        "MSU_id": 319
    },
    {
        "sentence": "The prediction time lags for the baseline model are 12 hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 64,
        "paper_id": 0,
        "paragraph_info": "The baseline model for Air pollution forecasting is also a DAL forecasting model. This model has the same structure as the DAL model for interpolation but the input time steps are 24 hours and the prediction time lags are 12 hours. We still pre-train an Auto-Encoder and then use it to train the prediction model. The spatial loss is computed by summing up the spatial loss for each 12 output image frames. The temporal loss is also the sum of the loss between 1 image slice with 2 neighbor image slices of the output (the DAL paper chose temporal neighbor size is 2). The final loss is the total of labeled loss and spatiotemporal loss.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            0.7546454668045044,
            -1.9312998056411743
        ],
        "MSU_id": 320
    },
    {
        "sentence": "We pre-train an Auto-Encoder to train the prediction model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 64,
        "paper_id": 0,
        "paragraph_info": "The baseline model for Air pollution forecasting is also a DAL forecasting model. This model has the same structure as the DAL model for interpolation but the input time steps are 24 hours and the prediction time lags are 12 hours. We still pre-train an Auto-Encoder and then use it to train the prediction model. The spatial loss is computed by summing up the spatial loss for each 12 output image frames. The temporal loss is also the sum of the loss between 1 image slice with 2 neighbor image slices of the output (the DAL paper chose temporal neighbor size is 2). The final loss is the total of labeled loss and spatiotemporal loss.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.0974911451339722,
            -2.061586856842041
        ],
        "MSU_id": 321
    },
    {
        "sentence": "The spatial loss is computed by summing up the spatial loss for each 12 output image frames.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 64,
        "paper_id": 0,
        "paragraph_info": "The baseline model for Air pollution forecasting is also a DAL forecasting model. This model has the same structure as the DAL model for interpolation but the input time steps are 24 hours and the prediction time lags are 12 hours. We still pre-train an Auto-Encoder and then use it to train the prediction model. The spatial loss is computed by summing up the spatial loss for each 12 output image frames. The temporal loss is also the sum of the loss between 1 image slice with 2 neighbor image slices of the output (the DAL paper chose temporal neighbor size is 2). The final loss is the total of labeled loss and spatiotemporal loss.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.26268288493156433,
            -2.011453628540039
        ],
        "MSU_id": 322
    },
    {
        "sentence": "The temporal loss is the sum of the loss between 1 image slice and 2 neighbor image slices of the output.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 64,
        "paper_id": 0,
        "paragraph_info": "The baseline model for Air pollution forecasting is also a DAL forecasting model. This model has the same structure as the DAL model for interpolation but the input time steps are 24 hours and the prediction time lags are 12 hours. We still pre-train an Auto-Encoder and then use it to train the prediction model. The spatial loss is computed by summing up the spatial loss for each 12 output image frames. The temporal loss is also the sum of the loss between 1 image slice with 2 neighbor image slices of the output (the DAL paper chose temporal neighbor size is 2). The final loss is the total of labeled loss and spatiotemporal loss.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.271669626235962,
            -1.9502946138381958
        ],
        "MSU_id": 323
    },
    {
        "sentence": "The forecasting ConvLSTM network predicts 12 hours from 12 previous hours as the input time steps.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 65,
        "paper_id": 0,
        "paragraph_info": "The forecasting ConvLSTM network also predicts 12 hours from 12 previous hours as the input time steps. The number of encoder layers is 3 as the same number for forecasting layers. The output channels are 16, 16 and 32, respectively.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.5128679275512695,
            -1.9870291948318481
        ],
        "MSU_id": 326
    },
    {
        "sentence": "The number of encoder layers is 3.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 65,
        "paper_id": 0,
        "paragraph_info": "The forecasting ConvLSTM network also predicts 12 hours from 12 previous hours as the input time steps. The number of encoder layers is 3 as the same number for forecasting layers. The output channels are 16, 16 and 32, respectively.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.1731868982315063,
            -2.000478982925415
        ],
        "MSU_id": 327
    },
    {
        "sentence": "The number of forecasting layers is also 3.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 65,
        "paper_id": 0,
        "paragraph_info": "The forecasting ConvLSTM network also predicts 12 hours from 12 previous hours as the input time steps. The number of encoder layers is 3 as the same number for forecasting layers. The output channels are 16, 16 and 32, respectively.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.647597074508667,
            -1.7670954465866089
        ],
        "MSU_id": 328
    },
    {
        "sentence": "The output channels are 16, 16 and 32, respectively.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 65,
        "paper_id": 0,
        "paragraph_info": "The forecasting ConvLSTM network also predicts 12 hours from 12 previous hours as the input time steps. The number of encoder layers is 3 as the same number for forecasting layers. The output channels are 16, 16 and 32, respectively.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.6505569815635681,
            -1.7807598114013672
        ],
        "MSU_id": 329
    },
    {
        "sentence": "We build 2 predicting models based on CNN Encoder-Decoder and FC-LSTM.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 66,
        "paper_id": 0,
        "paragraph_info": "Similar to the interpolation experiment section, we build 2 predicting models based on CNN Encoder-Decoder and FC-LSTM. The CNN Encoder-Decoder model has 3 layers for encoder and 3 layers for the decoder part which is similar to ConvLSTM predicting model.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.5674936771392822,
            -1.902974247932434
        ],
        "MSU_id": 330
    },
    {
        "sentence": "The CNN Encoder-Decoder model has 3 layers for the encoder.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 66,
        "paper_id": 0,
        "paragraph_info": "Similar to the interpolation experiment section, we build 2 predicting models based on CNN Encoder-Decoder and FC-LSTM. The CNN Encoder-Decoder model has 3 layers for encoder and 3 layers for the decoder part which is similar to ConvLSTM predicting model.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.2585506439208984,
            -1.9956849813461304
        ],
        "MSU_id": 331
    },
    {
        "sentence": "The CNN Encoder-Decoder model has 3 layers for the decoder part.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 66,
        "paper_id": 0,
        "paragraph_info": "Similar to the interpolation experiment section, we build 2 predicting models based on CNN Encoder-Decoder and FC-LSTM. The CNN Encoder-Decoder model has 3 layers for encoder and 3 layers for the decoder part which is similar to ConvLSTM predicting model.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.2575381994247437,
            -2.0049667358398438
        ],
        "MSU_id": 332
    },
    {
        "sentence": "The examining models include ConvLSTM (as baseline).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 69,
        "paper_id": 0,
        "paragraph_info": "*1) Forecasting with air pollution influence factors:* For the next experiment, we evaluate the forecasting results in term of combination with air pollution related spatiotemporal factors. The examining models are: ConvLSTM (as baseline), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and transportation traffic data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table V shows the RMSE of each examined models in the test set.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7680637836456299,
            -1.2134370803833008
        ],
        "MSU_id": 340
    },
    {
        "sentence": "The examining models include ConvLSTM + Met (air pollution and meteorological data).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 69,
        "paper_id": 0,
        "paragraph_info": "*1) Forecasting with air pollution influence factors:* For the next experiment, we evaluate the forecasting results in term of combination with air pollution related spatiotemporal factors. The examining models are: ConvLSTM (as baseline), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and transportation traffic data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table V shows the RMSE of each examined models in the test set.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9767922163009644,
            -1.5087072849273682
        ],
        "MSU_id": 341
    },
    {
        "sentence": "The examining models include ConvLSTM + Traffic (air pollution and transportation traffic data).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 69,
        "paper_id": 0,
        "paragraph_info": "*1) Forecasting with air pollution influence factors:* For the next experiment, we evaluate the forecasting results in term of combination with air pollution related spatiotemporal factors. The examining models are: ConvLSTM (as baseline), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and transportation traffic data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table V shows the RMSE of each examined models in the test set.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9537346363067627,
            -1.3993662595748901
        ],
        "MSU_id": 342
    },
    {
        "sentence": "The examining models include ConvLSTM + Speed (air pollution and vehicles average speed data).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 69,
        "paper_id": 0,
        "paragraph_info": "*1) Forecasting with air pollution influence factors:* For the next experiment, we evaluate the forecasting results in term of combination with air pollution related spatiotemporal factors. The examining models are: ConvLSTM (as baseline), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and transportation traffic data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table V shows the RMSE of each examined models in the test set.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9863345623016357,
            -1.4612905979156494
        ],
        "MSU_id": 343
    },
    {
        "sentence": "The examining models include ConvLSTM + External (air pollution and external air pollution data).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 69,
        "paper_id": 0,
        "paragraph_info": "*1) Forecasting with air pollution influence factors:* For the next experiment, we evaluate the forecasting results in term of combination with air pollution related spatiotemporal factors. The examining models are: ConvLSTM (as baseline), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and transportation traffic data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table V shows the RMSE of each examined models in the test set.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -2.001307249069214,
            -1.5628153085708618
        ],
        "MSU_id": 344
    },
    {
        "sentence": "The examining models include ConvLSTM + All (air pollution and all related factors).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 69,
        "paper_id": 0,
        "paragraph_info": "*1) Forecasting with air pollution influence factors:* For the next experiment, we evaluate the forecasting results in term of combination with air pollution related spatiotemporal factors. The examining models are: ConvLSTM (as baseline), ConvLSTM + Met (air pollution and meteorological data), ConvLSTM + Traffic (air pollution and transportation traffic data), ConvLSTM + Speed (air pollution and vehicles average speed data), ConvLSTM + External (air pollution and external air pollution data), ConvLSTM + All (air pollution and all related factors). Table V shows the RMSE of each examined models in the test set.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.9318360090255737,
            -1.4540292024612427
        ],
        "MSU_id": 345
    },
    {
        "sentence": "The proposed methods include Spatial averaging, Nearest neighbor, Inverse distance weighting (IDW), Kriging, and Shape Function based spatiotemporal interpolation.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 72,
        "paper_id": 0,
        "paragraph_info": "Air pollution interpolation was started researching a few years ago. There are some papers such as in [\\[11\\]](#page-7-4), [\\[19\\]](#page-7-5) that try to interpolate Air pollution at locations where are lack of monitoring stations. They proposed to use some basic interpolation methods such as Spatial averaging, Nearest neighbor, Inverse distance weighting (IDW), Kriging [\\[19\\]](#page-7-5), and Shape Function based spatiotemporal interpolation [\\[11\\]](#page-7-4). By our evaluation, these are basic and simple interpolation models that often used as baselines for more advanced methods.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.4458714723587036,
            -1.253485083580017
        ],
        "MSU_id": 353
    },
    {
        "sentence": "Models include a co-training-based semi-supervised learning approach.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 73,
        "paper_id": 0,
        "paragraph_info": "Recently, some air pollution related research has leveraged Machine Learning/Neural Networks based models in predicting Air pollution [\\[3\\]](#page-7-12), [\\[7\\]](#page-7-13), [\\[15\\]](#page-7-8), [\\[23\\]](#page-7-14), [\\[24\\]](#page-7-15). Most of these papers used common datasets like monitoring air pollution, meteorological data. Some papers used specific datasets such as GPS trajectories generated by over 30,000 taxis in Beijing in [\\[23\\]](#page-7-14) or road networks data in [\\[7\\]](#page-7-13). The proposed air pollution predicting models are quite diversity, from cotraining-based semi-supervised learning approach [\\[23\\]](#page-7-14), linear regression-based temporal predictor [\\[24\\]](#page-7-15) to Spatiotemporal Semi-supervised Learning [\\[15\\]](#page-7-8) and Attention Model [\\[3\\]](#page-7-12). Some research proposed grid-based air pollution interpolation or prediction. Nevertheless, they only focused on forecasting air pollution for discrete locations, not considering the whole city to be an image as in our approach. Furthermore, they used much hand-crafted spatial and temporal features that were difficult to generalize to other similar problems.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.668320655822754,
            -1.8833152055740356
        ],
        "MSU_id": 361
    },
    {
        "sentence": "Models include a linear regression-based temporal predictor.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 73,
        "paper_id": 0,
        "paragraph_info": "Recently, some air pollution related research has leveraged Machine Learning/Neural Networks based models in predicting Air pollution [\\[3\\]](#page-7-12), [\\[7\\]](#page-7-13), [\\[15\\]](#page-7-8), [\\[23\\]](#page-7-14), [\\[24\\]](#page-7-15). Most of these papers used common datasets like monitoring air pollution, meteorological data. Some papers used specific datasets such as GPS trajectories generated by over 30,000 taxis in Beijing in [\\[23\\]](#page-7-14) or road networks data in [\\[7\\]](#page-7-13). The proposed air pollution predicting models are quite diversity, from cotraining-based semi-supervised learning approach [\\[23\\]](#page-7-14), linear regression-based temporal predictor [\\[24\\]](#page-7-15) to Spatiotemporal Semi-supervised Learning [\\[15\\]](#page-7-8) and Attention Model [\\[3\\]](#page-7-12). Some research proposed grid-based air pollution interpolation or prediction. Nevertheless, they only focused on forecasting air pollution for discrete locations, not considering the whole city to be an image as in our approach. Furthermore, they used much hand-crafted spatial and temporal features that were difficult to generalize to other similar problems.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6279014348983765,
            -1.8849111795425415
        ],
        "MSU_id": 362
    },
    {
        "sentence": "Models include Spatiotemporal Semi-supervised Learning.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 73,
        "paper_id": 0,
        "paragraph_info": "Recently, some air pollution related research has leveraged Machine Learning/Neural Networks based models in predicting Air pollution [\\[3\\]](#page-7-12), [\\[7\\]](#page-7-13), [\\[15\\]](#page-7-8), [\\[23\\]](#page-7-14), [\\[24\\]](#page-7-15). Most of these papers used common datasets like monitoring air pollution, meteorological data. Some papers used specific datasets such as GPS trajectories generated by over 30,000 taxis in Beijing in [\\[23\\]](#page-7-14) or road networks data in [\\[7\\]](#page-7-13). The proposed air pollution predicting models are quite diversity, from cotraining-based semi-supervised learning approach [\\[23\\]](#page-7-14), linear regression-based temporal predictor [\\[24\\]](#page-7-15) to Spatiotemporal Semi-supervised Learning [\\[15\\]](#page-7-8) and Attention Model [\\[3\\]](#page-7-12). Some research proposed grid-based air pollution interpolation or prediction. Nevertheless, they only focused on forecasting air pollution for discrete locations, not considering the whole city to be an image as in our approach. Furthermore, they used much hand-crafted spatial and temporal features that were difficult to generalize to other similar problems.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7730032205581665,
            -1.7478512525558472
        ],
        "MSU_id": 363
    },
    {
        "sentence": "Models include an Attention Model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 73,
        "paper_id": 0,
        "paragraph_info": "Recently, some air pollution related research has leveraged Machine Learning/Neural Networks based models in predicting Air pollution [\\[3\\]](#page-7-12), [\\[7\\]](#page-7-13), [\\[15\\]](#page-7-8), [\\[23\\]](#page-7-14), [\\[24\\]](#page-7-15). Most of these papers used common datasets like monitoring air pollution, meteorological data. Some papers used specific datasets such as GPS trajectories generated by over 30,000 taxis in Beijing in [\\[23\\]](#page-7-14) or road networks data in [\\[7\\]](#page-7-13). The proposed air pollution predicting models are quite diversity, from cotraining-based semi-supervised learning approach [\\[23\\]](#page-7-14), linear regression-based temporal predictor [\\[24\\]](#page-7-15) to Spatiotemporal Semi-supervised Learning [\\[15\\]](#page-7-8) and Attention Model [\\[3\\]](#page-7-12). Some research proposed grid-based air pollution interpolation or prediction. Nevertheless, they only focused on forecasting air pollution for discrete locations, not considering the whole city to be an image as in our approach. Furthermore, they used much hand-crafted spatial and temporal features that were difficult to generalize to other similar problems.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.455916166305542,
            -1.8709355592727661
        ],
        "MSU_id": 364
    },
    {
        "sentence": "Some research proposed grid-based air pollution interpolation or prediction.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 73,
        "paper_id": 0,
        "paragraph_info": "Recently, some air pollution related research has leveraged Machine Learning/Neural Networks based models in predicting Air pollution [\\[3\\]](#page-7-12), [\\[7\\]](#page-7-13), [\\[15\\]](#page-7-8), [\\[23\\]](#page-7-14), [\\[24\\]](#page-7-15). Most of these papers used common datasets like monitoring air pollution, meteorological data. Some papers used specific datasets such as GPS trajectories generated by over 30,000 taxis in Beijing in [\\[23\\]](#page-7-14) or road networks data in [\\[7\\]](#page-7-13). The proposed air pollution predicting models are quite diversity, from cotraining-based semi-supervised learning approach [\\[23\\]](#page-7-14), linear regression-based temporal predictor [\\[24\\]](#page-7-15) to Spatiotemporal Semi-supervised Learning [\\[15\\]](#page-7-8) and Attention Model [\\[3\\]](#page-7-12). Some research proposed grid-based air pollution interpolation or prediction. Nevertheless, they only focused on forecasting air pollution for discrete locations, not considering the whole city to be an image as in our approach. Furthermore, they used much hand-crafted spatial and temporal features that were difficult to generalize to other similar problems.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.859184741973877,
            -1.5593403577804565
        ],
        "MSU_id": 365
    },
    {
        "sentence": "The authors proposed a ConvLSTM model for precipitation forecasting.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 74,
        "paper_id": 0,
        "paragraph_info": "Furthermore, we survey general Spatiotemporal Deep Learning algorithms. In [\\[16\\]](#page-7-0), the authors have proposed a ConvLSTM model and used for precipitation forecasting. In the paper, the authors demonstrated that ConvLSTM was better than Fully Connected LSTM in spatiotemporal problems like moving MNIST and weather radar echo images of Hong Kong for precipitation forecasting.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.6277565956115723,
            -1.7990708351135254
        ],
        "MSU_id": 370
    },
    {
        "sentence": "The authors presented a Deep Neural Network Spatiotemporal (DeepST) for predicting crowd flows in Beijing and New York.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 75,
        "paper_id": 0,
        "paragraph_info": "The spatiotemporal problem is also fit for the crowd flows prediction problem. In [\\[20\\]](#page-7-16), the authors presented a Deep Neural Network Spatiotemporal (DeepST) for predicting crowd flows in Beijing and New York. They proposed the DeepST model based on Convolutional Neural Network and used Residual Units (as in ResNet model) to build a very deep network to capture more citywide dependencies. The last layer was a Fusion layer to combine deep network results with external factors (such as meteorology, holidays).",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.3563069105148315,
            -1.667763590812683
        ],
        "MSU_id": 374
    },
    {
        "sentence": "They proposed the DeepST model based on Convolutional Neural Network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 75,
        "paper_id": 0,
        "paragraph_info": "The spatiotemporal problem is also fit for the crowd flows prediction problem. In [\\[20\\]](#page-7-16), the authors presented a Deep Neural Network Spatiotemporal (DeepST) for predicting crowd flows in Beijing and New York. They proposed the DeepST model based on Convolutional Neural Network and used Residual Units (as in ResNet model) to build a very deep network to capture more citywide dependencies. The last layer was a Fusion layer to combine deep network results with external factors (such as meteorology, holidays).",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.399880051612854,
            -1.9688392877578735
        ],
        "MSU_id": 375
    },
    {
        "sentence": "They used Residual Units (as in ResNet model) to build a very deep network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 75,
        "paper_id": 0,
        "paragraph_info": "The spatiotemporal problem is also fit for the crowd flows prediction problem. In [\\[20\\]](#page-7-16), the authors presented a Deep Neural Network Spatiotemporal (DeepST) for predicting crowd flows in Beijing and New York. They proposed the DeepST model based on Convolutional Neural Network and used Residual Units (as in ResNet model) to build a very deep network to capture more citywide dependencies. The last layer was a Fusion layer to combine deep network results with external factors (such as meteorology, holidays).",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.32010331749916077,
            -2.215762138366699
        ],
        "MSU_id": 376
    },
    {
        "sentence": "The last layer was a Fusion layer to combine deep network results with external factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 75,
        "paper_id": 0,
        "paragraph_info": "The spatiotemporal problem is also fit for the crowd flows prediction problem. In [\\[20\\]](#page-7-16), the authors presented a Deep Neural Network Spatiotemporal (DeepST) for predicting crowd flows in Beijing and New York. They proposed the DeepST model based on Convolutional Neural Network and used Residual Units (as in ResNet model) to build a very deep network to capture more citywide dependencies. The last layer was a Fusion layer to combine deep network results with external factors (such as meteorology, holidays).",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -0.2652525305747986,
            -2.101619243621826
        ],
        "MSU_id": 378
    },
    {
        "sentence": "We described and resolved the citywide scale Air Pollution Interpolation and Prediction problem by considering a whole city to be one image.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 76,
        "paper_id": 0,
        "paragraph_info": "In this research, we have introduced 3 main contributions. First, we described and resolved the citywide scale Air Pollution Interpolation and Prediction problem by considering a whole city to be one image. Second, we pointed out and collected several spatiotemporal datasets, which have effects on air pollution throughout the city. Lastly, we proposed a spatiotemporal Deep Learning based model for citywide air pollution interpolation and prediction. We proved that the proposed model does not only work better than CNN and LSTM themselves in spatial and temporal features analysis but also outperforms state-of-the-art relevant models. The leverage of using other spatiotemporal factors gives us a powerful model in interpolating and forecasting air pollution over the city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.7904014587402344,
            -1.5599192380905151
        ],
        "MSU_id": 381
    },
    {
        "sentence": "We proposed a spatiotemporal Deep Learning based model for citywide air pollution interpolation and prediction.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 76,
        "paper_id": 0,
        "paragraph_info": "In this research, we have introduced 3 main contributions. First, we described and resolved the citywide scale Air Pollution Interpolation and Prediction problem by considering a whole city to be one image. Second, we pointed out and collected several spatiotemporal datasets, which have effects on air pollution throughout the city. Lastly, we proposed a spatiotemporal Deep Learning based model for citywide air pollution interpolation and prediction. We proved that the proposed model does not only work better than CNN and LSTM themselves in spatial and temporal features analysis but also outperforms state-of-the-art relevant models. The leverage of using other spatiotemporal factors gives us a powerful model in interpolating and forecasting air pollution over the city.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.8071403503417969,
            -1.8936268091201782
        ],
        "MSU_id": 383
    },
    {
        "sentence": "In the future, we will extend this spatiotemporal research on urban traffic volume and driving speed data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 77,
        "paper_id": 0,
        "paragraph_info": "Our proposed method for air pollution problem is also suitable for other urban spatiotemporal based predictions such as traffic volume prediction or crowd flow forecasting. In the future, we will extend this spatiotemporal research on urban traffic volume and driving speed data to foresee traffic congestion and other urban relating problems.",
        "paper_info": "1911.12919v1",
        "2d_coord": [
            -1.971323847770691,
            -1.647497296333313
        ],
        "MSU_id": 388
    },
    {
        "sentence": "We predict the air quality of the next 48 hours for each monitoring station.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7533130645751953,
            -1.8362160921096802
        ],
        "MSU_id": 392
    },
    {
        "sentence": "We consider air quality data, meteorology data, and weather forecast data in our predictions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5369808673858643,
            -1.7876702547073364
        ],
        "MSU_id": 393
    },
    {
        "sentence": "We propose a deep neural network (DNN)-based approach entitled DeepAir.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7982186675071716,
            -2.1922056674957275
        ],
        "MSU_id": 394
    },
    {
        "sentence": "DeepAir consists of a spatial transformation component and a deep distributed fusion network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7295238971710205,
            -2.1573469638824463
        ],
        "MSU_id": 395
    },
    {
        "sentence": "The spatial transformation component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.1562036275863647,
            -1.933409333229065
        ],
        "MSU_id": 396
    },
    {
        "sentence": "The deep distributed fusion network adopts a neural distributed architecture to fuse heterogeneous urban data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.4711378812789917,
            -2.173840045928955
        ],
        "MSU_id": 397
    },
    {
        "sentence": "The fusion network captures factors affecting air quality, such as meteorological conditions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8245664834976196,
            -1.8834863901138306
        ],
        "MSU_id": 398
    },
    {
        "sentence": "We deployed DeepAir in our AirPollutionPrediction system.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 78,
        "paper_id": 1,
        "paragraph_info": "Accompanying the rapid urbanization, many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper, we predict the air quality of next 48 hours for each monitoring station, considering air quality data, meteorology data, and weather forecast data. Based on the domain knowledge about air pollution, we propose a deep neural network (DNN)-based approach (entitled DeepAir), which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations, the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously capturing the factors affecting air quality, e.g. meteorological conditions. We deployed DeepAir in our AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. The experimental results on the data from three-year nine Chinese-city demonstrate the advantages of DeepAir beyond 10 baseline methods. Comparing with the previous online approach in AirPollutionPrediction system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.9207779765129089,
            -2.1612348556518555
        ],
        "MSU_id": 399
    },
    {
        "sentence": "Chinese governments have built many air quality monitoring stations and published air quality data every hour in recent years.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 81,
        "paper_id": 1,
        "paragraph_info": "With the rapid development of urbanization, air pollution is becoming a severe environmental and societal issue for all developing countries around the world [1]. Air pollution consists of a mixture of particulate matter (i.e. PM2.5 and PM10) and gaseous species (i.e. NO<sub>2</sub>, CO, O<sub>3</sub> and SO<sub>2</sub>), which have both acute and chronic effects on human health, especially for young and elderly [2]. From statistical results [3], Beijing recorded 46 days of heavy pollution during 2015, accounting for 12.6 percent of the year. For monitoring real-time air pollution, Chinese governments have built many air quality monitoring stations and published air quality data every hour in recent years [4]. Besides monitoring, there is a rising demand for predicting future air quality, which can inform governments' policy-making (such as performing traffic control when the air is polluted seriously) and people's decision making (like whether to exercise outdoors).",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.24359674751758575,
            -1.293096661567688
        ],
        "MSU_id": 411
    },
    {
        "sentence": "Ratios in a) are calculated by $\\Delta = A\\bar{Q}I_{t+k} - AQI_t$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 90,
        "paper_id": 1,
        "paragraph_info": "Figure 2: Air quality change over multiple factors. Ratios in a) is calculated by  $\\Delta = A\\bar{Q}I_{t+k} - AQI_t$ , where  $AQI_t > 100$ ,  $Weather_t = rain$  and k is the time interval after rain.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.0435816049575806,
            -1.6004482507705688
        ],
        "MSU_id": 447
    },
    {
        "sentence": "The calculation is based on the condition that $AQI_t > 100$ and $Weather_t = rain$.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 90,
        "paper_id": 1,
        "paragraph_info": "Figure 2: Air quality change over multiple factors. Ratios in a) is calculated by  $\\Delta = A\\bar{Q}I_{t+k} - AQI_t$ , where  $AQI_t > 100$ ,  $Weather_t = rain$  and k is the time interval after rain.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.41766759753227234,
            -1.4515923261642456
        ],
        "MSU_id": 448
    },
    {
        "sentence": "We propose a DNN-based air quality prediction approach, entitled DeepAir.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 92,
        "paper_id": 1,
        "paragraph_info": "To address these challenges, we propose a DNN-based air quality prediction approach, entitled DeepAir. Our approach is inspired by the domain knowledge about air pollution, which can help design model structure with more interpretations. We deployed DeepAir in real-time AirPollutionPrediction system [8], providing 48-hour fine-grained air quality forecasts for 300+ Chinese cities. Our contributions are listed as below:",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.9173853993415833,
            -1.9591063261032104
        ],
        "MSU_id": 458
    },
    {
        "sentence": "We deployed DeepAir in a real-time AirPollutionPrediction system.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 92,
        "paper_id": 1,
        "paragraph_info": "To address these challenges, we propose a DNN-based air quality prediction approach, entitled DeepAir. Our approach is inspired by the domain knowledge about air pollution, which can help design model structure with more interpretations. We deployed DeepAir in real-time AirPollutionPrediction system [8], providing 48-hour fine-grained air quality forecasts for 300+ Chinese cities. Our contributions are listed as below:",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8070254325866699,
            -2.157947301864624
        ],
        "MSU_id": 460
    },
    {
        "sentence": "The AirPollutionPrediction system is deployed through a 'cloud + client' framework.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 95,
        "paper_id": 1,
        "paragraph_info": "AirPollutionPrediction system [8] is deployed through a \"cloud + client\" framework, where the cloud continuously collects realtime data and make predictions [9], and the web client public air quality information available. Figure 3 presents the website of AirPollutionPrediction, where the chart on the map showing AQI forecasts. For visualization, we show the min-max range of AQI for time intervals 7-12, 12-24, and 24-48 hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.6381392478942871,
            -2.061988353729248
        ],
        "MSU_id": 470
    },
    {
        "sentence": "The cloud continuously collects real-time data and makes predictions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 95,
        "paper_id": 1,
        "paragraph_info": "AirPollutionPrediction system [8] is deployed through a \"cloud + client\" framework, where the cloud continuously collects realtime data and make predictions [9], and the web client public air quality information available. Figure 3 presents the website of AirPollutionPrediction, where the chart on the map showing AQI forecasts. For visualization, we show the min-max range of AQI for time intervals 7-12, 12-24, and 24-48 hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.35119014978408813,
            -1.8897372484207153
        ],
        "MSU_id": 471
    },
    {
        "sentence": "The web client provides public air quality information.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 95,
        "paper_id": 1,
        "paragraph_info": "AirPollutionPrediction system [8] is deployed through a \"cloud + client\" framework, where the cloud continuously collects realtime data and make predictions [9], and the web client public air quality information available. Figure 3 presents the website of AirPollutionPrediction, where the chart on the map showing AQI forecasts. For visualization, we show the min-max range of AQI for time intervals 7-12, 12-24, and 24-48 hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.6254847645759583,
            -1.29580819606781
        ],
        "MSU_id": 472
    },
    {
        "sentence": "The spatial transformation component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.9935481548309326,
            -1.9746872186660767
        ],
        "MSU_id": 479
    },
    {
        "sentence": "The spatial transformation component uses spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.192429780960083,
            -2.0079517364501953
        ],
        "MSU_id": 480
    },
    {
        "sentence": "AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into the deep distributed fusion network.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.33518368005752563,
            -2.0246777534484863
        ],
        "MSU_id": 481
    },
    {
        "sentence": "The deep distributed fusion network adapts DNN to fuse heterogeneous urban data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5248463749885559,
            -2.1555607318878174
        ],
        "MSU_id": 482
    },
    {
        "sentence": "We use an embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.6410962343215942,
            -2.0845468044281006
        ],
        "MSU_id": 483
    },
    {
        "sentence": "We use the embedding of AQIs to simulate the direct factors from local emission and regional transport.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.2570334672927856,
            -1.7438454627990723
        ],
        "MSU_id": 484
    },
    {
        "sentence": "We use the embedding of the rest datasets as indirect factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.6081221103668213,
            -2.030513286590576
        ],
        "MSU_id": 485
    },
    {
        "sentence": "We propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5342103242874146,
            -1.969101071357727
        ],
        "MSU_id": 486
    },
    {
        "sentence": "We build four subnets (HW, WF, SP, and MP) to capture the individual influences from historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7136790752410889,
            -1.9892431497573853
        ],
        "MSU_id": 487
    },
    {
        "sentence": "We build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8398030996322632,
            -2.095155715942383
        ],
        "MSU_id": 488
    },
    {
        "sentence": "The outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.2413708120584488,
            -2.1166203022003174
        ],
        "MSU_id": 489
    },
    {
        "sentence": "The aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 98,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 4, the framework of DeepAir consists of two parts: spatial transformation component and deep distributed fusion network. As air pollutants are dispersed in geographical space, the former component regards the readings recorded by air quality monitoring stations as second-hand pollutant sources. Considering air pollutants' spatial correlations, spatial transformation component uses the spatial partition, spatial aggregation, and spatial interpolation to convert the spatial sparse air quality data into a consistent input, named AQIs. Then, AQIs and other datasets, i.e. meteorology, weather forecast, other pollutants, time, and station ID are fed into deep distributed fusion network, which adapts DNN to fuse heterogeneous urban data. We first use embedding method to transform the raw features of each domain data into a low-dimensional space for capturing temporal correlation and learning the intra-dynamics. Here, we use the embedding of AQIs to simulate the direct factors from local emission and regional transport and use the embedding of rest datasets as indirect factors respectively. Then, we propose a distributed fusion architecture to simultaneously model the interactions between these factors for learning the individual and holistic influences. As each indirect factor has own effort on direct factors affecting future air quality, we build four subnets (HW, WF, SP, and MP) to capture the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain, respectively. Besides individual influences, we build a subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. After that, the outputs of five subnets are aggregated by weighted merge to capture the high-level effects of these factors. Finally, the aggregation is mapped into [0, 1] by a Sigmoid function to generate final prediction results.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.26271548867225647,
            -2.182952404022217
        ],
        "MSU_id": 490
    },
    {
        "type": "figure",
        "para_id": 100,
        "paper_id": 1,
        "paragraph_info": "_page_2_Figure_4.jpeg",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.47417986392974854,
            -2.1349778175354004
        ],
        "MSU_id": 491,
        "sentence": "The image illustrates the framework of a Deep Distributed Fusion Network, which integrates various inputs such as meteorology, weather forecasts, other pollutants, time station ID, and AQIs through a series of FusionNet modules, followed by a weighted merge to produce outputs.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "We collectively predict the air quality in a couple of hours, e.g. 1-3 hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 101,
        "paper_id": 1,
        "paragraph_info": "Specifically, for temporal granularity, we collectively predict the air quality in a couple hours, e.g. 1-3 hours, as weather forecasts are usually segmented into 3-hour time intervals. For spatial granularity, we build one predictive model for all monitoring stations in the same city as spatial transformation component will generate a consistent input for each monitoring station and data augmentation for training DNN.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.1166276931762695,
            -1.8845270872116089
        ],
        "MSU_id": 493
    },
    {
        "sentence": "We build one predictive model for all monitoring stations in the same city.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 101,
        "paper_id": 1,
        "paragraph_info": "Specifically, for temporal granularity, we collectively predict the air quality in a couple hours, e.g. 1-3 hours, as weather forecasts are usually segmented into 3-hour time intervals. For spatial granularity, we build one predictive model for all monitoring stations in the same city as spatial transformation component will generate a consistent input for each monitoring station and data augmentation for training DNN.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.3202104568481445,
            -1.91549813747406
        ],
        "MSU_id": 495
    },
    {
        "sentence": "The spatial transformation component will generate a consistent input for each monitoring station.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 101,
        "paper_id": 1,
        "paragraph_info": "Specifically, for temporal granularity, we collectively predict the air quality in a couple hours, e.g. 1-3 hours, as weather forecasts are usually segmented into 3-hour time intervals. For spatial granularity, we build one predictive model for all monitoring stations in the same city as spatial transformation component will generate a consistent input for each monitoring station and data augmentation for training DNN.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8917711973190308,
            -1.9900466203689575
        ],
        "MSU_id": 496
    },
    {
        "sentence": "Data augmentation is used for training DNN.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 101,
        "paper_id": 1,
        "paragraph_info": "Specifically, for temporal granularity, we collectively predict the air quality in a couple hours, e.g. 1-3 hours, as weather forecasts are usually segmented into 3-hour time intervals. For spatial granularity, we build one predictive model for all monitoring stations in the same city as spatial transformation component will generate a consistent input for each monitoring station and data augmentation for training DNN.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.5590643286705017,
            -2.1737473011016846
        ],
        "MSU_id": 497
    },
    {
        "sentence": "We devise the spatial transformation component to convert spatial sparse air quality data into a consistent input for further predictive models.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 102,
        "paper_id": 1,
        "paragraph_info": "As pollutants are dispersed in geographical space, the air quality of a geo-location not only depends on its previous air quality but also depends on the air quality of its neighbors. For converting spatial sparse air quality data into a consistent input for the further predictive model, we devise the spatial transformation component, which can be applied to other spatial sparse datasets.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.9702968597412109,
            -1.818463921546936
        ],
        "MSU_id": 500
    },
    {
        "sentence": "The spatial transformation component can be applied to other spatial sparse datasets.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 102,
        "paper_id": 1,
        "paragraph_info": "As pollutants are dispersed in geographical space, the air quality of a geo-location not only depends on its previous air quality but also depends on the air quality of its neighbors. For converting spatial sparse air quality data into a consistent input for the further predictive model, we devise the spatial transformation component, which can be applied to other spatial sparse datasets.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.5436400175094604,
            -2.114004135131836
        ],
        "MSU_id": 501
    },
    {
        "sentence": "We partition the geographical space into 16 regions by four lines and two circles.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.34026920795440674,
            1.61959969997406
        ],
        "MSU_id": 504
    },
    {
        "sentence": "We aggregate the readings of air quality recorded by monitoring stations within the regions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.4787459373474121,
            -1.944240689277649
        ],
        "MSU_id": 507
    },
    {
        "sentence": "We fill the missing values in these regions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.4282134175300598,
            -1.7923681735992432
        ],
        "MSU_id": 510
    },
    {
        "sentence": "We first randomly generate some fake monitoring stations in these regions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.0472344271838665,
            -1.6144064664840698
        ],
        "MSU_id": 511
    },
    {
        "sentence": "We use a classic spatial interpolation method, inverse distance weighting (IDW), to interpolate the AQI of fake monitoring stations.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.01403145119547844,
            -0.5476306080818176
        ],
        "MSU_id": 512
    },
    {
        "sentence": "IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to the target sensor.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.39646419882774353,
            -1.8835164308547974
        ],
        "MSU_id": 513
    },
    {
        "sentence": "We aggregate these weights and readings by weighted average.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.5920441150665283,
            -0.8750690817832947
        ],
        "MSU_id": 514
    },
    {
        "sentence": "We aggregate the interpolated values of fake stations to calculate average AQI for the region.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.2411082535982132,
            -2.1069164276123047
        ],
        "MSU_id": 515
    },
    {
        "sentence": "We conduct the same process for each monitoring station over time.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 103,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 5(a), air quality monitoring stations (marked as dot) are randomly scattered in geographical space, where color on the dot means the level of air quality. Firstly, we partition the geographical space into 16 regions by four lines and two circles, e.g. 20 km and 100 km semidiameter. As depicted in Figure 5(b), all regions share the target monitoring station (denoted by the black point) as common center and regions in the inner circle have a small area, while regions in the outer circle have a big area. Also, regions with different angles fit eight wind directions, which may be further captured by meteorological conditions. Furthermore, we aggregate the readings of air quality recorded by monitoring stations within the regions, illustrated in Figure 5(c). As a result, regions with at least one station will have one average AQI. However, from the partition results of Beijing, we find that different target stations have different missing patterns and about 33% regions do not have monitoring stations. Thus, we fill the missing values in these regions shown in Figure 5(d). More specifically, we first random generate some fake monitoring stations in these regions. Then, we use a classic spatial interpolation method, inverse distance weighting (IDW) [11], to interpolate the AQI of fake monitoring stations. Considering the readings of geospatially adjacent stations located in both inside and outside the outer circle, IDW assigns a weight to each available reading of geospatially adjacent stations by the distance to target sensor, and then aggregates these weights and readings by weighted average. After that, we aggregate the interpolated values of fake stations to calculate average AQI for the region. Finally, we get 17 AQI in one timestamp which 1 AQI come from target station and 16 AQI come from neighbor regions. We conduct the same process for each monitoring stations along time.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5041519999504089,
            -0.12583139538764954
        ],
        "MSU_id": 517
    },
    {
        "sentence": "We design the spatial transformation component considering three aspects.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 104,
        "paper_id": 1,
        "paragraph_info": "We design the spatial transformation component considering the following three aspects. 1) Air pollution dispersion. Although we do not have first-hand city-wide pollutant emission data, the readings of air quality recorded by monitoring stations can be regarded as second-hand pollutant sources as air pollutants are dispersed among different locations. With the signals from spatial neighbors, the further predictive model can incorporate more information. 2) Spatial correlations. Spatial partition merge the scattered air quality data into regions, which closer regions have a finer granularity and farther regions have a coarser",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.207312822341919,
            -1.9413477182388306
        ],
        "MSU_id": 518
    },
    {
        "sentence": "The further predictive model can incorporate more information with signals from spatial neighbors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 104,
        "paper_id": 1,
        "paragraph_info": "We design the spatial transformation component considering the following three aspects. 1) Air pollution dispersion. Although we do not have first-hand city-wide pollutant emission data, the readings of air quality recorded by monitoring stations can be regarded as second-hand pollutant sources as air pollutants are dispersed among different locations. With the signals from spatial neighbors, the further predictive model can incorporate more information. 2) Spatial correlations. Spatial partition merge the scattered air quality data into regions, which closer regions have a finer granularity and farther regions have a coarser",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.808488667011261,
            -1.961422324180603
        ],
        "MSU_id": 522
    },
    {
        "sentence": "Spatial partition merges the scattered air quality data into regions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 104,
        "paper_id": 1,
        "paragraph_info": "We design the spatial transformation component considering the following three aspects. 1) Air pollution dispersion. Although we do not have first-hand city-wide pollutant emission data, the readings of air quality recorded by monitoring stations can be regarded as second-hand pollutant sources as air pollutants are dispersed among different locations. With the signals from spatial neighbors, the further predictive model can incorporate more information. 2) Spatial correlations. Spatial partition merge the scattered air quality data into regions, which closer regions have a finer granularity and farther regions have a coarser",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.6194095611572266,
            -2.033881187438965
        ],
        "MSU_id": 524
    },
    {
        "sentence": "Spatial aggregation reduces model complexity by setting an upper bound for the input.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 105,
        "paper_id": 1,
        "paragraph_info": "granularity. Moreover, regions with different distance show different impacts varying by distance, which follows the First Law of Geography [12], *i.e.* \"*Everything is related to everything else, but near things are more related than distant things*.\" 3) Scalability. Spatial aggregation reduces model complexity as it sets an upper bound (the number of regions) for the input. Moreover, spatial interpolation overcomes spatial sparsity by filling the missing values and generating a consistent input for all monitoring stations, which enable us to use different stations' data together to train a single model with more training data.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.1395205408334732,
            -2.086076498031616
        ],
        "MSU_id": 528
    },
    {
        "sentence": "Spatial interpolation overcomes spatial sparsity by filling the missing values.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 105,
        "paper_id": 1,
        "paragraph_info": "granularity. Moreover, regions with different distance show different impacts varying by distance, which follows the First Law of Geography [12], *i.e.* \"*Everything is related to everything else, but near things are more related than distant things*.\" 3) Scalability. Spatial aggregation reduces model complexity as it sets an upper bound (the number of regions) for the input. Moreover, spatial interpolation overcomes spatial sparsity by filling the missing values and generating a consistent input for all monitoring stations, which enable us to use different stations' data together to train a single model with more training data.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.8654893636703491,
            -1.8533180952072144
        ],
        "MSU_id": 529
    },
    {
        "sentence": "Spatial interpolation generates a consistent input for all monitoring stations.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 105,
        "paper_id": 1,
        "paragraph_info": "granularity. Moreover, regions with different distance show different impacts varying by distance, which follows the First Law of Geography [12], *i.e.* \"*Everything is related to everything else, but near things are more related than distant things*.\" 3) Scalability. Spatial aggregation reduces model complexity as it sets an upper bound (the number of regions) for the input. Moreover, spatial interpolation overcomes spatial sparsity by filling the missing values and generating a consistent input for all monitoring stations, which enable us to use different stations' data together to train a single model with more training data.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.37055879831314087,
            -1.2592607736587524
        ],
        "MSU_id": 530
    },
    {
        "sentence": "Using spatial interpolation enables us to use different stations' data together to train a single model.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 105,
        "paper_id": 1,
        "paragraph_info": "granularity. Moreover, regions with different distance show different impacts varying by distance, which follows the First Law of Geography [12], *i.e.* \"*Everything is related to everything else, but near things are more related than distant things*.\" 3) Scalability. Spatial aggregation reduces model complexity as it sets an upper bound (the number of regions) for the input. Moreover, spatial interpolation overcomes spatial sparsity by filling the missing values and generating a consistent input for all monitoring stations, which enable us to use different stations' data together to train a single model with more training data.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.052977442741394,
            -2.1417407989501953
        ],
        "MSU_id": 531
    },
    {
        "type": "figure",
        "para_id": 107,
        "paper_id": 1,
        "paragraph_info": "_page_3_Figure_3.jpeg",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7035431861877441,
            -1.4102528095245361
        ],
        "MSU_id": 533,
        "sentence": "Figure 5 illustrates the process of spatial transformation, including monitoring stations, spatial partition, spatial aggregation, and spatial interpolation.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "We design a DNN-based method to fuse cross-domain data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 108,
        "paper_id": 1,
        "paragraph_info": "For simultaneously capturing the factors affecting future air quality, *e.g.* meteorological conditions, we design a DNN-based method to fuse cross-domain data. As depicted in Figure 4, we build five subnets (HW, WF, SP, MP, and HI) to capture these factors. Though air quality is affected by multiple factors, the degree of influences from these factors may be different. Inspired by such observation, the outputs of five subnets are weighted merged using a parametric-matrix-based fusion [13] to model the dynamic influences and generate the final results:",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.32982268929481506,
            -2.1652779579162598
        ],
        "MSU_id": 535
    },
    {
        "sentence": "We build five subnets (HW, WF, SP, MP, and HI) to capture factors affecting future air quality.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 108,
        "paper_id": 1,
        "paragraph_info": "For simultaneously capturing the factors affecting future air quality, *e.g.* meteorological conditions, we design a DNN-based method to fuse cross-domain data. As depicted in Figure 4, we build five subnets (HW, WF, SP, MP, and HI) to capture these factors. Though air quality is affected by multiple factors, the degree of influences from these factors may be different. Inspired by such observation, the outputs of five subnets are weighted merged using a parametric-matrix-based fusion [13] to model the dynamic influences and generate the final results:",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.745171070098877,
            -2.06387996673584
        ],
        "MSU_id": 536
    },
    {
        "sentence": "The outputs of five subnets are weighted merged using a parametric-matrix-based fusion to model the dynamic influences.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 108,
        "paper_id": 1,
        "paragraph_info": "For simultaneously capturing the factors affecting future air quality, *e.g.* meteorological conditions, we design a DNN-based method to fuse cross-domain data. As depicted in Figure 4, we build five subnets (HW, WF, SP, MP, and HI) to capture these factors. Though air quality is affected by multiple factors, the degree of influences from these factors may be different. Inspired by such observation, the outputs of five subnets are weighted merged using a parametric-matrix-based fusion [13] to model the dynamic influences and generate the final results:",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.37201550602912903,
            -2.121279716491699
        ],
        "MSU_id": 537
    },
    {
        "sentence": "The prediction results are mapped into [0, 1] by the Sigmoid function.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 109,
        "paper_id": 1,
        "paragraph_info": "where \u0302 \u2208 <sup>\u210e</sup> are the predicted results, \u210e*, , , ,* \u210e are the outputs of five subnets, \u2218 is Hadamard product, and \u210e*, , , ,* \u210e are the learnable parameters that adjust the degrees affected by these subnets. Here, the prediction results are mapped into [0, 1] by Sigmoid function. And later, we denormalize the predictions to get the actual air quality.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.3277301788330078,
            -2.2410430908203125
        ],
        "MSU_id": 544
    },
    {
        "sentence": "We denormalize the predictions to get the actual air quality.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 109,
        "paper_id": 1,
        "paragraph_info": "where \u0302 \u2208 <sup>\u210e</sup> are the predicted results, \u210e*, , , ,* \u210e are the outputs of five subnets, \u2218 is Hadamard product, and \u210e*, , , ,* \u210e are the learnable parameters that adjust the degrees affected by these subnets. Here, the prediction results are mapped into [0, 1] by Sigmoid function. And later, we denormalize the predictions to get the actual air quality.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7950404286384583,
            -1.9474753141403198
        ],
        "MSU_id": 545
    },
    {
        "sentence": "We propose a distributed fusion architecture to capture individual and holistic influences.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 110,
        "paper_id": 1,
        "paragraph_info": "Based on domain knowledge, we know that direct and indirect factors have different effects on future air quality. At most time, all indirect factors will simultaneously determine the development environment of direct factors. Also, each indirect factor has an own individual effect on direct factors affecting future air quality. For capturing such individual and holistic influences, we propose a distributed fusion architecture as shown in Figure 6(a), which main feature fuses each auxiliary feature in a parallel manner, and then merge the outputs together. The key point in distributed fusion architecture is that we specify one feature as main feature and other features as auxiliary features. The reason for this partition is main feature and prediction target come from the same domain, while auxiliary features and prediction target come from different domains. Distributed fusion architecture highlights the main feature and captures the influences from auxiliary features as main feature respectively interacting with each auxiliary feature to learn the joint effects.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7069042921066284,
            -1.9872647523880005
        ],
        "MSU_id": 549
    },
    {
        "sentence": "The main feature of the distributed fusion architecture fuses each auxiliary feature in a parallel manner.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 110,
        "paper_id": 1,
        "paragraph_info": "Based on domain knowledge, we know that direct and indirect factors have different effects on future air quality. At most time, all indirect factors will simultaneously determine the development environment of direct factors. Also, each indirect factor has an own individual effect on direct factors affecting future air quality. For capturing such individual and holistic influences, we propose a distributed fusion architecture as shown in Figure 6(a), which main feature fuses each auxiliary feature in a parallel manner, and then merge the outputs together. The key point in distributed fusion architecture is that we specify one feature as main feature and other features as auxiliary features. The reason for this partition is main feature and prediction target come from the same domain, while auxiliary features and prediction target come from different domains. Distributed fusion architecture highlights the main feature and captures the influences from auxiliary features as main feature respectively interacting with each auxiliary feature to learn the joint effects.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.9247890710830688,
            -1.9790064096450806
        ],
        "MSU_id": 550
    },
    {
        "sentence": "The outputs of the auxiliary features are merged together in the distributed fusion architecture.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 110,
        "paper_id": 1,
        "paragraph_info": "Based on domain knowledge, we know that direct and indirect factors have different effects on future air quality. At most time, all indirect factors will simultaneously determine the development environment of direct factors. Also, each indirect factor has an own individual effect on direct factors affecting future air quality. For capturing such individual and holistic influences, we propose a distributed fusion architecture as shown in Figure 6(a), which main feature fuses each auxiliary feature in a parallel manner, and then merge the outputs together. The key point in distributed fusion architecture is that we specify one feature as main feature and other features as auxiliary features. The reason for this partition is main feature and prediction target come from the same domain, while auxiliary features and prediction target come from different domains. Distributed fusion architecture highlights the main feature and captures the influences from auxiliary features as main feature respectively interacting with each auxiliary feature to learn the joint effects.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.4811347723007202,
            -2.030449390411377
        ],
        "MSU_id": 551
    },
    {
        "sentence": "One feature is specified as the main feature and other features as auxiliary features in the distributed fusion architecture.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 110,
        "paper_id": 1,
        "paragraph_info": "Based on domain knowledge, we know that direct and indirect factors have different effects on future air quality. At most time, all indirect factors will simultaneously determine the development environment of direct factors. Also, each indirect factor has an own individual effect on direct factors affecting future air quality. For capturing such individual and holistic influences, we propose a distributed fusion architecture as shown in Figure 6(a), which main feature fuses each auxiliary feature in a parallel manner, and then merge the outputs together. The key point in distributed fusion architecture is that we specify one feature as main feature and other features as auxiliary features. The reason for this partition is main feature and prediction target come from the same domain, while auxiliary features and prediction target come from different domains. Distributed fusion architecture highlights the main feature and captures the influences from auxiliary features as main feature respectively interacting with each auxiliary feature to learn the joint effects.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8665482997894287,
            -2.047274112701416
        ],
        "MSU_id": 552
    },
    {
        "sentence": "We specify the embedding of AQIs as the main feature.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 111,
        "paper_id": 1,
        "paragraph_info": "In our task, we specify the embedding of AQIs as main feature and the embedding of other features (*i.e.* meteorology, weather forecast, other pollutants, time and station ID) as auxiliary features, which main feature can simulate the direct factors from local emission and regional transport, while auxiliary features can represent the indirect factors. For modeling the interaction between these factors, we build five subnets to capture the holistic influence from all influential factors and the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain. Here, main feature is shared across all subnets and all subnets have the same network structure, FusionNet.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.4998778700828552,
            -1.809411644935608
        ],
        "MSU_id": 556
    },
    {
        "sentence": "We specify the embedding of other features as auxiliary features.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 111,
        "paper_id": 1,
        "paragraph_info": "In our task, we specify the embedding of AQIs as main feature and the embedding of other features (*i.e.* meteorology, weather forecast, other pollutants, time and station ID) as auxiliary features, which main feature can simulate the direct factors from local emission and regional transport, while auxiliary features can represent the indirect factors. For modeling the interaction between these factors, we build five subnets to capture the holistic influence from all influential factors and the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain. Here, main feature is shared across all subnets and all subnets have the same network structure, FusionNet.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.5467173457145691,
            -2.0051538944244385
        ],
        "MSU_id": 557
    },
    {
        "sentence": "We build five subnets to model the interaction between these factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 111,
        "paper_id": 1,
        "paragraph_info": "In our task, we specify the embedding of AQIs as main feature and the embedding of other features (*i.e.* meteorology, weather forecast, other pollutants, time and station ID) as auxiliary features, which main feature can simulate the direct factors from local emission and regional transport, while auxiliary features can represent the indirect factors. For modeling the interaction between these factors, we build five subnets to capture the holistic influence from all influential factors and the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain. Here, main feature is shared across all subnets and all subnets have the same network structure, FusionNet.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.3026851415634155,
            -2.051833152770996
        ],
        "MSU_id": 560
    },
    {
        "sentence": "The subnets capture the holistic influence from all influential factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 111,
        "paper_id": 1,
        "paragraph_info": "In our task, we specify the embedding of AQIs as main feature and the embedding of other features (*i.e.* meteorology, weather forecast, other pollutants, time and station ID) as auxiliary features, which main feature can simulate the direct factors from local emission and regional transport, while auxiliary features can represent the indirect factors. For modeling the interaction between these factors, we build five subnets to capture the holistic influence from all influential factors and the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain. Here, main feature is shared across all subnets and all subnets have the same network structure, FusionNet.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8463563323020935,
            -2.0828492641448975
        ],
        "MSU_id": 561
    },
    {
        "sentence": "The subnets capture the individual influences from historical weather, weather forecast, secondary productions, and meta properties from time and terrain.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 111,
        "paper_id": 1,
        "paragraph_info": "In our task, we specify the embedding of AQIs as main feature and the embedding of other features (*i.e.* meteorology, weather forecast, other pollutants, time and station ID) as auxiliary features, which main feature can simulate the direct factors from local emission and regional transport, while auxiliary features can represent the indirect factors. For modeling the interaction between these factors, we build five subnets to capture the holistic influence from all influential factors and the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain. Here, main feature is shared across all subnets and all subnets have the same network structure, FusionNet.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.738702118396759,
            -1.8818069696426392
        ],
        "MSU_id": 562
    },
    {
        "sentence": "All subnets have the same network structure, FusionNet.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 111,
        "paper_id": 1,
        "paragraph_info": "In our task, we specify the embedding of AQIs as main feature and the embedding of other features (*i.e.* meteorology, weather forecast, other pollutants, time and station ID) as auxiliary features, which main feature can simulate the direct factors from local emission and regional transport, while auxiliary features can represent the indirect factors. For modeling the interaction between these factors, we build five subnets to capture the holistic influence from all influential factors and the individual influences from the historical weather, weather forecast, secondary productions, and meta properties from time and terrain. Here, main feature is shared across all subnets and all subnets have the same network structure, FusionNet.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.10967174172401428,
            -2.1160435676574707
        ],
        "MSU_id": 564
    },
    {
        "sentence": "FusionNet treats all features equally by using a concatenate layer to merge all features together.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 112,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 6(b), FusionNet treats all features equally by using a concatenate layer to merge all features together, then uses some fully-connected layers (FC) to learn higher-order feature interactions in a non-linear way. For training the neural network easier and more robust, we add some residual fullyconnected layers [21] between fully-connected layers, which previous information can be directly passed to following layers through the shortcut connections.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.6468113660812378,
            -2.175581455230713
        ],
        "MSU_id": 565
    },
    {
        "sentence": "FusionNet uses fully-connected layers (FC) to learn higher-order feature interactions in a non-linear way.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 112,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 6(b), FusionNet treats all features equally by using a concatenate layer to merge all features together, then uses some fully-connected layers (FC) to learn higher-order feature interactions in a non-linear way. For training the neural network easier and more robust, we add some residual fullyconnected layers [21] between fully-connected layers, which previous information can be directly passed to following layers through the shortcut connections.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.7553495764732361,
            -2.069547414779663
        ],
        "MSU_id": 566
    },
    {
        "sentence": "We add some residual fully-connected layers between fully-connected layers to make training the neural network easier and more robust.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 112,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 6(b), FusionNet treats all features equally by using a concatenate layer to merge all features together, then uses some fully-connected layers (FC) to learn higher-order feature interactions in a non-linear way. For training the neural network easier and more robust, we add some residual fullyconnected layers [21] between fully-connected layers, which previous information can be directly passed to following layers through the shortcut connections.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.685259461402893,
            -1.596052646636963
        ],
        "MSU_id": 567
    },
    {
        "sentence": "Previous information can be directly passed to following layers through the shortcut connections.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 112,
        "paper_id": 1,
        "paragraph_info": "As shown in Figure 6(b), FusionNet treats all features equally by using a concatenate layer to merge all features together, then uses some fully-connected layers (FC) to learn higher-order feature interactions in a non-linear way. For training the neural network easier and more robust, we add some residual fullyconnected layers [21] between fully-connected layers, which previous information can be directly passed to following layers through the shortcut connections.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.4337507486343384,
            -0.947071373462677
        ],
        "MSU_id": 568
    },
    {
        "type": "figure",
        "para_id": 114,
        "paper_id": 1,
        "paragraph_info": "_page_3_Figure_14.jpeg",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.03595979884266853,
            -2.026489496231079
        ],
        "MSU_id": 569,
        "sentence": "Figure 6 illustrates two architectures for feature fusion: (a) Distributed Fusion, which uses FusionNet to merge main and auxiliary features, and (b) FusionNet, which employs concatenation followed by fully connected layers including a residual layer.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "We build historical weather subnet (HW) and weather forecast subnet (WF) for capturing historical and future meteorological conditions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 115,
        "paper_id": 1,
        "paragraph_info": "We build historical weather subnet (HW) and weather forecast subnet (WF) for capturing historical and future meteorological conditions. The reason for building such two subnets is data realism and time interval, which historical weather provide hourly real weather conditions while weather forecast provide 3-hour segmented forecasted weather conditions. For historical weather data, we consider weather, wind speed, wind direction, humidity, and pressure as features; for weather forecast data, we consider weather, wind direction and wind strength as features. After feeding AQIs and features into subnets, we get  $\\boldsymbol{y}_{hw}$  and  $\\boldsymbol{y}_{wf}$ .",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8253078460693359,
            -1.9957798719406128
        ],
        "MSU_id": 571
    },
    {
        "sentence": "For historical weather data, we consider weather, wind speed, wind direction, humidity, and pressure as features.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 115,
        "paper_id": 1,
        "paragraph_info": "We build historical weather subnet (HW) and weather forecast subnet (WF) for capturing historical and future meteorological conditions. The reason for building such two subnets is data realism and time interval, which historical weather provide hourly real weather conditions while weather forecast provide 3-hour segmented forecasted weather conditions. For historical weather data, we consider weather, wind speed, wind direction, humidity, and pressure as features; for weather forecast data, we consider weather, wind direction and wind strength as features. After feeding AQIs and features into subnets, we get  $\\boldsymbol{y}_{hw}$  and  $\\boldsymbol{y}_{wf}$ .",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.6263617277145386,
            -1.9703816175460815
        ],
        "MSU_id": 575
    },
    {
        "sentence": "For weather forecast data, we consider weather, wind direction and wind strength as features.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 115,
        "paper_id": 1,
        "paragraph_info": "We build historical weather subnet (HW) and weather forecast subnet (WF) for capturing historical and future meteorological conditions. The reason for building such two subnets is data realism and time interval, which historical weather provide hourly real weather conditions while weather forecast provide 3-hour segmented forecasted weather conditions. For historical weather data, we consider weather, wind speed, wind direction, humidity, and pressure as features; for weather forecast data, we consider weather, wind direction and wind strength as features. After feeding AQIs and features into subnets, we get  $\\boldsymbol{y}_{hw}$  and  $\\boldsymbol{y}_{wf}$ .",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.4980621337890625,
            -1.9025648832321167
        ],
        "MSU_id": 576
    },
    {
        "sentence": "We design a secondary production subnet (HI) to simulate the chemical interaction between pollutants.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 116,
        "paper_id": 1,
        "paragraph_info": "Besides the direct emission of pollutants, it exists some secondary chemical reaction among pollutants in the atmosphere. Thus, we design a secondary production subnet (HI) to simulate the chemical interaction between pollutants. After fusing AQIs of  $PM_{2.5}$  and other pollutants ( $PM_{10}$ ,  $NO_2$ ,  $CO$ ,  $O_3$ , and  $SO_2$ ) recorded by target station, we get  $\\pmb{y}_{sp}.$",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.1384050846099854,
            -1.5316144227981567
        ],
        "MSU_id": 579
    },
    {
        "sentence": "We fuse AQIs of $PM_{2.5}$ and other pollutants ($PM_{10}$, $NO_2$, $CO$, $O_3$, and $SO_2$) recorded by the target station.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 116,
        "paper_id": 1,
        "paragraph_info": "Besides the direct emission of pollutants, it exists some secondary chemical reaction among pollutants in the atmosphere. Thus, we design a secondary production subnet (HI) to simulate the chemical interaction between pollutants. After fusing AQIs of  $PM_{2.5}$  and other pollutants ( $PM_{10}$ ,  $NO_2$ ,  $CO$ ,  $O_3$ , and  $SO_2$ ) recorded by target station, we get  $\\pmb{y}_{sp}.$",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.0955747365951538,
            -1.8618210554122925
        ],
        "MSU_id": 580
    },
    {
        "sentence": "Meta property subnet (MP) models the time and terrain properties affecting air quality.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 117,
        "paper_id": 1,
        "paragraph_info": "Meta property subnet (MP) models the time and terrain properties affecting air quality. Specifically, we use time (Month, DayOfWeek, TimeOfDay) to model the air quality pattern in temporal dimension, e.g. winter always has a higher AQI than summer due to heating. Also, we use station ID to simulate terrain affecting air quality, e.g. air quality is always worse in builtup areas than open areas. After fusing AQIs, time and station ID in FusionNet, we get  $\\pmb{y}_{mp}$ .",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.34977245330810547,
            -2.0876693725585938
        ],
        "MSU_id": 582
    },
    {
        "sentence": "We use time (Month, DayOfWeek, TimeOfDay) to model the air quality pattern in temporal dimension.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 117,
        "paper_id": 1,
        "paragraph_info": "Meta property subnet (MP) models the time and terrain properties affecting air quality. Specifically, we use time (Month, DayOfWeek, TimeOfDay) to model the air quality pattern in temporal dimension, e.g. winter always has a higher AQI than summer due to heating. Also, we use station ID to simulate terrain affecting air quality, e.g. air quality is always worse in builtup areas than open areas. After fusing AQIs, time and station ID in FusionNet, we get  $\\pmb{y}_{mp}$ .",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.3420005738735199,
            -2.071655750274658
        ],
        "MSU_id": 583
    },
    {
        "sentence": "We use station ID to simulate terrain affecting air quality.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 117,
        "paper_id": 1,
        "paragraph_info": "Meta property subnet (MP) models the time and terrain properties affecting air quality. Specifically, we use time (Month, DayOfWeek, TimeOfDay) to model the air quality pattern in temporal dimension, e.g. winter always has a higher AQI than summer due to heating. Also, we use station ID to simulate terrain affecting air quality, e.g. air quality is always worse in builtup areas than open areas. After fusing AQIs, time and station ID in FusionNet, we get  $\\pmb{y}_{mp}$ .",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.31383442878723145,
            -2.125154972076416
        ],
        "MSU_id": 585
    },
    {
        "sentence": "We design the holistic influence subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 118,
        "paper_id": 1,
        "paragraph_info": "Except for the individual effects, all indirect factors will simultaneously determine the development environment of direct factors affecting future air quality. For capturing such information, we design the holistic influence subnet (HI) to learn the holistic influence by fusing all direct and indirect factors together. Then, we get  $\\boldsymbol{y}_{hi}$ .",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7588844895362854,
            -2.150413990020752
        ],
        "MSU_id": 589
    },
    {
        "sentence": "We use embedding to capture temporal dependencies and learn intra-dynamics for each influential factor.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 119,
        "paper_id": 1,
        "paragraph_info": "Before distributed fusion, we use embedding [22] to capture temporal dependencies and learn intra-dynamics for each influential factor. For categorical features, embedding can transform the features represented by one-hot encoding to a real-valued vector and capture the similarity between different categories. For numerical features, embedding can transform the raw features to a low-dimensional space for reducing computational cost and learn the hidden representation.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.1112327575683594,
            -1.8503824472427368
        ],
        "MSU_id": 591
    },
    {
        "sentence": "Embedding can transform categorical features represented by one-hot encoding to a real-valued vector.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 119,
        "paper_id": 1,
        "paragraph_info": "Before distributed fusion, we use embedding [22] to capture temporal dependencies and learn intra-dynamics for each influential factor. For categorical features, embedding can transform the features represented by one-hot encoding to a real-valued vector and capture the similarity between different categories. For numerical features, embedding can transform the raw features to a low-dimensional space for reducing computational cost and learn the hidden representation.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.0042033195495605,
            -1.4221137762069702
        ],
        "MSU_id": 592
    },
    {
        "sentence": "Embedding can transform numerical features to a low-dimensional space for reducing computational cost.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 119,
        "paper_id": 1,
        "paragraph_info": "Before distributed fusion, we use embedding [22] to capture temporal dependencies and learn intra-dynamics for each influential factor. For categorical features, embedding can transform the features represented by one-hot encoding to a real-valued vector and capture the similarity between different categories. For numerical features, embedding can transform the raw features to a low-dimensional space for reducing computational cost and learn the hidden representation.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.2400864064693451,
            -1.8591220378875732
        ],
        "MSU_id": 594
    },
    {
        "sentence": "We detail the embedding settings for each influential factor.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 120,
        "paper_id": 1,
        "paragraph_info": "As shown in Table 1, we detail the embedding settings for each influential factor. For AQIs, other pollutants, historical weather, we use the data in past and current 6 hours to incorporate the temporal information. For weather forecast, we use  $k/3$ forecast instances to capture the dynamic changes of future weather conditions. Here, we combine the features from same domain together (e.g. Month, DayOfWeek, and TimeOfDay) to jointly learn the embedding for exploring intra-dynamics of each factor after feature interactions. Thus, we use the embedding of these domain data to simulate the direct factors and indirect factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7015129327774048,
            -1.9650565385818481
        ],
        "MSU_id": 596
    },
    {
        "sentence": "For AQIs, other pollutants, historical weather, we use the data in past and current 6 hours to incorporate the temporal information.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 120,
        "paper_id": 1,
        "paragraph_info": "As shown in Table 1, we detail the embedding settings for each influential factor. For AQIs, other pollutants, historical weather, we use the data in past and current 6 hours to incorporate the temporal information. For weather forecast, we use  $k/3$ forecast instances to capture the dynamic changes of future weather conditions. Here, we combine the features from same domain together (e.g. Month, DayOfWeek, and TimeOfDay) to jointly learn the embedding for exploring intra-dynamics of each factor after feature interactions. Thus, we use the embedding of these domain data to simulate the direct factors and indirect factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5132994651794434,
            -1.9162508249282837
        ],
        "MSU_id": 597
    },
    {
        "sentence": "For weather forecast, we use $k/3$ forecast instances to capture the dynamic changes of future weather conditions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 120,
        "paper_id": 1,
        "paragraph_info": "As shown in Table 1, we detail the embedding settings for each influential factor. For AQIs, other pollutants, historical weather, we use the data in past and current 6 hours to incorporate the temporal information. For weather forecast, we use  $k/3$ forecast instances to capture the dynamic changes of future weather conditions. Here, we combine the features from same domain together (e.g. Month, DayOfWeek, and TimeOfDay) to jointly learn the embedding for exploring intra-dynamics of each factor after feature interactions. Thus, we use the embedding of these domain data to simulate the direct factors and indirect factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.24878863990306854,
            -1.8916302919387817
        ],
        "MSU_id": 598
    },
    {
        "sentence": "We combine the features from the same domain together to jointly learn the embedding for exploring intra-dynamics of each factor after feature interactions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 120,
        "paper_id": 1,
        "paragraph_info": "As shown in Table 1, we detail the embedding settings for each influential factor. For AQIs, other pollutants, historical weather, we use the data in past and current 6 hours to incorporate the temporal information. For weather forecast, we use  $k/3$ forecast instances to capture the dynamic changes of future weather conditions. Here, we combine the features from same domain together (e.g. Month, DayOfWeek, and TimeOfDay) to jointly learn the embedding for exploring intra-dynamics of each factor after feature interactions. Thus, we use the embedding of these domain data to simulate the direct factors and indirect factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.23734302818775177,
            -1.9622563123703003
        ],
        "MSU_id": 599
    },
    {
        "sentence": "We use the embedding of these domain data to simulate the direct factors and indirect factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 120,
        "paper_id": 1,
        "paragraph_info": "As shown in Table 1, we detail the embedding settings for each influential factor. For AQIs, other pollutants, historical weather, we use the data in past and current 6 hours to incorporate the temporal information. For weather forecast, we use  $k/3$ forecast instances to capture the dynamic changes of future weather conditions. Here, we combine the features from same domain together (e.g. Month, DayOfWeek, and TimeOfDay) to jointly learn the embedding for exploring intra-dynamics of each factor after feature interactions. Thus, we use the embedding of these domain data to simulate the direct factors and indirect factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.820371687412262,
            -1.8903672695159912
        ],
        "MSU_id": 600
    },
    {
        "sentence": "We first construct the training instances from original heterogeneous urban data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 121,
        "paper_id": 1,
        "paragraph_info": "Algorithm 1 outlines the DeepAir training process. We first construct the training instances from original heterogeneous urban data (lines 1-11). Then, DeepAir is trained via backpropagation to minimize the mean absolute error between predictions and ground values (lines 12-16).",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.4041035175323486,
            -1.7271684408187866
        ],
        "MSU_id": 602
    },
    {
        "sentence": "DeepAir is trained via backpropagation to minimize the mean absolute error between predictions and ground values.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 121,
        "paper_id": 1,
        "paragraph_info": "Algorithm 1 outlines the DeepAir training process. We first construct the training instances from original heterogeneous urban data (lines 1-11). Then, DeepAir is trained via backpropagation to minimize the mean absolute error between predictions and ground values (lines 12-16).",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.6294374465942383,
            -2.198781967163086
        ],
        "MSU_id": 603
    },
    {
        "sentence": "The AirPollutionPrediction system collects air pollutants data from 2,296 official air quality monitoring stations in 302 Chinese cities every hour.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 122,
        "paper_id": 1,
        "paragraph_info": "Air quality data: AirPollutionPrediction system [8] collects air pollutants data from 2,296 official air quality monitoring stations in 302 Chinese cities every hour. Each air quality record consists of the concentration of six pollutants: PM2.5, PM10, NO2, CO, O3, and SO<sub>2</sub>. We convert these concentrations into corresponding AQI for each pollutant based on Chinese AQI standards.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.040666740387678146,
            -2.0424320697784424
        ],
        "MSU_id": 604
    },
    {
        "sentence": "We convert these concentrations into corresponding AQI for each pollutant based on Chinese AQI standards.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 122,
        "paper_id": 1,
        "paragraph_info": "Air quality data: AirPollutionPrediction system [8] collects air pollutants data from 2,296 official air quality monitoring stations in 302 Chinese cities every hour. Each air quality record consists of the concentration of six pollutants: PM2.5, PM10, NO2, CO, O3, and SO<sub>2</sub>. We convert these concentrations into corresponding AQI for each pollutant based on Chinese AQI standards.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.7331984639167786,
            -1.4782968759536743
        ],
        "MSU_id": 606
    },
    {
        "sentence": "The updating frequency of the forecasts is 12 hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 124,
        "paper_id": 1,
        "paragraph_info": "*Weather forecast data*: The system collects weather forecast data for 2,612 cities/districts. The updating frequency of the forecasts is 12 hours, updating twice a day at 8 am and 8 pm. We collect the forecasts for the next three days for each update, which is usually segmented into 3-hour time interval. Each record consists of weather, temperature, wind strength and wind direction.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.9910681247711182,
            -1.8505010604858398
        ],
        "MSU_id": 612
    },
    {
        "sentence": "The forecasts are updated twice a day at 8 am and 8 pm.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 124,
        "paper_id": 1,
        "paragraph_info": "*Weather forecast data*: The system collects weather forecast data for 2,612 cities/districts. The updating frequency of the forecasts is 12 hours, updating twice a day at 8 am and 8 pm. We collect the forecasts for the next three days for each update, which is usually segmented into 3-hour time interval. Each record consists of weather, temperature, wind strength and wind direction.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5596877932548523,
            -1.8910707235336304
        ],
        "MSU_id": 613
    },
    {
        "sentence": "We collect the forecasts for the next three days for each update.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 124,
        "paper_id": 1,
        "paragraph_info": "*Weather forecast data*: The system collects weather forecast data for 2,612 cities/districts. The updating frequency of the forecasts is 12 hours, updating twice a day at 8 am and 8 pm. We collect the forecasts for the next three days for each update, which is usually segmented into 3-hour time interval. Each record consists of weather, temperature, wind strength and wind direction.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.0936194360256195,
            -1.905462384223938
        ],
        "MSU_id": 614
    },
    {
        "sentence": "The forecasts are usually segmented into 3-hour time intervals.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 124,
        "paper_id": 1,
        "paragraph_info": "*Weather forecast data*: The system collects weather forecast data for 2,612 cities/districts. The updating frequency of the forecasts is 12 hours, updating twice a day at 8 am and 8 pm. We collect the forecasts for the next three days for each update, which is usually segmented into 3-hour time interval. Each record consists of weather, temperature, wind strength and wind direction.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5974283218383789,
            -1.9226359128952026
        ],
        "MSU_id": 615
    },
    {
        "sentence": "Each record consists of weather, temperature, wind strength and wind direction.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 124,
        "paper_id": 1,
        "paragraph_info": "*Weather forecast data*: The system collects weather forecast data for 2,612 cities/districts. The updating frequency of the forecasts is 12 hours, updating twice a day at 8 am and 8 pm. We collect the forecasts for the next three days for each update, which is usually segmented into 3-hour time interval. Each record consists of weather, temperature, wind strength and wind direction.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8491749167442322,
            -1.9157949686050415
        ],
        "MSU_id": 616
    },
    {
        "sentence": "The colors in Figure 7, defined by Chinese standards, represent the level of air pollution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 125,
        "paper_id": 1,
        "paragraph_info": "For evaluation, we use three-year (from 2014/5/1 to 2017/4/30) data in nine major Chinese cities (Beijing, Tianjin, Shanghai, Nanjing, Hangzhou, Guangzhou, Shenzhen, Chengdu, and Chongqing). Figure 7 shows the distribution about AQI of PM2.5 between 2014/5 to 2017/4 in nine cities, which the colors, defined by Chinese standards, represent the level of air pollution. In general, Beijing and Tianjin have worse air quality and Shenzhen and Guangzhou are better. As Beijing has the most complicated air quality, we focus on Beijing's data when comparing with different baselines, while showing overall results for the other eight cities. Table 2 details the statistical results about Beijing dataset. To predict the air quality of 36 monitoring stations in Beijing, 74 neighbor stations within 100km (semidiameter) to Beijing are retrieved. Among all air quality records, 2.3% cases are sudden changes. In the experiments, the data in the first 24 months is used for training, and the data in last 12 months is used for testing.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.4818034172058105,
            -1.096459984779358
        ],
        "MSU_id": 620
    },
    {
        "sentence": "We focus on Beijing's data when comparing with different baselines.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 125,
        "paper_id": 1,
        "paragraph_info": "For evaluation, we use three-year (from 2014/5/1 to 2017/4/30) data in nine major Chinese cities (Beijing, Tianjin, Shanghai, Nanjing, Hangzhou, Guangzhou, Shenzhen, Chengdu, and Chongqing). Figure 7 shows the distribution about AQI of PM2.5 between 2014/5 to 2017/4 in nine cities, which the colors, defined by Chinese standards, represent the level of air pollution. In general, Beijing and Tianjin have worse air quality and Shenzhen and Guangzhou are better. As Beijing has the most complicated air quality, we focus on Beijing's data when comparing with different baselines, while showing overall results for the other eight cities. Table 2 details the statistical results about Beijing dataset. To predict the air quality of 36 monitoring stations in Beijing, 74 neighbor stations within 100km (semidiameter) to Beijing are retrieved. Among all air quality records, 2.3% cases are sudden changes. In the experiments, the data in the first 24 months is used for training, and the data in last 12 months is used for testing.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -2.0826261043548584,
            0.3299792408943176
        ],
        "MSU_id": 622
    },
    {
        "sentence": "To predict the air quality of 36 monitoring stations in Beijing, 74 neighbor stations within 100km are retrieved.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 125,
        "paper_id": 1,
        "paragraph_info": "For evaluation, we use three-year (from 2014/5/1 to 2017/4/30) data in nine major Chinese cities (Beijing, Tianjin, Shanghai, Nanjing, Hangzhou, Guangzhou, Shenzhen, Chengdu, and Chongqing). Figure 7 shows the distribution about AQI of PM2.5 between 2014/5 to 2017/4 in nine cities, which the colors, defined by Chinese standards, represent the level of air pollution. In general, Beijing and Tianjin have worse air quality and Shenzhen and Guangzhou are better. As Beijing has the most complicated air quality, we focus on Beijing's data when comparing with different baselines, while showing overall results for the other eight cities. Table 2 details the statistical results about Beijing dataset. To predict the air quality of 36 monitoring stations in Beijing, 74 neighbor stations within 100km (semidiameter) to Beijing are retrieved. Among all air quality records, 2.3% cases are sudden changes. In the experiments, the data in the first 24 months is used for training, and the data in last 12 months is used for testing.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.03359897807240486,
            -2.074810743331909
        ],
        "MSU_id": 624
    },
    {
        "sentence": "In the experiments, the data in the first 24 months is used for training, and the data in the last 12 months is used for testing.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 125,
        "paper_id": 1,
        "paragraph_info": "For evaluation, we use three-year (from 2014/5/1 to 2017/4/30) data in nine major Chinese cities (Beijing, Tianjin, Shanghai, Nanjing, Hangzhou, Guangzhou, Shenzhen, Chengdu, and Chongqing). Figure 7 shows the distribution about AQI of PM2.5 between 2014/5 to 2017/4 in nine cities, which the colors, defined by Chinese standards, represent the level of air pollution. In general, Beijing and Tianjin have worse air quality and Shenzhen and Guangzhou are better. As Beijing has the most complicated air quality, we focus on Beijing's data when comparing with different baselines, while showing overall results for the other eight cities. Table 2 details the statistical results about Beijing dataset. To predict the air quality of 36 monitoring stations in Beijing, 74 neighbor stations within 100km (semidiameter) to Beijing are retrieved. Among all air quality records, 2.3% cases are sudden changes. In the experiments, the data in the first 24 months is used for training, and the data in last 12 months is used for testing.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.5232667922973633,
            -0.031372301280498505
        ],
        "MSU_id": 626
    },
    {
        "sentence": "We use prediction accuracy ( $acc$ ) to evaluate our algorithms.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 129,
        "paper_id": 1,
        "paragraph_info": "We use prediction accuracy ( $acc$ ) and mean absolute error ( $mae$ ) to evaluate our algorithms, which are defined as follow:",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.2458598613739014,
            -1.7435189485549927
        ],
        "MSU_id": 631
    },
    {
        "sentence": "We use mean absolute error ( $mae$ ) to evaluate our algorithms.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 129,
        "paper_id": 1,
        "paragraph_info": "We use prediction accuracy ( $acc$ ) and mean absolute error ( $mae$ ) to evaluate our algorithms, which are defined as follow:",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.2730432748794556,
            -1.3826974630355835
        ],
        "MSU_id": 632
    },
    {
        "sentence": "We select the cases whose AQI is bigger than 100.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 130,
        "paper_id": 1,
        "paragraph_info": "For sudden changes [7], we select the cases whose AQI is bigger than 100 and decreases over a threshold in the next few hours, e.g. 50 in the coming one hour, or 100 in the coming two hours, or 150 in the coming three hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.45979756116867065,
            0.06036967411637306
        ],
        "MSU_id": 634
    },
    {
        "sentence": "The AQI decreases over a threshold in the next few hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 130,
        "paper_id": 1,
        "paragraph_info": "For sudden changes [7], we select the cases whose AQI is bigger than 100 and decreases over a threshold in the next few hours, e.g. 50 in the coming one hour, or 100 in the coming two hours, or 150 in the coming three hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.5913207530975342,
            -1.3717073202133179
        ],
        "MSU_id": 635
    },
    {
        "sentence": "The threshold can be 50 in the coming one hour.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 130,
        "paper_id": 1,
        "paragraph_info": "For sudden changes [7], we select the cases whose AQI is bigger than 100 and decreases over a threshold in the next few hours, e.g. 50 in the coming one hour, or 100 in the coming two hours, or 150 in the coming three hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8523820042610168,
            -1.7858434915542603
        ],
        "MSU_id": 636
    },
    {
        "sentence": "The threshold can be 100 in the coming two hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 130,
        "paper_id": 1,
        "paragraph_info": "For sudden changes [7], we select the cases whose AQI is bigger than 100 and decreases over a threshold in the next few hours, e.g. 50 in the coming one hour, or 100 in the coming two hours, or 150 in the coming three hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.9911789894104004,
            -1.8632067441940308
        ],
        "MSU_id": 637
    },
    {
        "sentence": "The threshold can be 150 in the coming three hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 130,
        "paper_id": 1,
        "paragraph_info": "For sudden changes [7], we select the cases whose AQI is bigger than 100 and decreases over a threshold in the next few hours, e.g. 50 in the coming one hour, or 100 in the coming two hours, or 150 in the coming three hours.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.1459619998931885,
            -1.7411898374557495
        ],
        "MSU_id": 638
    },
    {
        "sentence": "DeepAir can automatically discover complicated air pollution patterns by modeling the underlying complex interactions of direct factors and indirect factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 131,
        "paper_id": 1,
        "paragraph_info": "Table 3 shows the performance of the proposed approach with other competing baselines. DeepAir achieves the highest accuracy in both general cases and sudden changes as it can automatically discover complicated air pollution patterns by modeling the underlying complex interactions of direct factors and indirect factors. By considering air quality data recorded by neighbor stations, LSTM-STC outperforms LSTM significantly, which shows the importance of spatial signals. The results of LSTM methods are not good for two reasons. One is that air quality is affected by many complex factors and the other is air quality has temporal closeness without obvious daily/weekly/monthly patterns. Comparing with DeepST, the results show that CNN is not suited in air quality prediction task as air quality data is sparse and the image size is small after preprocessing. As a result, DMVST-Net is not suited as other influential factors are more important than spatio-temporal correlations in the complex environment of air pollution. Comparing with DeepFM, the results show the effectiveness of DeepAir as DeepFM is designed for high-dimensional and extremely sparse data. Thus, a deep understanding of problem and data is important. Comparing with DeepSD, the results show that distributed architecture is more suited for air quality prediction task than sequential architecture as each indirect factor has an individual effect on direct factors affecting future air quality.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.45579925179481506,
            -1.8447202444076538
        ],
        "MSU_id": 641
    },
    {
        "sentence": "We evaluate the prediction results in both hourly station level and 12-hour min-max district level.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 132,
        "paper_id": 1,
        "paragraph_info": "Table 4 shows the comparison between DeepAir and WFM during the time span: 2014/10/1 to 2016/12/30. As WFM provides the predictions in district-level min-max range for the next 12 hours and DeepAir provide the predictions in station-level for each hour over the next 48 hours, we evaluate the prediction results in both hourly station level and 12-hour min-max district level. For hourly station-level, we split the predictions of WFM to hourly station-level by considering the average of min-max range; for district-level, we merge the predictions of DeepAir to district-level and get the min-max range for the next 12 hours. In both evaluation settings, DeepAir has a higher accuracy than WFM. In addition, DeepAir has a finer spatial and temporal granularity, a farther prediction period and a faster updating frequency. From the results, we can also find DeepAir has a good performance on 12-hour district-level min-max prediction, which means DeepAir is robust and general enough for other prediction settings.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.12375621497631073,
            -1.9291259050369263
        ],
        "MSU_id": 658
    },
    {
        "sentence": "For hourly station-level, we split the predictions of WFM to hourly station-level by considering the average of min-max range.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 132,
        "paper_id": 1,
        "paragraph_info": "Table 4 shows the comparison between DeepAir and WFM during the time span: 2014/10/1 to 2016/12/30. As WFM provides the predictions in district-level min-max range for the next 12 hours and DeepAir provide the predictions in station-level for each hour over the next 48 hours, we evaluate the prediction results in both hourly station level and 12-hour min-max district level. For hourly station-level, we split the predictions of WFM to hourly station-level by considering the average of min-max range; for district-level, we merge the predictions of DeepAir to district-level and get the min-max range for the next 12 hours. In both evaluation settings, DeepAir has a higher accuracy than WFM. In addition, DeepAir has a finer spatial and temporal granularity, a farther prediction period and a faster updating frequency. From the results, we can also find DeepAir has a good performance on 12-hour district-level min-max prediction, which means DeepAir is robust and general enough for other prediction settings.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.0902281254529953,
            -1.9391154050827026
        ],
        "MSU_id": 659
    },
    {
        "sentence": "For district-level, we merge the predictions of DeepAir to district-level and get the min-max range for the next 12 hours.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 132,
        "paper_id": 1,
        "paragraph_info": "Table 4 shows the comparison between DeepAir and WFM during the time span: 2014/10/1 to 2016/12/30. As WFM provides the predictions in district-level min-max range for the next 12 hours and DeepAir provide the predictions in station-level for each hour over the next 48 hours, we evaluate the prediction results in both hourly station level and 12-hour min-max district level. For hourly station-level, we split the predictions of WFM to hourly station-level by considering the average of min-max range; for district-level, we merge the predictions of DeepAir to district-level and get the min-max range for the next 12 hours. In both evaluation settings, DeepAir has a higher accuracy than WFM. In addition, DeepAir has a finer spatial and temporal granularity, a farther prediction period and a faster updating frequency. From the results, we can also find DeepAir has a good performance on 12-hour district-level min-max prediction, which means DeepAir is robust and general enough for other prediction settings.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.5943508148193359,
            -2.084202527999878
        ],
        "MSU_id": 660
    },
    {
        "sentence": "FFA trains four separate prediction models for modeling influential features respectively.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 133,
        "paper_id": 1,
        "paragraph_info": "Figure 8 shows the comparison between DeepAir and previous state-of-the-art online approach, FFA, in AirPollutionPrediction system on 9 major Chinese cities. In general, DeepAir can achieve an average accuracy of (81.1%, 63%, 46%) in (1-6h, 7-48h, sudden changes) for all cities. Comparing with FFA, our approach has a better performance in all nine cities, with 2.4%,  $12.2\\%,\\ 63.2\\%$  relative accuracy improvements on short-term, long-term and sudden changes prediction. The reason behind it is that FFA trains four separate prediction models for modeling influential features respectively, which may fail to capture the interactions among all factors. Also, FFA is a shallow method which cannot capture the underlying complex pattern of each factor. Moreover, the features in FFA is not strong enough as it ignores the dynamic change of weather forecasts.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.007846120744943619,
            -2.062324047088623
        ],
        "MSU_id": 670
    },
    {
        "sentence": "For neural network models, we run each of them 5 times.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 134,
        "paper_id": 1,
        "paragraph_info": "Table 3. Comparison with different baselines in Beijing. For neural network models, we run each of them 5 times and show \"mean  $\\pm$  standard deviation\".",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.899878203868866,
            -2.154160499572754
        ],
        "MSU_id": 675
    },
    {
        "sentence": "We show the results as 'mean \u00b1 standard deviation'.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 134,
        "paper_id": 1,
        "paragraph_info": "Table 3. Comparison with different baselines in Beijing. For neural network models, we run each of them 5 times and show \"mean  $\\pm$  standard deviation\".",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.7915277481079102,
            -1.538941502571106
        ],
        "MSU_id": 676
    },
    {
        "sentence": "With the signals from spatial neighbors, DeepAir can capture the dynamic changes of air quality.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 137,
        "paper_id": 1,
        "paragraph_info": "We show the effectiveness of our spatial transformation component (STC) in Table 5. Comparing with only using the air quality data from target station, DeepAir has a higher accuracy on general cases and sudden changes as air pollutants are dispersed in geographical space. With the signals from spatial neighbors, DeepAir can capture the dynamic changes of air quality. If we directly fed air quality readings from k-nearest stations (k=17, same size with STC) as inputs, the result is worse than STC. The reason behind it is each station has totally different k-nearest stations, while STC considers spatial correlations and generates a consistent input from eight directions. In STC, we find that inner & outer circles have a better performance than a single inner circle as it considers the signals from distant cities.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.89243084192276,
            -2.045565128326416
        ],
        "MSU_id": 681
    },
    {
        "sentence": "The embedding method captures the intra-dynamics of each factor.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 139,
        "paper_id": 1,
        "paragraph_info": "We show the effectiveness of embedding method in Table 7. After embedding, we can see a clear improvement on general cases and sudden changes after as it captures the intra-dynamics of each factor. Especially for direct factors, embedding can learn the spatio-temporal correlations of air pollution dispersion.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.3567076921463013,
            -1.865288257598877
        ],
        "MSU_id": 698
    },
    {
        "sentence": "Embedding can learn the spatio-temporal correlations of air pollution dispersion.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 139,
        "paper_id": 1,
        "paragraph_info": "We show the effectiveness of embedding method in Table 7. After embedding, we can see a clear improvement on general cases and sudden changes after as it captures the intra-dynamics of each factor. Especially for direct factors, embedding can learn the spatio-temporal correlations of air pollution dispersion.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.1198713779449463,
            -1.8390116691589355
        ],
        "MSU_id": 699
    },
    {
        "sentence": "Classical dispersion models identify the root cause of air pollution from chemical, emission, climatological and combinations of these factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 140,
        "paper_id": 1,
        "paragraph_info": "Air quality prediction methods mainly fall into two categories: classical dispersion models and data-driven models [23, 24]. Classical dispersion models identify the root cause of air pollution from chemical, emission, climatological and combinations of these factors. These models are most a numerical function of emissions from industry and vehicular, meteorology, and other factors. However, it is very difficult to get all these factors completely and accurately. Thus, the prediction accuracy is hard to be guaranteed. Also, the computation complexity is very high.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.41875895857810974,
            -0.40286874771118164
        ],
        "MSU_id": 701
    },
    {
        "sentence": "Classical dispersion models are a numerical function of emissions from industry and vehicular, meteorology, and other factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 140,
        "paper_id": 1,
        "paragraph_info": "Air quality prediction methods mainly fall into two categories: classical dispersion models and data-driven models [23, 24]. Classical dispersion models identify the root cause of air pollution from chemical, emission, climatological and combinations of these factors. These models are most a numerical function of emissions from industry and vehicular, meteorology, and other factors. However, it is very difficult to get all these factors completely and accurately. Thus, the prediction accuracy is hard to be guaranteed. Also, the computation complexity is very high.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.13323290646076202,
            -1.505592942237854
        ],
        "MSU_id": 702
    },
    {
        "sentence": "Zheng et al. proposed a multi-view-based hybrid model consisting of a temporal predictor, a spatial predictor, a dynamic aggregator, and an inflection predictor.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 141,
        "paper_id": 1,
        "paragraph_info": "Data-driven models, *e.g.* artificial neural networks, forecast air pollutions based on a variety of features. Recently, Zheng et al. proposed a multi-view-based hybrid model [7], consisting of a temporal predictor, a spatial predictor, a dynamic aggregator, and an inflection predictor. However, FFA is a shallow ensemble method, which may fail to capture complex interactions between influential factors. Also, the features used in FFA are not strong enough. Our DeepAir approach learns the air pollution patterns in a deep manner, simultaneously considering the individual and holistic influences, which is more capable of predicting general cases and sudden changes than FFA.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.3839588165283203,
            -1.8880549669265747
        ],
        "MSU_id": 707
    },
    {
        "sentence": "Our DeepAir approach learns the air pollution patterns in a deep manner.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 141,
        "paper_id": 1,
        "paragraph_info": "Data-driven models, *e.g.* artificial neural networks, forecast air pollutions based on a variety of features. Recently, Zheng et al. proposed a multi-view-based hybrid model [7], consisting of a temporal predictor, a spatial predictor, a dynamic aggregator, and an inflection predictor. However, FFA is a shallow ensemble method, which may fail to capture complex interactions between influential factors. Also, the features used in FFA are not strong enough. Our DeepAir approach learns the air pollution patterns in a deep manner, simultaneously considering the individual and holistic influences, which is more capable of predicting general cases and sudden changes than FFA.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.037283182144165,
            -1.7717578411102295
        ],
        "MSU_id": 710
    },
    {
        "sentence": "DeepAir simultaneously considers the individual and holistic influences.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 141,
        "paper_id": 1,
        "paragraph_info": "Data-driven models, *e.g.* artificial neural networks, forecast air pollutions based on a variety of features. Recently, Zheng et al. proposed a multi-view-based hybrid model [7], consisting of a temporal predictor, a spatial predictor, a dynamic aggregator, and an inflection predictor. However, FFA is a shallow ensemble method, which may fail to capture complex interactions between influential factors. Also, the features used in FFA are not strong enough. Our DeepAir approach learns the air pollution patterns in a deep manner, simultaneously considering the individual and holistic influences, which is more capable of predicting general cases and sudden changes than FFA.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            1.156696081161499,
            -1.6849054098129272
        ],
        "MSU_id": 711
    },
    {
        "sentence": "Song et al. proposed a recurrent neural network to simulate and predict human mobility.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 142,
        "paper_id": 1,
        "paragraph_info": "Currently, many works show the strength of DNN on solving spatio-temporal prediction problems. Song et al. proposed a recurrent neural network to simulate and predict human mobility [25]. To predict citywide crowd flows, Zhang et al. proposed a CNN-based network to extract features [13, 15, 16]. Yao et al. proposed a deep multi-view network to predict taxi demand based on CNN and LSTM [26]. Among these methods, CNN is wildly used for capturing spatial correlation and LSTM is used for modeling temporal dependency. In our task, we use DNN to learn the spatio-temporal correlations without CNN and LSTM due to the characteristics of air pollution. As air quality data is sparse in the spatial dimension, CNN is not suited for handling such sparse data. Another is air quality do not have strong temporal dependency as it is heavily affected by other factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.6797710657119751,
            -1.8398581743240356
        ],
        "MSU_id": 714
    },
    {
        "sentence": "Zhang et al. proposed a CNN-based network to extract features for predicting citywide crowd flows.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 142,
        "paper_id": 1,
        "paragraph_info": "Currently, many works show the strength of DNN on solving spatio-temporal prediction problems. Song et al. proposed a recurrent neural network to simulate and predict human mobility [25]. To predict citywide crowd flows, Zhang et al. proposed a CNN-based network to extract features [13, 15, 16]. Yao et al. proposed a deep multi-view network to predict taxi demand based on CNN and LSTM [26]. Among these methods, CNN is wildly used for capturing spatial correlation and LSTM is used for modeling temporal dependency. In our task, we use DNN to learn the spatio-temporal correlations without CNN and LSTM due to the characteristics of air pollution. As air quality data is sparse in the spatial dimension, CNN is not suited for handling such sparse data. Another is air quality do not have strong temporal dependency as it is heavily affected by other factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.9596341848373413,
            -1.6647597551345825
        ],
        "MSU_id": 715
    },
    {
        "sentence": "Yao et al. proposed a deep multi-view network to predict taxi demand based on CNN and LSTM.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 142,
        "paper_id": 1,
        "paragraph_info": "Currently, many works show the strength of DNN on solving spatio-temporal prediction problems. Song et al. proposed a recurrent neural network to simulate and predict human mobility [25]. To predict citywide crowd flows, Zhang et al. proposed a CNN-based network to extract features [13, 15, 16]. Yao et al. proposed a deep multi-view network to predict taxi demand based on CNN and LSTM [26]. Among these methods, CNN is wildly used for capturing spatial correlation and LSTM is used for modeling temporal dependency. In our task, we use DNN to learn the spatio-temporal correlations without CNN and LSTM due to the characteristics of air pollution. As air quality data is sparse in the spatial dimension, CNN is not suited for handling such sparse data. Another is air quality do not have strong temporal dependency as it is heavily affected by other factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.4827719926834106,
            -1.7152959108352661
        ],
        "MSU_id": 716
    },
    {
        "sentence": "We use DNN to learn the spatio-temporal correlations without CNN and LSTM due to the characteristics of air pollution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 142,
        "paper_id": 1,
        "paragraph_info": "Currently, many works show the strength of DNN on solving spatio-temporal prediction problems. Song et al. proposed a recurrent neural network to simulate and predict human mobility [25]. To predict citywide crowd flows, Zhang et al. proposed a CNN-based network to extract features [13, 15, 16]. Yao et al. proposed a deep multi-view network to predict taxi demand based on CNN and LSTM [26]. Among these methods, CNN is wildly used for capturing spatial correlation and LSTM is used for modeling temporal dependency. In our task, we use DNN to learn the spatio-temporal correlations without CNN and LSTM due to the characteristics of air pollution. As air quality data is sparse in the spatial dimension, CNN is not suited for handling such sparse data. Another is air quality do not have strong temporal dependency as it is heavily affected by other factors.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -1.4358952045440674,
            -2.043257236480713
        ],
        "MSU_id": 719
    },
    {
        "sentence": "Simple methods for fusing cross-domain data by DNN directly concatenate all features together.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 143,
        "paper_id": 1,
        "paragraph_info": "For fusing cross-domain data by DNN, simple methods directly concatenate all features together. Recently, Wang et al. adapted a sequential fusion architecture, which fuses two features firstly, then fuses some new features in the same manner iteratively in a sequence [22]. However, sequential fusion need design the order of fusion sequence, which costs lots of time for tuning. Our DeepAir adapts a distributed fusion architecture to learn the feature interactions by enhancing main feature interacting with auxiliary features respectively, which is derived from domain knowledge as each indirect factor will have an individual effect on direct factors affecting future air quality.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.0625493973493576,
            -2.188781261444092
        ],
        "MSU_id": 722
    },
    {
        "sentence": "Wang et al. adapted a sequential fusion architecture, which fuses two features firstly, then fuses some new features in the same manner iteratively in a sequence.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 143,
        "paper_id": 1,
        "paragraph_info": "For fusing cross-domain data by DNN, simple methods directly concatenate all features together. Recently, Wang et al. adapted a sequential fusion architecture, which fuses two features firstly, then fuses some new features in the same manner iteratively in a sequence [22]. However, sequential fusion need design the order of fusion sequence, which costs lots of time for tuning. Our DeepAir adapts a distributed fusion architecture to learn the feature interactions by enhancing main feature interacting with auxiliary features respectively, which is derived from domain knowledge as each indirect factor will have an individual effect on direct factors affecting future air quality.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            -0.06374512612819672,
            -2.0773282051086426
        ],
        "MSU_id": 723
    },
    {
        "sentence": "Our DeepAir adapts a distributed fusion architecture to learn the feature interactions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 143,
        "paper_id": 1,
        "paragraph_info": "For fusing cross-domain data by DNN, simple methods directly concatenate all features together. Recently, Wang et al. adapted a sequential fusion architecture, which fuses two features firstly, then fuses some new features in the same manner iteratively in a sequence [22]. However, sequential fusion need design the order of fusion sequence, which costs lots of time for tuning. Our DeepAir adapts a distributed fusion architecture to learn the feature interactions by enhancing main feature interacting with auxiliary features respectively, which is derived from domain knowledge as each indirect factor will have an individual effect on direct factors affecting future air quality.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.6541473269462585,
            -2.0961737632751465
        ],
        "MSU_id": 725
    },
    {
        "sentence": "DeepAir enhances the main feature interacting with auxiliary features respectively.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 143,
        "paper_id": 1,
        "paragraph_info": "For fusing cross-domain data by DNN, simple methods directly concatenate all features together. Recently, Wang et al. adapted a sequential fusion architecture, which fuses two features firstly, then fuses some new features in the same manner iteratively in a sequence [22]. However, sequential fusion need design the order of fusion sequence, which costs lots of time for tuning. Our DeepAir adapts a distributed fusion architecture to learn the feature interactions by enhancing main feature interacting with auxiliary features respectively, which is derived from domain knowledge as each indirect factor will have an individual effect on direct factors affecting future air quality.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8378098607063293,
            -1.9806982278823853
        ],
        "MSU_id": 726
    },
    {
        "sentence": "We propose a DNN-based approach to predict air quality.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 144,
        "paper_id": 1,
        "paragraph_info": "In this paper, we propose a DNN-based approach to predict air quality. Based on the domain knowledge about air pollution, we adopt a novel distributed fusion architecture to fuse heterogeneous urban data, which can simultaneously capture the individual and holistic effects from all influential factors affecting air quality. Comparing with 10 baselines with three-year data from 9 Chinese cities, our approach achieves a higher accuracy in both general cases and sudden changes. We have deployed DeepAir in AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. Comparing with the previous online approach in the system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.8955883383750916,
            -1.8739088773727417
        ],
        "MSU_id": 729
    },
    {
        "sentence": "We adopt a novel distributed fusion architecture to fuse heterogeneous urban data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 144,
        "paper_id": 1,
        "paragraph_info": "In this paper, we propose a DNN-based approach to predict air quality. Based on the domain knowledge about air pollution, we adopt a novel distributed fusion architecture to fuse heterogeneous urban data, which can simultaneously capture the individual and holistic effects from all influential factors affecting air quality. Comparing with 10 baselines with three-year data from 9 Chinese cities, our approach achieves a higher accuracy in both general cases and sudden changes. We have deployed DeepAir in AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. Comparing with the previous online approach in the system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.4997853636741638,
            -2.167386531829834
        ],
        "MSU_id": 730
    },
    {
        "sentence": "We have deployed DeepAir in the AirPollutionPrediction system.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 144,
        "paper_id": 1,
        "paragraph_info": "In this paper, we propose a DNN-based approach to predict air quality. Based on the domain knowledge about air pollution, we adopt a novel distributed fusion architecture to fuse heterogeneous urban data, which can simultaneously capture the individual and holistic effects from all influential factors affecting air quality. Comparing with 10 baselines with three-year data from 9 Chinese cities, our approach achieves a higher accuracy in both general cases and sudden changes. We have deployed DeepAir in AirPollutionPrediction system, providing fine-grained air quality forecasts for 300+ Chinese cities every hour. Comparing with the previous online approach in the system, we have 2.4%, 12.2%, 63.2% relative accuracy improvements on short-term, long-term and sudden changes prediction, respectively.",
        "paper_info": "3219819.3219822",
        "2d_coord": [
            0.912135899066925,
            -2.1931018829345703
        ],
        "MSU_id": 734
    },
    {
        "sentence": "We conducted a continuous 2-month measurement campaign with state-of-the-art instruments to elucidate the NPF and growth mechanisms in northern Italy.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 150,
        "paper_id": 2,
        "paragraph_info": "**Abstract.** New particle formation (NPF) is a major source of aerosol particles and cloud condensation nuclei in the troposphere, playing an important role in both air quality and climate. Frequent NPF events have been observed in heavily polluted urban environments, contributing to the aerosol number concentration by a significant amount. The Po Valley region in northern Italy has been characterized as a hotspot for high aerosol loadings and frequent NPF events in southern Europe. However, the mechanisms of NPF and growth in this region are not completely understood. In this study, we conducted a continuous 2-month measurement campaign with stateof-the-art instruments to elucidate the NPF and growth mechanisms in northern Italy. Our results demonstrate that frequent NPF events (66% of all days during the measurement campaign) are primarily driven by abundant sulfuric acid  $(8.5 \\times 10^6 \\text{ cm}^{-3})$  and basic molecules in this area. In contrast, oxygenated organic molecules from the atmospheric oxidation of volatile organic compounds (VOCs) appear to play a minor role in the initial cluster formation but contribute significantly to the consecutive growth process. Regarding alkaline molecules, amines are insufficient to stabilize all sulfuric acid clusters in the Po Valley. Ion cluster measurements and kinetic models suggest that ammonia (10 ppb) must therefore also play a role in the nucleation process. Generally, the high formation rates of sub-2 nm particles  $(87 \\text{ cm}^{-3} \\text{ s}^{-1})$  and nucleation-mode growth rates  $(5.1 \\text{ nm h}^{-1})$  as well as the relatively low condensational sink  $(8.9 \\times 10^{-3} \\text{ s}^{-1})$  will result in a high survival probability for newly formed particles, making NPF crucial for the springtime aerosol number budget. Our results also indicate that reducing key pollutants, such as  $SO_2$ , amine and  $NH_3$ , could help to substantially decrease the particle number concentrations in the Po Valley region.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.4771156311035156,
            0.48925238847732544
        ],
        "MSU_id": 743
    },
    {
        "sentence": "State-of-the-art instruments are capable of measuring size distributions down to $1-2 \text{ nm}$ and directly identifying clusters and vapors.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 154,
        "paper_id": 2,
        "paragraph_info": "frequent high pollution levels, NPF has been reported to be associated with SA along with highly oxygenated organic molecules (HOMs) (Brean et al., 2020). These discrepancies in the reported NPF mechanisms may arise from the limited utilization of state-of-the-art instruments, such as those capable of measuring size distributions down to  $1-2 \\text{ nm}$  as well as directly identifying clusters and vapors, which are influenced by spatiotemporal variations (Wang et al., 2017). Therefore, gaining a better knowledge of the key participants, nucleation mechanisms and roles of pre-existing particles is crucial for comprehending the causes of the high NPF frequencies in polluted regions. This knowledge can be essential for developing effective local  $PM_{2.5}$  control and implementation strategies.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.7310644388198853,
            0.19540265202522278
        ],
        "MSU_id": 778
    },
    {
        "sentence": "We identified the chemical composition of atmospheric neutral and ion clusters using a set of state-of-the-art mass spectrometers.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 156,
        "paper_id": 2,
        "paragraph_info": "While previous studies conducted in the Po Valley have reported frequent NPF events characterized by high nucleation and growth rates, the clustering mechanism and the dominant precursors for particle growth have not been investigated to date. Specifically with respect to the distinct features of the Po Valley compared with the more intensely researched megacity environments, a deeper understanding of frequent NPF events, including their precursors, nucleation mechanisms and growth processes, is crucial for air pollution control and the effective implementation of  $PM_{2.5}$  mitigation measures in such a semi-urban but highly industrialized region. In this study, we conducted a 2-month field campaign in the months of March and April 2022. During this field campaign, we  $(1)$  identified the chemical composition of atmospheric neutral and ion clusters using a set of state-ofthe-art mass spectrometers,  $(2)$  characterized the initial NPF and further growth rates using particle number size distribution measurements down to  $1 \\text{ nm}$ , and (3) compared the field measurement results with the recent Cosmics Leaving Outdoor Droplets (CLOUD) chamber experiments to investigate the mechanism of NPF events in the Po Valley region. This allowed us to elucidate the NPF and growth mechanisms at a polluted southern European site and to give insights into the best mitigation strategies for ultrafine particle pollution in the context of already implemented  $PM_{2.5}$  reduction strategies.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.9470014572143555,
            -0.5636823773384094
        ],
        "MSU_id": 800
    },
    {
        "sentence": "We characterized the initial NPF and further growth rates using particle number size distribution measurements down to 1 nm.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 156,
        "paper_id": 2,
        "paragraph_info": "While previous studies conducted in the Po Valley have reported frequent NPF events characterized by high nucleation and growth rates, the clustering mechanism and the dominant precursors for particle growth have not been investigated to date. Specifically with respect to the distinct features of the Po Valley compared with the more intensely researched megacity environments, a deeper understanding of frequent NPF events, including their precursors, nucleation mechanisms and growth processes, is crucial for air pollution control and the effective implementation of  $PM_{2.5}$  mitigation measures in such a semi-urban but highly industrialized region. In this study, we conducted a 2-month field campaign in the months of March and April 2022. During this field campaign, we  $(1)$  identified the chemical composition of atmospheric neutral and ion clusters using a set of state-ofthe-art mass spectrometers,  $(2)$  characterized the initial NPF and further growth rates using particle number size distribution measurements down to  $1 \\text{ nm}$ , and (3) compared the field measurement results with the recent Cosmics Leaving Outdoor Droplets (CLOUD) chamber experiments to investigate the mechanism of NPF events in the Po Valley region. This allowed us to elucidate the NPF and growth mechanisms at a polluted southern European site and to give insights into the best mitigation strategies for ultrafine particle pollution in the context of already implemented  $PM_{2.5}$  reduction strategies.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.6690360307693481,
            0.48505735397338867
        ],
        "MSU_id": 801
    },
    {
        "sentence": "We compared the field measurement results with the recent Cosmics Leaving Outdoor Droplets (CLOUD) chamber experiments.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 156,
        "paper_id": 2,
        "paragraph_info": "While previous studies conducted in the Po Valley have reported frequent NPF events characterized by high nucleation and growth rates, the clustering mechanism and the dominant precursors for particle growth have not been investigated to date. Specifically with respect to the distinct features of the Po Valley compared with the more intensely researched megacity environments, a deeper understanding of frequent NPF events, including their precursors, nucleation mechanisms and growth processes, is crucial for air pollution control and the effective implementation of  $PM_{2.5}$  mitigation measures in such a semi-urban but highly industrialized region. In this study, we conducted a 2-month field campaign in the months of March and April 2022. During this field campaign, we  $(1)$  identified the chemical composition of atmospheric neutral and ion clusters using a set of state-ofthe-art mass spectrometers,  $(2)$  characterized the initial NPF and further growth rates using particle number size distribution measurements down to  $1 \\text{ nm}$ , and (3) compared the field measurement results with the recent Cosmics Leaving Outdoor Droplets (CLOUD) chamber experiments to investigate the mechanism of NPF events in the Po Valley region. This allowed us to elucidate the NPF and growth mechanisms at a polluted southern European site and to give insights into the best mitigation strategies for ultrafine particle pollution in the context of already implemented  $PM_{2.5}$  reduction strategies.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.9958083629608154,
            -0.13794052600860596
        ],
        "MSU_id": 802
    },
    {
        "sentence": "The instruments for the NPF measurement were operated in a temperature-controlled container from 1 March to 30 April 2022.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 157,
        "paper_id": 2,
        "paragraph_info": "Our measurement was part of the Fog and Aerosol InterRAction Research Italy (FAIRARI) field campaign in San Pietro Capofiume (SPC; 44.65\u00b0 N, 11.62\u00b0 E; 5 m a.s.l., meters above sea level), located in the Po Valley region in northern Italy. The measurement site is part of the Aerosol, Clouds and Trace Gases Research Infrastructure (ACTRIS) Italy network and is operated by the National Research Council of Italy -Institute of Atmospheric Sciences and Climate (CNR-ISAC). The SPC site is approximately 30 km northeast of Bologna (population of  $\\sim 400000$ ) and 20 km south of Ferrara (population of  $\\sim 130000$ ), the two major cities in the area. The distance from the measurement site to the Adriatic Sea (to the east) is about  $50 \\,\\mathrm{km}$ . The area around the sampling site consists of agricultural fields, a smaller town (population of  $< 2000$ , within 5 km) and smaller settlements in close proximity. Given its location, the SPC rural station is considered to be representative of the regional background of the Po Valley (Paglione et al., 2020, 2021; Paasonen et al., 2010; Hamed et al., 2007; Saarikoski et al., 2012; Decesari et al., 2014). The instruments for the NPF measurement were operated in a temperature-controlled ( $\\sim 20 \\,^{\\circ}\\text{C}$ ) container from 1 March to 30 April 2022.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.3882670402526855,
            0.43580371141433716
        ],
        "MSU_id": 811
    },
    {
        "sentence": "The chemical composition of cluster ions was measured using a high-resolution atmospheric-pressure-interface time-of-flight mass spectrometer (APi-ToF, Aerodyne Research Inc. and Tofwerk AG).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 159,
        "paper_id": 2,
        "paragraph_info": "The chemical composition of cluster ions was measured using a high-resolution atmospheric-pressure-interface timeof-flight mass spectrometer (APi-ToF, Aerodyne Research Inc. and Tofwerk AG). The APi-ToF measures naturally charged ions in the ambient environment. A detailed description of the instrument can be found in Junninen et al.  $(2010)$ . In this study, ambient air was sampled through a 0.57 m stainless-steel tube with a flow rate of  $\\sim 10 \\, \\text{L} \\, \\text{min}^{-1}$  (LPM), with 0.8 LPM of the sample flow entering the APi-ToF.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            2.0147347450256348,
            -0.2909088134765625
        ],
        "MSU_id": 822
    },
    {
        "sentence": "The APi-ToF measures naturally charged ions in the ambient environment.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 159,
        "paper_id": 2,
        "paragraph_info": "The chemical composition of cluster ions was measured using a high-resolution atmospheric-pressure-interface timeof-flight mass spectrometer (APi-ToF, Aerodyne Research Inc. and Tofwerk AG). The APi-ToF measures naturally charged ions in the ambient environment. A detailed description of the instrument can be found in Junninen et al.  $(2010)$ . In this study, ambient air was sampled through a 0.57 m stainless-steel tube with a flow rate of  $\\sim 10 \\, \\text{L} \\, \\text{min}^{-1}$  (LPM), with 0.8 LPM of the sample flow entering the APi-ToF.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.5420846939086914,
            0.35699668526649475
        ],
        "MSU_id": 823
    },
    {
        "sentence": "In this study, ambient air was sampled through a 0.57 m stainless-steel tube.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 159,
        "paper_id": 2,
        "paragraph_info": "The chemical composition of cluster ions was measured using a high-resolution atmospheric-pressure-interface timeof-flight mass spectrometer (APi-ToF, Aerodyne Research Inc. and Tofwerk AG). The APi-ToF measures naturally charged ions in the ambient environment. A detailed description of the instrument can be found in Junninen et al.  $(2010)$ . In this study, ambient air was sampled through a 0.57 m stainless-steel tube with a flow rate of  $\\sim 10 \\, \\text{L} \\, \\text{min}^{-1}$  (LPM), with 0.8 LPM of the sample flow entering the APi-ToF.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.0616072416305542,
            0.49539029598236084
        ],
        "MSU_id": 824
    },
    {
        "sentence": "The flow rate of the sampling was approximately 10 L min^-1 (LPM).",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 159,
        "paper_id": 2,
        "paragraph_info": "The chemical composition of cluster ions was measured using a high-resolution atmospheric-pressure-interface timeof-flight mass spectrometer (APi-ToF, Aerodyne Research Inc. and Tofwerk AG). The APi-ToF measures naturally charged ions in the ambient environment. A detailed description of the instrument can be found in Junninen et al.  $(2010)$ . In this study, ambient air was sampled through a 0.57 m stainless-steel tube with a flow rate of  $\\sim 10 \\, \\text{L} \\, \\text{min}^{-1}$  (LPM), with 0.8 LPM of the sample flow entering the APi-ToF.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.05194086953997612,
            0.8232036828994751
        ],
        "MSU_id": 825
    },
    {
        "sentence": "0.8 LPM of the sample flow entered the APi-ToF.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 159,
        "paper_id": 2,
        "paragraph_info": "The chemical composition of cluster ions was measured using a high-resolution atmospheric-pressure-interface timeof-flight mass spectrometer (APi-ToF, Aerodyne Research Inc. and Tofwerk AG). The APi-ToF measures naturally charged ions in the ambient environment. A detailed description of the instrument can be found in Junninen et al.  $(2010)$ . In this study, ambient air was sampled through a 0.57 m stainless-steel tube with a flow rate of  $\\sim 10 \\, \\text{L} \\, \\text{min}^{-1}$  (LPM), with 0.8 LPM of the sample flow entering the APi-ToF.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.8626844882965088,
            -0.8083402514457703
        ],
        "MSU_id": 826
    },
    {
        "sentence": "The concentration of SA was measured using a nitrate-ion-based chemical-ionization atmospheric-pressure-interface time-of-flight mass spectrometer.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 160,
        "paper_id": 2,
        "paragraph_info": "The concentration of SA was measured using a nitrate-ionbased ( $NO_3^-$ -based) chemical-ionization (CI) atmosphericpressure-interface time-of-flight mass spectrometer (CI-APi-ToF, Aerodyne Research Inc. and Tofwerk AG; Jokinen et al., 2012). The CI-APi-ToF is an APi-ToF coupled with a CI unit, equipped with a soft X-ray source (L9490, Hamamatsu Photonics,  $9.5 \\,\\mathrm{kV}$ ) to produce the primary ions. The sampling flow went into the instrument through a  $\\sim 0.6 \\text{ m } (0.75 \\text{ in.})$ stainless-steel tube. The sampling flow was 10 LPM and the sheath flow was set to 20 LPM. Data acquisition for CI-APi-ToF was performed with a time resolution of 10 s. A calibration factor of  $1.0 \\times 10^{10} \\text{ cm}^{-3}$  for SA was determined with sampling loss corrections before the campaign according to the method proposed by Kurten et al. (2012).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.743177890777588,
            0.05994356423616409
        ],
        "MSU_id": 828
    },
    {
        "sentence": "The CI-APi-ToF is an APi-ToF coupled with a CI unit, equipped with a soft X-ray source to produce the primary ions.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 160,
        "paper_id": 2,
        "paragraph_info": "The concentration of SA was measured using a nitrate-ionbased ( $NO_3^-$ -based) chemical-ionization (CI) atmosphericpressure-interface time-of-flight mass spectrometer (CI-APi-ToF, Aerodyne Research Inc. and Tofwerk AG; Jokinen et al., 2012). The CI-APi-ToF is an APi-ToF coupled with a CI unit, equipped with a soft X-ray source (L9490, Hamamatsu Photonics,  $9.5 \\,\\mathrm{kV}$ ) to produce the primary ions. The sampling flow went into the instrument through a  $\\sim 0.6 \\text{ m } (0.75 \\text{ in.})$ stainless-steel tube. The sampling flow was 10 LPM and the sheath flow was set to 20 LPM. Data acquisition for CI-APi-ToF was performed with a time resolution of 10 s. A calibration factor of  $1.0 \\times 10^{10} \\text{ cm}^{-3}$  for SA was determined with sampling loss corrections before the campaign according to the method proposed by Kurten et al. (2012).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.8412294387817383,
            -0.04012680798768997
        ],
        "MSU_id": 829
    },
    {
        "sentence": "The sampling flow went into the instrument through a stainless-steel tube.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 160,
        "paper_id": 2,
        "paragraph_info": "The concentration of SA was measured using a nitrate-ionbased ( $NO_3^-$ -based) chemical-ionization (CI) atmosphericpressure-interface time-of-flight mass spectrometer (CI-APi-ToF, Aerodyne Research Inc. and Tofwerk AG; Jokinen et al., 2012). The CI-APi-ToF is an APi-ToF coupled with a CI unit, equipped with a soft X-ray source (L9490, Hamamatsu Photonics,  $9.5 \\,\\mathrm{kV}$ ) to produce the primary ions. The sampling flow went into the instrument through a  $\\sim 0.6 \\text{ m } (0.75 \\text{ in.})$ stainless-steel tube. The sampling flow was 10 LPM and the sheath flow was set to 20 LPM. Data acquisition for CI-APi-ToF was performed with a time resolution of 10 s. A calibration factor of  $1.0 \\times 10^{10} \\text{ cm}^{-3}$  for SA was determined with sampling loss corrections before the campaign according to the method proposed by Kurten et al. (2012).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.0056257247924805,
            0.6966823935508728
        ],
        "MSU_id": 830
    },
    {
        "sentence": "The sampling flow was 10 LPM and the sheath flow was set to 20 LPM.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 160,
        "paper_id": 2,
        "paragraph_info": "The concentration of SA was measured using a nitrate-ionbased ( $NO_3^-$ -based) chemical-ionization (CI) atmosphericpressure-interface time-of-flight mass spectrometer (CI-APi-ToF, Aerodyne Research Inc. and Tofwerk AG; Jokinen et al., 2012). The CI-APi-ToF is an APi-ToF coupled with a CI unit, equipped with a soft X-ray source (L9490, Hamamatsu Photonics,  $9.5 \\,\\mathrm{kV}$ ) to produce the primary ions. The sampling flow went into the instrument through a  $\\sim 0.6 \\text{ m } (0.75 \\text{ in.})$ stainless-steel tube. The sampling flow was 10 LPM and the sheath flow was set to 20 LPM. Data acquisition for CI-APi-ToF was performed with a time resolution of 10 s. A calibration factor of  $1.0 \\times 10^{10} \\text{ cm}^{-3}$  for SA was determined with sampling loss corrections before the campaign according to the method proposed by Kurten et al. (2012).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.950498104095459,
            0.768811047077179
        ],
        "MSU_id": 831
    },
    {
        "sentence": "Data acquisition for CI-APi-ToF was performed with a time resolution of 10 s.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 160,
        "paper_id": 2,
        "paragraph_info": "The concentration of SA was measured using a nitrate-ionbased ( $NO_3^-$ -based) chemical-ionization (CI) atmosphericpressure-interface time-of-flight mass spectrometer (CI-APi-ToF, Aerodyne Research Inc. and Tofwerk AG; Jokinen et al., 2012). The CI-APi-ToF is an APi-ToF coupled with a CI unit, equipped with a soft X-ray source (L9490, Hamamatsu Photonics,  $9.5 \\,\\mathrm{kV}$ ) to produce the primary ions. The sampling flow went into the instrument through a  $\\sim 0.6 \\text{ m } (0.75 \\text{ in.})$ stainless-steel tube. The sampling flow was 10 LPM and the sheath flow was set to 20 LPM. Data acquisition for CI-APi-ToF was performed with a time resolution of 10 s. A calibration factor of  $1.0 \\times 10^{10} \\text{ cm}^{-3}$  for SA was determined with sampling loss corrections before the campaign according to the method proposed by Kurten et al. (2012).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.5854239463806152,
            -0.6480153203010559
        ],
        "MSU_id": 832
    },
    {
        "sentence": "The focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a pressure of 2.0 mbar.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 161,
        "paper_id": 2,
        "paragraph_info": "Dimethylamine (DMA) measurements were performed with a Vocus CI-ToF (time-of-flight) mass spectrometer (hereafter Vocus, Aerodyne Research Inc. and Tofwerk AG) using  $H_3O^+$  as a reagent ion. The Vocus has been described in detail in Krechmer et al. (2018), and the study by Wang et al. (2020) utilized a Vocus instrument for DMA observations. In this study, the focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a pressure of 2.0 mbar and a temperature of 100\u00b0C with a radio frequency amplitude of 350 V and a frequency of  $1.4 \\times 10^6$  Hz. Data acquisition was performed with a time resolution of  $10 \\text{ s}$  in the atomic mass unit range of  $0-1000$  amu.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.764772653579712,
            0.02243833988904953
        ],
        "MSU_id": 837
    },
    {
        "sentence": "The focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a temperature of 100\u00b0C.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 161,
        "paper_id": 2,
        "paragraph_info": "Dimethylamine (DMA) measurements were performed with a Vocus CI-ToF (time-of-flight) mass spectrometer (hereafter Vocus, Aerodyne Research Inc. and Tofwerk AG) using  $H_3O^+$  as a reagent ion. The Vocus has been described in detail in Krechmer et al. (2018), and the study by Wang et al. (2020) utilized a Vocus instrument for DMA observations. In this study, the focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a pressure of 2.0 mbar and a temperature of 100\u00b0C with a radio frequency amplitude of 350 V and a frequency of  $1.4 \\times 10^6$  Hz. Data acquisition was performed with a time resolution of  $10 \\text{ s}$  in the atomic mass unit range of  $0-1000$  amu.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.6073815822601318,
            0.26357731223106384
        ],
        "MSU_id": 838
    },
    {
        "sentence": "The focusing ion-molecule reactor (FIMR) of the Vocus instrument operated with a radio frequency amplitude of 350 V.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 161,
        "paper_id": 2,
        "paragraph_info": "Dimethylamine (DMA) measurements were performed with a Vocus CI-ToF (time-of-flight) mass spectrometer (hereafter Vocus, Aerodyne Research Inc. and Tofwerk AG) using  $H_3O^+$  as a reagent ion. The Vocus has been described in detail in Krechmer et al. (2018), and the study by Wang et al. (2020) utilized a Vocus instrument for DMA observations. In this study, the focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a pressure of 2.0 mbar and a temperature of 100\u00b0C with a radio frequency amplitude of 350 V and a frequency of  $1.4 \\times 10^6$  Hz. Data acquisition was performed with a time resolution of  $10 \\text{ s}$  in the atomic mass unit range of  $0-1000$  amu.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.6642290353775024,
            0.11669974774122238
        ],
        "MSU_id": 839
    },
    {
        "sentence": "The focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a frequency of $1.4 \times 10^6$ Hz.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 161,
        "paper_id": 2,
        "paragraph_info": "Dimethylamine (DMA) measurements were performed with a Vocus CI-ToF (time-of-flight) mass spectrometer (hereafter Vocus, Aerodyne Research Inc. and Tofwerk AG) using  $H_3O^+$  as a reagent ion. The Vocus has been described in detail in Krechmer et al. (2018), and the study by Wang et al. (2020) utilized a Vocus instrument for DMA observations. In this study, the focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a pressure of 2.0 mbar and a temperature of 100\u00b0C with a radio frequency amplitude of 350 V and a frequency of  $1.4 \\times 10^6$  Hz. Data acquisition was performed with a time resolution of  $10 \\text{ s}$  in the atomic mass unit range of  $0-1000$  amu.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.7020184993743896,
            -0.00413040816783905
        ],
        "MSU_id": 840
    },
    {
        "sentence": "Data acquisition was performed with a time resolution of $10 \text{ s}$ in the atomic mass unit range of $0-1000$ amu.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 161,
        "paper_id": 2,
        "paragraph_info": "Dimethylamine (DMA) measurements were performed with a Vocus CI-ToF (time-of-flight) mass spectrometer (hereafter Vocus, Aerodyne Research Inc. and Tofwerk AG) using  $H_3O^+$  as a reagent ion. The Vocus has been described in detail in Krechmer et al. (2018), and the study by Wang et al. (2020) utilized a Vocus instrument for DMA observations. In this study, the focusing ion-molecule reactor (FIMR) of the Vocus instrument operated at a pressure of 2.0 mbar and a temperature of 100\u00b0C with a radio frequency amplitude of 350 V and a frequency of  $1.4 \\times 10^6$  Hz. Data acquisition was performed with a time resolution of  $10 \\text{ s}$  in the atomic mass unit range of  $0-1000$  amu.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.5657093524932861,
            -0.6377871632575989
        ],
        "MSU_id": 841
    },
    {
        "sentence": "The Airmodus A11 nano-CNC system is capable of measuring particle size distributions of sub-3 nm particles.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 162,
        "paper_id": 2,
        "paragraph_info": "The Airmodus A11 nano-CNC (nano condensation nucleus counter) system, colloquially known as the particle size magnifier (PSM), is a two-step condensation particle counter (CPC) capable of measuring particle size distributions of sub-3 nm particles (Vanhanen et al., 2011). The sys-",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.8752915859222412,
            -0.06553881615400314
        ],
        "MSU_id": 843
    },
    {
        "sentence": "The PSM (Airmodus A10) acts as a preconditioner where particles are grown first.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 165,
        "paper_id": 2,
        "paragraph_info": "tem consists of two parts, in which the PSM (Airmodus A10) acts as a preconditioner where particles are grown first before being funneled to the CPC (Airmodus A20) for further growth and optical detection. In the PSM, the sample flow is turbulently mixed with a heated flow saturated with diethylene glycol (DEG) in the mixing section, and the DEG then condenses on the particles in the growth tube. By scanning the flow rate through the DEG saturator, the smallest activated particle size is altered which can be converted into a sub-3 nm particle size distribution. Further particle growth is achieved by butanol in the CPC such that the particles reach optically detectable sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.55953049659729,
            0.1799176037311554
        ],
        "MSU_id": 851
    },
    {
        "sentence": "Particles are funneled to the CPC (Airmodus A20) for further growth and optical detection.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 165,
        "paper_id": 2,
        "paragraph_info": "tem consists of two parts, in which the PSM (Airmodus A10) acts as a preconditioner where particles are grown first before being funneled to the CPC (Airmodus A20) for further growth and optical detection. In the PSM, the sample flow is turbulently mixed with a heated flow saturated with diethylene glycol (DEG) in the mixing section, and the DEG then condenses on the particles in the growth tube. By scanning the flow rate through the DEG saturator, the smallest activated particle size is altered which can be converted into a sub-3 nm particle size distribution. Further particle growth is achieved by butanol in the CPC such that the particles reach optically detectable sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.1710128784179688,
            0.7110111713409424
        ],
        "MSU_id": 852
    },
    {
        "sentence": "In the PSM, the sample flow is turbulently mixed with a heated flow saturated with diethylene glycol (DEG) in the mixing section.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 165,
        "paper_id": 2,
        "paragraph_info": "tem consists of two parts, in which the PSM (Airmodus A10) acts as a preconditioner where particles are grown first before being funneled to the CPC (Airmodus A20) for further growth and optical detection. In the PSM, the sample flow is turbulently mixed with a heated flow saturated with diethylene glycol (DEG) in the mixing section, and the DEG then condenses on the particles in the growth tube. By scanning the flow rate through the DEG saturator, the smallest activated particle size is altered which can be converted into a sub-3 nm particle size distribution. Further particle growth is achieved by butanol in the CPC such that the particles reach optically detectable sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.3962368965148926,
            0.36088210344314575
        ],
        "MSU_id": 853
    },
    {
        "sentence": "The DEG condenses on the particles in the growth tube.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 165,
        "paper_id": 2,
        "paragraph_info": "tem consists of two parts, in which the PSM (Airmodus A10) acts as a preconditioner where particles are grown first before being funneled to the CPC (Airmodus A20) for further growth and optical detection. In the PSM, the sample flow is turbulently mixed with a heated flow saturated with diethylene glycol (DEG) in the mixing section, and the DEG then condenses on the particles in the growth tube. By scanning the flow rate through the DEG saturator, the smallest activated particle size is altered which can be converted into a sub-3 nm particle size distribution. Further particle growth is achieved by butanol in the CPC such that the particles reach optically detectable sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.1404967308044434,
            0.8466376066207886
        ],
        "MSU_id": 854
    },
    {
        "sentence": "By scanning the flow rate through the DEG saturator, the smallest activated particle size is altered.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 165,
        "paper_id": 2,
        "paragraph_info": "tem consists of two parts, in which the PSM (Airmodus A10) acts as a preconditioner where particles are grown first before being funneled to the CPC (Airmodus A20) for further growth and optical detection. In the PSM, the sample flow is turbulently mixed with a heated flow saturated with diethylene glycol (DEG) in the mixing section, and the DEG then condenses on the particles in the growth tube. By scanning the flow rate through the DEG saturator, the smallest activated particle size is altered which can be converted into a sub-3 nm particle size distribution. Further particle growth is achieved by butanol in the CPC such that the particles reach optically detectable sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.689347267150879,
            0.0887138769030571
        ],
        "MSU_id": 855
    },
    {
        "sentence": "Further particle growth is achieved by butanol in the CPC.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 165,
        "paper_id": 2,
        "paragraph_info": "tem consists of two parts, in which the PSM (Airmodus A10) acts as a preconditioner where particles are grown first before being funneled to the CPC (Airmodus A20) for further growth and optical detection. In the PSM, the sample flow is turbulently mixed with a heated flow saturated with diethylene glycol (DEG) in the mixing section, and the DEG then condenses on the particles in the growth tube. By scanning the flow rate through the DEG saturator, the smallest activated particle size is altered which can be converted into a sub-3 nm particle size distribution. Further particle growth is achieved by butanol in the CPC such that the particles reach optically detectable sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.0513312816619873,
            0.8726050853729248
        ],
        "MSU_id": 857
    },
    {
        "sentence": "The PSM was calibrated according to the standard operation procedure for PSM.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 166,
        "paper_id": 2,
        "paragraph_info": "The PSM was calibrated according to the standard operation procedure for PSM (Lehtipalo et al., 2022) using a known aerosol population from a glowing-tungsten-wire generator (Kangasluoma et al., 2015; Peineke et al., 2006). The detection efficiency for different particle sizes was determined by comparing the concentration of size-selected particles to a reference instrument, in this case a Faraday cup electrometer.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.0751605033874512,
            -0.6328766942024231
        ],
        "MSU_id": 859
    },
    {
        "sentence": "The calibration used a known aerosol population from a glowing-tungsten-wire generator.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 166,
        "paper_id": 2,
        "paragraph_info": "The PSM was calibrated according to the standard operation procedure for PSM (Lehtipalo et al., 2022) using a known aerosol population from a glowing-tungsten-wire generator (Kangasluoma et al., 2015; Peineke et al., 2006). The detection efficiency for different particle sizes was determined by comparing the concentration of size-selected particles to a reference instrument, in this case a Faraday cup electrometer.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.3305140733718872,
            -0.516536295413971
        ],
        "MSU_id": 860
    },
    {
        "sentence": "The detection efficiency for different particle sizes was determined by comparing the concentration of size-selected particles to a reference instrument.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 166,
        "paper_id": 2,
        "paragraph_info": "The PSM was calibrated according to the standard operation procedure for PSM (Lehtipalo et al., 2022) using a known aerosol population from a glowing-tungsten-wire generator (Kangasluoma et al., 2015; Peineke et al., 2006). The detection efficiency for different particle sizes was determined by comparing the concentration of size-selected particles to a reference instrument, in this case a Faraday cup electrometer.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.0398489236831665,
            0.4966137707233429
        ],
        "MSU_id": 861
    },
    {
        "sentence": "The reference instrument used was a Faraday cup electrometer.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 166,
        "paper_id": 2,
        "paragraph_info": "The PSM was calibrated according to the standard operation procedure for PSM (Lehtipalo et al., 2022) using a known aerosol population from a glowing-tungsten-wire generator (Kangasluoma et al., 2015; Peineke et al., 2006). The detection efficiency for different particle sizes was determined by comparing the concentration of size-selected particles to a reference instrument, in this case a Faraday cup electrometer.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.4970776438713074,
            -0.4216511845588684
        ],
        "MSU_id": 862
    },
    {
        "sentence": "The system was set up with an Airmodus nanoparticle diluter (AND) inlet for sample dilution and automatic background measurement.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 167,
        "paper_id": 2,
        "paragraph_info": "The system was set up with an Airmodus nanoparticle diluter (AND) inlet (Lampim\u00e4ki et al., 2023) for sample dilution and automatic background measurement to make sure that the CPC stayed within a single counting range during the campaign. The inlet was set up at around 2 m above the ground, and the background was measured roughly every 8 h and subtracted from the signal during the inversion process.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.5292863845825195,
            -0.0985364243388176
        ],
        "MSU_id": 863
    },
    {
        "sentence": "The inlet was set up at around 2 m above the ground.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 167,
        "paper_id": 2,
        "paragraph_info": "The system was set up with an Airmodus nanoparticle diluter (AND) inlet (Lampim\u00e4ki et al., 2023) for sample dilution and automatic background measurement to make sure that the CPC stayed within a single counting range during the campaign. The inlet was set up at around 2 m above the ground, and the background was measured roughly every 8 h and subtracted from the signal during the inversion process.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.12189623713493347,
            1.0256812572479248
        ],
        "MSU_id": 865
    },
    {
        "sentence": "The background was measured roughly every 8 h and subtracted from the signal during the inversion process.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 167,
        "paper_id": 2,
        "paragraph_info": "The system was set up with an Airmodus nanoparticle diluter (AND) inlet (Lampim\u00e4ki et al., 2023) for sample dilution and automatic background measurement to make sure that the CPC stayed within a single counting range during the campaign. The inlet was set up at around 2 m above the ground, and the background was measured roughly every 8 h and subtracted from the signal during the inversion process.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.1750266551971436,
            -1.3914748430252075
        ],
        "MSU_id": 866
    },
    {
        "sentence": "The high-flow differential mobility particle sizer (HFDMPS) system utilizes a half-mini differential mobility analyzer (DMA) to size-select particles.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 168,
        "paper_id": 2,
        "paragraph_info": "The high-flow differential mobility particle sizer (HFDMPS) system utilizes a half-mini differential mobility analyzer (DMA; Fern\u00e1ndez de la Mora and Kozlowski, 2013; Cai et al., 2018) to size-select particles that are then grown and detected by an A11 nano-CNC system (Airmodus Ltd.; Kangasluoma et al., 2018). The HFDMPS significantly improves sub-10 nm particle measurements compared with a typical differential mobility particle sizer (DMPS) system, allowing us to better characterize the sub-10 nm particle size distribution when combined with the PSM measurements. The DMA was size-calibrated with electro-sprayed positively charged monomer ions of tetraheptylammonium bromide (THA+; Ude and de la Mora, 2005).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.9041913747787476,
            0.013938002288341522
        ],
        "MSU_id": 867
    },
    {
        "sentence": "The particles are then grown and detected by an A11 nano-CNC system.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 168,
        "paper_id": 2,
        "paragraph_info": "The high-flow differential mobility particle sizer (HFDMPS) system utilizes a half-mini differential mobility analyzer (DMA; Fern\u00e1ndez de la Mora and Kozlowski, 2013; Cai et al., 2018) to size-select particles that are then grown and detected by an A11 nano-CNC system (Airmodus Ltd.; Kangasluoma et al., 2018). The HFDMPS significantly improves sub-10 nm particle measurements compared with a typical differential mobility particle sizer (DMPS) system, allowing us to better characterize the sub-10 nm particle size distribution when combined with the PSM measurements. The DMA was size-calibrated with electro-sprayed positively charged monomer ions of tetraheptylammonium bromide (THA+; Ude and de la Mora, 2005).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.762511134147644,
            0.27230173349380493
        ],
        "MSU_id": 868
    },
    {
        "sentence": "The DMA was size-calibrated with electro-sprayed positively charged monomer ions of tetraheptylammonium bromide (THA+).",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 168,
        "paper_id": 2,
        "paragraph_info": "The high-flow differential mobility particle sizer (HFDMPS) system utilizes a half-mini differential mobility analyzer (DMA; Fern\u00e1ndez de la Mora and Kozlowski, 2013; Cai et al., 2018) to size-select particles that are then grown and detected by an A11 nano-CNC system (Airmodus Ltd.; Kangasluoma et al., 2018). The HFDMPS significantly improves sub-10 nm particle measurements compared with a typical differential mobility particle sizer (DMPS) system, allowing us to better characterize the sub-10 nm particle size distribution when combined with the PSM measurements. The DMA was size-calibrated with electro-sprayed positively charged monomer ions of tetraheptylammonium bromide (THA+; Ude and de la Mora, 2005).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            2.0396361351013184,
            -0.25758469104766846
        ],
        "MSU_id": 871
    },
    {
        "sentence": "The HFDMPS inlet was set up at a height of 1 m.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 169,
        "paper_id": 2,
        "paragraph_info": "The HFDMPS inlet was set up at a height of 1 m and used a 50 cm long, 10 mm outer diameter tube with a core sampling system to minimize losses (Kangasluoma et al., 2016; Fu et al., 2019). A home-built soft X-Ray ionization source (similar to the Model 3087, TSI Inc.) was used to charge particles. The HFDMPS measured the particle size distribution from 2 to 15 nm for both polarities at 15 predefined size steps within 10 min.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.8664754629135132,
            0.4196508228778839
        ],
        "MSU_id": 872
    },
    {
        "sentence": "The HFDMPS inlet used a 50 cm long, 10 mm outer diameter tube with a core sampling system to minimize losses.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 169,
        "paper_id": 2,
        "paragraph_info": "The HFDMPS inlet was set up at a height of 1 m and used a 50 cm long, 10 mm outer diameter tube with a core sampling system to minimize losses (Kangasluoma et al., 2016; Fu et al., 2019). A home-built soft X-Ray ionization source (similar to the Model 3087, TSI Inc.) was used to charge particles. The HFDMPS measured the particle size distribution from 2 to 15 nm for both polarities at 15 predefined size steps within 10 min.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.3517662286758423,
            0.25134754180908203
        ],
        "MSU_id": 873
    },
    {
        "sentence": "A home-built soft X-Ray ionization source was used to charge particles.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 169,
        "paper_id": 2,
        "paragraph_info": "The HFDMPS inlet was set up at a height of 1 m and used a 50 cm long, 10 mm outer diameter tube with a core sampling system to minimize losses (Kangasluoma et al., 2016; Fu et al., 2019). A home-built soft X-Ray ionization source (similar to the Model 3087, TSI Inc.) was used to charge particles. The HFDMPS measured the particle size distribution from 2 to 15 nm for both polarities at 15 predefined size steps within 10 min.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.4930903911590576,
            0.40953952074050903
        ],
        "MSU_id": 874
    },
    {
        "sentence": "A conventional DMPS system equipped with a Hauke-type DMA measured the particle size distribution from 10 to 800 nm at 16 predefined size steps within 10 min.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 170,
        "paper_id": 2,
        "paragraph_info": "Sampling from the same inlet and using the same charging device, a conventional DMPS system equipped with a Hauke-type DMA (aerosol flow 1 LPM, sheath flow 5 LPM) and a TSI Inc. CPC (Model 3772) measured the particle size distribution from 10 to 800 nm at 16 predefined size steps within 10 min. In addition, a DMPS measuring from 15 to 800 nm was available in another measurement container at the same field site. The total particle number concentrations obtained from integrating the particle size distribution measured by the DMPS was compared with a reference CPC (Model 3025A, TSI Inc.) operated at the same site during the first weeks of the campaign. It revealed, on average, a factor of 2 lower concentrations measured by the Hauke-type DMPS that was confirmed to be rather size-independent via a comparison of the measured size distributions and their overlap with the HFDMPS system and was, thus, subsequently corrected for.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.7709659337997437,
            0.18964272737503052
        ],
        "MSU_id": 876
    },
    {
        "sentence": "The DMPS system used an aerosol flow of 1 LPM and a sheath flow of 5 LPM.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 170,
        "paper_id": 2,
        "paragraph_info": "Sampling from the same inlet and using the same charging device, a conventional DMPS system equipped with a Hauke-type DMA (aerosol flow 1 LPM, sheath flow 5 LPM) and a TSI Inc. CPC (Model 3772) measured the particle size distribution from 10 to 800 nm at 16 predefined size steps within 10 min. In addition, a DMPS measuring from 15 to 800 nm was available in another measurement container at the same field site. The total particle number concentrations obtained from integrating the particle size distribution measured by the DMPS was compared with a reference CPC (Model 3025A, TSI Inc.) operated at the same site during the first weeks of the campaign. It revealed, on average, a factor of 2 lower concentrations measured by the Hauke-type DMPS that was confirmed to be rather size-independent via a comparison of the measured size distributions and their overlap with the HFDMPS system and was, thus, subsequently corrected for.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.0291013717651367,
            0.7178481817245483
        ],
        "MSU_id": 877
    },
    {
        "sentence": "An online high-resolution time-of-flight aerosol mass spectrometer (HR-ToF-AMS) was operated at the same site for the measurement of non-refractory species.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 171,
        "paper_id": 2,
        "paragraph_info": "Additional co-located measurements of auxiliary data from the CNR-ISAC network [\\(https://www.isac.cnr.it/en,](https://www.isac.cnr.it/en) last access: 10 February 2024) and from the routine monitoring program of the Regional Environmental Protection Agency of Emilia-Romagna (ARPA-E, [https://www.arpae.it/it,](https://www.arpae.it/it) last access: 10 February 2024) were used in this study. An online high-resolution time-of-flight aerosol mass spectrometer (HR-ToF-AMS, Aerodyne Research) and a multi-angle absorption photometer (MAAP, Thermo Scientific) were operated at the same site for the measurement of non-refractory species and black carbon (BC), respectively. Trace gases were also measured with a 1 min time resolution, including  $O_3$  (Model 49i, Thermo Scientific),  $NO_x$  (Model 200A, Teledyne API), NH<sub>3</sub> (Model 201E, Teledyne API) and SO<sub>2</sub> (Model 43i enhanced trace level analyzer, Thermo Scientific). Moreover, meteorological parameters (e.g., RH, temperature, wind direction and wind speed) were measured by a meteorology station (Model WXT536, Vaisala Ltd).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.923173427581787,
            -0.4213252663612366
        ],
        "MSU_id": 886
    },
    {
        "sentence": "A multi-angle absorption photometer (MAAP) was operated at the same site for the measurement of black carbon (BC).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 171,
        "paper_id": 2,
        "paragraph_info": "Additional co-located measurements of auxiliary data from the CNR-ISAC network [\\(https://www.isac.cnr.it/en,](https://www.isac.cnr.it/en) last access: 10 February 2024) and from the routine monitoring program of the Regional Environmental Protection Agency of Emilia-Romagna (ARPA-E, [https://www.arpae.it/it,](https://www.arpae.it/it) last access: 10 February 2024) were used in this study. An online high-resolution time-of-flight aerosol mass spectrometer (HR-ToF-AMS, Aerodyne Research) and a multi-angle absorption photometer (MAAP, Thermo Scientific) were operated at the same site for the measurement of non-refractory species and black carbon (BC), respectively. Trace gases were also measured with a 1 min time resolution, including  $O_3$  (Model 49i, Thermo Scientific),  $NO_x$  (Model 200A, Teledyne API), NH<sub>3</sub> (Model 201E, Teledyne API) and SO<sub>2</sub> (Model 43i enhanced trace level analyzer, Thermo Scientific). Moreover, meteorological parameters (e.g., RH, temperature, wind direction and wind speed) were measured by a meteorology station (Model WXT536, Vaisala Ltd).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.9142107963562012,
            -0.8045396208763123
        ],
        "MSU_id": 887
    },
    {
        "sentence": "Trace gases were measured with a 1 min time resolution, including $O_3$, $NO_x$, NH<sub>3</sub>, and SO<sub>2$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 171,
        "paper_id": 2,
        "paragraph_info": "Additional co-located measurements of auxiliary data from the CNR-ISAC network [\\(https://www.isac.cnr.it/en,](https://www.isac.cnr.it/en) last access: 10 February 2024) and from the routine monitoring program of the Regional Environmental Protection Agency of Emilia-Romagna (ARPA-E, [https://www.arpae.it/it,](https://www.arpae.it/it) last access: 10 February 2024) were used in this study. An online high-resolution time-of-flight aerosol mass spectrometer (HR-ToF-AMS, Aerodyne Research) and a multi-angle absorption photometer (MAAP, Thermo Scientific) were operated at the same site for the measurement of non-refractory species and black carbon (BC), respectively. Trace gases were also measured with a 1 min time resolution, including  $O_3$  (Model 49i, Thermo Scientific),  $NO_x$  (Model 200A, Teledyne API), NH<sub>3</sub> (Model 201E, Teledyne API) and SO<sub>2</sub> (Model 43i enhanced trace level analyzer, Thermo Scientific). Moreover, meteorological parameters (e.g., RH, temperature, wind direction and wind speed) were measured by a meteorology station (Model WXT536, Vaisala Ltd).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.5826153755187988,
            -0.7716203331947327
        ],
        "MSU_id": 888
    },
    {
        "sentence": "Meteorological parameters (e.g., RH, temperature, wind direction and wind speed) were measured by a meteorology station.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 171,
        "paper_id": 2,
        "paragraph_info": "Additional co-located measurements of auxiliary data from the CNR-ISAC network [\\(https://www.isac.cnr.it/en,](https://www.isac.cnr.it/en) last access: 10 February 2024) and from the routine monitoring program of the Regional Environmental Protection Agency of Emilia-Romagna (ARPA-E, [https://www.arpae.it/it,](https://www.arpae.it/it) last access: 10 February 2024) were used in this study. An online high-resolution time-of-flight aerosol mass spectrometer (HR-ToF-AMS, Aerodyne Research) and a multi-angle absorption photometer (MAAP, Thermo Scientific) were operated at the same site for the measurement of non-refractory species and black carbon (BC), respectively. Trace gases were also measured with a 1 min time resolution, including  $O_3$  (Model 49i, Thermo Scientific),  $NO_x$  (Model 200A, Teledyne API), NH<sub>3</sub> (Model 201E, Teledyne API) and SO<sub>2</sub> (Model 43i enhanced trace level analyzer, Thermo Scientific). Moreover, meteorological parameters (e.g., RH, temperature, wind direction and wind speed) were measured by a meteorology station (Model WXT536, Vaisala Ltd).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.8934800028800964,
            -1.7221291065216064
        ],
        "MSU_id": 889
    },
    {
        "sentence": "We classified each day according to whether a growing mode appeared in the particle size distribution or not.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.4025261402130127,
            0.38125449419021606
        ],
        "MSU_id": 890
    },
    {
        "sentence": "This classification was done separately for both the HFDMPS and the PSM data.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.006210204213857651,
            -1.9078255891799927
        ],
        "MSU_id": 891
    },
    {
        "sentence": "A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least 2 h.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.3022613525390625,
            0.7731856107711792
        ],
        "MSU_id": 892
    },
    {
        "sentence": "If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as 'NPF with growth'.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.4350056648254395,
            0.03147905319929123
        ],
        "MSU_id": 893
    },
    {
        "sentence": "If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as 'NPF with no growth'.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.4001073837280273,
            -0.20937451720237732
        ],
        "MSU_id": 894
    },
    {
        "sentence": "If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as 'no NPF event'.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.7663300037384033,
            0.36117297410964966
        ],
        "MSU_id": 895
    },
    {
        "sentence": "If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as 'Unclear'.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.2369431257247925,
            -0.5530959963798523
        ],
        "MSU_id": 897
    },
    {
        "sentence": "Days that lacked data from one of the instruments were marked as 'No data'.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 172,
        "paper_id": 2,
        "paragraph_info": "We classified each day according to whether a growing mode appeared in the particle size distribution or not. This classification was done separately for both the HFDMPS and the PSM data. A growing mode was defined as a new particle mode that appeared in the particle size distribution and continued to grow to larger sizes for at least  $2 \\text{ h}$ . If there was a growing mode visible in both the PSM and HFDMPS data, the day was defined as \"NPF with growth\". If there was no growth or the growth was unclear in the HFDMPS data but there was a growing mode in the PSM data, then the day was classified as \"NPF with no growth\". If there was no growing mode in either of the size distributions measured by HFDMPS and PSM, then the day was marked as \"no NPF event\" (Fig. S1 in the Supplement). The definition is similar to Dada et al. (2018), who used naturally charged ions to separate between NPF days with clustering only and those with clustering and visible growth. If there was a growing or an undefined new mode visible in the combined size distribution but there was no clustering detected by the PSM, this day was marked as \"Unclear\". Days that lacked data from one of the instruments were marked as \"No data\".",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.5948057174682617,
            0.34302088618278503
        ],
        "MSU_id": 898
    },
    {
        "sentence": "The condensation sink and coagulation sink were calculated according to Dal Maso et al. (2005).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 173,
        "paper_id": 2,
        "paragraph_info": "The condensation sink and coagulation sink were calculated according to Dal Maso et al. (2005) from the Hauke-type DMPS size distribution without any correction of aerosol hygroscopic behavior. Growth rates were calculated using the maximum concentration method, in which we fit a Gaussian distribution to the particle concentration evolution at a fixed size to determine the time of maximum concentration for a given size channel in the HFDMPS.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.2376880645751953,
            -0.09572728723287582
        ],
        "MSU_id": 899
    },
    {
        "sentence": "The condensation sink and coagulation sink were calculated from the Hauke-type DMPS size distribution without any correction of aerosol hygroscopic behavior.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 173,
        "paper_id": 2,
        "paragraph_info": "The condensation sink and coagulation sink were calculated according to Dal Maso et al. (2005) from the Hauke-type DMPS size distribution without any correction of aerosol hygroscopic behavior. Growth rates were calculated using the maximum concentration method, in which we fit a Gaussian distribution to the particle concentration evolution at a fixed size to determine the time of maximum concentration for a given size channel in the HFDMPS.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.847217082977295,
            -0.008473493158817291
        ],
        "MSU_id": 900
    },
    {
        "sentence": "Growth rates were calculated using the maximum concentration method.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 173,
        "paper_id": 2,
        "paragraph_info": "The condensation sink and coagulation sink were calculated according to Dal Maso et al. (2005) from the Hauke-type DMPS size distribution without any correction of aerosol hygroscopic behavior. Growth rates were calculated using the maximum concentration method, in which we fit a Gaussian distribution to the particle concentration evolution at a fixed size to determine the time of maximum concentration for a given size channel in the HFDMPS.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.09465587139129639,
            1.184619665145874
        ],
        "MSU_id": 901
    },
    {
        "sentence": "The maximum concentration method fits a Gaussian distribution to the particle concentration evolution at a fixed size.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 173,
        "paper_id": 2,
        "paragraph_info": "The condensation sink and coagulation sink were calculated according to Dal Maso et al. (2005) from the Hauke-type DMPS size distribution without any correction of aerosol hygroscopic behavior. Growth rates were calculated using the maximum concentration method, in which we fit a Gaussian distribution to the particle concentration evolution at a fixed size to determine the time of maximum concentration for a given size channel in the HFDMPS.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.0188084840774536,
            0.5036565661430359
        ],
        "MSU_id": 902
    },
    {
        "sentence": "The time of maximum concentration for a given size channel in the HFDMPS was determined.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 173,
        "paper_id": 2,
        "paragraph_info": "The condensation sink and coagulation sink were calculated according to Dal Maso et al. (2005) from the Hauke-type DMPS size distribution without any correction of aerosol hygroscopic behavior. Growth rates were calculated using the maximum concentration method, in which we fit a Gaussian distribution to the particle concentration evolution at a fixed size to determine the time of maximum concentration for a given size channel in the HFDMPS.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.4186046123504639,
            -1.036453127861023
        ],
        "MSU_id": 903
    },
    {
        "sentence": "The growth rates (GRs) were calculated by first determining the time to reach 50% of the maximum concentration.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 174,
        "paper_id": 2,
        "paragraph_info": "The growth rates (GRs) were calculated by first determining the time to reach  $50\\%$  of the maximum concentration, and the average growth rate was then derived as the slope of the linear fit between the time and diameter:",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.897800087928772,
            0.6312764286994934
        ],
        "MSU_id": 904
    },
    {
        "sentence": "The average growth rate was then derived as the slope of the linear fit between the time and diameter.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 174,
        "paper_id": 2,
        "paragraph_info": "The growth rates (GRs) were calculated by first determining the time to reach  $50\\%$  of the maximum concentration, and the average growth rate was then derived as the slope of the linear fit between the time and diameter:",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.9190112352371216,
            -0.1669159233570099
        ],
        "MSU_id": 905
    },
    {
        "sentence": "The growth rate was calculated as the slope of a linear least-squares fit to the time points of maximum concentration and their corresponding particle diameters.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 176,
        "paper_id": 2,
        "paragraph_info": "From these, the growth rate was calculated as the slope of a linear least-squares fit to the time points of maximum concentration and their corresponding particle diameters. The formation rates were calculated for several sizes with the balance equation of Kulmala et al. (2012) using the combined-DMPS size distributions  $(J_2, J_3 \\text{ and } J_6)$  and the PSM and combined-DMPS size distribution  $(J_{1,7})$ . Formation rates were then calculated by rearranging the equation describing the time evolution of the particle size distribution. The formation rate for a given diameter  $d_{p_1}$  is calculated as follows:",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.47028011083602905,
            0.8130264282226562
        ],
        "MSU_id": 908
    },
    {
        "sentence": "The formation rates were calculated for several sizes with the balance equation of Kulmala et al. (2012) using the combined-DMPS size distributions $(J_2, J_3 \text{ and } J_6)$ and the PSM and combined-DMPS size distribution $(J_{1,7})$.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 176,
        "paper_id": 2,
        "paragraph_info": "From these, the growth rate was calculated as the slope of a linear least-squares fit to the time points of maximum concentration and their corresponding particle diameters. The formation rates were calculated for several sizes with the balance equation of Kulmala et al. (2012) using the combined-DMPS size distributions  $(J_2, J_3 \\text{ and } J_6)$  and the PSM and combined-DMPS size distribution  $(J_{1,7})$ . Formation rates were then calculated by rearranging the equation describing the time evolution of the particle size distribution. The formation rate for a given diameter  $d_{p_1}$  is calculated as follows:",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.787217140197754,
            0.018136627972126007
        ],
        "MSU_id": 909
    },
    {
        "sentence": "Formation rates were then calculated by rearranging the equation describing the time evolution of the particle size distribution.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 176,
        "paper_id": 2,
        "paragraph_info": "From these, the growth rate was calculated as the slope of a linear least-squares fit to the time points of maximum concentration and their corresponding particle diameters. The formation rates were calculated for several sizes with the balance equation of Kulmala et al. (2012) using the combined-DMPS size distributions  $(J_2, J_3 \\text{ and } J_6)$  and the PSM and combined-DMPS size distribution  $(J_{1,7})$ . Formation rates were then calculated by rearranging the equation describing the time evolution of the particle size distribution. The formation rate for a given diameter  $d_{p_1}$  is calculated as follows:",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.5951964855194092,
            -0.35138070583343506
        ],
        "MSU_id": 910
    },
    {
        "sentence": "The formation rate for a given diameter $d_{p_1}$ is calculated as follows:",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 176,
        "paper_id": 2,
        "paragraph_info": "From these, the growth rate was calculated as the slope of a linear least-squares fit to the time points of maximum concentration and their corresponding particle diameters. The formation rates were calculated for several sizes with the balance equation of Kulmala et al. (2012) using the combined-DMPS size distributions  $(J_2, J_3 \\text{ and } J_6)$  and the PSM and combined-DMPS size distribution  $(J_{1,7})$ . Formation rates were then calculated by rearranging the equation describing the time evolution of the particle size distribution. The formation rate for a given diameter  $d_{p_1}$  is calculated as follows:",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.7902556657791138,
            0.2555367648601532
        ],
        "MSU_id": 911
    },
    {
        "sentence": "The APi-ToF and CI-APi-ToF data were analyzed using the Tofware package (v.3.1.0, Tofwerk, Switzerland, and Aerodyne, USA) in the Igor Pro software (v.7.08, WaveMetrics, USA).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 177,
        "paper_id": 2,
        "paragraph_info": "The APi-ToF and CI-APi-ToF data were analyzed using the Tofware package (v.3.1.0, Tofwerk, Switzerland, and Aerodyne, USA) in the Igor Pro software (v.7.08, WaveMetrics, USA). The mass accuracy was within  $10 \\text{ ppm}$  (APi-ToF) and 5 ppm (CI-APi-ToF), and the mass resolutions were  $\\sim$  $4500 \\text{ (API-ToF)}$  and  $\\sim 5000 \\text{ (CI-APi-ToF)}$  for ions  $> 200 \\text{ Th.}$ The raw signals were first normalized by the primary ions  $(NO_3^-$ , monomer, dimer and trimer) and then multiplied by the calibration factor of SA. Detailed information on the mass spectrometer data analysis methods can be found in previous studies (Cai et al., 2022; J. Cai et al., 2023; Zha et al., 2018, 2023a, b; Fan et al., 2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.35913321375846863,
            -0.41987210512161255
        ],
        "MSU_id": 912
    },
    {
        "sentence": "The raw signals were first normalized by the primary ions (NO3-, monomer, dimer and trimer).",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 177,
        "paper_id": 2,
        "paragraph_info": "The APi-ToF and CI-APi-ToF data were analyzed using the Tofware package (v.3.1.0, Tofwerk, Switzerland, and Aerodyne, USA) in the Igor Pro software (v.7.08, WaveMetrics, USA). The mass accuracy was within  $10 \\text{ ppm}$  (APi-ToF) and 5 ppm (CI-APi-ToF), and the mass resolutions were  $\\sim$  $4500 \\text{ (API-ToF)}$  and  $\\sim 5000 \\text{ (CI-APi-ToF)}$  for ions  $> 200 \\text{ Th.}$ The raw signals were first normalized by the primary ions  $(NO_3^-$ , monomer, dimer and trimer) and then multiplied by the calibration factor of SA. Detailed information on the mass spectrometer data analysis methods can be found in previous studies (Cai et al., 2022; J. Cai et al., 2023; Zha et al., 2018, 2023a, b; Fan et al., 2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.6035979986190796,
            -0.8550325036048889
        ],
        "MSU_id": 915
    },
    {
        "sentence": "The raw signals were then multiplied by the calibration factor of SA.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 177,
        "paper_id": 2,
        "paragraph_info": "The APi-ToF and CI-APi-ToF data were analyzed using the Tofware package (v.3.1.0, Tofwerk, Switzerland, and Aerodyne, USA) in the Igor Pro software (v.7.08, WaveMetrics, USA). The mass accuracy was within  $10 \\text{ ppm}$  (APi-ToF) and 5 ppm (CI-APi-ToF), and the mass resolutions were  $\\sim$  $4500 \\text{ (API-ToF)}$  and  $\\sim 5000 \\text{ (CI-APi-ToF)}$  for ions  $> 200 \\text{ Th.}$ The raw signals were first normalized by the primary ions  $(NO_3^-$ , monomer, dimer and trimer) and then multiplied by the calibration factor of SA. Detailed information on the mass spectrometer data analysis methods can be found in previous studies (Cai et al., 2022; J. Cai et al., 2023; Zha et al., 2018, 2023a, b; Fan et al., 2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.10423101484775543,
            -2.0249719619750977
        ],
        "MSU_id": 916
    },
    {
        "sentence": "We applied a kinetic model to simulate SA dimer concentrations.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 178,
        "paper_id": 2,
        "paragraph_info": "In order to evaluate the contribution of SA-amine clustering to cluster formation in the Po Valley, we applied a kinetic model to simulate SA dimer concentrations. We simulated the cluster concentrations and particle formation rates under different amine levels based on the model. The simulation was performed with a temperature of 283 K, an atmospheric pressure of  $1.01 \\times 10^5$  Pa and a condensation sink (CS) of  $0.01 \\text{ s}^{-1}$ , based on our measurement during the sampling period. In the model, the formation rate of SA tetramer was regarded as the simulated particle formation rate. The standard molar Gibbs free energy of formation and the corresponding evaporation of SA-amine clusters was based on quantum chemistry with corrections from the experimental data. The detailed settings of the kinetic model can be found in Cai et al. (2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.9183119535446167,
            -0.48734408617019653
        ],
        "MSU_id": 918
    },
    {
        "sentence": "We simulated the cluster concentrations and particle formation rates under different amine levels based on the model.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 178,
        "paper_id": 2,
        "paragraph_info": "In order to evaluate the contribution of SA-amine clustering to cluster formation in the Po Valley, we applied a kinetic model to simulate SA dimer concentrations. We simulated the cluster concentrations and particle formation rates under different amine levels based on the model. The simulation was performed with a temperature of 283 K, an atmospheric pressure of  $1.01 \\times 10^5$  Pa and a condensation sink (CS) of  $0.01 \\text{ s}^{-1}$ , based on our measurement during the sampling period. In the model, the formation rate of SA tetramer was regarded as the simulated particle formation rate. The standard molar Gibbs free energy of formation and the corresponding evaporation of SA-amine clusters was based on quantum chemistry with corrections from the experimental data. The detailed settings of the kinetic model can be found in Cai et al. (2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.6427216529846191,
            0.20177018642425537
        ],
        "MSU_id": 919
    },
    {
        "sentence": "The simulation was performed with a temperature of 283 K, an atmospheric pressure of $1.01 \\times 10^5$ Pa and a condensation sink (CS) of $0.01 \\text{ s}^{-1}$.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 178,
        "paper_id": 2,
        "paragraph_info": "In order to evaluate the contribution of SA-amine clustering to cluster formation in the Po Valley, we applied a kinetic model to simulate SA dimer concentrations. We simulated the cluster concentrations and particle formation rates under different amine levels based on the model. The simulation was performed with a temperature of 283 K, an atmospheric pressure of  $1.01 \\times 10^5$  Pa and a condensation sink (CS) of  $0.01 \\text{ s}^{-1}$ , based on our measurement during the sampling period. In the model, the formation rate of SA tetramer was regarded as the simulated particle formation rate. The standard molar Gibbs free energy of formation and the corresponding evaporation of SA-amine clusters was based on quantum chemistry with corrections from the experimental data. The detailed settings of the kinetic model can be found in Cai et al. (2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.3459959030151367,
            0.38232946395874023
        ],
        "MSU_id": 920
    },
    {
        "sentence": "In the model, the formation rate of SA tetramer was regarded as the simulated particle formation rate.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 178,
        "paper_id": 2,
        "paragraph_info": "In order to evaluate the contribution of SA-amine clustering to cluster formation in the Po Valley, we applied a kinetic model to simulate SA dimer concentrations. We simulated the cluster concentrations and particle formation rates under different amine levels based on the model. The simulation was performed with a temperature of 283 K, an atmospheric pressure of  $1.01 \\times 10^5$  Pa and a condensation sink (CS) of  $0.01 \\text{ s}^{-1}$ , based on our measurement during the sampling period. In the model, the formation rate of SA tetramer was regarded as the simulated particle formation rate. The standard molar Gibbs free energy of formation and the corresponding evaporation of SA-amine clusters was based on quantum chemistry with corrections from the experimental data. The detailed settings of the kinetic model can be found in Cai et al. (2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.5207173824310303,
            0.07633215934038162
        ],
        "MSU_id": 921
    },
    {
        "sentence": "The standard molar Gibbs free energy of formation and the corresponding evaporation of SA-amine clusters was based on quantum chemistry with corrections from the experimental data.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 178,
        "paper_id": 2,
        "paragraph_info": "In order to evaluate the contribution of SA-amine clustering to cluster formation in the Po Valley, we applied a kinetic model to simulate SA dimer concentrations. We simulated the cluster concentrations and particle formation rates under different amine levels based on the model. The simulation was performed with a temperature of 283 K, an atmospheric pressure of  $1.01 \\times 10^5$  Pa and a condensation sink (CS) of  $0.01 \\text{ s}^{-1}$ , based on our measurement during the sampling period. In the model, the formation rate of SA tetramer was regarded as the simulated particle formation rate. The standard molar Gibbs free energy of formation and the corresponding evaporation of SA-amine clusters was based on quantum chemistry with corrections from the experimental data. The detailed settings of the kinetic model can be found in Cai et al. (2021).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            2.176010847091675,
            -0.5085967779159546
        ],
        "MSU_id": 922
    },
    {
        "sentence": "The CLOUD chamber experiments simulated NPF under polluted boundary layer conditions with anthropogenic emissions.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 185,
        "paper_id": 2,
        "paragraph_info": "To investigate the NPF mechanism in the Po Valley, we firstly compared the simultaneously measured  $J_{1,7}$  and SA with recent Cosmics Leaving Outdoor Droplets (CLOUD) chamber experiments that simulated NPF under polluted boundary layer conditions with anthropogenic emissions (Xiao et",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.6974995136260986,
            0.7582876682281494
        ],
        "MSU_id": 963
    },
    {
        "sentence": "The lines in panel (b) are from the kinetic model simulations under different DMA levels.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 187,
        "paper_id": 2,
        "paragraph_info": "**Figure 3.** (a) The formation rate of 1.7 nm particles (J1.7) versus SA concentrations during springtime in the Po Valley (shown as circles) and experimental results from CLOUD chamber experiments. The solid lines are from fitted results of CLOUD chamber experiments; the black hexagons represent the median values under different SA levels from the ambient measurement. (b) The relationship between the sulfuric acid dimer (SA dimer) concentration, the square of monomer (SA)<sup>2</sup> concentrations and the CS. The lines are from the kinetic model simulations under different DMA levels, whereas the dots are from the measurement. In panels (a) and (b), the results from the field measurements are from the daytime (10:00\u201314:00 LT) and are color-coded by the temperature at the site. The J1.7 and corresponding SA concentrations of CLOUD chamber results are from previous literature (Xiao et al., 2021). (c) Calculated growth rates for 1.5\u20133, 3\u20137 and 7\u201315 nm from this study and values reported by Kontkanen et al. (2016, yellow squares). The red horizontal lines are the median values, the blue boxes show the values between the 25th and 75th percentiles, and the black whiskers mark the 5th and 95th percentiles. The solid green line represents predicted growth rates from pure sulfuric acid without organic condensation (Stolzenburg et al., 2020). The width of the box is proportional to the square root of the number of the GR values.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.2962958812713623,
            -1.1216694116592407
        ],
        "MSU_id": 969
    },
    {
        "sentence": "The width of the box is proportional to the square root of the number of the GR values.",
        "category": "Method",
        "rank": 2,
        "type": "text",
        "para_id": 187,
        "paper_id": 2,
        "paragraph_info": "**Figure 3.** (a) The formation rate of 1.7 nm particles (J1.7) versus SA concentrations during springtime in the Po Valley (shown as circles) and experimental results from CLOUD chamber experiments. The solid lines are from fitted results of CLOUD chamber experiments; the black hexagons represent the median values under different SA levels from the ambient measurement. (b) The relationship between the sulfuric acid dimer (SA dimer) concentration, the square of monomer (SA)<sup>2</sup> concentrations and the CS. The lines are from the kinetic model simulations under different DMA levels, whereas the dots are from the measurement. In panels (a) and (b), the results from the field measurements are from the daytime (10:00\u201314:00 LT) and are color-coded by the temperature at the site. The J1.7 and corresponding SA concentrations of CLOUD chamber results are from previous literature (Xiao et al., 2021). (c) Calculated growth rates for 1.5\u20133, 3\u20137 and 7\u201315 nm from this study and values reported by Kontkanen et al. (2016, yellow squares). The red horizontal lines are the median values, the blue boxes show the values between the 25th and 75th percentiles, and the black whiskers mark the 5th and 95th percentiles. The solid green line represents predicted growth rates from pure sulfuric acid without organic condensation (Stolzenburg et al., 2020). The width of the box is proportional to the square root of the number of the GR values.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.736541509628296,
            0.014684900641441345
        ],
        "MSU_id": 976
    },
    {
        "sentence": "The source and sink terms of the SA dimer can be determined by calculating the formation rate from SA monomer collisions.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 189,
        "paper_id": 2,
        "paragraph_info": "The SA dimer measured by CI-APi-ToF is typically used as an indicator for the initial step for the cluster formation in NPF events (Yan et al., 2021). According to a previous study (Yan et al., 2021), the source and sink terms of the SA dimer can be determined by calculating the formation rate from SA monomer collisions and the loss rate from the SA dimer through coagulation onto pre-existing particles (Fig. 2b). In general, the correlation coefficient between the SA dimer and its source to sink term ratios ( $r = 0.80$ , Spearman correlation coefficient) indicated that, similar to Chinese urban areas, the SA dimer was in a pseudo-steady state between the formation of SA monomer collision and the loss onto the CS by coagulation.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            2.1512951850891113,
            -0.49878591299057007
        ],
        "MSU_id": 987
    },
    {
        "sentence": "The loss rate from the SA dimer occurs through coagulation onto pre-existing particles.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 189,
        "paper_id": 2,
        "paragraph_info": "The SA dimer measured by CI-APi-ToF is typically used as an indicator for the initial step for the cluster formation in NPF events (Yan et al., 2021). According to a previous study (Yan et al., 2021), the source and sink terms of the SA dimer can be determined by calculating the formation rate from SA monomer collisions and the loss rate from the SA dimer through coagulation onto pre-existing particles (Fig. 2b). In general, the correlation coefficient between the SA dimer and its source to sink term ratios ( $r = 0.80$ , Spearman correlation coefficient) indicated that, similar to Chinese urban areas, the SA dimer was in a pseudo-steady state between the formation of SA monomer collision and the loss onto the CS by coagulation.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.988067865371704,
            -0.30401861667633057
        ],
        "MSU_id": 988
    },
    {
        "sentence": "We used the kinetic model to assess the influence of DMA.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 190,
        "paper_id": 2,
        "paragraph_info": "To further assess the influence of DMA, one of the most common and efficient alkaline molecules for NPF in urban environments (Yao et al.,  $2018$ ), we compared the measured SA dimer concentrations with the simulated values under different DMA levels (from 0.1 ppt to reaching the kinetic limit) using the kinetic model (Fig. 3b). From our cluster kinetics simulations, during the peak hours of NPF, DMA concentrations are expected to be in the range of  $0.1$  to  $5 \\text{ ppt}$ , which is lower than the requirement to reach the kinetic limit (Figs. 3b and S3). This implies that other factors, e.g., the abundant ambient NH<sub>3</sub> ( $\\sim 10 \\text{ ppb}$ ) or TMA during our study period, may also participate in cluster formation. This is consistent with the Vocus measurement, which suggests that the ambient DMA signals were close to the background levels (Fig. S4). Possible reasons for not reaching SA-DMA limit during the campaign could be  $(1)$  the relatively lower DMA emissions (such as vehicle flows) than those in Chinese megacities (Ge et al., 2011; Zhu et al., 2022) and (2) the quick scavenging caused by photolysis and nighttime high RH (85 %) (Leng et al., 2015; Yao et al., 2016). Therefore, both the abundant ambient NH<sub>3</sub> concentrations ( $\\sim 10 \\text{ ppb}$ ) and amines likely participated in cluster formation during our study period.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.7046208381652832,
            -0.5674205422401428
        ],
        "MSU_id": 992
    },
    {
        "sentence": "We compared the GR during NPF with and without growth events using the method proposed in Kulmala et al. (2022).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 191,
        "paper_id": 2,
        "paragraph_info": "Median particle growth rates (GRs) during NPF events for the 1.5\u20133, 3\u20137 and 7\u201315 nm size ranges were  $1.3(1.0-$ 2.4) nm h<sup>-1</sup>, 4.6 (2.9\u20135.8) nm h<sup>-1</sup> and 5.1 (3.8\u20138.8) nm h<sup>-1</sup>, respectively. The values in parentheses represent the respective 25th and 75th percentiles of data (Fig. 3c). Growth rates increase with particle diameter, which is a phenomenon also observed in other campaigns around the world (Kontkanen et al., 2017; Kulmala et al., 2013), typically indicative of an increasing organic vapor contribution with size (e.g., Stolzenburg et al., 2018). The growth rates observed here were similar to those observed by Kontkanen et al. (2016) at SPC in summer (7.2 nm  $h^{-1}$  for 7\u201320 nm). Moreover, our 1.5\u2013 3 nm growth rate matches well with Manninen et al. (2010)  $(1.5 \\text{ nm h}^{-1})$  during spring in the Po Valley. A comparison to predicted growth rates from sulfuric acid condensation without organics, which was calculated based on kinetic collisions of the measured SA concentrations and the effect of van der Waals forces on the collision frequency (Stolzenburg et al., 2020), suggests that sulfuric acid condensation may be, on average, sufficient for the growth of the smallest clusters (Fig. 3c). This supports the argument that sulfuric acid and its stabilizing molecules (likely the bases, such as  $NH_3$  and amines) were controlling particle formation in the initial steps of NPF and growth in the Po Valley. However, for particles to grow beyond 3 nm in size, other vapors were needed, which was suggested by the significantly lower contribution of growth by SA (indicated by the green line) than the measured GR for  $3-7$  and  $7-15$  nm particles (Fig. 3c). Those vapors were likely a mixture of organics from anthropogenic and biogenic origins (with the latter emitted at higher rates during summer). We compared the GR during NPF with and without growth events using the method proposed in Kulmala et al.  $(2022)$ : the signal was averaged for all classified non-event days and an appearance time fit was then performed for each size channel independently, also revealing a growth pattern. We found no significant difference with respect to the GR in the  $7-15 \\text{ nm}$  size range for NPF with or without growth days ( $\\text{GR} = 5.1 \\text{ nm h}^{-1}$  for NPF with growth days and  $GR = 6.1 \\text{ nm h}^{-1}$  for NPF without growth days). Considering the similar CS and GR levels for NPF with and without growth days, the higher formation rates at  $1.7 \\text{ nm}$  ( $87 \\text{ cm}^{-3} \\text{ s}^{-1}$ ) may be a more important factor to surpass the CS. Under stable meteorological conditions, a higher formation rate may significantly elevate the possibility that newly formed particles overcome the CS and continuously grow to larger sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.4834095239639282,
            0.7025859951972961
        ],
        "MSU_id": 1009
    },
    {
        "sentence": "The signal was averaged for all classified non-event days and an appearance time fit was then performed for each size channel independently.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 191,
        "paper_id": 2,
        "paragraph_info": "Median particle growth rates (GRs) during NPF events for the 1.5\u20133, 3\u20137 and 7\u201315 nm size ranges were  $1.3(1.0-$ 2.4) nm h<sup>-1</sup>, 4.6 (2.9\u20135.8) nm h<sup>-1</sup> and 5.1 (3.8\u20138.8) nm h<sup>-1</sup>, respectively. The values in parentheses represent the respective 25th and 75th percentiles of data (Fig. 3c). Growth rates increase with particle diameter, which is a phenomenon also observed in other campaigns around the world (Kontkanen et al., 2017; Kulmala et al., 2013), typically indicative of an increasing organic vapor contribution with size (e.g., Stolzenburg et al., 2018). The growth rates observed here were similar to those observed by Kontkanen et al. (2016) at SPC in summer (7.2 nm  $h^{-1}$  for 7\u201320 nm). Moreover, our 1.5\u2013 3 nm growth rate matches well with Manninen et al. (2010)  $(1.5 \\text{ nm h}^{-1})$  during spring in the Po Valley. A comparison to predicted growth rates from sulfuric acid condensation without organics, which was calculated based on kinetic collisions of the measured SA concentrations and the effect of van der Waals forces on the collision frequency (Stolzenburg et al., 2020), suggests that sulfuric acid condensation may be, on average, sufficient for the growth of the smallest clusters (Fig. 3c). This supports the argument that sulfuric acid and its stabilizing molecules (likely the bases, such as  $NH_3$  and amines) were controlling particle formation in the initial steps of NPF and growth in the Po Valley. However, for particles to grow beyond 3 nm in size, other vapors were needed, which was suggested by the significantly lower contribution of growth by SA (indicated by the green line) than the measured GR for  $3-7$  and  $7-15$  nm particles (Fig. 3c). Those vapors were likely a mixture of organics from anthropogenic and biogenic origins (with the latter emitted at higher rates during summer). We compared the GR during NPF with and without growth events using the method proposed in Kulmala et al.  $(2022)$ : the signal was averaged for all classified non-event days and an appearance time fit was then performed for each size channel independently, also revealing a growth pattern. We found no significant difference with respect to the GR in the  $7-15 \\text{ nm}$  size range for NPF with or without growth days ( $\\text{GR} = 5.1 \\text{ nm h}^{-1}$  for NPF with growth days and  $GR = 6.1 \\text{ nm h}^{-1}$  for NPF without growth days). Considering the similar CS and GR levels for NPF with and without growth days, the higher formation rates at  $1.7 \\text{ nm}$  ( $87 \\text{ cm}^{-3} \\text{ s}^{-1}$ ) may be a more important factor to surpass the CS. Under stable meteorological conditions, a higher formation rate may significantly elevate the possibility that newly formed particles overcome the CS and continuously grow to larger sizes.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.38927850127220154,
            -1.909722924232483
        ],
        "MSU_id": 1010
    },
    {
        "sentence": "The size of the dots is proportional to the logarithm of the signal intensity of each cluster.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 195,
        "paper_id": 2,
        "paragraph_info": "**Figure 4.** Mass defect plots, which represent the difference between compounds' exact mass and nominal mass, for  $(a)$  ion clusters and (b) neutral clusters during the NPF period  $(10:00-14:00 \\text{LT})$  on 20 April. The size of the dots is proportional to the logarithm of the signal intensity of each cluster.",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.8287662863731384,
            -0.22689968347549438
        ],
        "MSU_id": 1033
    },
    {
        "sentence": "For the Po Valley data, the formation rates, growth rates, SA concentrations, and CS data were selected for 10:00\u201314:00 LT.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 208,
        "paper_id": 2,
        "paragraph_info": "**Figure 5.** Parameters and gaseous precursors related to NPF in the Po Valley and other environments: (a) the formation rate of sub-2 nm particles, (b) the atmospheric NH3 concentrations, (c) the SA concentrations, (d) the DMA concentrations, (e) the CS levels and (f) the growth rate in different environments. Diamonds represent the median values; the error bars represent the 25th and 75th percentiles. For the Po Valley data, the formation rates, growth rates, SA concentrations and CS data were selected for 10:00\u201314:00 LT. The formation rates, growth rates, SA concentrations and CS during NPF in Beijing, Shanghai, Hyyti\u00e4l\u00e4, Jungfraujoch and Chacaltaya are from Deng et al. (2020). The GR calculation range used for comparison varies for different sites: Beijing (GR7\u201315; Deng et al., 2020), Shanghai (GR7\u201325; Yao et al., 2018), Nanjing (GR3\u201320; Yu et al., 2016), Hyyti\u00e4l\u00e4 (GR3\u201320; Vana et al., 2016), Jungfraujoch (GR7\u201320; Boulon et al., 2010), Chacaltaya (GR7\u201320; Rose et al., 2015) and Po Valley (GR7\u201315; this study). The NH3 and DMA concentrations are from the literature (as listed in the Table S1). Half of the limit of detection (LOD) of DMA concentrations in Hyyti\u00e4l\u00e4 was applied in panel (d) (Hemmil\u00e4 et al., 2018). DMA concentrations in the Po Valley were presented as the detection limit reported by Wang et al. (2020) with large uncertainties, as they were not quantified in this study (Fig. S4, Table S1).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            0.9244093894958496,
            -0.5430275797843933
        ],
        "MSU_id": 1120
    },
    {
        "sentence": "Half of the limit of detection (LOD) of DMA concentrations in Hyyti\u00e4l\u00e4 was applied in panel (d) (Hemmil\u00e4 et al., 2018).",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 208,
        "paper_id": 2,
        "paragraph_info": "**Figure 5.** Parameters and gaseous precursors related to NPF in the Po Valley and other environments: (a) the formation rate of sub-2 nm particles, (b) the atmospheric NH3 concentrations, (c) the SA concentrations, (d) the DMA concentrations, (e) the CS levels and (f) the growth rate in different environments. Diamonds represent the median values; the error bars represent the 25th and 75th percentiles. For the Po Valley data, the formation rates, growth rates, SA concentrations and CS data were selected for 10:00\u201314:00 LT. The formation rates, growth rates, SA concentrations and CS during NPF in Beijing, Shanghai, Hyyti\u00e4l\u00e4, Jungfraujoch and Chacaltaya are from Deng et al. (2020). The GR calculation range used for comparison varies for different sites: Beijing (GR7\u201315; Deng et al., 2020), Shanghai (GR7\u201325; Yao et al., 2018), Nanjing (GR3\u201320; Yu et al., 2016), Hyyti\u00e4l\u00e4 (GR3\u201320; Vana et al., 2016), Jungfraujoch (GR7\u201320; Boulon et al., 2010), Chacaltaya (GR7\u201320; Rose et al., 2015) and Po Valley (GR7\u201315; this study). The NH3 and DMA concentrations are from the literature (as listed in the Table S1). Half of the limit of detection (LOD) of DMA concentrations in Hyyti\u00e4l\u00e4 was applied in panel (d) (Hemmil\u00e4 et al., 2018). DMA concentrations in the Po Valley were presented as the detection limit reported by Wang et al. (2020) with large uncertainties, as they were not quantified in this study (Fig. S4, Table S1).",
        "paper_info": "acp-24-2423-2024",
        "2d_coord": [
            1.503779649734497,
            -0.11253509670495987
        ],
        "MSU_id": 1124
    },
    {
        "sentence": "Aerosol mass spectrometry (AMS) has been widely used to estimate the total amount of organic nitrates.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 229,
        "paper_id": 3,
        "paragraph_info": "Several compound categories of ON have been identified, including urea (Mace et al., 2003; Violaki and Mihalopoulos, 2011), amino acids (Zhang et al., 2002; Ren et al., 2018), amines (Ho et al., 2016; Liu et al., 2018a), N-heterocyclics (Samy and Hays, 2013; Rizwan Khan et al., 2017), nitroaromatics (Chow et al., 2016; Xie et al., 2017), nitro-PAHs (Wei et al., 2012), and organic nitrates (Li et al., 2018; Huang et al., 2021b). While urea stands as a single compound, several to dozens of individual compounds have been quantified in each of the other categories. Despite considerable uncertainty of quantification, aerosol mass spectrometry (AMS) has been widely used to estimate the total amount of organic nitrates (Farmer et al., 2010; Huang et al., 2021b; Xu et al., 2021). Overall, the quantifiable individual ON species or a specific ON category commonly constitute only a minor fraction of the total ON aerosol content (Jickells et al., 2013). The comprehensive quantification of every ON molecule to derive the total ON aerosol budget is impractical due to the lack of knowledge of molecular composition of the ON fraction and standards. Alternatively, bulk ON measurement, though lacking detailed compositional data, enables mass closure and aids in exploring major sources of ON aerosol. Traditional methods of aerosol ON quantification have relied on the difference method, where ON is calculated as the difference between total nitrogen (TN) and inorganic nitrogen (IN) (Cape et al., 2011). Limitations with the traditional analytical approach for aerosol ON determination have led to three deficiencies in the current status of aerosol ON data.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.602306604385376,
            0.0040919482707977295
        ],
        "MSU_id": 1179
    },
    {
        "sentence": "Bulk ON measurement enables mass closure and aids in exploring major sources of ON aerosol.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 229,
        "paper_id": 3,
        "paragraph_info": "Several compound categories of ON have been identified, including urea (Mace et al., 2003; Violaki and Mihalopoulos, 2011), amino acids (Zhang et al., 2002; Ren et al., 2018), amines (Ho et al., 2016; Liu et al., 2018a), N-heterocyclics (Samy and Hays, 2013; Rizwan Khan et al., 2017), nitroaromatics (Chow et al., 2016; Xie et al., 2017), nitro-PAHs (Wei et al., 2012), and organic nitrates (Li et al., 2018; Huang et al., 2021b). While urea stands as a single compound, several to dozens of individual compounds have been quantified in each of the other categories. Despite considerable uncertainty of quantification, aerosol mass spectrometry (AMS) has been widely used to estimate the total amount of organic nitrates (Farmer et al., 2010; Huang et al., 2021b; Xu et al., 2021). Overall, the quantifiable individual ON species or a specific ON category commonly constitute only a minor fraction of the total ON aerosol content (Jickells et al., 2013). The comprehensive quantification of every ON molecule to derive the total ON aerosol budget is impractical due to the lack of knowledge of molecular composition of the ON fraction and standards. Alternatively, bulk ON measurement, though lacking detailed compositional data, enables mass closure and aids in exploring major sources of ON aerosol. Traditional methods of aerosol ON quantification have relied on the difference method, where ON is calculated as the difference between total nitrogen (TN) and inorganic nitrogen (IN) (Cape et al., 2011). Limitations with the traditional analytical approach for aerosol ON determination have led to three deficiencies in the current status of aerosol ON data.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            2.1284804344177246,
            -0.5372726917266846
        ],
        "MSU_id": 1182
    },
    {
        "sentence": "Traditional methods of aerosol ON quantification have relied on the difference method, where ON is calculated as the difference between total nitrogen (TN) and inorganic nitrogen (IN).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 229,
        "paper_id": 3,
        "paragraph_info": "Several compound categories of ON have been identified, including urea (Mace et al., 2003; Violaki and Mihalopoulos, 2011), amino acids (Zhang et al., 2002; Ren et al., 2018), amines (Ho et al., 2016; Liu et al., 2018a), N-heterocyclics (Samy and Hays, 2013; Rizwan Khan et al., 2017), nitroaromatics (Chow et al., 2016; Xie et al., 2017), nitro-PAHs (Wei et al., 2012), and organic nitrates (Li et al., 2018; Huang et al., 2021b). While urea stands as a single compound, several to dozens of individual compounds have been quantified in each of the other categories. Despite considerable uncertainty of quantification, aerosol mass spectrometry (AMS) has been widely used to estimate the total amount of organic nitrates (Farmer et al., 2010; Huang et al., 2021b; Xu et al., 2021). Overall, the quantifiable individual ON species or a specific ON category commonly constitute only a minor fraction of the total ON aerosol content (Jickells et al., 2013). The comprehensive quantification of every ON molecule to derive the total ON aerosol budget is impractical due to the lack of knowledge of molecular composition of the ON fraction and standards. Alternatively, bulk ON measurement, though lacking detailed compositional data, enables mass closure and aids in exploring major sources of ON aerosol. Traditional methods of aerosol ON quantification have relied on the difference method, where ON is calculated as the difference between total nitrogen (TN) and inorganic nitrogen (IN) (Cape et al., 2011). Limitations with the traditional analytical approach for aerosol ON determination have led to three deficiencies in the current status of aerosol ON data.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.5316314697265625,
            -0.5572490096092224
        ],
        "MSU_id": 1183
    },
    {
        "sentence": "This approach produces WSON through taking the difference between WSTN and IN.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 230,
        "paper_id": 3,
        "paragraph_info": "First, the assessment of aerosol total ON, including both water-soluble ON (WSON) and water-insoluble ON (WION), has been quite restricted, with most determinations focusing solely on water-soluble TN (WSTN), omitting WION measurements (Cape et al., 2011). This approach produces WSON through taking the difference between WSTN and IN. Some studies have employed elemental analyzers for TN determination, calculating ON as the difference between TN and IN (Duan et al., 2009; Miyazaki et al., 2011; Pavuluri et al., 2015; Matsumoto et al., 2019). However, the elemental analyzers' detection limit of nitrogen is insufficient for accurate measurements of trace-level aerosol nitrogen (Duan et al., 2009), limiting its widespread use in aerosol nitrogen analysis. Despite significant uncertainty, a few studies suggested that WION, deduced by subtracting WSTN from TN, could be more abundant than WSON in coastal or urban areas (Pavuluri et al., 2015; Matsumoto et al., 2019), highlighting the necessity of quantifying total ON to determine the extent of ON aerosol presence. Second, the quantification of both WSON and WION using the difference method introduces considerable uncertainty, especially when ON is a minor fraction of TN (Yu et al., 2021). This approach has led to the reporting of physically implausible negative WSON concentrations in past studies (Mace et al., 2003; Nakamura et al., 2006; Violaki and Mihalopoulos, 2010; Yu et al., 2017). Third, the absence of high-time resolution or online measurement methods for aerosol ON has hampered the investigation of ON aerosol sources and formation processes in previous research.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            -0.04669247940182686,
            -1.6889551877975464
        ],
        "MSU_id": 1187
    },
    {
        "sentence": "Some studies have employed elemental analyzers for TN determination.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 230,
        "paper_id": 3,
        "paragraph_info": "First, the assessment of aerosol total ON, including both water-soluble ON (WSON) and water-insoluble ON (WION), has been quite restricted, with most determinations focusing solely on water-soluble TN (WSTN), omitting WION measurements (Cape et al., 2011). This approach produces WSON through taking the difference between WSTN and IN. Some studies have employed elemental analyzers for TN determination, calculating ON as the difference between TN and IN (Duan et al., 2009; Miyazaki et al., 2011; Pavuluri et al., 2015; Matsumoto et al., 2019). However, the elemental analyzers' detection limit of nitrogen is insufficient for accurate measurements of trace-level aerosol nitrogen (Duan et al., 2009), limiting its widespread use in aerosol nitrogen analysis. Despite significant uncertainty, a few studies suggested that WION, deduced by subtracting WSTN from TN, could be more abundant than WSON in coastal or urban areas (Pavuluri et al., 2015; Matsumoto et al., 2019), highlighting the necessity of quantifying total ON to determine the extent of ON aerosol presence. Second, the quantification of both WSON and WION using the difference method introduces considerable uncertainty, especially when ON is a minor fraction of TN (Yu et al., 2021). This approach has led to the reporting of physically implausible negative WSON concentrations in past studies (Mace et al., 2003; Nakamura et al., 2006; Violaki and Mihalopoulos, 2010; Yu et al., 2017). Third, the absence of high-time resolution or online measurement methods for aerosol ON has hampered the investigation of ON aerosol sources and formation processes in previous research.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.22356311976909637,
            0.5925301313400269
        ],
        "MSU_id": 1188
    },
    {
        "sentence": "ON is calculated as the difference between TN and IN.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 230,
        "paper_id": 3,
        "paragraph_info": "First, the assessment of aerosol total ON, including both water-soluble ON (WSON) and water-insoluble ON (WION), has been quite restricted, with most determinations focusing solely on water-soluble TN (WSTN), omitting WION measurements (Cape et al., 2011). This approach produces WSON through taking the difference between WSTN and IN. Some studies have employed elemental analyzers for TN determination, calculating ON as the difference between TN and IN (Duan et al., 2009; Miyazaki et al., 2011; Pavuluri et al., 2015; Matsumoto et al., 2019). However, the elemental analyzers' detection limit of nitrogen is insufficient for accurate measurements of trace-level aerosol nitrogen (Duan et al., 2009), limiting its widespread use in aerosol nitrogen analysis. Despite significant uncertainty, a few studies suggested that WION, deduced by subtracting WSTN from TN, could be more abundant than WSON in coastal or urban areas (Pavuluri et al., 2015; Matsumoto et al., 2019), highlighting the necessity of quantifying total ON to determine the extent of ON aerosol presence. Second, the quantification of both WSON and WION using the difference method introduces considerable uncertainty, especially when ON is a minor fraction of TN (Yu et al., 2021). This approach has led to the reporting of physically implausible negative WSON concentrations in past studies (Mace et al., 2003; Nakamura et al., 2006; Violaki and Mihalopoulos, 2010; Yu et al., 2017). Third, the absence of high-time resolution or online measurement methods for aerosol ON has hampered the investigation of ON aerosol sources and formation processes in previous research.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.7775753736495972,
            -1.8741027116775513
        ],
        "MSU_id": 1189
    },
    {
        "sentence": "We have developed an analyzer system that utilizes programmed thermal evolution of carbonaceous and nitrogenous aerosols and chemiluminescence detection coupled with multivariate curve resolution data treatment.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 231,
        "paper_id": 3,
        "paragraph_info": "We have developed an analyzer system that utilizes programmed thermal evolution of carbonaceous and nitrogenous aerosols and chemiluminescence detection coupled with multivariate curve resolution data treatment (Yu et al., 2021). This system enables simultaneous quantification of aerosol IN and ON with high sensitivity and accuracy. Unlike conventional methods, our new approach avoids the occurrence of negative ON concentrations, which are often encountered in difference methods. Furthermore, the method allows for both offline and online measurements of aerosol ON. During the summer of 2021, we conducted a two-month period of online observations of aerosol IN and ON in urban Shanghai (Yu et al., 2023). Our findings revealed significant diurnal variations in ON concentrations, with vehicle emissions and secondary formation processes identified as major drivers of episodic ON enhancements. However, due to the lack of comprehensive organic source markers, we were unable to fully attribute the contributions of certain potentially important sources and/or formation processes to the ON budget.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.2796359062194824,
            -0.26921361684799194
        ],
        "MSU_id": 1197
    },
    {
        "sentence": "Our new approach avoids the occurrence of negative ON concentrations, which are often encountered in difference methods.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 231,
        "paper_id": 3,
        "paragraph_info": "We have developed an analyzer system that utilizes programmed thermal evolution of carbonaceous and nitrogenous aerosols and chemiluminescence detection coupled with multivariate curve resolution data treatment (Yu et al., 2021). This system enables simultaneous quantification of aerosol IN and ON with high sensitivity and accuracy. Unlike conventional methods, our new approach avoids the occurrence of negative ON concentrations, which are often encountered in difference methods. Furthermore, the method allows for both offline and online measurements of aerosol ON. During the summer of 2021, we conducted a two-month period of online observations of aerosol IN and ON in urban Shanghai (Yu et al., 2023). Our findings revealed significant diurnal variations in ON concentrations, with vehicle emissions and secondary formation processes identified as major drivers of episodic ON enhancements. However, due to the lack of comprehensive organic source markers, we were unable to fully attribute the contributions of certain potentially important sources and/or formation processes to the ON budget.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.7776187658309937,
            0.8064122200012207
        ],
        "MSU_id": 1199
    },
    {
        "sentence": "The method allows for both offline and online measurements of aerosol ON.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 231,
        "paper_id": 3,
        "paragraph_info": "We have developed an analyzer system that utilizes programmed thermal evolution of carbonaceous and nitrogenous aerosols and chemiluminescence detection coupled with multivariate curve resolution data treatment (Yu et al., 2021). This system enables simultaneous quantification of aerosol IN and ON with high sensitivity and accuracy. Unlike conventional methods, our new approach avoids the occurrence of negative ON concentrations, which are often encountered in difference methods. Furthermore, the method allows for both offline and online measurements of aerosol ON. During the summer of 2021, we conducted a two-month period of online observations of aerosol IN and ON in urban Shanghai (Yu et al., 2023). Our findings revealed significant diurnal variations in ON concentrations, with vehicle emissions and secondary formation processes identified as major drivers of episodic ON enhancements. However, due to the lack of comprehensive organic source markers, we were unable to fully attribute the contributions of certain potentially important sources and/or formation processes to the ON budget.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.13593511283397675,
            -1.1813653707504272
        ],
        "MSU_id": 1200
    },
    {
        "sentence": "We conducted comprehensive measurements of aerosol major components and source markers on an hourly/bihourly scale.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 232,
        "paper_id": 3,
        "paragraph_info": "In this study, we extended our investigation through online measurements of aerosol ON in urban Shanghai during the fall-winter period of 2021. Concurrently, we conducted comprehensive measurements of aerosol major components and source markers on an hourly/bihourly scale. Specifically, we measured a comprehensive array of organic tracers representing distinct primary emission sources and secondary formation processes. These measurements enabled us to quantitatively apportion total ON to different primary and secondary sources using positive matrix factorization (PMF) receptor modeling. Our focus lies in examining the secondary formation sources of ON, as our knowledge regarding the formation mechanisms of ON aerosols remains limited. By combining the high-time resolution measurements of ON and comprehensive organic markers, we demonstrate the successful quantitative source analysis of ON aerosols in an urban atmosphere, revealing significant contributions of secondary formation pathways to ON.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.0544750690460205,
            -1.6000725030899048
        ],
        "MSU_id": 1206
    },
    {
        "sentence": "We measured a comprehensive array of organic tracers representing distinct primary emission sources and secondary formation processes.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 232,
        "paper_id": 3,
        "paragraph_info": "In this study, we extended our investigation through online measurements of aerosol ON in urban Shanghai during the fall-winter period of 2021. Concurrently, we conducted comprehensive measurements of aerosol major components and source markers on an hourly/bihourly scale. Specifically, we measured a comprehensive array of organic tracers representing distinct primary emission sources and secondary formation processes. These measurements enabled us to quantitatively apportion total ON to different primary and secondary sources using positive matrix factorization (PMF) receptor modeling. Our focus lies in examining the secondary formation sources of ON, as our knowledge regarding the formation mechanisms of ON aerosols remains limited. By combining the high-time resolution measurements of ON and comprehensive organic markers, we demonstrate the successful quantitative source analysis of ON aerosols in an urban atmosphere, revealing significant contributions of secondary formation pathways to ON.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            2.0358376502990723,
            -0.718646228313446
        ],
        "MSU_id": 1207
    },
    {
        "sentence": "These measurements enabled us to quantitatively apportion total ON to different primary and secondary sources using positive matrix factorization (PMF) receptor modeling.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 232,
        "paper_id": 3,
        "paragraph_info": "In this study, we extended our investigation through online measurements of aerosol ON in urban Shanghai during the fall-winter period of 2021. Concurrently, we conducted comprehensive measurements of aerosol major components and source markers on an hourly/bihourly scale. Specifically, we measured a comprehensive array of organic tracers representing distinct primary emission sources and secondary formation processes. These measurements enabled us to quantitatively apportion total ON to different primary and secondary sources using positive matrix factorization (PMF) receptor modeling. Our focus lies in examining the secondary formation sources of ON, as our knowledge regarding the formation mechanisms of ON aerosols remains limited. By combining the high-time resolution measurements of ON and comprehensive organic markers, we demonstrate the successful quantitative source analysis of ON aerosols in an urban atmosphere, revealing significant contributions of secondary formation pathways to ON.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.2880260944366455,
            -1.4828605651855469
        ],
        "MSU_id": 1208
    },
    {
        "sentence": "All measurements were carried out at a monitoring site (31.17\u00b0N, $121.43^{\\circ} \\text{E}$).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 233,
        "paper_id": 3,
        "paragraph_info": "The field measurement was conducted in Shanghai, a megacity located in the Yangtze River Delta (YRD) region of China and with a population of over 24 million. In recent years, the city has experienced frequent episodes of  $PM_{2.5}$  pollution, with nitrogenous components becoming increasingly prominent contributors to  $PM_{2.5}$  mass (Zhou et al., 2022). All measurements were carried out at a monitoring site (31.17\u00b0N,  $121.43^{\\circ} \\text{E}$ ) situated on the rooftop of an eight-story building, approximately 30 m above the ground, at the Shanghai Academy of Environmental Sciences (SAES). This site is surrounded by urban roads, commercial activities, and residential dwellings, making it a representative urban location influenced by a diverse range of emission sources (Wang et al., 2018; Zhou et al., 2022). The observations were conducted during the fall-winter period from 6 November to 31 December 2021.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.8104535937309265,
            -0.28575649857521057
        ],
        "MSU_id": 1218
    },
    {
        "sentence": "The monitoring site is situated on the rooftop of an eight-story building, approximately 30 m above the ground.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 233,
        "paper_id": 3,
        "paragraph_info": "The field measurement was conducted in Shanghai, a megacity located in the Yangtze River Delta (YRD) region of China and with a population of over 24 million. In recent years, the city has experienced frequent episodes of  $PM_{2.5}$  pollution, with nitrogenous components becoming increasingly prominent contributors to  $PM_{2.5}$  mass (Zhou et al., 2022). All measurements were carried out at a monitoring site (31.17\u00b0N,  $121.43^{\\circ} \\text{E}$ ) situated on the rooftop of an eight-story building, approximately 30 m above the ground, at the Shanghai Academy of Environmental Sciences (SAES). This site is surrounded by urban roads, commercial activities, and residential dwellings, making it a representative urban location influenced by a diverse range of emission sources (Wang et al., 2018; Zhou et al., 2022). The observations were conducted during the fall-winter period from 6 November to 31 December 2021.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            -1.0428214073181152,
            -0.1078639104962349
        ],
        "MSU_id": 1219
    },
    {
        "sentence": "The monitoring site is located at the Shanghai Academy of Environmental Sciences (SAES).",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 233,
        "paper_id": 3,
        "paragraph_info": "The field measurement was conducted in Shanghai, a megacity located in the Yangtze River Delta (YRD) region of China and with a population of over 24 million. In recent years, the city has experienced frequent episodes of  $PM_{2.5}$  pollution, with nitrogenous components becoming increasingly prominent contributors to  $PM_{2.5}$  mass (Zhou et al., 2022). All measurements were carried out at a monitoring site (31.17\u00b0N,  $121.43^{\\circ} \\text{E}$ ) situated on the rooftop of an eight-story building, approximately 30 m above the ground, at the Shanghai Academy of Environmental Sciences (SAES). This site is surrounded by urban roads, commercial activities, and residential dwellings, making it a representative urban location influenced by a diverse range of emission sources (Wang et al., 2018; Zhou et al., 2022). The observations were conducted during the fall-winter period from 6 November to 31 December 2021.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.9254884123802185,
            0.31829118728637695
        ],
        "MSU_id": 1220
    },
    {
        "sentence": "The analytical system enables sensitive and simultaneous measurements of aerosol ON and IN.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 234,
        "paper_id": 3,
        "paragraph_info": "Aerosol ON was measured bihourly using our newly developed analytical system, which enables sensitive and simultaneous measurements of aerosol ON and IN. Detailed descriptions of the new method can be found in our previous work (Yu et al., 2021, 2023). In brief, the analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence  $NO_x$  analyzer. Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures and then catalytically oxidized to  $CO_2$  and nitrogen oxides ( $NO_{\\nu}$ ), respectively. The C signal was monitored using the non-dispersive infrared (NDIR) method, while the N signal was recorded through chemiluminescence detection after converting  $NO_{\\nu}$  to NO. The C signal assists in differentiating IN and ON components since ON aerosols produce both C and N signals, while the IN fraction only gives an N signal. The programmed thermal evolution facilitates the separation of aerosol IN and ON, as they exhibit distinct thermal characteristics. The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions (Yu et al., 2021).",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.3325556516647339,
            -0.5862827301025391
        ],
        "MSU_id": 1225
    },
    {
        "sentence": "The analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence $NO_x$ analyzer.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 234,
        "paper_id": 3,
        "paragraph_info": "Aerosol ON was measured bihourly using our newly developed analytical system, which enables sensitive and simultaneous measurements of aerosol ON and IN. Detailed descriptions of the new method can be found in our previous work (Yu et al., 2021, 2023). In brief, the analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence  $NO_x$  analyzer. Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures and then catalytically oxidized to  $CO_2$  and nitrogen oxides ( $NO_{\\nu}$ ), respectively. The C signal was monitored using the non-dispersive infrared (NDIR) method, while the N signal was recorded through chemiluminescence detection after converting  $NO_{\\nu}$  to NO. The C signal assists in differentiating IN and ON components since ON aerosols produce both C and N signals, while the IN fraction only gives an N signal. The programmed thermal evolution facilitates the separation of aerosol IN and ON, as they exhibit distinct thermal characteristics. The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions (Yu et al., 2021).",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.6589158773422241,
            -0.35760262608528137
        ],
        "MSU_id": 1226
    },
    {
        "sentence": "Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 234,
        "paper_id": 3,
        "paragraph_info": "Aerosol ON was measured bihourly using our newly developed analytical system, which enables sensitive and simultaneous measurements of aerosol ON and IN. Detailed descriptions of the new method can be found in our previous work (Yu et al., 2021, 2023). In brief, the analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence  $NO_x$  analyzer. Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures and then catalytically oxidized to  $CO_2$  and nitrogen oxides ( $NO_{\\nu}$ ), respectively. The C signal was monitored using the non-dispersive infrared (NDIR) method, while the N signal was recorded through chemiluminescence detection after converting  $NO_{\\nu}$  to NO. The C signal assists in differentiating IN and ON components since ON aerosols produce both C and N signals, while the IN fraction only gives an N signal. The programmed thermal evolution facilitates the separation of aerosol IN and ON, as they exhibit distinct thermal characteristics. The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions (Yu et al., 2021).",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.5999475717544556,
            -0.3969763219356537
        ],
        "MSU_id": 1227
    },
    {
        "sentence": "The carbonaceous aerosols were catalytically oxidized to $CO_2$ and nitrogen oxides ($NO_{\nu}$).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 234,
        "paper_id": 3,
        "paragraph_info": "Aerosol ON was measured bihourly using our newly developed analytical system, which enables sensitive and simultaneous measurements of aerosol ON and IN. Detailed descriptions of the new method can be found in our previous work (Yu et al., 2021, 2023). In brief, the analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence  $NO_x$  analyzer. Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures and then catalytically oxidized to  $CO_2$  and nitrogen oxides ( $NO_{\\nu}$ ), respectively. The C signal was monitored using the non-dispersive infrared (NDIR) method, while the N signal was recorded through chemiluminescence detection after converting  $NO_{\\nu}$  to NO. The C signal assists in differentiating IN and ON components since ON aerosols produce both C and N signals, while the IN fraction only gives an N signal. The programmed thermal evolution facilitates the separation of aerosol IN and ON, as they exhibit distinct thermal characteristics. The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions (Yu et al., 2021).",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.899834156036377,
            0.10771717876195908
        ],
        "MSU_id": 1228
    },
    {
        "sentence": "The C signal was monitored using the non-dispersive infrared (NDIR) method.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 234,
        "paper_id": 3,
        "paragraph_info": "Aerosol ON was measured bihourly using our newly developed analytical system, which enables sensitive and simultaneous measurements of aerosol ON and IN. Detailed descriptions of the new method can be found in our previous work (Yu et al., 2021, 2023). In brief, the analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence  $NO_x$  analyzer. Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures and then catalytically oxidized to  $CO_2$  and nitrogen oxides ( $NO_{\\nu}$ ), respectively. The C signal was monitored using the non-dispersive infrared (NDIR) method, while the N signal was recorded through chemiluminescence detection after converting  $NO_{\\nu}$  to NO. The C signal assists in differentiating IN and ON components since ON aerosols produce both C and N signals, while the IN fraction only gives an N signal. The programmed thermal evolution facilitates the separation of aerosol IN and ON, as they exhibit distinct thermal characteristics. The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions (Yu et al., 2021).",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.8517779111862183,
            0.6323307752609253
        ],
        "MSU_id": 1229
    },
    {
        "sentence": "The N signal was recorded through chemiluminescence detection after converting $NO_{\nu}$ to NO.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 234,
        "paper_id": 3,
        "paragraph_info": "Aerosol ON was measured bihourly using our newly developed analytical system, which enables sensitive and simultaneous measurements of aerosol ON and IN. Detailed descriptions of the new method can be found in our previous work (Yu et al., 2021, 2023). In brief, the analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence  $NO_x$  analyzer. Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures and then catalytically oxidized to  $CO_2$  and nitrogen oxides ( $NO_{\\nu}$ ), respectively. The C signal was monitored using the non-dispersive infrared (NDIR) method, while the N signal was recorded through chemiluminescence detection after converting  $NO_{\\nu}$  to NO. The C signal assists in differentiating IN and ON components since ON aerosols produce both C and N signals, while the IN fraction only gives an N signal. The programmed thermal evolution facilitates the separation of aerosol IN and ON, as they exhibit distinct thermal characteristics. The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions (Yu et al., 2021).",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.778718113899231,
            -0.2984660267829895
        ],
        "MSU_id": 1230
    },
    {
        "sentence": "The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 234,
        "paper_id": 3,
        "paragraph_info": "Aerosol ON was measured bihourly using our newly developed analytical system, which enables sensitive and simultaneous measurements of aerosol ON and IN. Detailed descriptions of the new method can be found in our previous work (Yu et al., 2021, 2023). In brief, the analyzer system integrates two commercial instruments: an online aerosol carbon (C) analyzer and a chemiluminescence  $NO_x$  analyzer. Carbonaceous and nitrogenous aerosols collected on quartz filters were thermally evolved under programmed temperatures and then catalytically oxidized to  $CO_2$  and nitrogen oxides ( $NO_{\\nu}$ ), respectively. The C signal was monitored using the non-dispersive infrared (NDIR) method, while the N signal was recorded through chemiluminescence detection after converting  $NO_{\\nu}$  to NO. The C signal assists in differentiating IN and ON components since ON aerosols produce both C and N signals, while the IN fraction only gives an N signal. The programmed thermal evolution facilitates the separation of aerosol IN and ON, as they exhibit distinct thermal characteristics. The quantification of IN and ON is achieved through multivariate curve resolution data treatment of C and N thermal fractions (Yu et al., 2021).",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.7508959770202637,
            -0.6843372583389282
        ],
        "MSU_id": 1234
    },
    {
        "sentence": "The time resolution for ON measurement was 2h.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 235,
        "paper_id": 3,
        "paragraph_info": "The time resolution for ON measurement was 2h, with each sampling lasting 1 h, followed by an analysis step taking approximately 50 min. Sampling commenced at even hours (e.g., 02:00, 04:00). In total, 598 pairs of available ON and IN data points were collected. 4-methyl-imidazole served as the calibration standard for  $C$  and  $N$  measurements, with systematic calibrations conducted twice monthly. Example calibration curves could be found in Yu et al. (2023). The detection limit for aerosol N is  $0.013 \\mu$ g N, corresponding to an air concentration of  $0.027 \\,\\mu\\text{g N m}^{-3}$ . A comparative analysis of aerosol IN concentrations obtained through the new method and those measured by the Monitor for AeRosols and GAses (MARGA) system is presented in Fig. S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.2548471689224243,
            -1.4102801084518433
        ],
        "MSU_id": 1236
    },
    {
        "sentence": "Each sampling lasted 1 h, followed by an analysis step taking approximately 50 min.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 235,
        "paper_id": 3,
        "paragraph_info": "The time resolution for ON measurement was 2h, with each sampling lasting 1 h, followed by an analysis step taking approximately 50 min. Sampling commenced at even hours (e.g., 02:00, 04:00). In total, 598 pairs of available ON and IN data points were collected. 4-methyl-imidazole served as the calibration standard for  $C$  and  $N$  measurements, with systematic calibrations conducted twice monthly. Example calibration curves could be found in Yu et al. (2023). The detection limit for aerosol N is  $0.013 \\mu$ g N, corresponding to an air concentration of  $0.027 \\,\\mu\\text{g N m}^{-3}$ . A comparative analysis of aerosol IN concentrations obtained through the new method and those measured by the Monitor for AeRosols and GAses (MARGA) system is presented in Fig. S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.36998051404953003,
            0.5338063836097717
        ],
        "MSU_id": 1237
    },
    {
        "sentence": "Sampling commenced at even hours (e.g., 02:00, 04:00).",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 235,
        "paper_id": 3,
        "paragraph_info": "The time resolution for ON measurement was 2h, with each sampling lasting 1 h, followed by an analysis step taking approximately 50 min. Sampling commenced at even hours (e.g., 02:00, 04:00). In total, 598 pairs of available ON and IN data points were collected. 4-methyl-imidazole served as the calibration standard for  $C$  and  $N$  measurements, with systematic calibrations conducted twice monthly. Example calibration curves could be found in Yu et al. (2023). The detection limit for aerosol N is  $0.013 \\mu$ g N, corresponding to an air concentration of  $0.027 \\,\\mu\\text{g N m}^{-3}$ . A comparative analysis of aerosol IN concentrations obtained through the new method and those measured by the Monitor for AeRosols and GAses (MARGA) system is presented in Fig. S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.18504628539085388,
            0.4660724401473999
        ],
        "MSU_id": 1238
    },
    {
        "sentence": "4-methyl-imidazole served as the calibration standard for $C$ and $N$ measurements.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 235,
        "paper_id": 3,
        "paragraph_info": "The time resolution for ON measurement was 2h, with each sampling lasting 1 h, followed by an analysis step taking approximately 50 min. Sampling commenced at even hours (e.g., 02:00, 04:00). In total, 598 pairs of available ON and IN data points were collected. 4-methyl-imidazole served as the calibration standard for  $C$  and  $N$  measurements, with systematic calibrations conducted twice monthly. Example calibration curves could be found in Yu et al. (2023). The detection limit for aerosol N is  $0.013 \\mu$ g N, corresponding to an air concentration of  $0.027 \\,\\mu\\text{g N m}^{-3}$ . A comparative analysis of aerosol IN concentrations obtained through the new method and those measured by the Monitor for AeRosols and GAses (MARGA) system is presented in Fig. S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.6142587661743164,
            -0.016174882650375366
        ],
        "MSU_id": 1240
    },
    {
        "sentence": "Systematic calibrations were conducted twice monthly.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 235,
        "paper_id": 3,
        "paragraph_info": "The time resolution for ON measurement was 2h, with each sampling lasting 1 h, followed by an analysis step taking approximately 50 min. Sampling commenced at even hours (e.g., 02:00, 04:00). In total, 598 pairs of available ON and IN data points were collected. 4-methyl-imidazole served as the calibration standard for  $C$  and  $N$  measurements, with systematic calibrations conducted twice monthly. Example calibration curves could be found in Yu et al. (2023). The detection limit for aerosol N is  $0.013 \\mu$ g N, corresponding to an air concentration of  $0.027 \\,\\mu\\text{g N m}^{-3}$ . A comparative analysis of aerosol IN concentrations obtained through the new method and those measured by the Monitor for AeRosols and GAses (MARGA) system is presented in Fig. S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.8592978119850159,
            0.027997076511383057
        ],
        "MSU_id": 1241
    },
    {
        "sentence": "$PM_{2.5}$ concentration was measured using a beta attenuation particulate monitor.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 236,
        "paper_id": 3,
        "paragraph_info": "The measurement methods for  $PM_{2.5}$  mass and major aerosol components at the site have been described in detail elsewhere (Qiao et al., 2014).  $PM_{2.5}$  concentration was measured using a beta attenuation particulate monitor (Thermo Fisher Scientific, FH 62 C14 series). Organic and elemental carbon (OC and EC) were monitored using a semicontinuous OC/EC analyzer (model RT-4, Sunset Laboratory, Tigard, OR, USA). The major water-soluble ionic species  $(NO_3^-, Cl^-, SO_4^{2-},$  $\\mathrm{Na}^+$ ,  $\\mathrm{NH}_4^+$ ,  $\\mathrm{K}^+$ ,  $\\mathrm{Mg}^{2+}$ , and  $\\mathrm{Ca}^{2+}$ ) in PM<sub>2.5</sub> were measured using the MARGA (ADI, 2080; Applikon Analytical B.V.). Elements in PM<sub>2.5</sub> (e.g., Al, K, Ca, Mn, Fe, Ni, Cu, Zn, As, Se, Cd, Pb) were monitored using an online X-ray fluorescence (XRF) spectrometer (Xact<sup>\u00ae</sup> 625, Cooper Environmental Services, Tigard, OR, USA). All the instruments were equipped with individual sampling inlets with a cyclone to achieve a  $2.5 \\,\\mu\\text{m}$  cut size. The sampling lines, made of stainless steel, were approximately  $2-2.5$  m in length.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.2556331157684326,
            0.8085063695907593
        ],
        "MSU_id": 1246
    },
    {
        "sentence": "Organic and elemental carbon (OC and EC) were monitored using a semicontinuous OC/EC analyzer.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 236,
        "paper_id": 3,
        "paragraph_info": "The measurement methods for  $PM_{2.5}$  mass and major aerosol components at the site have been described in detail elsewhere (Qiao et al., 2014).  $PM_{2.5}$  concentration was measured using a beta attenuation particulate monitor (Thermo Fisher Scientific, FH 62 C14 series). Organic and elemental carbon (OC and EC) were monitored using a semicontinuous OC/EC analyzer (model RT-4, Sunset Laboratory, Tigard, OR, USA). The major water-soluble ionic species  $(NO_3^-, Cl^-, SO_4^{2-},$  $\\mathrm{Na}^+$ ,  $\\mathrm{NH}_4^+$ ,  $\\mathrm{K}^+$ ,  $\\mathrm{Mg}^{2+}$ , and  $\\mathrm{Ca}^{2+}$ ) in PM<sub>2.5</sub> were measured using the MARGA (ADI, 2080; Applikon Analytical B.V.). Elements in PM<sub>2.5</sub> (e.g., Al, K, Ca, Mn, Fe, Ni, Cu, Zn, As, Se, Cd, Pb) were monitored using an online X-ray fluorescence (XRF) spectrometer (Xact<sup>\u00ae</sup> 625, Cooper Environmental Services, Tigard, OR, USA). All the instruments were equipped with individual sampling inlets with a cyclone to achieve a  $2.5 \\,\\mu\\text{m}$  cut size. The sampling lines, made of stainless steel, were approximately  $2-2.5$  m in length.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.336817741394043,
            0.24653255939483643
        ],
        "MSU_id": 1247
    },
    {
        "sentence": "The major water-soluble ionic species in PM<sub>2.5</sub> were measured using the MARGA.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 236,
        "paper_id": 3,
        "paragraph_info": "The measurement methods for  $PM_{2.5}$  mass and major aerosol components at the site have been described in detail elsewhere (Qiao et al., 2014).  $PM_{2.5}$  concentration was measured using a beta attenuation particulate monitor (Thermo Fisher Scientific, FH 62 C14 series). Organic and elemental carbon (OC and EC) were monitored using a semicontinuous OC/EC analyzer (model RT-4, Sunset Laboratory, Tigard, OR, USA). The major water-soluble ionic species  $(NO_3^-, Cl^-, SO_4^{2-},$  $\\mathrm{Na}^+$ ,  $\\mathrm{NH}_4^+$ ,  $\\mathrm{K}^+$ ,  $\\mathrm{Mg}^{2+}$ , and  $\\mathrm{Ca}^{2+}$ ) in PM<sub>2.5</sub> were measured using the MARGA (ADI, 2080; Applikon Analytical B.V.). Elements in PM<sub>2.5</sub> (e.g., Al, K, Ca, Mn, Fe, Ni, Cu, Zn, As, Se, Cd, Pb) were monitored using an online X-ray fluorescence (XRF) spectrometer (Xact<sup>\u00ae</sup> 625, Cooper Environmental Services, Tigard, OR, USA). All the instruments were equipped with individual sampling inlets with a cyclone to achieve a  $2.5 \\,\\mu\\text{m}$  cut size. The sampling lines, made of stainless steel, were approximately  $2-2.5$  m in length.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.6589264869689941,
            -0.11123981326818466
        ],
        "MSU_id": 1248
    },
    {
        "sentence": "Elements in PM<sub>2.5</sub> were monitored using an online X-ray fluorescence (XRF) spectrometer.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 236,
        "paper_id": 3,
        "paragraph_info": "The measurement methods for  $PM_{2.5}$  mass and major aerosol components at the site have been described in detail elsewhere (Qiao et al., 2014).  $PM_{2.5}$  concentration was measured using a beta attenuation particulate monitor (Thermo Fisher Scientific, FH 62 C14 series). Organic and elemental carbon (OC and EC) were monitored using a semicontinuous OC/EC analyzer (model RT-4, Sunset Laboratory, Tigard, OR, USA). The major water-soluble ionic species  $(NO_3^-, Cl^-, SO_4^{2-},$  $\\mathrm{Na}^+$ ,  $\\mathrm{NH}_4^+$ ,  $\\mathrm{K}^+$ ,  $\\mathrm{Mg}^{2+}$ , and  $\\mathrm{Ca}^{2+}$ ) in PM<sub>2.5</sub> were measured using the MARGA (ADI, 2080; Applikon Analytical B.V.). Elements in PM<sub>2.5</sub> (e.g., Al, K, Ca, Mn, Fe, Ni, Cu, Zn, As, Se, Cd, Pb) were monitored using an online X-ray fluorescence (XRF) spectrometer (Xact<sup>\u00ae</sup> 625, Cooper Environmental Services, Tigard, OR, USA). All the instruments were equipped with individual sampling inlets with a cyclone to achieve a  $2.5 \\,\\mu\\text{m}$  cut size. The sampling lines, made of stainless steel, were approximately  $2-2.5$  m in length.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.3171880841255188,
            -0.048573993146419525
        ],
        "MSU_id": 1249
    },
    {
        "sentence": "All the instruments were equipped with individual sampling inlets with a cyclone to achieve a $2.5 \\,\\mu\\text{m}$ cut size.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 236,
        "paper_id": 3,
        "paragraph_info": "The measurement methods for  $PM_{2.5}$  mass and major aerosol components at the site have been described in detail elsewhere (Qiao et al., 2014).  $PM_{2.5}$  concentration was measured using a beta attenuation particulate monitor (Thermo Fisher Scientific, FH 62 C14 series). Organic and elemental carbon (OC and EC) were monitored using a semicontinuous OC/EC analyzer (model RT-4, Sunset Laboratory, Tigard, OR, USA). The major water-soluble ionic species  $(NO_3^-, Cl^-, SO_4^{2-},$  $\\mathrm{Na}^+$ ,  $\\mathrm{NH}_4^+$ ,  $\\mathrm{K}^+$ ,  $\\mathrm{Mg}^{2+}$ , and  $\\mathrm{Ca}^{2+}$ ) in PM<sub>2.5</sub> were measured using the MARGA (ADI, 2080; Applikon Analytical B.V.). Elements in PM<sub>2.5</sub> (e.g., Al, K, Ca, Mn, Fe, Ni, Cu, Zn, As, Se, Cd, Pb) were monitored using an online X-ray fluorescence (XRF) spectrometer (Xact<sup>\u00ae</sup> 625, Cooper Environmental Services, Tigard, OR, USA). All the instruments were equipped with individual sampling inlets with a cyclone to achieve a  $2.5 \\,\\mu\\text{m}$  cut size. The sampling lines, made of stainless steel, were approximately  $2-2.5$  m in length.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.8649793267250061,
            -0.08614005893468857
        ],
        "MSU_id": 1250
    },
    {
        "sentence": "The sampling lines were made of stainless steel and were approximately $2-2.5$ m in length.",
        "category": "Method",
        "rank": 2,
        "type": "text",
        "para_id": 236,
        "paper_id": 3,
        "paragraph_info": "The measurement methods for  $PM_{2.5}$  mass and major aerosol components at the site have been described in detail elsewhere (Qiao et al., 2014).  $PM_{2.5}$  concentration was measured using a beta attenuation particulate monitor (Thermo Fisher Scientific, FH 62 C14 series). Organic and elemental carbon (OC and EC) were monitored using a semicontinuous OC/EC analyzer (model RT-4, Sunset Laboratory, Tigard, OR, USA). The major water-soluble ionic species  $(NO_3^-, Cl^-, SO_4^{2-},$  $\\mathrm{Na}^+$ ,  $\\mathrm{NH}_4^+$ ,  $\\mathrm{K}^+$ ,  $\\mathrm{Mg}^{2+}$ , and  $\\mathrm{Ca}^{2+}$ ) in PM<sub>2.5</sub> were measured using the MARGA (ADI, 2080; Applikon Analytical B.V.). Elements in PM<sub>2.5</sub> (e.g., Al, K, Ca, Mn, Fe, Ni, Cu, Zn, As, Se, Cd, Pb) were monitored using an online X-ray fluorescence (XRF) spectrometer (Xact<sup>\u00ae</sup> 625, Cooper Environmental Services, Tigard, OR, USA). All the instruments were equipped with individual sampling inlets with a cyclone to achieve a  $2.5 \\,\\mu\\text{m}$  cut size. The sampling lines, made of stainless steel, were approximately  $2-2.5$  m in length.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.06259457767009735,
            1.1728708744049072
        ],
        "MSU_id": 1251
    },
    {
        "sentence": "The TAG system operated at a time resolution of 2 h.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.03474394604563713,
            -0.49465078115463257
        ],
        "MSU_id": 1254
    },
    {
        "sentence": "During the first hour, ambient air was drawn through a $PM_{2.5}$ cyclone at a flow rate of $10 \\text{ L min}^{-1}$, passing through a carbon denuder to remove the gas phase.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.159313440322876,
            0.26295360922813416
        ],
        "MSU_id": 1255
    },
    {
        "sentence": "Particles were then collected onto a thermal desorption cell (CTD).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.1830024719238281,
            0.6121458411216736
        ],
        "MSU_id": 1256
    },
    {
        "sentence": "In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.3678038120269775,
            0.3267110288143158
        ],
        "MSU_id": 1257
    },
    {
        "sentence": "In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.167297124862671,
            0.3669767379760742
        ],
        "MSU_id": 1258
    },
    {
        "sentence": "During the thermal desorption step, the polar organic compounds in the $PM_{2.5}$ were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA).",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.8357707262039185,
            -0.14491218328475952
        ],
        "MSU_id": 1259
    },
    {
        "sentence": "The organic compounds were reconcentrated onto a focusing trap cooled by a fan.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.5382812023162842,
            0.40493834018707275
        ],
        "MSU_id": 1260
    },
    {
        "sentence": "The CTD was purged with pure helium to remove excess MSTFA.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.1346178948879242,
            1.0492637157440186
        ],
        "MSU_id": 1261
    },
    {
        "sentence": "The focusing trap was heated to $330,^{circ}mathrm{C}$ to transfer the organic compounds into the valveless injection system.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.839233160018921,
            -0.23793888092041016
        ],
        "MSU_id": 1262
    },
    {
        "sentence": "The GC-MS analysis was then initiated.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 237,
        "paper_id": 3,
        "paragraph_info": "Quantification of a suite of speciated organic markers was conducted using a thermal desorption Aerosol Ggas chromatography-mass spectrometer (TAG, Aerodyne Research Inc.). The measurement principle and operational procedure of the TAG system have been described in detail in previous studies (Williams et al., 2006; He et al., 2020; Zhu et al., 2021). In brief, the TAG system operated at a time resolution of 2 h. During the first hour, ambient air was drawn through a  $PM_{2.5}$  cyclone at a flow rate of  $10 \\text{ L min}^{-1}$ , passing through a carbon denuder to remove the gas phase, and particles were then collected onto a thermal desorption cell (CTD). In the second hour, the collected particles underwent thermal desorption and gas chromatography-mass spectrometry (GC-MS) analysis. In each analysis, 5 \u00b5L of an internal standard mixture was added to the CTD that was loaded with particles collected in the preceding hour. During the thermal desorption step, the polar organic compounds in the  $PM_{2.5}$  were derivatized to their trimethylsilyl derivatives under a helium stream saturated with the derivatization agent Nmethyl-N-(trimethylsilyl) trifluoroacetamide (MSTFA). Subsequently, the organic compounds were reconcentrated onto a focusing trap cooled by a fan. Following this, the CTD was purged with pure helium to remove excess MSTFA, and the focusing trap was heated to  $330\\,^{\\circ}\\mathrm{C}$  to transfer the organic compounds into the valveless injection system, which utilizes a restrictive capillary tube to connect to the GC inlet. The GC-MS analysis was then initiated. A total of approximately 100 polar and non-polar organic compounds could be identified and quantified with authentic standards (Zhu et al., 2021). The individual TAG-measured source tracers used for PMF receptor modeling are listed in Table S1 in the Supplement.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.36051157116889954,
            1.0731031894683838
        ],
        "MSU_id": 1263
    },
    {
        "sentence": "The trace gas and meteorological data were averaged to an hourly resolution.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 238,
        "paper_id": 3,
        "paragraph_info": "Gaseous pollutants, including sulfur dioxide  $(SO_2)$ , ozone  $(O_3)$ , nitrogen dioxide (NO<sub>2</sub>), nitric oxide (NO), and carbon monoxide (CO), along with meteorological parameters such as temperature, relative humidity, atmospheric pressure, visibility, wind speed, and wind direction, were also recorded. The trace gas and meteorological data were averaged to an hourly resolution to match the time resolution of other analyses.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.7767719030380249,
            -1.4293559789657593
        ],
        "MSU_id": 1268
    },
    {
        "sentence": "These data enabled a quantitative source apportionment of ON using PMF receptor modeling.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 241,
        "paper_id": 3,
        "paragraph_info": "In this study, bihourly measurements of aerosol total ON, together with a comprehensive list of organic and inorganic source markers, were available. These data enabled a quantitative source apportionment of ON using PMF receptor modeling. The PMF results allowed investigation of the diel variations in ON sources. Details regarding the PMF configuration and diagnostics are provided in Text S1 in the Supplement. Benefiting from the comprehensive array of molecular source tracers, the PMF analysis resolved a total of 18 factors, including eight primary emission sources and 10 secondary formation sources. The factor profiles and contributions are displayed in Figs. S3 and S4 in the Supplement, respectively. Source identification was based on established molecular and elemental markers (Qiao et al., 2014; Wang et al., 2015). These factors and their corresponding markers are as follows. (1) Industrial emissions were represented by manganese (Mn), iron (Fe), and zinc (Zn). (2) Coal combustion was identified through selenium (Se) and lead (Pb). (3) Biomass burning was characterized by the presence of levoglucosan, mannosan, and galactosan. (4) Vehicle emissions were indicated by hopanes, nitrogen oxides  $(NO_x)$ , and elemental carbon (EC). (5) Residue oil combustion was marked by high loadings of nickel (Ni). (6) Cooking emissions were indicated by saturated and unsaturated fatty acids. (7) Oxygenated cooking OA formation was characterized by the high loadings of azelaic acid, 9-oxononanoic acid, and nonanoic acid, which are oxidation products of oleic acid or other unsaturated fatty acids with  $-C = C$  at the C9 position that are emitted directly from cooking activities (Huang et al., 2021a; Wang and Yu, 2021). This factor reflects secondary oxidation products originating from primary cooking emissions and showed pronounced enhancements during dinner hours, as illustrated in Fig. S4a. (8) Sea salt emissions were distinguished by sodium  $(Na^+)$  and chloride  $(Cl^-)$ . (9) Soil dust was indicated by silicon (Si) and calcium (Ca). (10) Nitrocatechol formation processes were represented by 4-nitrocatechol, 3-",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.5273284912109375,
            -0.7417805194854736
        ],
        "MSU_id": 1288
    },
    {
        "sentence": "Source identification was based on established molecular and elemental markers.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 241,
        "paper_id": 3,
        "paragraph_info": "In this study, bihourly measurements of aerosol total ON, together with a comprehensive list of organic and inorganic source markers, were available. These data enabled a quantitative source apportionment of ON using PMF receptor modeling. The PMF results allowed investigation of the diel variations in ON sources. Details regarding the PMF configuration and diagnostics are provided in Text S1 in the Supplement. Benefiting from the comprehensive array of molecular source tracers, the PMF analysis resolved a total of 18 factors, including eight primary emission sources and 10 secondary formation sources. The factor profiles and contributions are displayed in Figs. S3 and S4 in the Supplement, respectively. Source identification was based on established molecular and elemental markers (Qiao et al., 2014; Wang et al., 2015). These factors and their corresponding markers are as follows. (1) Industrial emissions were represented by manganese (Mn), iron (Fe), and zinc (Zn). (2) Coal combustion was identified through selenium (Se) and lead (Pb). (3) Biomass burning was characterized by the presence of levoglucosan, mannosan, and galactosan. (4) Vehicle emissions were indicated by hopanes, nitrogen oxides  $(NO_x)$ , and elemental carbon (EC). (5) Residue oil combustion was marked by high loadings of nickel (Ni). (6) Cooking emissions were indicated by saturated and unsaturated fatty acids. (7) Oxygenated cooking OA formation was characterized by the high loadings of azelaic acid, 9-oxononanoic acid, and nonanoic acid, which are oxidation products of oleic acid or other unsaturated fatty acids with  $-C = C$  at the C9 position that are emitted directly from cooking activities (Huang et al., 2021a; Wang and Yu, 2021). This factor reflects secondary oxidation products originating from primary cooking emissions and showed pronounced enhancements during dinner hours, as illustrated in Fig. S4a. (8) Sea salt emissions were distinguished by sodium  $(Na^+)$  and chloride  $(Cl^-)$ . (9) Soil dust was indicated by silicon (Si) and calcium (Ca). (10) Nitrocatechol formation processes were represented by 4-nitrocatechol, 3-",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.1782212257385254,
            0.5683272480964661
        ],
        "MSU_id": 1293
    },
    {
        "sentence": "The OC / ON values are atomic ratios.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 243,
        "paper_id": 3,
        "paragraph_info": "Figure 1. (a) Time series of aerosol N and C concentrations as well as  $ON / TN$  and  $OC / ON$  ratios during the fall-winter field observations in urban Shanghai from 6 November to 31 December 2021. The OC / ON values are atomic ratios, calculated by measured OC / ON mass ratios divided by  $(12/14)$ . (b) Diel variations of ON and IN concentrations as well as ON / TN and OC / ON ratios.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.6572017669677734,
            -1.114483118057251
        ],
        "MSU_id": 1307
    },
    {
        "sentence": "The OC / ON values are calculated by measured OC / ON mass ratios divided by (12/14).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 243,
        "paper_id": 3,
        "paragraph_info": "Figure 1. (a) Time series of aerosol N and C concentrations as well as  $ON / TN$  and  $OC / ON$  ratios during the fall-winter field observations in urban Shanghai from 6 November to 31 December 2021. The OC / ON values are atomic ratios, calculated by measured OC / ON mass ratios divided by  $(12/14)$ . (b) Diel variations of ON and IN concentrations as well as ON / TN and OC / ON ratios.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.8517885208129883,
            -1.1551299095153809
        ],
        "MSU_id": 1308
    },
    {
        "sentence": "Both nitrocatechols and nitrophenol were included in the PMF analysis to resolve ON fractions associated with nitroaromatic species.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 244,
        "paper_id": 3,
        "paragraph_info": "methyl-5-nitrocatechol, and 4-methyl-5-nitrocatechol. These compounds exhibited strong inter-species correlations, with  $R^2$  values ranging from 0.4 to 0.8, suggesting a common formation pathway. (11) Nitrophenol formation was identified through 4-nitrophenol. As nitroaromatic compounds are significant components of nitrogen-containing OA, both nitrocatechols and nitrophenol were included in the PMF analysis to resolve ON fractions associated with nitroaromatic species. (12) Nitrate formation processes were indicated by nitrate  $(NO_3^-)$ . (13) Sulfate formation processes were identified through sulfate  $(SO_4^{2-})$ . (14) Photochemical formation processes were associated with a high loading of ozone  $(O_3)$ . (15) Phthalic acid formation processes were resolved using phthalic acid as a tracer. (16) Dicarboxylic acid (DCA) formation was identified through a suite of dicarboxylic acids. (17) Isoprene- and \u03b1-pinene-derived secondary OA (SOA) formation was represented by their respective oxidation products. (18) \u03b2-Caryophyllene SOA formation was characterized by \u03b2-caryophyllenic acid. The 18 factor solution exhibited excellent agreement with the observed ON and OC masses (Fig. S5). Among theses factors, 12 contributed to ON mass. The remaining six factors\u2013 biomass burning, residue oil combustion, sea salt emission, sulfate formation processes, phthalic acid formation, and isoprene and \u03b1-pinene SOA formation processes\u2013showed negligible or no contribution to ON.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.1230807304382324,
            0.5433995127677917
        ],
        "MSU_id": 1314
    },
    {
        "sentence": "Phthalic acid formation processes were resolved using phthalic acid as a tracer.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 244,
        "paper_id": 3,
        "paragraph_info": "methyl-5-nitrocatechol, and 4-methyl-5-nitrocatechol. These compounds exhibited strong inter-species correlations, with  $R^2$  values ranging from 0.4 to 0.8, suggesting a common formation pathway. (11) Nitrophenol formation was identified through 4-nitrophenol. As nitroaromatic compounds are significant components of nitrogen-containing OA, both nitrocatechols and nitrophenol were included in the PMF analysis to resolve ON fractions associated with nitroaromatic species. (12) Nitrate formation processes were indicated by nitrate  $(NO_3^-)$ . (13) Sulfate formation processes were identified through sulfate  $(SO_4^{2-})$ . (14) Photochemical formation processes were associated with a high loading of ozone  $(O_3)$ . (15) Phthalic acid formation processes were resolved using phthalic acid as a tracer. (16) Dicarboxylic acid (DCA) formation was identified through a suite of dicarboxylic acids. (17) Isoprene- and \u03b1-pinene-derived secondary OA (SOA) formation was represented by their respective oxidation products. (18) \u03b2-Caryophyllene SOA formation was characterized by \u03b2-caryophyllenic acid. The 18 factor solution exhibited excellent agreement with the observed ON and OC masses (Fig. S5). Among theses factors, 12 contributed to ON mass. The remaining six factors\u2013 biomass burning, residue oil combustion, sea salt emission, sulfate formation processes, phthalic acid formation, and isoprene and \u03b1-pinene SOA formation processes\u2013showed negligible or no contribution to ON.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.5738582611083984,
            0.18587902188301086
        ],
        "MSU_id": 1318
    },
    {
        "sentence": "We examined the day-by-day variations of cooking emission-related tracers.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 248,
        "paper_id": 3,
        "paragraph_info": "The formation of ON compounds associated with oxygenated cooking OA probably involves the reactive uptake of N2O<sup>5</sup> / NO<sup>3</sup> radicals by unsaturated fatty acid particles, leading to the production of organic nitrates (Gross et al., 2009; Zhao et al., 2011). The combined contribution from the two cooking-related factors was particularly pronounced during dinnertime, reaching 17 \u00b1 10 %. It is noted that the study-wide average contributions to ON from cooking emission and their oxidation product factors were much lower at noon compared to evening (Fig. 2). This difference might be attributed to the lower cooking emissions and/or more favorable dispersion conditions during lunchtime. It is also of note that the study-wide average contributions shown in Fig. 2 obscure the diel variation patterns on individual days. To address this, we examined the day-by-day variations of cooking emission-related tracers. On many days, both unsaturated fatty acids (indicative of primary cooking emissions) and azelaic acid (a marker of oxygenated cooking OA) exhibited bimodal peaks during lunchtime and dinnertime. Fig. S8 highlights five representative days in which the concentrations of these tracers, along with their associated-ON contributions, clearly showed maxima at both mealtime periods.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.4947612285614014,
            -0.5365280508995056
        ],
        "MSU_id": 1361
    },
    {
        "sentence": "This interpretation is supported by correlation analysis.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 250,
        "paper_id": 3,
        "paragraph_info": "Insignificant ON was apportioned to the factor representing SOA formation from isoprene and \u03b1-pinene oxidation. While it is known that reactions between biogenic volatile organic compounds such as isoprene and \u03b1-pinene with NO<sup>x</sup> or NO<sup>3</sup> radicals can yield organic nitrates, such contributions may have been captured within the nitrate formation factor, rather than the biogenic SOA factors, in the PMF analysis. This interpretation is supported by correlation analysis, where ON showed stronger associations with  $NO_x$  $(R^2 = 0.45)$  and nitrate  $(R^2 = 0.39)$  than with isoprene- and  $\\alpha$ -pinene-derived SOA tracers ( $R^2 = 0.18-0.19$ ). The apparent allocation of biogenically derived organic nitrates to the nitrate formation factor may reflect differences in the formation mechanisms of organic nitrates versus those of traditional biogenic SOA tracers.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            -0.5896749496459961,
            1.1718310117721558
        ],
        "MSU_id": 1375
    },
    {
        "sentence": "We estimated the amount of oxidized ON by summing the ON apportioned to the factors associated with atmospheric oxidation processes.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 252,
        "paper_id": 3,
        "paragraph_info": "Finally, we also estimated the amount of oxidized ON by summing the ON apportioned to the factors associated with atmospheric oxidation processes, including the photochemical formation, nitrate formation, and nitroaromatic formation factors. Based on this approach, oxidized ON, mainly organic nitrates and nitroaromatics, had a concentration range of  $0.02-0.85 \\,\\mu\\text{g N m}^{-3}$ , with an average of  $0.25 \\,\\mu\\text{g N m}^{-3}$ . This oxidized ON accounted for 4 %-68 % (25 % on average) of the total oxidized N (oxidized ON plus nitrate-N) (Fig. S10b). Both oxidized ON and inorganic nitrate are formed from nitrogen oxides  $(NO_x)$ , indicating shared precursors and partially overlapping formation pathways. Our results suggest that, under urban atmospheric conditions, the conversion ratio of  $NO_x$ -N to aerosol-phase ON and nitrate-N is approximately  $1:3$ . While this estimate is subject to uncertainties inherent in source apportionment and chemical transformation processes, it provides valuable for evaluating the fate of  $NO_x$  and its partitioning into organic and inorganic aerosol nitrogen. These findings underscore the importance of quantifying bulk ON to fully characterize the abundance and chemical nature of N-containing OAs.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.8496081829071045,
            -0.9088901877403259
        ],
        "MSU_id": 1381
    },
    {
        "sentence": "The part of ON related to DCA formation processes (here termed as DCA_ON) may represent the reduced-ON species formed through the heterogeneous / aqueous phase reactions between DCAs and NH3 / NH4+.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 253,
        "paper_id": 3,
        "paragraph_info": "Note that a significant fraction of ON  $(8\\%)$  was associated with the formation processes of DCAs (Fig. 2). DCAs in ambient aerosols are primarily derived from the oxidation of anthropogenic and biogenic volatile organic compounds. The part of ON related to DCA formation processes (here termed as DCA\\_ON) may represent the reduced-ON species formed through the heterogeneous / aqueous phase reactions between DCAs and  $NH_3 / NH_4^+$ , as discussed below. Previous lab studies and field measurements have suggested that the amount of particulate  $NH_4^+$ , as measured by AMS, exceeded the quantity required to balance anions including nitrate  $(NO_3^-)$ , sulfate  $(SO_4^{2-})$ , and chloride  $(Cl^-)$ . The excess  $NH_{4}^{+}$  was believed to bind with organic acids such as DCAs to form organic ammonium salts (Schlag et al.,  $2017$ ; Hao et al.,  $2020$ ). We note that the measurement of  $NH_4^+$  by AMS relies on the quantification of  $NH_x^+$  fragments, which could also originate from the fragmentation of other reduced ON species, such as amines and amides, in addition to  $NH_{4}^{+}$  and organic ammonium salts. Consequently, the specific molecules into which the excess  $NH_{4}^{+}$ -N is incorporated remain unclear due to the lack of molecular information on ON-containing compounds.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            2.1976191997528076,
            -0.6713221073150635
        ],
        "MSU_id": 1392
    },
    {
        "sentence": "The measurement of NH4+ by AMS relies on the quantification of NHx+ fragments.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 253,
        "paper_id": 3,
        "paragraph_info": "Note that a significant fraction of ON  $(8\\%)$  was associated with the formation processes of DCAs (Fig. 2). DCAs in ambient aerosols are primarily derived from the oxidation of anthropogenic and biogenic volatile organic compounds. The part of ON related to DCA formation processes (here termed as DCA\\_ON) may represent the reduced-ON species formed through the heterogeneous / aqueous phase reactions between DCAs and  $NH_3 / NH_4^+$ , as discussed below. Previous lab studies and field measurements have suggested that the amount of particulate  $NH_4^+$ , as measured by AMS, exceeded the quantity required to balance anions including nitrate  $(NO_3^-)$ , sulfate  $(SO_4^{2-})$ , and chloride  $(Cl^-)$ . The excess  $NH_{4}^{+}$  was believed to bind with organic acids such as DCAs to form organic ammonium salts (Schlag et al.,  $2017$ ; Hao et al.,  $2020$ ). We note that the measurement of  $NH_4^+$  by AMS relies on the quantification of  $NH_x^+$  fragments, which could also originate from the fragmentation of other reduced ON species, such as amines and amides, in addition to  $NH_{4}^{+}$  and organic ammonium salts. Consequently, the specific molecules into which the excess  $NH_{4}^{+}$ -N is incorporated remain unclear due to the lack of molecular information on ON-containing compounds.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            2.08331561088562,
            -0.6363893151283264
        ],
        "MSU_id": 1395
    },
    {
        "sentence": "Further investigations are needed to determine their major chemical compositions and formation mechanisms.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 258,
        "paper_id": 3,
        "paragraph_info": "ous phase formation pathway of these species (Liu et al., 2023). The summed concentration level of the eight imidazoles was lower by 1\u20132 orders of magnitude compared to our estimated bulk concentration, indicating the prevalence of unidentified reduced ON species. Our analyses suggested that ON aerosols originating from NH<sup>3</sup> chemistry could be a significant source of nitrogenous SOA. Further investigations are needed to determine their major chemical compositions and formation mechanisms.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.5004544258117676,
            0.046902574598789215
        ],
        "MSU_id": 1434
    },
    {
        "sentence": "We focus on the cases where SON showed continuous increment for a period of 4 h or longer.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 259,
        "paper_id": 3,
        "paragraph_info": "The PMF source apportionment analysis has provided the total quantity of the secondary ON (SON) and its apportionment to individual formation pathways. This greatly facilitates investigating the largely under-evaluated formation processes of N-containing OA. We next focus on the cases where SON showed continuous increment for a period of 4 h or longer and discuss the driving factors behind these increments; 42 cases were identified throughout the entire observation period. To isolate the local formation of SON from the influence of transported air masses, we extracted cases with wind speeds lower than 3 m s\u2212<sup>1</sup> as cases of local SON formation (Zhou et al., 2022). The following discussion will exclusively focus on the local SON formation cases.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.553285539150238,
            1.1975051164627075
        ],
        "MSU_id": 1438
    },
    {
        "sentence": "To isolate the local formation of SON from the influence of transported air masses, we extracted cases with wind speeds lower than 3 m s\u22121.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 259,
        "paper_id": 3,
        "paragraph_info": "The PMF source apportionment analysis has provided the total quantity of the secondary ON (SON) and its apportionment to individual formation pathways. This greatly facilitates investigating the largely under-evaluated formation processes of N-containing OA. We next focus on the cases where SON showed continuous increment for a period of 4 h or longer and discuss the driving factors behind these increments; 42 cases were identified throughout the entire observation period. To isolate the local formation of SON from the influence of transported air masses, we extracted cases with wind speeds lower than 3 m s\u2212<sup>1</sup> as cases of local SON formation (Zhou et al., 2022). The following discussion will exclusively focus on the local SON formation cases.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.1020009517669678,
            -0.23499181866645813
        ],
        "MSU_id": 1440
    },
    {
        "sentence": "The classification was based on the dominant formation pathway of SON, as revealed by the PMF analysis.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 260,
        "paper_id": 3,
        "paragraph_info": "A total of 24 local SON formation cases were identified and classified into five types based on the dominant formation pathway of SON, as revealed by the PMF analysis. Figure 4 illustrates the variations in the sources of SON and secondary organic carbon (SOC) for the five types of local SON increment. The ensuing discussion shows our paired measurements of bulk aerosol ON and OC, along with subsequent source analyses, provide unique insights into the formation processes of N-containing OA.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.336658239364624,
            -0.9309273362159729
        ],
        "MSU_id": 1443
    },
    {
        "sentence": "Organic nitrate formation encompasses two main pathways: hydroxyl radical (OH)-initiated oxidation of hydrocarbons in the presence of $NO_x$ during the day and nitrate radical ($NO_3$)-initiated oxidation of alkenes during the night.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 268,
        "paper_id": 3,
        "paragraph_info": "Four Type 5 cases were identified, each characterized with nitrate formation processing as the driving source for the increase in SON. This fraction of SON may indicate the formation of organic nitrates, which share common precursor of  $NO_x$  with nitrate. Organic nitrates have long been recognized as notable components of secondary OAs in ambient air (Rollins et al., 2012; Perring et al., 2013). Organic nitrate formation encompasses two main pathways: hydroxyl radical (OH)-initiated oxidation of hydrocarbons in the presence of  $NO_x$  during the day and nitrate radical ( $NO_3$ )-initiated oxidation of alkenes during the night. Both pathways involve the formation of organic nitrates in the gas phase, followed by partitioning to the particulate phase (Perring et al., 2013). This study, through integrated analyses of SON and SOC, provides evidence suggesting that organic nitrates might also form through heterogeneous or aqueous reactions. As depicted in Fig. 4, the nitrate formation process produced  $0.17 \\,\\mu\\text{g N m}^{-3}$  of  $\\Delta\\text{SON}$  and  $0.43 \\,\\mu\\text{g C m}^{-3}$  of  $\\Delta\\text{SOC}$  from the night of 20 December to the following morning, yielding a  $\\Delta$ SOC /  $\\Delta$ SON atomic ratio of only 2.9. Gas-phase formation of organic nitrates followed by gas-to-particle partitioning would not result in such a low  $C/N$  ratio. Therefore, a large number of organic nitrates might be formed through heterogeneous or aqueous reactions between organic compounds and  $\\text{HNO}_3 / \\text{NO}_3$ , enhancing the ON content while not affecting the OC content which is already present in the particle phase. In a previous study, it was suggested that organic nitrates can be produced through non-radical reactions of hydrated glyoxal and nitric acid in the aqueous phase (Lim et al., 2016). Xu et al. (2020) found that aerosol liquid water promotes the formation of water-soluble ON, probably in the form of organic nitrate species. Previous studies have identified an 80 % underestimation of monoterpene hydroxyl nitrate by the GEOS-Chem model, which considers both OH oxidation and  $NO_3$  oxidation mechanisms of monoterpene (Li et al., 2018; Zhang et al., 2021), indicating an incomplete understanding of the formation mechanisms of organic nitrates. Our observational results, combined with previous investigations, suggest the need for further exploration of the formation mechanisms of particulate organic nitrates, such as heterogeneous/aqueous phase reaction processes.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.8684310913085938,
            0.05402419716119766
        ],
        "MSU_id": 1499
    },
    {
        "sentence": "Both pathways involve the formation of organic nitrates in the gas phase, followed by partitioning to the particulate phase.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 268,
        "paper_id": 3,
        "paragraph_info": "Four Type 5 cases were identified, each characterized with nitrate formation processing as the driving source for the increase in SON. This fraction of SON may indicate the formation of organic nitrates, which share common precursor of  $NO_x$  with nitrate. Organic nitrates have long been recognized as notable components of secondary OAs in ambient air (Rollins et al., 2012; Perring et al., 2013). Organic nitrate formation encompasses two main pathways: hydroxyl radical (OH)-initiated oxidation of hydrocarbons in the presence of  $NO_x$  during the day and nitrate radical ( $NO_3$ )-initiated oxidation of alkenes during the night. Both pathways involve the formation of organic nitrates in the gas phase, followed by partitioning to the particulate phase (Perring et al., 2013). This study, through integrated analyses of SON and SOC, provides evidence suggesting that organic nitrates might also form through heterogeneous or aqueous reactions. As depicted in Fig. 4, the nitrate formation process produced  $0.17 \\,\\mu\\text{g N m}^{-3}$  of  $\\Delta\\text{SON}$  and  $0.43 \\,\\mu\\text{g C m}^{-3}$  of  $\\Delta\\text{SOC}$  from the night of 20 December to the following morning, yielding a  $\\Delta$ SOC /  $\\Delta$ SON atomic ratio of only 2.9. Gas-phase formation of organic nitrates followed by gas-to-particle partitioning would not result in such a low  $C/N$  ratio. Therefore, a large number of organic nitrates might be formed through heterogeneous or aqueous reactions between organic compounds and  $\\text{HNO}_3 / \\text{NO}_3$ , enhancing the ON content while not affecting the OC content which is already present in the particle phase. In a previous study, it was suggested that organic nitrates can be produced through non-radical reactions of hydrated glyoxal and nitric acid in the aqueous phase (Lim et al., 2016). Xu et al. (2020) found that aerosol liquid water promotes the formation of water-soluble ON, probably in the form of organic nitrate species. Previous studies have identified an 80 % underestimation of monoterpene hydroxyl nitrate by the GEOS-Chem model, which considers both OH oxidation and  $NO_3$  oxidation mechanisms of monoterpene (Li et al., 2018; Zhang et al., 2021), indicating an incomplete understanding of the formation mechanisms of organic nitrates. Our observational results, combined with previous investigations, suggest the need for further exploration of the formation mechanisms of particulate organic nitrates, such as heterogeneous/aqueous phase reaction processes.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.8434650897979736,
            -0.09186912328004837
        ],
        "MSU_id": 1500
    },
    {
        "sentence": "This methodological breakthrough allows for the online measurement of bulk aerosol ON.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 269,
        "paper_id": 3,
        "paragraph_info": "At present, the knowledge of total aerosol ON budget is severely limited, with source analysis predominantly qualitative. Building on a methodological breakthrough that allows for the online measurement of bulk aerosol ON and concurrent measurements of a comprehensive array of molecular source tracers, we have identified both primary emissions and secondary formation processes as substantial contributors to  $PM_{2.5}$  ON mass in urban Shanghai during the fall-winter period of 2021. While we acknowledge the inherent uncertainties of PMF modeling in distinguishing certain related sources/processes, this approach remains valuable for identifying major source categories and inferring dominant formation pathways. It provides quantitative insights into the relative contributions of different sources/processes to the overall ON budget.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            0.6140678524971008,
            -0.5199853777885437
        ],
        "MSU_id": 1513
    },
    {
        "sentence": "This methodological breakthrough allows for concurrent measurements of a comprehensive array of molecular source tracers.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 269,
        "paper_id": 3,
        "paragraph_info": "At present, the knowledge of total aerosol ON budget is severely limited, with source analysis predominantly qualitative. Building on a methodological breakthrough that allows for the online measurement of bulk aerosol ON and concurrent measurements of a comprehensive array of molecular source tracers, we have identified both primary emissions and secondary formation processes as substantial contributors to  $PM_{2.5}$  ON mass in urban Shanghai during the fall-winter period of 2021. While we acknowledge the inherent uncertainties of PMF modeling in distinguishing certain related sources/processes, this approach remains valuable for identifying major source categories and inferring dominant formation pathways. It provides quantitative insights into the relative contributions of different sources/processes to the overall ON budget.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.696241855621338,
            -0.9655613303184509
        ],
        "MSU_id": 1514
    },
    {
        "sentence": "Bulk ON measurements enable mass closure and are advantageous for constraining the major sources and formation processes of ON aerosols.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 275,
        "paper_id": 3,
        "paragraph_info": "Looking ahead, future research efforts should focus on refining our understanding of the detailed mechanisms driving ON aerosol formation, including the chemical reactions involving major precursors and secondary processes. Furthermore, continued monitoring and analysis of ON aerosol composition in different environmental settings will be crucial for assessing the broader implications of ON aerosols on air quality, climate, and public health. Bulk ON measurements enable mass closure and are advantageous for constraining the major sources and formation processes of ON aerosols. This methodology complements the molecular-level characterization of ON molecules, which provides chemical composition information but falls short of capturing total ON. Future research efforts should emphasize identifying and quantifying ON species that can indicate specific sources and formation processes.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            2.2149548530578613,
            -0.6738352179527283
        ],
        "MSU_id": 1537
    },
    {
        "sentence": "This methodology complements the molecular-level characterization of ON molecules.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 275,
        "paper_id": 3,
        "paragraph_info": "Looking ahead, future research efforts should focus on refining our understanding of the detailed mechanisms driving ON aerosol formation, including the chemical reactions involving major precursors and secondary processes. Furthermore, continued monitoring and analysis of ON aerosol composition in different environmental settings will be crucial for assessing the broader implications of ON aerosols on air quality, climate, and public health. Bulk ON measurements enable mass closure and are advantageous for constraining the major sources and formation processes of ON aerosols. This methodology complements the molecular-level characterization of ON molecules, which provides chemical composition information but falls short of capturing total ON. Future research efforts should emphasize identifying and quantifying ON species that can indicate specific sources and formation processes.",
        "paper_info": "acp-25-9061-2025",
        "2d_coord": [
            1.8655154705047607,
            -0.4771153926849365
        ],
        "MSU_id": 1538
    },
    {
        "type": "figure",
        "para_id": 277,
        "paper_id": 4,
        "paragraph_info": "_page_0_Figure_2.jpeg",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2723796367645264,
            0.7572396993637085
        ],
        "MSU_id": 1541,
        "sentence": "The system interface of AirVis includes a control panel for interactive mining, filtering, and selection of propagation patterns, a motif view for visualizing significant motifs with uncertainty, a pattern view for depicting patterns with glyphs and graphs, and an instance view for inspecting propagation instances.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "The control panel enables the interactive mining, filtering, and selection of the propagation patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 277,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-0-0\"></span>Fig. 1. The system interface of AirVis: (A) the control panel enables the interactive mining, filtering, and selection of the propagation patterns; (B) the motif view presents the extracted significant motifs with uncertainty-aware visualizations; (C) the pattern view depicts the patterns with compact pattern glyphs and pattern graphs; (D) the instance view helps users inspect the propagation instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.135002613067627,
            0.5389419794082642
        ],
        "MSU_id": 1543
    },
    {
        "sentence": "The motif view presents the extracted significant motifs with uncertainty-aware visualizations.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 277,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-0-0\"></span>Fig. 1. The system interface of AirVis: (A) the control panel enables the interactive mining, filtering, and selection of the propagation patterns; (B) the motif view presents the extracted significant motifs with uncertainty-aware visualizations; (C) the pattern view depicts the patterns with compact pattern glyphs and pattern graphs; (D) the instance view helps users inspect the propagation instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9819526672363281,
            0.6109549403190613
        ],
        "MSU_id": 1544
    },
    {
        "sentence": "The pattern view depicts the patterns with compact pattern glyphs and pattern graphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 277,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-0-0\"></span>Fig. 1. The system interface of AirVis: (A) the control panel enables the interactive mining, filtering, and selection of the propagation patterns; (B) the motif view presents the extracted significant motifs with uncertainty-aware visualizations; (C) the pattern view depicts the patterns with compact pattern glyphs and pattern graphs; (D) the instance view helps users inspect the propagation instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8454095125198364,
            1.2007256746292114
        ],
        "MSU_id": 1545
    },
    {
        "sentence": "The instance view helps users inspect the propagation instances.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 277,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-0-0\"></span>Fig. 1. The system interface of AirVis: (A) the control panel enables the interactive mining, filtering, and selection of the propagation patterns; (B) the motif view presents the extracted significant motifs with uncertainty-aware visualizations; (C) the pattern view depicts the patterns with compact pattern glyphs and pattern graphs; (D) the instance view helps users inspect the propagation instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2305281162261963,
            0.8254342675209045
        ],
        "MSU_id": 1546
    },
    {
        "sentence": "AirVis is a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 278,
        "paper_id": 4,
        "paragraph_info": "Abstract\u2014 Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.5042529106140137,
            0.585241436958313
        ],
        "MSU_id": 1552
    },
    {
        "sentence": "Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 278,
        "paper_id": 4,
        "paragraph_info": "Abstract\u2014 Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3879146575927734,
            0.8121680617332458
        ],
        "MSU_id": 1553
    },
    {
        "sentence": "We develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 278,
        "paper_id": 4,
        "paragraph_info": "Abstract\u2014 Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2445554733276367,
            -0.1652364730834961
        ],
        "MSU_id": 1554
    },
    {
        "sentence": "We organize the extracted patterns hierarchically based on the minimum description length (MDL) principle.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 278,
        "paper_id": 4,
        "paragraph_info": "Abstract\u2014 Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2166874408721924,
            0.4024560749530792
        ],
        "MSU_id": 1555
    },
    {
        "sentence": "We empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 278,
        "paper_id": 4,
        "paragraph_info": "Abstract\u2014 Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1179230213165283,
            1.134179949760437
        ],
        "MSU_id": 1556
    },
    {
        "sentence": "The state-of-the-art approach HYSPLIT was put forward in the environmental science literature to analyze the propagation of air pollution.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 283,
        "paper_id": 4,
        "paragraph_info": "With the advancement in data sensing and management technologies [75], data-driven solutions for monitoring, analyzing, and predicting air pollution, such as quality forecasting  $[70, 78]$  and local sources discovery [32], are now possible with the large-scale atmospheric data collected by widely distributed weather stations. To analyze the propagation of air pollution, state-of-the-art approach HYSPLIT [52] was put forward in the environmental science literature. This approach was proposed to automatically infer how pollutants are dispersed in the atmosphere and affect an area. Although the potential pollution sources are identified for the given area, HYSPLIT considers neither a) the inherent uncertainties in the dynamic propagation patterns nor b) the complex district-level interactions among multiple cities. Moreover, the lack of an interactive tool that presents the propagation processes from the overview to details at a large spatial scale actively prohibits expert",
        "paper_info": "airvis",
        "2d_coord": [
            -1.929663896560669,
            0.532514214515686
        ],
        "MSU_id": 1573
    },
    {
        "sentence": "HYSPLIT was proposed to automatically infer how pollutants are dispersed in the atmosphere and affect an area.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 283,
        "paper_id": 4,
        "paragraph_info": "With the advancement in data sensing and management technologies [75], data-driven solutions for monitoring, analyzing, and predicting air pollution, such as quality forecasting  $[70, 78]$  and local sources discovery [32], are now possible with the large-scale atmospheric data collected by widely distributed weather stations. To analyze the propagation of air pollution, state-of-the-art approach HYSPLIT [52] was put forward in the environmental science literature. This approach was proposed to automatically infer how pollutants are dispersed in the atmosphere and affect an area. Although the potential pollution sources are identified for the given area, HYSPLIT considers neither a) the inherent uncertainties in the dynamic propagation patterns nor b) the complex district-level interactions among multiple cities. Moreover, the lack of an interactive tool that presents the propagation processes from the overview to details at a large spatial scale actively prohibits expert",
        "paper_info": "airvis",
        "2d_coord": [
            -1.367746114730835,
            -0.8099715113639832
        ],
        "MSU_id": 1574
    },
    {
        "sentence": "We aim to develop an interactive visualization system to facilitate the understanding of massive uncertain propagation patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 285,
        "paper_id": 4,
        "paragraph_info": "The aforementioned limitations in the automated approach motivate us to adopt a user-centric analytics approach and develop an interactive visualization system to facilitate the understanding of massive uncertain propagation patterns and identification of major pollution sources and pathways. However, developing such a system poses three challenges.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.142054796218872,
            0.6619607210159302
        ],
        "MSU_id": 1580
    },
    {
        "sentence": "We aim to develop an interactive visualization system to identify major pollution sources and pathways.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 285,
        "paper_id": 4,
        "paragraph_info": "The aforementioned limitations in the automated approach motivate us to adopt a user-centric analytics approach and develop an interactive visualization system to facilitate the understanding of massive uncertain propagation patterns and identification of major pollution sources and pathways. However, developing such a system poses three challenges.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1155331134796143,
            0.990783154964447
        ],
        "MSU_id": 1581
    },
    {
        "sentence": "An efficient model is required to extract frequent propagation patterns from multistep transportation events.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 286,
        "paper_id": 4,
        "paragraph_info": "Extraction of propagation patterns. Understanding how pollutants propagate across multiple districts is the key to finding the cause of air pollution. However, the propagation processes of these pollutants can vary considerably in terms of both space and time. The pollutants in an area can be transported from different sets of polluted upstream areas at different times because wind fields are fluctuating every moment. The transportation speeds also change constantly with the wind speeds at different locations. Hence, an efficient model is required to extract frequent propagation patterns from multistep transportation events and capture the uncertainties of the patterns accurately.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2968342304229736,
            0.46619200706481934
        ],
        "MSU_id": 1588
    },
    {
        "sentence": "The model should capture the uncertainties of the patterns accurately.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 286,
        "paper_id": 4,
        "paragraph_info": "Extraction of propagation patterns. Understanding how pollutants propagate across multiple districts is the key to finding the cause of air pollution. However, the propagation processes of these pollutants can vary considerably in terms of both space and time. The pollutants in an area can be transported from different sets of polluted upstream areas at different times because wind fields are fluctuating every moment. The transportation speeds also change constantly with the wind speeds at different locations. Hence, an efficient model is required to extract frequent propagation patterns from multistep transportation events and capture the uncertainties of the patterns accurately.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.6327049732208252,
            -1.0760799646377563
        ],
        "MSU_id": 1589
    },
    {
        "sentence": "An intuitive uncertainty-driven visual representation based on directed graphs must be established for these patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 287,
        "paper_id": 4,
        "paragraph_info": "Scalability of pattern presentations. To aid the analysis of the propagation patterns with the visual analytics approach, an intuitive uncertainty-driven visual representation based on directed graphs must be established for these patterns to better illustrate the propagation of air pollution. The problem is that numerous patterns can be extracted from the massive atmospheric data collected at large spatial and temporal scales, demanding considerable effort from users in searching for common and meaningful patterns with traditional graph visualization techniques. Organizing these patterns in a scalable and clutter-free way, which then enables users to identify latent patterns easily with such representations, remains an important yet challenging task.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.515941858291626,
            0.888785719871521
        ],
        "MSU_id": 1591
    },
    {
        "sentence": "The proposed interactive system must support effective drill-down exploration in the pattern-instance hierarchy.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 288,
        "paper_id": 4,
        "paragraph_info": "Analysis of the propagation processes. The propagation processes are massive, spatiotemporal, and uncertain. To assist users in externalizing the pattern identification and analysis procedures, the proposed interactive system must support the effective drill-down exploration [\\[51\\]](#page-9-4) in the pattern-instance hierarchy, associating the abstract patterns with physical instances (i.e., pollution events). Moreover, such a system should also incorporate the topology analysis of the propagation processes. For example, star-like propagation structures may indicate that the areas at the center are the major pollution sources. Hence, a novel visualization approach is demanded to facilitate the sophisticated analyses of these processes and reveal in-depth insights.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.156768321990967,
            1.0844167470932007
        ],
        "MSU_id": 1597
    },
    {
        "sentence": "The proposed interactive system assists users in externalizing the pattern identification and analysis procedures.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 288,
        "paper_id": 4,
        "paragraph_info": "Analysis of the propagation processes. The propagation processes are massive, spatiotemporal, and uncertain. To assist users in externalizing the pattern identification and analysis procedures, the proposed interactive system must support the effective drill-down exploration [\\[51\\]](#page-9-4) in the pattern-instance hierarchy, associating the abstract patterns with physical instances (i.e., pollution events). Moreover, such a system should also incorporate the topology analysis of the propagation processes. For example, star-like propagation structures may indicate that the areas at the center are the major pollution sources. Hence, a novel visualization approach is demanded to facilitate the sophisticated analyses of these processes and reveal in-depth insights.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.98231840133667,
            1.0766996145248413
        ],
        "MSU_id": 1598
    },
    {
        "sentence": "The system should incorporate the topology analysis of the propagation processes.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 288,
        "paper_id": 4,
        "paragraph_info": "Analysis of the propagation processes. The propagation processes are massive, spatiotemporal, and uncertain. To assist users in externalizing the pattern identification and analysis procedures, the proposed interactive system must support the effective drill-down exploration [\\[51\\]](#page-9-4) in the pattern-instance hierarchy, associating the abstract patterns with physical instances (i.e., pollution events). Moreover, such a system should also incorporate the topology analysis of the propagation processes. For example, star-like propagation structures may indicate that the areas at the center are the major pollution sources. Hence, a novel visualization approach is demanded to facilitate the sophisticated analyses of these processes and reveal in-depth insights.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8889074325561523,
            0.48522132635116577
        ],
        "MSU_id": 1599
    },
    {
        "sentence": "We derive a novel pattern mining framework based on frequent subgraph mining (FSM) method.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2225096225738525,
            0.9483267664909363
        ],
        "MSU_id": 1603
    },
    {
        "sentence": "We combine air quality data with meteorological data to model the transportation of air pollutants.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.96673983335495,
            -1.7288771867752075
        ],
        "MSU_id": 1604
    },
    {
        "sentence": "We detect latent propagation patterns at large spatial and temporal scales.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0869157314300537,
            -0.1099049523472786
        ],
        "MSU_id": 1605
    },
    {
        "sentence": "We propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.4658122062683105,
            0.5885742902755737
        ],
        "MSU_id": 1607
    },
    {
        "sentence": "We extract significant motifs from these patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0846192836761475,
            0.6818175911903381
        ],
        "MSU_id": 1608
    },
    {
        "sentence": "We aggregate the patterns based on topology similarities with the minimum description length (MDL) principle.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0881965160369873,
            0.44996142387390137
        ],
        "MSU_id": 1609
    },
    {
        "sentence": "The patterns are organized hierarchically with multiple coordinated views.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.9505596160888672,
            0.24584069848060608
        ],
        "MSU_id": 1611
    },
    {
        "sentence": "The patterns are presented with uncertainty visualization techniques to facilitate effective exploration and analyses of the pollution propagation processes.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 289,
        "paper_id": 4,
        "paragraph_info": "To address these challenges, we first derive a novel pattern mining framework based on frequent subgraph mining (FSM) method [\\[25\\]](#page-9-5) by combining air quality data with meteorological data to model the transportation of air pollutants and detect latent propagation patterns at large spatial and temporal scales. FSM is particularly effective in extracting frequent subgraphs that represent typical propagation patterns. On the basis of this framework, we further propose AirVis, a visual analytics system that enables scalable and intuitive analyses of massive propagation patterns. In particular, we extract significant motifs (i.e., contextless frequent topological structures) from these patterns and aggregate the patterns based on topology similarities with the minimum description length (MDL) principle [\\[46\\]](#page-9-6) which compresses data by creating summary representations for similar data items. Moreover, the patterns are organized hierarchically with multiple coordinated views and presented with uncertainty visualization techniques to facilitate the effective exploration and analyses of the pollution propagation processes. To the best of our knowledge, AirVis is the first attempt to establish an interactive topology-driven analysis of uncertain air pollution propagation. Our contributions are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.493602991104126,
            1.3045693635940552
        ],
        "MSU_id": 1612
    },
    {
        "sentence": "CMAQ computes the concentration of air pollutants based on advection, diffusion, and chemical reactions.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 291,
        "paper_id": 4,
        "paragraph_info": "*Model-driven.* Air pollution has been extensively studied in the atmospheric environment literature to analyze and mitigate the pollution [\\[14\\]](#page-9-7). CMAQ [\\[10\\]](#page-9-8) is one of the most comprehensive atmospheric dispersion models for analyzing regional air pollution. With the given air pollutant emission and meteorological data, CMAQ computes the concentration of air pollutants based on advection, diffusion, and chemical reactions. For the propagation of air pollution, HYSPLIT [\\[52\\]](#page-9-3) is widely used to identify regional pollution sources [\\[29\\]](#page-9-9) and propagation pathways [\\[37\\]](#page-9-10). Based on the meteorological data, HYSPLIT attempts to trace back the trajectories of many air parcels starting from a given area (i.e., receptor) for each timestamp. Each of these trajectories is assigned with an estimated concentration value. These trajectories can be further clustered [\\[62\\]](#page-10-5) to identify potential patterns or produce a heatmap as a static picture, but no temporal information is provided.",
        "paper_info": "airvis",
        "2d_coord": [
            0.4811554551124573,
            -0.27560651302337646
        ],
        "MSU_id": 1621
    },
    {
        "sentence": "HYSPLIT is widely used to identify regional pollution sources and propagation pathways.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 291,
        "paper_id": 4,
        "paragraph_info": "*Model-driven.* Air pollution has been extensively studied in the atmospheric environment literature to analyze and mitigate the pollution [\\[14\\]](#page-9-7). CMAQ [\\[10\\]](#page-9-8) is one of the most comprehensive atmospheric dispersion models for analyzing regional air pollution. With the given air pollutant emission and meteorological data, CMAQ computes the concentration of air pollutants based on advection, diffusion, and chemical reactions. For the propagation of air pollution, HYSPLIT [\\[52\\]](#page-9-3) is widely used to identify regional pollution sources [\\[29\\]](#page-9-9) and propagation pathways [\\[37\\]](#page-9-10). Based on the meteorological data, HYSPLIT attempts to trace back the trajectories of many air parcels starting from a given area (i.e., receptor) for each timestamp. Each of these trajectories is assigned with an estimated concentration value. These trajectories can be further clustered [\\[62\\]](#page-10-5) to identify potential patterns or produce a heatmap as a static picture, but no temporal information is provided.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.529390573501587,
            0.01036093384027481
        ],
        "MSU_id": 1622
    },
    {
        "sentence": "HYSPLIT attempts to trace back the trajectories of many air parcels starting from a given area for each timestamp.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 291,
        "paper_id": 4,
        "paragraph_info": "*Model-driven.* Air pollution has been extensively studied in the atmospheric environment literature to analyze and mitigate the pollution [\\[14\\]](#page-9-7). CMAQ [\\[10\\]](#page-9-8) is one of the most comprehensive atmospheric dispersion models for analyzing regional air pollution. With the given air pollutant emission and meteorological data, CMAQ computes the concentration of air pollutants based on advection, diffusion, and chemical reactions. For the propagation of air pollution, HYSPLIT [\\[52\\]](#page-9-3) is widely used to identify regional pollution sources [\\[29\\]](#page-9-9) and propagation pathways [\\[37\\]](#page-9-10). Based on the meteorological data, HYSPLIT attempts to trace back the trajectories of many air parcels starting from a given area (i.e., receptor) for each timestamp. Each of these trajectories is assigned with an estimated concentration value. These trajectories can be further clustered [\\[62\\]](#page-10-5) to identify potential patterns or produce a heatmap as a static picture, but no temporal information is provided.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.10437211394309998,
            -0.9295186400413513
        ],
        "MSU_id": 1623
    },
    {
        "sentence": "These trajectories can be further clustered to identify potential patterns or produce a heatmap as a static picture.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 291,
        "paper_id": 4,
        "paragraph_info": "*Model-driven.* Air pollution has been extensively studied in the atmospheric environment literature to analyze and mitigate the pollution [\\[14\\]](#page-9-7). CMAQ [\\[10\\]](#page-9-8) is one of the most comprehensive atmospheric dispersion models for analyzing regional air pollution. With the given air pollutant emission and meteorological data, CMAQ computes the concentration of air pollutants based on advection, diffusion, and chemical reactions. For the propagation of air pollution, HYSPLIT [\\[52\\]](#page-9-3) is widely used to identify regional pollution sources [\\[29\\]](#page-9-9) and propagation pathways [\\[37\\]](#page-9-10). Based on the meteorological data, HYSPLIT attempts to trace back the trajectories of many air parcels starting from a given area (i.e., receptor) for each timestamp. Each of these trajectories is assigned with an estimated concentration value. These trajectories can be further clustered [\\[62\\]](#page-10-5) to identify potential patterns or produce a heatmap as a static picture, but no temporal information is provided.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.6213706135749817,
            1.4142177104949951
        ],
        "MSU_id": 1625
    },
    {
        "sentence": "Large-scale heterogeneous urban data can be used to obtain or predict air quality.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 292,
        "paper_id": 4,
        "paragraph_info": "*Data-driven.* Recent developments in smart city technologies [\\[75\\]](#page-10-2) have provided unprecedented opportunities for the data-driven analysis of air pollution with large-scale heterogeneous urban data. Various types of data, including text, image, and traffic data, were used to obtain [\\[33,](#page-9-11) [38,](#page-9-12) [77\\]](#page-10-6) or predict [\\[16,](#page-9-13) [70,](#page-10-3) [78\\]](#page-10-4) the air quality. In order to identify pollution sources and propagation patterns, Granger causality [\\[19\\]](#page-9-14) has been recently exploited to infer the relationships between different observations [\\[26\\]](#page-9-15). Li et al. [\\[32\\]](#page-9-2) constructed massive causality graphs and identified the sources and propagation patterns from them. pg-Causality [\\[80\\]](#page-10-7) combined pattern mining techniques and Bayesian learning to capture the causal pathways between neighboring cities.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.35613781213760376,
            -2.0194640159606934
        ],
        "MSU_id": 1628
    },
    {
        "sentence": "Various types of data, including text, image, and traffic data, were used to obtain or predict the air quality.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 292,
        "paper_id": 4,
        "paragraph_info": "*Data-driven.* Recent developments in smart city technologies [\\[75\\]](#page-10-2) have provided unprecedented opportunities for the data-driven analysis of air pollution with large-scale heterogeneous urban data. Various types of data, including text, image, and traffic data, were used to obtain [\\[33,](#page-9-11) [38,](#page-9-12) [77\\]](#page-10-6) or predict [\\[16,](#page-9-13) [70,](#page-10-3) [78\\]](#page-10-4) the air quality. In order to identify pollution sources and propagation patterns, Granger causality [\\[19\\]](#page-9-14) has been recently exploited to infer the relationships between different observations [\\[26\\]](#page-9-15). Li et al. [\\[32\\]](#page-9-2) constructed massive causality graphs and identified the sources and propagation patterns from them. pg-Causality [\\[80\\]](#page-10-7) combined pattern mining techniques and Bayesian learning to capture the causal pathways between neighboring cities.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6795263290405273,
            -1.6610194444656372
        ],
        "MSU_id": 1629
    },
    {
        "sentence": "Granger causality has been recently exploited to infer the relationships between different observations.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 292,
        "paper_id": 4,
        "paragraph_info": "*Data-driven.* Recent developments in smart city technologies [\\[75\\]](#page-10-2) have provided unprecedented opportunities for the data-driven analysis of air pollution with large-scale heterogeneous urban data. Various types of data, including text, image, and traffic data, were used to obtain [\\[33,](#page-9-11) [38,](#page-9-12) [77\\]](#page-10-6) or predict [\\[16,](#page-9-13) [70,](#page-10-3) [78\\]](#page-10-4) the air quality. In order to identify pollution sources and propagation patterns, Granger causality [\\[19\\]](#page-9-14) has been recently exploited to infer the relationships between different observations [\\[26\\]](#page-9-15). Li et al. [\\[32\\]](#page-9-2) constructed massive causality graphs and identified the sources and propagation patterns from them. pg-Causality [\\[80\\]](#page-10-7) combined pattern mining techniques and Bayesian learning to capture the causal pathways between neighboring cities.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.4921643137931824,
            -1.6249274015426636
        ],
        "MSU_id": 1630
    },
    {
        "sentence": "pg-Causality combined pattern mining techniques and Bayesian learning to capture the causal pathways between neighboring cities.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 292,
        "paper_id": 4,
        "paragraph_info": "*Data-driven.* Recent developments in smart city technologies [\\[75\\]](#page-10-2) have provided unprecedented opportunities for the data-driven analysis of air pollution with large-scale heterogeneous urban data. Various types of data, including text, image, and traffic data, were used to obtain [\\[33,](#page-9-11) [38,](#page-9-12) [77\\]](#page-10-6) or predict [\\[16,](#page-9-13) [70,](#page-10-3) [78\\]](#page-10-4) the air quality. In order to identify pollution sources and propagation patterns, Granger causality [\\[19\\]](#page-9-14) has been recently exploited to infer the relationships between different observations [\\[26\\]](#page-9-15). Li et al. [\\[32\\]](#page-9-2) constructed massive causality graphs and identified the sources and propagation patterns from them. pg-Causality [\\[80\\]](#page-10-7) combined pattern mining techniques and Bayesian learning to capture the causal pathways between neighboring cities.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.85279381275177,
            -0.19496572017669678
        ],
        "MSU_id": 1632
    },
    {
        "sentence": "We propose a novel pattern mining method.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 293,
        "paper_id": 4,
        "paragraph_info": "Although the existing approaches have been proven useful for air pollution analysis, they have limitations. Specifically, the model-driven methods cannot capture the complex district-level interactions (e.g., the pollutants from district A affect both districts B and C), while the data-driven methods fail to consider the continuous propagation across multiple districts (e.g., the pollutants from district A are transported to district D via districts B and C sequentially). The uncertainties of propagation processes are neglected in both types of methods. Moreover, few studies are combined with interactive visualization, leading to obstacles in understanding the propagation. To address the limitations, we propose a novel pattern mining method and design an interactive visualization system to facilitate analyses of air pollution propagation.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.122087240219116,
            0.8141382336616516
        ],
        "MSU_id": 1642
    },
    {
        "sentence": "We design an interactive visualization system to facilitate analyses of air pollution propagation.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 293,
        "paper_id": 4,
        "paragraph_info": "Although the existing approaches have been proven useful for air pollution analysis, they have limitations. Specifically, the model-driven methods cannot capture the complex district-level interactions (e.g., the pollutants from district A affect both districts B and C), while the data-driven methods fail to consider the continuous propagation across multiple districts (e.g., the pollutants from district A are transported to district D via districts B and C sequentially). The uncertainties of propagation processes are neglected in both types of methods. Moreover, few studies are combined with interactive visualization, leading to obstacles in understanding the propagation. To address the limitations, we propose a novel pattern mining method and design an interactive visualization system to facilitate analyses of air pollution propagation.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.273104667663574,
            0.8591323494911194
        ],
        "MSU_id": 1643
    },
    {
        "sentence": "Movement data can be directly depicted using visual elements, such as points for OD pairs, polylines, tubes, stacked bands, and space-time cubes for trajectories.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 294,
        "paper_id": 4,
        "paragraph_info": "Spatiotemporal data visualization has been applied in various domains, such as location selection [\\[63,](#page-10-8) [64\\]](#page-10-9), urban planning [\\[44,](#page-9-16) [53\\]](#page-9-17), and air pollution [\\[45,](#page-9-18) [76\\]](#page-10-10), yet no visualization tool is available to analyze pollution propagation. In essence, air pollution propagation can be regarded as a type of movement data. Spatiotemporal visualization for movement data can generally be classified into three categories [\\[1\\]](#page-9-19), namely, direct depiction, summarization, and pattern extraction. Specifically, movement data can be directly depicted using visual elements, such as points [\\[17\\]](#page-9-20) for OD pairs, polylines [\\[2\\]](#page-9-21), tubes [\\[34\\]](#page-9-22), stacked bands [\\[56\\]](#page-10-11), and space-time cubes [\\[3\\]](#page-9-23) for trajectories. Movement data can also be summarized as density maps [\\[35,](#page-9-24) [47\\]](#page-9-25), graphs [\\[59\\]](#page-10-12), flow maps [\\[8,](#page-9-26) [22\\]](#page-9-27), OD matrices [\\[21,](#page-9-28)[69\\]](#page-10-13), and OD maps [\\[21\\]](#page-9-28). In addition, pattern extraction can be applied to obtain significant latent patterns from the movement data [\\[12,](#page-9-29) [55,](#page-10-14) [65,](#page-10-15) [66,](#page-10-16) [79,](#page-10-17) [81\\]](#page-10-18). However, the existing methods cannot be used to visualize the propagation of air pollution because of its sheer volume and uncertain nature, such as presenting the aggregated uncertainties of the pollutants propagated across districts A, B, and C. To this end, we apply pattern extraction and uncertain graph visualization techniques together with overview-to-detail mechanisms, empowering users to analyze the propagation processes of air pollution interactively.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.0415271520614624,
            1.281502366065979
        ],
        "MSU_id": 1649
    },
    {
        "sentence": "Movement data can be summarized as density maps, graphs, flow maps, OD matrices, and OD maps.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 294,
        "paper_id": 4,
        "paragraph_info": "Spatiotemporal data visualization has been applied in various domains, such as location selection [\\[63,](#page-10-8) [64\\]](#page-10-9), urban planning [\\[44,](#page-9-16) [53\\]](#page-9-17), and air pollution [\\[45,](#page-9-18) [76\\]](#page-10-10), yet no visualization tool is available to analyze pollution propagation. In essence, air pollution propagation can be regarded as a type of movement data. Spatiotemporal visualization for movement data can generally be classified into three categories [\\[1\\]](#page-9-19), namely, direct depiction, summarization, and pattern extraction. Specifically, movement data can be directly depicted using visual elements, such as points [\\[17\\]](#page-9-20) for OD pairs, polylines [\\[2\\]](#page-9-21), tubes [\\[34\\]](#page-9-22), stacked bands [\\[56\\]](#page-10-11), and space-time cubes [\\[3\\]](#page-9-23) for trajectories. Movement data can also be summarized as density maps [\\[35,](#page-9-24) [47\\]](#page-9-25), graphs [\\[59\\]](#page-10-12), flow maps [\\[8,](#page-9-26) [22\\]](#page-9-27), OD matrices [\\[21,](#page-9-28)[69\\]](#page-10-13), and OD maps [\\[21\\]](#page-9-28). In addition, pattern extraction can be applied to obtain significant latent patterns from the movement data [\\[12,](#page-9-29) [55,](#page-10-14) [65,](#page-10-15) [66,](#page-10-16) [79,](#page-10-17) [81\\]](#page-10-18). However, the existing methods cannot be used to visualize the propagation of air pollution because of its sheer volume and uncertain nature, such as presenting the aggregated uncertainties of the pollutants propagated across districts A, B, and C. To this end, we apply pattern extraction and uncertain graph visualization techniques together with overview-to-detail mechanisms, empowering users to analyze the propagation processes of air pollution interactively.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.8291611671447754,
            0.7487871050834656
        ],
        "MSU_id": 1650
    },
    {
        "sentence": "Pattern extraction can be applied to obtain significant latent patterns from the movement data.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 294,
        "paper_id": 4,
        "paragraph_info": "Spatiotemporal data visualization has been applied in various domains, such as location selection [\\[63,](#page-10-8) [64\\]](#page-10-9), urban planning [\\[44,](#page-9-16) [53\\]](#page-9-17), and air pollution [\\[45,](#page-9-18) [76\\]](#page-10-10), yet no visualization tool is available to analyze pollution propagation. In essence, air pollution propagation can be regarded as a type of movement data. Spatiotemporal visualization for movement data can generally be classified into three categories [\\[1\\]](#page-9-19), namely, direct depiction, summarization, and pattern extraction. Specifically, movement data can be directly depicted using visual elements, such as points [\\[17\\]](#page-9-20) for OD pairs, polylines [\\[2\\]](#page-9-21), tubes [\\[34\\]](#page-9-22), stacked bands [\\[56\\]](#page-10-11), and space-time cubes [\\[3\\]](#page-9-23) for trajectories. Movement data can also be summarized as density maps [\\[35,](#page-9-24) [47\\]](#page-9-25), graphs [\\[59\\]](#page-10-12), flow maps [\\[8,](#page-9-26) [22\\]](#page-9-27), OD matrices [\\[21,](#page-9-28)[69\\]](#page-10-13), and OD maps [\\[21\\]](#page-9-28). In addition, pattern extraction can be applied to obtain significant latent patterns from the movement data [\\[12,](#page-9-29) [55,](#page-10-14) [65,](#page-10-15) [66,](#page-10-16) [79,](#page-10-17) [81\\]](#page-10-18). However, the existing methods cannot be used to visualize the propagation of air pollution because of its sheer volume and uncertain nature, such as presenting the aggregated uncertainties of the pollutants propagated across districts A, B, and C. To this end, we apply pattern extraction and uncertain graph visualization techniques together with overview-to-detail mechanisms, empowering users to analyze the propagation processes of air pollution interactively.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.137125015258789,
            0.9094697833061218
        ],
        "MSU_id": 1651
    },
    {
        "sentence": "We apply pattern extraction and uncertain graph visualization techniques together with overview-to-detail mechanisms.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 294,
        "paper_id": 4,
        "paragraph_info": "Spatiotemporal data visualization has been applied in various domains, such as location selection [\\[63,](#page-10-8) [64\\]](#page-10-9), urban planning [\\[44,](#page-9-16) [53\\]](#page-9-17), and air pollution [\\[45,](#page-9-18) [76\\]](#page-10-10), yet no visualization tool is available to analyze pollution propagation. In essence, air pollution propagation can be regarded as a type of movement data. Spatiotemporal visualization for movement data can generally be classified into three categories [\\[1\\]](#page-9-19), namely, direct depiction, summarization, and pattern extraction. Specifically, movement data can be directly depicted using visual elements, such as points [\\[17\\]](#page-9-20) for OD pairs, polylines [\\[2\\]](#page-9-21), tubes [\\[34\\]](#page-9-22), stacked bands [\\[56\\]](#page-10-11), and space-time cubes [\\[3\\]](#page-9-23) for trajectories. Movement data can also be summarized as density maps [\\[35,](#page-9-24) [47\\]](#page-9-25), graphs [\\[59\\]](#page-10-12), flow maps [\\[8,](#page-9-26) [22\\]](#page-9-27), OD matrices [\\[21,](#page-9-28)[69\\]](#page-10-13), and OD maps [\\[21\\]](#page-9-28). In addition, pattern extraction can be applied to obtain significant latent patterns from the movement data [\\[12,](#page-9-29) [55,](#page-10-14) [65,](#page-10-15) [66,](#page-10-16) [79,](#page-10-17) [81\\]](#page-10-18). However, the existing methods cannot be used to visualize the propagation of air pollution because of its sheer volume and uncertain nature, such as presenting the aggregated uncertainties of the pollutants propagated across districts A, B, and C. To this end, we apply pattern extraction and uncertain graph visualization techniques together with overview-to-detail mechanisms, empowering users to analyze the propagation processes of air pollution interactively.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2197515964508057,
            0.9816941618919373
        ],
        "MSU_id": 1653
    },
    {
        "sentence": "Existing FSM methods can be categorized into single graph-based and graph transaction-based methods.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 295,
        "paper_id": 4,
        "paragraph_info": "Frequent subgraph mining (FSM), a classic research topic in data mining [\\[25\\]](#page-9-5), has a wide range of applications in various domains (e.g., biology [\\[74\\]](#page-10-19), communication [\\[6\\]](#page-9-30), and chemistry [\\[15\\]](#page-9-31)). Based on the input dataset, existing FSM methods can be categorized into *single graph-based* and *graph transaction-based* methods. The *single graph-based* FSM extracts the patterns that frequently occur within a single but very large graph [\\[58\\]](#page-10-20), while the *graph transaction-based*",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6774808168411255,
            0.007847681641578674
        ],
        "MSU_id": 1657
    },
    {
        "sentence": "The single graph-based FSM extracts the patterns that frequently occur within a single but very large graph.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 295,
        "paper_id": 4,
        "paragraph_info": "Frequent subgraph mining (FSM), a classic research topic in data mining [\\[25\\]](#page-9-5), has a wide range of applications in various domains (e.g., biology [\\[74\\]](#page-10-19), communication [\\[6\\]](#page-9-30), and chemistry [\\[15\\]](#page-9-31)). Based on the input dataset, existing FSM methods can be categorized into *single graph-based* and *graph transaction-based* methods. The *single graph-based* FSM extracts the patterns that frequently occur within a single but very large graph [\\[58\\]](#page-10-20), while the *graph transaction-based*",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2418594360351562,
            0.7903774380683899
        ],
        "MSU_id": 1658
    },
    {
        "sentence": "We modify the formulation to take into account spatiotemporal context and air pollution.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 296,
        "paper_id": 4,
        "paragraph_info": "focuses on those that frequently occur among numerous different graphs named transactions [\\[68\\]](#page-10-21). Our problem is the latter one where the transactions correspond to the massive propagation processes. However, the existing methods like [\\[24\\]](#page-9-32) cannot be directly applied to meet our domain-specific problem of extracting significant propagation patterns of air pollution. Thus, we modify the formulation to take into account two aspects of the data, spatiotemporal context and air pollution.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6329929828643799,
            -1.4587677717208862
        ],
        "MSU_id": 1662
    },
    {
        "sentence": "Techniques of dynamic graph visualization aim to organize numerous chronologically evolving graphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 297,
        "paper_id": 4,
        "paragraph_info": "A subgraph is essentially a type of graph. Graph visualization is a broad research field [\\[23,](#page-9-33) [60\\]](#page-10-22). We focus on the most related parts of visualizing a large number of graphs. Some studies focus on either the structure- [\\[30,](#page-9-34) [71\\]](#page-10-23) or metric-oriented [\\[18,](#page-9-35) [27\\]](#page-9-36) analyses of a large number of graphs, but they cannot be applied to propagation patterns wherein both uncertainties and structure are meaningful. Techniques of dynamic graph visualization [\\[4\\]](#page-9-37) aim to organize numerous chronologically evolving graphs (e.g., in a radial [\\[20\\]](#page-9-38) or list layout [\\[9,](#page-9-39) [57\\]](#page-10-24)) for efficient time-oriented analysis. These techniques cannot deal with propagation patterns that are not chronologically ordered. Therefore, we propose an MDL-based hierarchical organization of massive patterns exploiting their topology similarities, wherein the uncertainties of the patterns are also visually encoded.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8051440715789795,
            1.170425534248352
        ],
        "MSU_id": 1668
    },
    {
        "sentence": "These techniques are used for efficient time-oriented analysis.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 297,
        "paper_id": 4,
        "paragraph_info": "A subgraph is essentially a type of graph. Graph visualization is a broad research field [\\[23,](#page-9-33) [60\\]](#page-10-22). We focus on the most related parts of visualizing a large number of graphs. Some studies focus on either the structure- [\\[30,](#page-9-34) [71\\]](#page-10-23) or metric-oriented [\\[18,](#page-9-35) [27\\]](#page-9-36) analyses of a large number of graphs, but they cannot be applied to propagation patterns wherein both uncertainties and structure are meaningful. Techniques of dynamic graph visualization [\\[4\\]](#page-9-37) aim to organize numerous chronologically evolving graphs (e.g., in a radial [\\[20\\]](#page-9-38) or list layout [\\[9,](#page-9-39) [57\\]](#page-10-24)) for efficient time-oriented analysis. These techniques cannot deal with propagation patterns that are not chronologically ordered. Therefore, we propose an MDL-based hierarchical organization of massive patterns exploiting their topology similarities, wherein the uncertainties of the patterns are also visually encoded.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.361142873764038,
            0.08879269659519196
        ],
        "MSU_id": 1669
    },
    {
        "sentence": "We propose an MDL-based hierarchical organization of massive patterns exploiting their topology similarities.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 297,
        "paper_id": 4,
        "paragraph_info": "A subgraph is essentially a type of graph. Graph visualization is a broad research field [\\[23,](#page-9-33) [60\\]](#page-10-22). We focus on the most related parts of visualizing a large number of graphs. Some studies focus on either the structure- [\\[30,](#page-9-34) [71\\]](#page-10-23) or metric-oriented [\\[18,](#page-9-35) [27\\]](#page-9-36) analyses of a large number of graphs, but they cannot be applied to propagation patterns wherein both uncertainties and structure are meaningful. Techniques of dynamic graph visualization [\\[4\\]](#page-9-37) aim to organize numerous chronologically evolving graphs (e.g., in a radial [\\[20\\]](#page-9-38) or list layout [\\[9,](#page-9-39) [57\\]](#page-10-24)) for efficient time-oriented analysis. These techniques cannot deal with propagation patterns that are not chronologically ordered. Therefore, we propose an MDL-based hierarchical organization of massive patterns exploiting their topology similarities, wherein the uncertainties of the patterns are also visually encoded.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2492482662200928,
            0.8522470593452454
        ],
        "MSU_id": 1671
    },
    {
        "sentence": "The uncertainties of the patterns are also visually encoded.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 297,
        "paper_id": 4,
        "paragraph_info": "A subgraph is essentially a type of graph. Graph visualization is a broad research field [\\[23,](#page-9-33) [60\\]](#page-10-22). We focus on the most related parts of visualizing a large number of graphs. Some studies focus on either the structure- [\\[30,](#page-9-34) [71\\]](#page-10-23) or metric-oriented [\\[18,](#page-9-35) [27\\]](#page-9-36) analyses of a large number of graphs, but they cannot be applied to propagation patterns wherein both uncertainties and structure are meaningful. Techniques of dynamic graph visualization [\\[4\\]](#page-9-37) aim to organize numerous chronologically evolving graphs (e.g., in a radial [\\[20\\]](#page-9-38) or list layout [\\[9,](#page-9-39) [57\\]](#page-10-24)) for efficient time-oriented analysis. These techniques cannot deal with propagation patterns that are not chronologically ordered. Therefore, we propose an MDL-based hierarchical organization of massive patterns exploiting their topology similarities, wherein the uncertainties of the patterns are also visually encoded.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6144880056381226,
            0.6394425630569458
        ],
        "MSU_id": 1672
    },
    {
        "sentence": "This paper presents concepts to characterize the pattern-based analysis of air pollution propagation.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 299,
        "paper_id": 4,
        "paragraph_info": "The rapidly progressing problem of air pollution has become a major issue for many large cities. Among all factors involved in the development of air pollution, the regional transportation of pollutants is generally considered the foremost one, as demonstrated by case studies where environmental scientists analyzed the air pollution problem in Beijing, China [\\[31,](#page-9-1) [73\\]](#page-10-1). To address this problem, it is important to trace back to the source areas where the pollutants are generated along the propagation pathways and enforce specific policies to mitigate the pollution, such as limiting road traffic and suspending chemical factories. To this end, this paper presents the following concepts to characterize the pattern-based analysis of air pollution propagation and help urban and environmental science experts better understand the transmission of pollutants among multiple cities at a large spatial scale.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2795827388763428,
            -0.4229962229728699
        ],
        "MSU_id": 1681
    },
    {
        "sentence": "These samples are collected on an hourly basis.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 300,
        "paper_id": 4,
        "paragraph_info": "Public meteorological and air quality datasets [\\[77,](#page-10-6) [78\\]](#page-10-4) are used in this study. Each dataset includes a *station table* and a *data table*. In the station table, each row represents a meteorological or air quality station identified by its name and district ID (for meteorological stations) or GPS coordinates (for air quality stations). In the data table, each row represents a sample collected in a meteorological or air quality station at a specific timestamp. A meteorological sample comprises weather information, including wind speed and direction, whereas an air quality sample records the concentrations of different air pollutants (e.g., PM2*.*5, SO2). These samples are collected on an hourly basis.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.2518733739852905,
            0.17441004514694214
        ],
        "MSU_id": 1689
    },
    {
        "sentence": "A meteorological sample and an air quality sample for every hour were obtained.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 301,
        "paper_id": 4,
        "paragraph_info": "Without loss of generality, this study focuses mainly on analyzing the propagation of PM2*.*5, a major type of air pollutant that can be transported over long distances [\\[61\\]](#page-10-25) and seriously affects public health [\\[67\\]](#page-10-26). After data cleaning and preprocessing, a meteorological sample and an air quality sample for every hour (5,448 hours) were obtained between Sept. 16, 2014 and Apr. 30, 2015 from 138 meteorological stations and 38 air quality stations. We refer to these stations as *districts* because they represent the regional atmospheric conditions.",
        "paper_info": "airvis",
        "2d_coord": [
            1.0625933408737183,
            -1.7224663496017456
        ],
        "MSU_id": 1693
    },
    {
        "sentence": "5,448 hours of data were collected between Sept. 16, 2014 and Apr. 30, 2015.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 301,
        "paper_id": 4,
        "paragraph_info": "Without loss of generality, this study focuses mainly on analyzing the propagation of PM2*.*5, a major type of air pollutant that can be transported over long distances [\\[61\\]](#page-10-25) and seriously affects public health [\\[67\\]](#page-10-26). After data cleaning and preprocessing, a meteorological sample and an air quality sample for every hour (5,448 hours) were obtained between Sept. 16, 2014 and Apr. 30, 2015 from 138 meteorological stations and 38 air quality stations. We refer to these stations as *districts* because they represent the regional atmospheric conditions.",
        "paper_info": "airvis",
        "2d_coord": [
            0.4734199047088623,
            0.854187548160553
        ],
        "MSU_id": 1694
    },
    {
        "sentence": "Data were obtained from 138 meteorological stations and 38 air quality stations.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 301,
        "paper_id": 4,
        "paragraph_info": "Without loss of generality, this study focuses mainly on analyzing the propagation of PM2*.*5, a major type of air pollutant that can be transported over long distances [\\[61\\]](#page-10-25) and seriously affects public health [\\[67\\]](#page-10-26). After data cleaning and preprocessing, a meteorological sample and an air quality sample for every hour (5,448 hours) were obtained between Sept. 16, 2014 and Apr. 30, 2015 from 138 meteorological stations and 38 air quality stations. We refer to these stations as *districts* because they represent the regional atmospheric conditions.",
        "paper_info": "airvis",
        "2d_coord": [
            0.3381805419921875,
            -1.4598499536514282
        ],
        "MSU_id": 1695
    },
    {
        "sentence": "We closely followed the *ninestage design study methodology framework*.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 302,
        "paper_id": 4,
        "paragraph_info": "To identify the user requirements for analyzing air pollution propagation, we closely worked with three domain experts, EA, EB, and EC, from the fields of urban computing and atmospheric science in the past year. EA and EB have decades of experience in utilizing data-driven automated approaches to study various urban problems, including air pollution, while EC is a recognized environmental scientist specializing in the analysis of air pollution and its propagation. This cooperation attempts to integrate their expertise in evaluating significant propagation patterns and finding major sources of air pollution using the visual analytics approach. To achieve this goal, we closely followed the *ninestage design study methodology framework* [\\[49\\]](#page-9-40). In particular, we first conducted comprehensive literature review (*learn*) regarding the analysis of pollution propagation and the visualization of spatiotemporal graph data, and then attempted to identify user requirements (*discover*) by holding bi-weekly discussions with the experts for three months. During the development of our system, we iteratively prototyped and implemented several design alternatives (*design & implement*) and evaluated the proposed designs with the experts (*deploy*) to verify the effectiveness of our approach. The derived user requirements are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.03262724354863167,
            0.5976300239562988
        ],
        "MSU_id": 1701
    },
    {
        "sentence": "We conducted a comprehensive literature review regarding the analysis of pollution propagation and the visualization of spatiotemporal graph data.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 302,
        "paper_id": 4,
        "paragraph_info": "To identify the user requirements for analyzing air pollution propagation, we closely worked with three domain experts, EA, EB, and EC, from the fields of urban computing and atmospheric science in the past year. EA and EB have decades of experience in utilizing data-driven automated approaches to study various urban problems, including air pollution, while EC is a recognized environmental scientist specializing in the analysis of air pollution and its propagation. This cooperation attempts to integrate their expertise in evaluating significant propagation patterns and finding major sources of air pollution using the visual analytics approach. To achieve this goal, we closely followed the *ninestage design study methodology framework* [\\[49\\]](#page-9-40). In particular, we first conducted comprehensive literature review (*learn*) regarding the analysis of pollution propagation and the visualization of spatiotemporal graph data, and then attempted to identify user requirements (*discover*) by holding bi-weekly discussions with the experts for three months. During the development of our system, we iteratively prototyped and implemented several design alternatives (*design & implement*) and evaluated the proposed designs with the experts (*deploy*) to verify the effectiveness of our approach. The derived user requirements are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.217655658721924,
            0.6332271099090576
        ],
        "MSU_id": 1702
    },
    {
        "sentence": "We attempted to identify user requirements by holding bi-weekly discussions with the experts for three months.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 302,
        "paper_id": 4,
        "paragraph_info": "To identify the user requirements for analyzing air pollution propagation, we closely worked with three domain experts, EA, EB, and EC, from the fields of urban computing and atmospheric science in the past year. EA and EB have decades of experience in utilizing data-driven automated approaches to study various urban problems, including air pollution, while EC is a recognized environmental scientist specializing in the analysis of air pollution and its propagation. This cooperation attempts to integrate their expertise in evaluating significant propagation patterns and finding major sources of air pollution using the visual analytics approach. To achieve this goal, we closely followed the *ninestage design study methodology framework* [\\[49\\]](#page-9-40). In particular, we first conducted comprehensive literature review (*learn*) regarding the analysis of pollution propagation and the visualization of spatiotemporal graph data, and then attempted to identify user requirements (*discover*) by holding bi-weekly discussions with the experts for three months. During the development of our system, we iteratively prototyped and implemented several design alternatives (*design & implement*) and evaluated the proposed designs with the experts (*deploy*) to verify the effectiveness of our approach. The derived user requirements are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7236593961715698,
            1.2139993906021118
        ],
        "MSU_id": 1703
    },
    {
        "sentence": "During the development of our system, we iteratively prototyped and implemented several design alternatives.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 302,
        "paper_id": 4,
        "paragraph_info": "To identify the user requirements for analyzing air pollution propagation, we closely worked with three domain experts, EA, EB, and EC, from the fields of urban computing and atmospheric science in the past year. EA and EB have decades of experience in utilizing data-driven automated approaches to study various urban problems, including air pollution, while EC is a recognized environmental scientist specializing in the analysis of air pollution and its propagation. This cooperation attempts to integrate their expertise in evaluating significant propagation patterns and finding major sources of air pollution using the visual analytics approach. To achieve this goal, we closely followed the *ninestage design study methodology framework* [\\[49\\]](#page-9-40). In particular, we first conducted comprehensive literature review (*learn*) regarding the analysis of pollution propagation and the visualization of spatiotemporal graph data, and then attempted to identify user requirements (*discover*) by holding bi-weekly discussions with the experts for three months. During the development of our system, we iteratively prototyped and implemented several design alternatives (*design & implement*) and evaluated the proposed designs with the experts (*deploy*) to verify the effectiveness of our approach. The derived user requirements are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6106021404266357,
            0.088161900639534
        ],
        "MSU_id": 1704
    },
    {
        "sentence": "We evaluated the proposed designs with the experts to verify the effectiveness of our approach.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 302,
        "paper_id": 4,
        "paragraph_info": "To identify the user requirements for analyzing air pollution propagation, we closely worked with three domain experts, EA, EB, and EC, from the fields of urban computing and atmospheric science in the past year. EA and EB have decades of experience in utilizing data-driven automated approaches to study various urban problems, including air pollution, while EC is a recognized environmental scientist specializing in the analysis of air pollution and its propagation. This cooperation attempts to integrate their expertise in evaluating significant propagation patterns and finding major sources of air pollution using the visual analytics approach. To achieve this goal, we closely followed the *ninestage design study methodology framework* [\\[49\\]](#page-9-40). In particular, we first conducted comprehensive literature review (*learn*) regarding the analysis of pollution propagation and the visualization of spatiotemporal graph data, and then attempted to identify user requirements (*discover*) by holding bi-weekly discussions with the experts for three months. During the development of our system, we iteratively prototyped and implemented several design alternatives (*design & implement*) and evaluated the proposed designs with the experts (*deploy*) to verify the effectiveness of our approach. The derived user requirements are summarized as follows.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.83431077003479,
            1.296128273010254
        ],
        "MSU_id": 1705
    },
    {
        "sentence": "Topology analysis allows experts to intuitively classify patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 303,
        "paper_id": 4,
        "paragraph_info": "R1: Explore a topology-based overview of patterns. To interpret the massive propagation patterns extracted from atmospheric data, the experts must first grasp an overview of these patterns through their topologies, which are the key factors in understanding their roles. For example, a star-like topology indicates that the district at the center of the topology could be a major source of air pollution, while a linked topology represents the long-range transportation of pollutants. Such topology analysis allows the experts to intuitively classify patterns and find promising ones on the basis of their spatial structures.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0982308387756348,
            1.0182987451553345
        ],
        "MSU_id": 1712
    },
    {
        "sentence": "Experts should be able to obtain a clear summary of each propagation pattern in terms of their spatial and temporal dimensions.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 304,
        "paper_id": 4,
        "paragraph_info": "R2: Obtain the spatiotemporal summaries of patterns. To identify interesting patterns from those with identical topologies, the experts should be able to obtain a clear summary of each propagation pattern in terms of their spatial (*On which path is the pollution propagated?*) and temporal (*When did the associated pollution instances occur?*) dimensions. The summary enables experts to integrate domain knowledge to initially evaluate a propagation pattern, like determining *how a city suffered from the pollution propagated from an industrial city* and *whether it was an abnormity against the meteorological common sense.* R3: Unfold the uncertain propagation process of a pattern. The experts aim to establish how the pollutants are transported between districts in a specific pattern. In addition to the general overview of propagation pathways, they are particularly interested in analyzing the probabilistic cause-effect relationship between source (*A*) and destination (*B*) districts in the pattern. *How much is the expected amount of pollutant transportation from A to B? Which district is the largest contributor to the pollution in B? Which district has received the largest impact of the pollution in A?*",
        "paper_info": "airvis",
        "2d_coord": [
            -2.083348512649536,
            0.4152366518974304
        ],
        "MSU_id": 1714
    },
    {
        "sentence": "Experts aim to establish how the pollutants are transported between districts in a specific pattern.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 304,
        "paper_id": 4,
        "paragraph_info": "R2: Obtain the spatiotemporal summaries of patterns. To identify interesting patterns from those with identical topologies, the experts should be able to obtain a clear summary of each propagation pattern in terms of their spatial (*On which path is the pollution propagated?*) and temporal (*When did the associated pollution instances occur?*) dimensions. The summary enables experts to integrate domain knowledge to initially evaluate a propagation pattern, like determining *how a city suffered from the pollution propagated from an industrial city* and *whether it was an abnormity against the meteorological common sense.* R3: Unfold the uncertain propagation process of a pattern. The experts aim to establish how the pollutants are transported between districts in a specific pattern. In addition to the general overview of propagation pathways, they are particularly interested in analyzing the probabilistic cause-effect relationship between source (*A*) and destination (*B*) districts in the pattern. *How much is the expected amount of pollutant transportation from A to B? Which district is the largest contributor to the pollution in B? Which district has received the largest impact of the pollution in A?*",
        "paper_info": "airvis",
        "2d_coord": [
            -1.624129295349121,
            1.3482426404953003
        ],
        "MSU_id": 1716
    },
    {
        "sentence": "Experts are particularly interested in analyzing the probabilistic cause-effect relationship between source (A) and destination (B) districts in the pattern.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 304,
        "paper_id": 4,
        "paragraph_info": "R2: Obtain the spatiotemporal summaries of patterns. To identify interesting patterns from those with identical topologies, the experts should be able to obtain a clear summary of each propagation pattern in terms of their spatial (*On which path is the pollution propagated?*) and temporal (*When did the associated pollution instances occur?*) dimensions. The summary enables experts to integrate domain knowledge to initially evaluate a propagation pattern, like determining *how a city suffered from the pollution propagated from an industrial city* and *whether it was an abnormity against the meteorological common sense.* R3: Unfold the uncertain propagation process of a pattern. The experts aim to establish how the pollutants are transported between districts in a specific pattern. In addition to the general overview of propagation pathways, they are particularly interested in analyzing the probabilistic cause-effect relationship between source (*A*) and destination (*B*) districts in the pattern. *How much is the expected amount of pollutant transportation from A to B? Which district is the largest contributor to the pollution in B? Which district has received the largest impact of the pollution in A?*",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7626917362213135,
            0.9529121518135071
        ],
        "MSU_id": 1717
    },
    {
        "sentence": "Experts need to compare between patterns based on the topologies and properties of the patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 305,
        "paper_id": 4,
        "paragraph_info": "R4: Find the similarities or differences between patterns. To identify similar or abnormal propagation processes, experts need to compare between these patterns based on the topologies and properties of the patterns. For example, patterns may share the same pollution source but propagate via different pathways. To study the effect of a pollution source, experts need to conduct the comparative analysis based on the cause-effect relationships, including propagation paths and strength, to determine the major pathways. The discovery of similar patterns also allows the experts to analyze them in batch to speed up the workflow. R5: Examine the propagation instances in a pattern. Each pattern is associated with numerous propagation instances. To obtain reliable and convincing results, the experts need to check these instances for detailed",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2182204723358154,
            0.9135294556617737
        ],
        "MSU_id": 1721
    },
    {
        "sentence": "Experts need to conduct the comparative analysis based on the cause-effect relationships, including propagation paths and strength.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 305,
        "paper_id": 4,
        "paragraph_info": "R4: Find the similarities or differences between patterns. To identify similar or abnormal propagation processes, experts need to compare between these patterns based on the topologies and properties of the patterns. For example, patterns may share the same pollution source but propagate via different pathways. To study the effect of a pollution source, experts need to conduct the comparative analysis based on the cause-effect relationships, including propagation paths and strength, to determine the major pathways. The discovery of similar patterns also allows the experts to analyze them in batch to speed up the workflow. R5: Examine the propagation instances in a pattern. Each pattern is associated with numerous propagation instances. To obtain reliable and convincing results, the experts need to check these instances for detailed",
        "paper_info": "airvis",
        "2d_coord": [
            -2.121695041656494,
            0.9840589165687561
        ],
        "MSU_id": 1723
    },
    {
        "sentence": "Experts need to check these instances for detailed analysis to obtain reliable and convincing results.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 305,
        "paper_id": 4,
        "paragraph_info": "R4: Find the similarities or differences between patterns. To identify similar or abnormal propagation processes, experts need to compare between these patterns based on the topologies and properties of the patterns. For example, patterns may share the same pollution source but propagate via different pathways. To study the effect of a pollution source, experts need to conduct the comparative analysis based on the cause-effect relationships, including propagation paths and strength, to determine the major pathways. The discovery of similar patterns also allows the experts to analyze them in batch to speed up the workflow. R5: Examine the propagation instances in a pattern. Each pattern is associated with numerous propagation instances. To obtain reliable and convincing results, the experts need to check these instances for detailed",
        "paper_info": "airvis",
        "2d_coord": [
            -1.3917510509490967,
            1.2602965831756592
        ],
        "MSU_id": 1726
    },
    {
        "type": "figure",
        "para_id": 307,
        "paper_id": 4,
        "paragraph_info": "_page_3_Figure_0.jpeg",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2103843688964844,
            0.9732813835144043
        ],
        "MSU_id": 1727,
        "sentence": "The image illustrates the pipeline of a frequent pattern mining framework, showing the process from transportation instances to the extraction of a frequent subgraph.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "The pipeline of the proposed frequent pattern mining framework includes multiple components.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 307,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-0\"></span>Fig. 2. The pipeline of the proposed frequent pattern mining framework: (A) two transportation instances that describe the pollutants transported between 1 and 2 (larger) and between 1 and 3 (smaller); (B) a propagation instance that involves four transportation instances; (C) a propagation pattern identified from four propagation instances, each encoded with a color; (D) a propagation graph (i.e., a propagation instance) constructed from massive transportation graphs;  $(E)$  a frequent subgraph (i.e., a propagation pattern) extracted from massive graph transactions.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.9097880721092224,
            -0.12011943012475967
        ],
        "MSU_id": 1728
    },
    {
        "sentence": "Two transportation instances describe the pollutants transported between 1 and 2 and between 1 and 3.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 307,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-0\"></span>Fig. 2. The pipeline of the proposed frequent pattern mining framework: (A) two transportation instances that describe the pollutants transported between 1 and 2 (larger) and between 1 and 3 (smaller); (B) a propagation instance that involves four transportation instances; (C) a propagation pattern identified from four propagation instances, each encoded with a color; (D) a propagation graph (i.e., a propagation instance) constructed from massive transportation graphs;  $(E)$  a frequent subgraph (i.e., a propagation pattern) extracted from massive graph transactions.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2568252086639404,
            -0.2864081859588623
        ],
        "MSU_id": 1729
    },
    {
        "sentence": "A propagation instance involves four transportation instances.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 307,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-0\"></span>Fig. 2. The pipeline of the proposed frequent pattern mining framework: (A) two transportation instances that describe the pollutants transported between 1 and 2 (larger) and between 1 and 3 (smaller); (B) a propagation instance that involves four transportation instances; (C) a propagation pattern identified from four propagation instances, each encoded with a color; (D) a propagation graph (i.e., a propagation instance) constructed from massive transportation graphs;  $(E)$  a frequent subgraph (i.e., a propagation pattern) extracted from massive graph transactions.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2637522220611572,
            0.3006879389286041
        ],
        "MSU_id": 1730
    },
    {
        "sentence": "A propagation pattern is identified from four propagation instances, each encoded with a color.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 307,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-0\"></span>Fig. 2. The pipeline of the proposed frequent pattern mining framework: (A) two transportation instances that describe the pollutants transported between 1 and 2 (larger) and between 1 and 3 (smaller); (B) a propagation instance that involves four transportation instances; (C) a propagation pattern identified from four propagation instances, each encoded with a color; (D) a propagation graph (i.e., a propagation instance) constructed from massive transportation graphs;  $(E)$  a frequent subgraph (i.e., a propagation pattern) extracted from massive graph transactions.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7569942474365234,
            -0.05231190472841263
        ],
        "MSU_id": 1731
    },
    {
        "sentence": "A propagation graph is constructed from massive transportation graphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 307,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-0\"></span>Fig. 2. The pipeline of the proposed frequent pattern mining framework: (A) two transportation instances that describe the pollutants transported between 1 and 2 (larger) and between 1 and 3 (smaller); (B) a propagation instance that involves four transportation instances; (C) a propagation pattern identified from four propagation instances, each encoded with a color; (D) a propagation graph (i.e., a propagation instance) constructed from massive transportation graphs;  $(E)$  a frequent subgraph (i.e., a propagation pattern) extracted from massive graph transactions.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.277524948120117,
            0.7086238265037537
        ],
        "MSU_id": 1732
    },
    {
        "sentence": "A frequent subgraph is extracted from massive graph transactions.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 307,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-0\"></span>Fig. 2. The pipeline of the proposed frequent pattern mining framework: (A) two transportation instances that describe the pollutants transported between 1 and 2 (larger) and between 1 and 3 (smaller); (B) a propagation instance that involves four transportation instances; (C) a propagation pattern identified from four propagation instances, each encoded with a color; (D) a propagation graph (i.e., a propagation instance) constructed from massive transportation graphs;  $(E)$  a frequent subgraph (i.e., a propagation pattern) extracted from massive graph transactions.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.227644443511963,
            0.8565841317176819
        ],
        "MSU_id": 1733
    },
    {
        "sentence": "We develop AirVis which comprises two parts, namely, the backend and the frontend.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            0.09297467768192291,
            -1.554331660270691
        ],
        "MSU_id": 1738
    },
    {
        "sentence": "The backend of the system is implemented in Node.js.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.6819029450416565,
            0.3498779535293579
        ],
        "MSU_id": 1739
    },
    {
        "sentence": "The backend integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2692718505859375,
            0.9158791303634644
        ],
        "MSU_id": 1740
    },
    {
        "sentence": "The extraction of patterns is based on the parameters specified by the users.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.4548192024230957,
            0.40131622552871704
        ],
        "MSU_id": 1741
    },
    {
        "sentence": "The frontend is written in Vue.js and TypeScript.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.4530901610851288,
            -0.29140397906303406
        ],
        "MSU_id": 1742
    },
    {
        "sentence": "The frontend runs in modern web browsers.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.2171889543533325,
            0.7208008170127869
        ],
        "MSU_id": 1743
    },
    {
        "sentence": "The frontend allows users to interactively explore and analyze the complex propagation patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3186099529266357,
            0.5407440066337585
        ],
        "MSU_id": 1744
    },
    {
        "sentence": "The complex propagation patterns are revealed with hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 309,
        "paper_id": 4,
        "paragraph_info": "Based on the aforementioned requirements, we develop AirVis which comprise two parts, namely, the backend and the frontend. The backend of the system, implemented in Node.js, integrates an FSM-based pattern mining model to extract frequent propagation patterns efficiently based on the parameters specified by the users. The frontend, written in Vue.js and TypeScript, runs in modern web browsers and allows users to interactively explore and analyze the complex propagation patterns, which are revealed with the hierarchical visualizations based on the topologies, propagation processes, and instances of the patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.4423625469207764,
            0.7506248354911804
        ],
        "MSU_id": 1745
    },
    {
        "sentence": "We model the transportation of air pollutants quantitatively.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 310,
        "paper_id": 4,
        "paragraph_info": "This section describes a novel mining framework for the efficient extraction of air pollution propagation patterns. First, we model the transportation of air pollutants quantitatively. Then, we construct propagation graphs based on the modelled transportation instances. Finally, we leverage the FSM method to extract the propagation patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.7799526453018188,
            -1.0410451889038086
        ],
        "MSU_id": 1747
    },
    {
        "sentence": "We construct propagation graphs based on the modelled transportation instances.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 310,
        "paper_id": 4,
        "paragraph_info": "This section describes a novel mining framework for the efficient extraction of air pollution propagation patterns. First, we model the transportation of air pollutants quantitatively. Then, we construct propagation graphs based on the modelled transportation instances. Finally, we leverage the FSM method to extract the propagation patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2265639305114746,
            0.5948458313941956
        ],
        "MSU_id": 1748
    },
    {
        "sentence": "We leverage the FSM method to extract the propagation patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 310,
        "paper_id": 4,
        "paragraph_info": "This section describes a novel mining framework for the efficient extraction of air pollution propagation patterns. First, we model the transportation of air pollutants quantitatively. Then, we construct propagation graphs based on the modelled transportation instances. Finally, we leverage the FSM method to extract the propagation patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7599397897720337,
            -0.594290554523468
        ],
        "MSU_id": 1749
    },
    {
        "sentence": "To model the transportation of air pollutants from district *i* to district *j*, we need to determine the probability of the air pollutants transported from *i* to *j*.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 311,
        "paper_id": 4,
        "paragraph_info": "The transportation of air pollutants between two districts is highly uncertain due to the varying wind fields. To model such a process from district *i* to  $j$ , for example, we need to determine the probability of the air pollutants transported from  $i$  to  $j$  (Fig. 3A). By leveraging the *air parcel* concept from the environmental science literature [50], we attempt to simulate the movement of air pollutants with air parcels based on a quantitative sampling method (Fig.  $3C$ ). Specifically,  $s$  air parcels, representing the air pollutants, are released near the district  $i$  at the timestamp  $t$  in a simulation. The locations of these air parcels are updated iteratively based on the meteorological conditions, including the wind speed and direction (Fig. 3B), until the distance between the air parcel and the district j falls under  $d_e = 20 \\,\\mathrm{km}$  or the time limit is exceeded. Inspired by HYSPLIT [52], we update the location of an air parcel with the following equations at the timestamp  $t$ :",
        "paper_info": "airvis",
        "2d_coord": [
            -0.7367517948150635,
            0.26100045442581177
        ],
        "MSU_id": 1751
    },
    {
        "sentence": "We attempt to simulate the movement of air pollutants with air parcels based on a quantitative sampling method.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 311,
        "paper_id": 4,
        "paragraph_info": "The transportation of air pollutants between two districts is highly uncertain due to the varying wind fields. To model such a process from district *i* to  $j$ , for example, we need to determine the probability of the air pollutants transported from  $i$  to  $j$  (Fig. 3A). By leveraging the *air parcel* concept from the environmental science literature [50], we attempt to simulate the movement of air pollutants with air parcels based on a quantitative sampling method (Fig.  $3C$ ). Specifically,  $s$  air parcels, representing the air pollutants, are released near the district  $i$  at the timestamp  $t$  in a simulation. The locations of these air parcels are updated iteratively based on the meteorological conditions, including the wind speed and direction (Fig. 3B), until the distance between the air parcel and the district j falls under  $d_e = 20 \\,\\mathrm{km}$  or the time limit is exceeded. Inspired by HYSPLIT [52], we update the location of an air parcel with the following equations at the timestamp  $t$ :",
        "paper_info": "airvis",
        "2d_coord": [
            0.6363469362258911,
            0.3394016623497009
        ],
        "MSU_id": 1752
    },
    {
        "sentence": "$s$ air parcels, representing the air pollutants, are released near district $i$ at the timestamp $t$ in a simulation.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 311,
        "paper_id": 4,
        "paragraph_info": "The transportation of air pollutants between two districts is highly uncertain due to the varying wind fields. To model such a process from district *i* to  $j$ , for example, we need to determine the probability of the air pollutants transported from  $i$  to  $j$  (Fig. 3A). By leveraging the *air parcel* concept from the environmental science literature [50], we attempt to simulate the movement of air pollutants with air parcels based on a quantitative sampling method (Fig.  $3C$ ). Specifically,  $s$  air parcels, representing the air pollutants, are released near the district  $i$  at the timestamp  $t$  in a simulation. The locations of these air parcels are updated iteratively based on the meteorological conditions, including the wind speed and direction (Fig. 3B), until the distance between the air parcel and the district j falls under  $d_e = 20 \\,\\mathrm{km}$  or the time limit is exceeded. Inspired by HYSPLIT [52], we update the location of an air parcel with the following equations at the timestamp  $t$ :",
        "paper_info": "airvis",
        "2d_coord": [
            0.7322713136672974,
            -1.0483819246292114
        ],
        "MSU_id": 1753
    },
    {
        "sentence": "The locations of these air parcels are updated iteratively based on the meteorological conditions, including the wind speed and direction.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 311,
        "paper_id": 4,
        "paragraph_info": "The transportation of air pollutants between two districts is highly uncertain due to the varying wind fields. To model such a process from district *i* to  $j$ , for example, we need to determine the probability of the air pollutants transported from  $i$  to  $j$  (Fig. 3A). By leveraging the *air parcel* concept from the environmental science literature [50], we attempt to simulate the movement of air pollutants with air parcels based on a quantitative sampling method (Fig.  $3C$ ). Specifically,  $s$  air parcels, representing the air pollutants, are released near the district  $i$  at the timestamp  $t$  in a simulation. The locations of these air parcels are updated iteratively based on the meteorological conditions, including the wind speed and direction (Fig. 3B), until the distance between the air parcel and the district j falls under  $d_e = 20 \\,\\mathrm{km}$  or the time limit is exceeded. Inspired by HYSPLIT [52], we update the location of an air parcel with the following equations at the timestamp  $t$ :",
        "paper_info": "airvis",
        "2d_coord": [
            0.508986234664917,
            -1.7944202423095703
        ],
        "MSU_id": 1754
    },
    {
        "sentence": "The updating continues until the distance between the air parcel and district *j* falls under $d_e = 20 \\,\\mathrm{km}$ or the time limit is exceeded.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 311,
        "paper_id": 4,
        "paragraph_info": "The transportation of air pollutants between two districts is highly uncertain due to the varying wind fields. To model such a process from district *i* to  $j$ , for example, we need to determine the probability of the air pollutants transported from  $i$  to  $j$  (Fig. 3A). By leveraging the *air parcel* concept from the environmental science literature [50], we attempt to simulate the movement of air pollutants with air parcels based on a quantitative sampling method (Fig.  $3C$ ). Specifically,  $s$  air parcels, representing the air pollutants, are released near the district  $i$  at the timestamp  $t$  in a simulation. The locations of these air parcels are updated iteratively based on the meteorological conditions, including the wind speed and direction (Fig. 3B), until the distance between the air parcel and the district j falls under  $d_e = 20 \\,\\mathrm{km}$  or the time limit is exceeded. Inspired by HYSPLIT [52], we update the location of an air parcel with the following equations at the timestamp  $t$ :",
        "paper_info": "airvis",
        "2d_coord": [
            0.6744803190231323,
            -0.6464667916297913
        ],
        "MSU_id": 1755
    },
    {
        "sentence": "We update the location of an air parcel with specific equations at the timestamp $t$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 311,
        "paper_id": 4,
        "paragraph_info": "The transportation of air pollutants between two districts is highly uncertain due to the varying wind fields. To model such a process from district *i* to  $j$ , for example, we need to determine the probability of the air pollutants transported from  $i$  to  $j$  (Fig. 3A). By leveraging the *air parcel* concept from the environmental science literature [50], we attempt to simulate the movement of air pollutants with air parcels based on a quantitative sampling method (Fig.  $3C$ ). Specifically,  $s$  air parcels, representing the air pollutants, are released near the district  $i$  at the timestamp  $t$  in a simulation. The locations of these air parcels are updated iteratively based on the meteorological conditions, including the wind speed and direction (Fig. 3B), until the distance between the air parcel and the district j falls under  $d_e = 20 \\,\\mathrm{km}$  or the time limit is exceeded. Inspired by HYSPLIT [52], we update the location of an air parcel with the following equations at the timestamp  $t$ :",
        "paper_info": "airvis",
        "2d_coord": [
            0.8951190710067749,
            -1.822407841682434
        ],
        "MSU_id": 1756
    },
    {
        "type": "figure",
        "para_id": 314,
        "paper_id": 4,
        "paragraph_info": "_page_3_Figure_11.jpeg",
        "paper_info": "airvis",
        "2d_coord": [
            -1.4143998622894287,
            0.7936191558837891
        ],
        "MSU_id": 1764,
        "sentence": "The image illustrates the process of estimating transportation probabilities of air pollutants between districts using empirical observations, including the iterative update of air parcel locations and quantitative sampling methods.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "The probabilities of the air pollutants transported from district *i* to *j* at the timestamp $t$ are estimated.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 314,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-1\"></span>Fig. 3. (A) The probabilities of the air pollutants transported from 1. (B) The iterative update of the air parcel locations. (C) The quantitative sampling method. (D) The extracted transportation instances. estimate the transportation probability  $p_{ijt}$  from district *i* to *j* at the timestamp  $t$  with the empirical observations:",
        "paper_info": "airvis",
        "2d_coord": [
            0.23504091799259186,
            -1.3582059144973755
        ],
        "MSU_id": 1765
    },
    {
        "sentence": "The iterative update of the air parcel locations is performed.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 314,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-1\"></span>Fig. 3. (A) The probabilities of the air pollutants transported from 1. (B) The iterative update of the air parcel locations. (C) The quantitative sampling method. (D) The extracted transportation instances. estimate the transportation probability  $p_{ijt}$  from district *i* to *j* at the timestamp  $t$  with the empirical observations:",
        "paper_info": "airvis",
        "2d_coord": [
            0.339311420917511,
            -0.5921790599822998
        ],
        "MSU_id": 1766
    },
    {
        "sentence": "The quantitative sampling method is utilized.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 314,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-1\"></span>Fig. 3. (A) The probabilities of the air pollutants transported from 1. (B) The iterative update of the air parcel locations. (C) The quantitative sampling method. (D) The extracted transportation instances. estimate the transportation probability  $p_{ijt}$  from district *i* to *j* at the timestamp  $t$  with the empirical observations:",
        "paper_info": "airvis",
        "2d_coord": [
            0.13592146337032318,
            1.0649317502975464
        ],
        "MSU_id": 1767
    },
    {
        "sentence": "The extracted transportation instances are analyzed.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 314,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-1\"></span>Fig. 3. (A) The probabilities of the air pollutants transported from 1. (B) The iterative update of the air parcel locations. (C) The quantitative sampling method. (D) The extracted transportation instances. estimate the transportation probability  $p_{ijt}$  from district *i* to *j* at the timestamp  $t$  with the empirical observations:",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2580599784851074,
            0.5011202692985535
        ],
        "MSU_id": 1768
    },
    {
        "sentence": "The transportation probability $p_{ijt}$ is estimated with the empirical observations.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 314,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-3-1\"></span>Fig. 3. (A) The probabilities of the air pollutants transported from 1. (B) The iterative update of the air parcel locations. (C) The quantitative sampling method. (D) The extracted transportation instances. estimate the transportation probability  $p_{ijt}$  from district *i* to *j* at the timestamp  $t$  with the empirical observations:",
        "paper_info": "airvis",
        "2d_coord": [
            -0.4886155128479004,
            -0.9766505360603333
        ],
        "MSU_id": 1769
    },
    {
        "sentence": "The average transportation time $tt_{ijt}$ is calculated to be $(\\sum_{k=1}^{s_r} tt_k)/s_r$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 315,
        "paper_id": 4,
        "paragraph_info": "The average transportation time  $tt_{ijt}$  is calculated to be  $(\\sum_{k=1}^{s_r} tt_k)/s_r$ . Fig. 3C and 3D demonstrate an example of inferring transportation probabilities from air parcel sampling.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.8956805467605591,
            -0.7539675831794739
        ],
        "MSU_id": 1770
    },
    {
        "sentence": "We represent each transportation instance with a transportation graph.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1924455165863037,
            0.666714072227478
        ],
        "MSU_id": 1772
    },
    {
        "sentence": "Each transportation graph has two nodes $n_i$ and $n_j$ that represent two respective districts i and j.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.226712703704834,
            0.81903076171875
        ],
        "MSU_id": 1773
    },
    {
        "sentence": "Each transportation graph has one directed edge $e_{ij}$ indicating the transportation process.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1845271587371826,
            0.47283831238746643
        ],
        "MSU_id": 1774
    },
    {
        "sentence": "Each node $n$ has two extra attributes: the timestamp $n.t$ and the pollution concentration $n.c$ observed at the timestamp $n.t$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6348806619644165,
            -0.970519483089447
        ],
        "MSU_id": 1775
    },
    {
        "sentence": "We compute the transportation time of the transportation instance denoted with $e_{ij}.tt$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.087470293045044,
            -1.2731890678405762
        ],
        "MSU_id": 1776
    },
    {
        "sentence": "The estimated transportation probability is denoted with $e_{ij}.p$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.47922226786613464,
            -1.2078560590744019
        ],
        "MSU_id": 1777
    },
    {
        "sentence": "The estimated transportation probability $e_{ij}.p$ describes the ratio of the pollutants transported from the source to the destination district.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            0.16064395010471344,
            -0.6953641772270203
        ],
        "MSU_id": 1778
    },
    {
        "sentence": "The expected amount of the transported pollutants is derived with $e_{ij}.tc = e_{ij}.p \\times n_i.c$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            0.7945168614387512,
            -1.2709518671035767
        ],
        "MSU_id": 1779
    },
    {
        "sentence": "The impact factor $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            0.8321250677108765,
            -0.7650177478790283
        ],
        "MSU_id": 1780
    },
    {
        "sentence": "We removed the graphs with $e_{ij}.tc < 30$, assuming that no pollutant is transported.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 316,
        "paper_id": 4,
        "paragraph_info": "Subsequently, we represent each transportation instance with a *transportation graph* (Fig. 2D). Each transportation graph has two nodes  $n_i$ and  $n_j$  that represent two respective districts i and j and one directed edge  $e_{ij}$  indicating the transportation process. In addition to the inherent attributes, such as the name and geo-location, each node  $n$  has two extra attributes, namely, the timestamp  $n.t$  and the pollution concentration  $n.c$  observed at the timestamp  $n.t.$  Furthermore, we compute the following attributes and associate them with the edge  $e_{ij}$ : a) the transportation time of the transportation instance is denoted with  $e_{ij}.tt$ ; b) the estimated transportation probability is denoted with  $e_{ij}$ ,  $p$ , which is also the *contribution* factor of this transportation instance that describes the ratio of the pollutants transported from the source to the destination district; c) the expected amount of the transported pollutants is derived with  $e_{ij}.tc = e_{ij}.p \\times n_i.c$ ; and d) the *impact* factor  $e_{ij}.a = e_{ij}.tc/n_j.c$ indicates the ratio of the pollutants in the destination that are received from the source district. Based on experts' suggestions, we removed the graphs with  $e_{ij}.tc < 30$ , assuming that no pollutant is transported.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.7952600717544556,
            1.162222981452942
        ],
        "MSU_id": 1781
    },
    {
        "sentence": "To characterize the pollutants propagated among multiple districts, we derive the propagation instances.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 317,
        "paper_id": 4,
        "paragraph_info": "The transportation instances only describe the pollutant transmission from one district to another. To characterize the pollutants propagated among multiple districts, we derive the propagation instances, represented by *propagation graphs* (Fig. 2D), by searching and merging the extracted transportation graphs.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.4004037380218506,
            0.5601376295089722
        ],
        "MSU_id": 1783
    },
    {
        "sentence": "The propagation instances are represented by propagation graphs.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 317,
        "paper_id": 4,
        "paragraph_info": "The transportation instances only describe the pollutant transmission from one district to another. To characterize the pollutants propagated among multiple districts, we derive the propagation instances, represented by *propagation graphs* (Fig. 2D), by searching and merging the extracted transportation graphs.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3235418796539307,
            0.6410422921180725
        ],
        "MSU_id": 1784
    },
    {
        "sentence": "We derive the propagation instances by searching and merging the extracted transportation graphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 317,
        "paper_id": 4,
        "paragraph_info": "The transportation instances only describe the pollutant transmission from one district to another. To characterize the pollutants propagated among multiple districts, we derive the propagation instances, represented by *propagation graphs* (Fig. 2D), by searching and merging the extracted transportation graphs.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.227504253387451,
            0.5671442747116089
        ],
        "MSU_id": 1785
    },
    {
        "sentence": "We follow a depth-first search procedure to construct propagation graphs.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 318,
        "paper_id": 4,
        "paragraph_info": "To better illustrate the construction of propagation graphs, we first define the concept of *spatiotemporal continuity* (Fig. 4): two transportation graphs are spatiotemporally continuous iff they share one and only one node, where the locations and timestamps of the shared nodes are equal, respectively. Based on this concept, we follow a depth-first search procedure outlined as follows: starting from a random transportation graph, we recursively add the transportation graphs that are spatiotemporally continuous with the added ones to the propagation graph. To simulate the decomposition of air pollutants, we limit the maximum time span of the propagation graph to 200 hours, as recommended by the experts. By repeating this procedure, we are able to generate a massive number of propagation graphs  $pG = (V, E)$  until all the transportation graphs have been visited. The attributes associated with the nodes and edges in the propagation graphs are identical to those in the transportation graphs. Such method allows us to obtain the continuous long-distance propagation instances naturally as paths in the graphs, which are almost impossible to detect with the prior methods.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.294224500656128,
            0.44670817255973816
        ],
        "MSU_id": 1789
    },
    {
        "sentence": "We start from a random transportation graph.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 318,
        "paper_id": 4,
        "paragraph_info": "To better illustrate the construction of propagation graphs, we first define the concept of *spatiotemporal continuity* (Fig. 4): two transportation graphs are spatiotemporally continuous iff they share one and only one node, where the locations and timestamps of the shared nodes are equal, respectively. Based on this concept, we follow a depth-first search procedure outlined as follows: starting from a random transportation graph, we recursively add the transportation graphs that are spatiotemporally continuous with the added ones to the propagation graph. To simulate the decomposition of air pollutants, we limit the maximum time span of the propagation graph to 200 hours, as recommended by the experts. By repeating this procedure, we are able to generate a massive number of propagation graphs  $pG = (V, E)$  until all the transportation graphs have been visited. The attributes associated with the nodes and edges in the propagation graphs are identical to those in the transportation graphs. Such method allows us to obtain the continuous long-distance propagation instances naturally as paths in the graphs, which are almost impossible to detect with the prior methods.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9631590843200684,
            0.09343741834163666
        ],
        "MSU_id": 1790
    },
    {
        "sentence": "We recursively add the transportation graphs that are spatiotemporally continuous to the propagation graph.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 318,
        "paper_id": 4,
        "paragraph_info": "To better illustrate the construction of propagation graphs, we first define the concept of *spatiotemporal continuity* (Fig. 4): two transportation graphs are spatiotemporally continuous iff they share one and only one node, where the locations and timestamps of the shared nodes are equal, respectively. Based on this concept, we follow a depth-first search procedure outlined as follows: starting from a random transportation graph, we recursively add the transportation graphs that are spatiotemporally continuous with the added ones to the propagation graph. To simulate the decomposition of air pollutants, we limit the maximum time span of the propagation graph to 200 hours, as recommended by the experts. By repeating this procedure, we are able to generate a massive number of propagation graphs  $pG = (V, E)$  until all the transportation graphs have been visited. The attributes associated with the nodes and edges in the propagation graphs are identical to those in the transportation graphs. Such method allows us to obtain the continuous long-distance propagation instances naturally as paths in the graphs, which are almost impossible to detect with the prior methods.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.149059534072876,
            0.667987585067749
        ],
        "MSU_id": 1791
    },
    {
        "sentence": "We limit the maximum time span of the propagation graph to 200 hours.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 318,
        "paper_id": 4,
        "paragraph_info": "To better illustrate the construction of propagation graphs, we first define the concept of *spatiotemporal continuity* (Fig. 4): two transportation graphs are spatiotemporally continuous iff they share one and only one node, where the locations and timestamps of the shared nodes are equal, respectively. Based on this concept, we follow a depth-first search procedure outlined as follows: starting from a random transportation graph, we recursively add the transportation graphs that are spatiotemporally continuous with the added ones to the propagation graph. To simulate the decomposition of air pollutants, we limit the maximum time span of the propagation graph to 200 hours, as recommended by the experts. By repeating this procedure, we are able to generate a massive number of propagation graphs  $pG = (V, E)$  until all the transportation graphs have been visited. The attributes associated with the nodes and edges in the propagation graphs are identical to those in the transportation graphs. Such method allows us to obtain the continuous long-distance propagation instances naturally as paths in the graphs, which are almost impossible to detect with the prior methods.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.5410066246986389,
            -0.6560055613517761
        ],
        "MSU_id": 1792
    },
    {
        "sentence": "We seek to find the persistent and significant parts in the generated propagation instances.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 319,
        "paper_id": 4,
        "paragraph_info": "To extract the meaningful patterns from the propagation instances, we seek to find the persistent and significant parts in the generated propaga-",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0113980770111084,
            -0.05992906540632248
        ],
        "MSU_id": 1797
    },
    {
        "sentence": "We aim to extract meaningful patterns from the propagation instances.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 319,
        "paper_id": 4,
        "paragraph_info": "To extract the meaningful patterns from the propagation instances, we seek to find the persistent and significant parts in the generated propaga-",
        "paper_info": "airvis",
        "2d_coord": [
            -2.386312246322632,
            0.4605894386768341
        ],
        "MSU_id": 1798
    },
    {
        "type": "figure",
        "para_id": 321,
        "paper_id": 4,
        "paragraph_info": "_page_4_Figure_0.jpeg",
        "paper_info": "airvis",
        "2d_coord": [
            -2.310535192489624,
            0.6849583983421326
        ],
        "MSU_id": 1799,
        "sentence": "Spatiotemporally continuous transportation instances are connected as a propagation graph in (D).",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "Spatiotemporally continuous transportation instances are connected as a propagation graph.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 321,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-4-0\"></span>Fig. 4. (A) Spatiotemporally continuous transportation instances are connected as a propagation graph in (D). (B) and (C) illustrate the temporally and spatially discontinuous transportation instances, respectively.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2852513790130615,
            0.6701682806015015
        ],
        "MSU_id": 1800
    },
    {
        "sentence": "We convert the extraction of the propagation patterns to an FSM problem.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 322,
        "paper_id": 4,
        "paragraph_info": "tion graphs with the frequent subgraph mining (FSM) techniques. We convert the extraction of the propagation patterns to an FSM problem with the following concepts (Fig. 2E):",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0314629077911377,
            -0.2884939908981323
        ],
        "MSU_id": 1803
    },
    {
        "sentence": "We employ a well-established Apriori-based method to extract the frequent subgraphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 323,
        "paper_id": 4,
        "paragraph_info": "We employ a well-established Apriori-based method [24] to extract the frequent subgraphs. In addition, we allow users to interactively control the pattern mining process by setting a transported pollutant threshold  $\\lambda_p$  to exclude from support computation the propagation graphs where the pollutants transported on the matched edges  $e.c$  are below the threshold. Furthermore, the support is calculated with the time span covered by the matched transactions divided by the total time span to emphasize the importance of the pollution durations.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.103522777557373,
            1.157718539237976
        ],
        "MSU_id": 1805
    },
    {
        "sentence": "We allow users to interactively control the pattern mining process by setting a transported pollutant threshold \u03bb_p.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 323,
        "paper_id": 4,
        "paragraph_info": "We employ a well-established Apriori-based method [24] to extract the frequent subgraphs. In addition, we allow users to interactively control the pattern mining process by setting a transported pollutant threshold  $\\lambda_p$  to exclude from support computation the propagation graphs where the pollutants transported on the matched edges  $e.c$  are below the threshold. Furthermore, the support is calculated with the time span covered by the matched transactions divided by the total time span to emphasize the importance of the pollution durations.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1283936500549316,
            0.7797364592552185
        ],
        "MSU_id": 1806
    },
    {
        "sentence": "The threshold \u03bb_p excludes from support computation the propagation graphs where the pollutants transported on the matched edges e.c are below the threshold.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 323,
        "paper_id": 4,
        "paragraph_info": "We employ a well-established Apriori-based method [24] to extract the frequent subgraphs. In addition, we allow users to interactively control the pattern mining process by setting a transported pollutant threshold  $\\lambda_p$  to exclude from support computation the propagation graphs where the pollutants transported on the matched edges  $e.c$  are below the threshold. Furthermore, the support is calculated with the time span covered by the matched transactions divided by the total time span to emphasize the importance of the pollution durations.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1237473487854004,
            0.6834016442298889
        ],
        "MSU_id": 1807
    },
    {
        "sentence": "The support is calculated with the time span covered by the matched transactions divided by the total time span.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 323,
        "paper_id": 4,
        "paragraph_info": "We employ a well-established Apriori-based method [24] to extract the frequent subgraphs. In addition, we allow users to interactively control the pattern mining process by setting a transported pollutant threshold  $\\lambda_p$  to exclude from support computation the propagation graphs where the pollutants transported on the matched edges  $e.c$  are below the threshold. Furthermore, the support is calculated with the time span covered by the matched transactions divided by the total time span to emphasize the importance of the pollution durations.",
        "paper_info": "airvis",
        "2d_coord": [
            0.21978183090686798,
            -1.0692659616470337
        ],
        "MSU_id": 1808
    },
    {
        "sentence": "The massive propagation patterns can be efficiently extracted.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 324,
        "paper_id": 4,
        "paragraph_info": "Finally, the massive propagation patterns (i.e., frequent subgraphs) can be efficiently extracted. Each pattern  $P = (V, E)$  comprises a node set V comprising the involved districts and an edge set  $E$  comprising the propagation pathways. Each node  $v_i \\in V$  maintains a list of the pollution concentrations  $v_i$ .C collected from the corresponding nodes in the matched propagation graphs. Similarly, each pathway  $w_{ij} \\in E$ from district i to j is associated with  $w_{ij}.TT$ ,  $w_{ij}.P$ ,  $w_{ij}.TC$ ,  $w_{ij}.A$ , lists of transportation times, transportation probabilities, transported pollutant concentrations, impact factors, respectively. Please refer to the appendices for all used notations and details of pattern extraction.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2512683868408203,
            0.4098111391067505
        ],
        "MSU_id": 1810
    },
    {
        "sentence": "Each pattern P comprises a node set V comprising the involved districts and an edge set E comprising the propagation pathways.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 324,
        "paper_id": 4,
        "paragraph_info": "Finally, the massive propagation patterns (i.e., frequent subgraphs) can be efficiently extracted. Each pattern  $P = (V, E)$  comprises a node set V comprising the involved districts and an edge set  $E$  comprising the propagation pathways. Each node  $v_i \\in V$  maintains a list of the pollution concentrations  $v_i$ .C collected from the corresponding nodes in the matched propagation graphs. Similarly, each pathway  $w_{ij} \\in E$ from district i to j is associated with  $w_{ij}.TT$ ,  $w_{ij}.P$ ,  $w_{ij}.TC$ ,  $w_{ij}.A$ , lists of transportation times, transportation probabilities, transported pollutant concentrations, impact factors, respectively. Please refer to the appendices for all used notations and details of pattern extraction.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3480143547058105,
            0.6717345714569092
        ],
        "MSU_id": 1811
    },
    {
        "sentence": "Each node v_i in V maintains a list of the pollution concentrations v_i.C collected from the corresponding nodes in the matched propagation graphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 324,
        "paper_id": 4,
        "paragraph_info": "Finally, the massive propagation patterns (i.e., frequent subgraphs) can be efficiently extracted. Each pattern  $P = (V, E)$  comprises a node set V comprising the involved districts and an edge set  $E$  comprising the propagation pathways. Each node  $v_i \\in V$  maintains a list of the pollution concentrations  $v_i$ .C collected from the corresponding nodes in the matched propagation graphs. Similarly, each pathway  $w_{ij} \\in E$ from district i to j is associated with  $w_{ij}.TT$ ,  $w_{ij}.P$ ,  $w_{ij}.TC$ ,  $w_{ij}.A$ , lists of transportation times, transportation probabilities, transported pollutant concentrations, impact factors, respectively. Please refer to the appendices for all used notations and details of pattern extraction.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.255934238433838,
            0.2823300063610077
        ],
        "MSU_id": 1812
    },
    {
        "sentence": "Each pathway w_{ij} in E from district i to j is associated with w_{ij}.TT, w_{ij}.P, w_{ij}.TC, w_{ij}.A.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 324,
        "paper_id": 4,
        "paragraph_info": "Finally, the massive propagation patterns (i.e., frequent subgraphs) can be efficiently extracted. Each pattern  $P = (V, E)$  comprises a node set V comprising the involved districts and an edge set  $E$  comprising the propagation pathways. Each node  $v_i \\in V$  maintains a list of the pollution concentrations  $v_i$ .C collected from the corresponding nodes in the matched propagation graphs. Similarly, each pathway  $w_{ij} \\in E$ from district i to j is associated with  $w_{ij}.TT$ ,  $w_{ij}.P$ ,  $w_{ij}.TC$ ,  $w_{ij}.A$ , lists of transportation times, transportation probabilities, transported pollutant concentrations, impact factors, respectively. Please refer to the appendices for all used notations and details of pattern extraction.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9182180166244507,
            0.4186461865901947
        ],
        "MSU_id": 1813
    },
    {
        "sentence": "The lists of transportation times, transportation probabilities, transported pollutant concentrations, and impact factors are associated with each pathway.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 324,
        "paper_id": 4,
        "paragraph_info": "Finally, the massive propagation patterns (i.e., frequent subgraphs) can be efficiently extracted. Each pattern  $P = (V, E)$  comprises a node set V comprising the involved districts and an edge set  $E$  comprising the propagation pathways. Each node  $v_i \\in V$  maintains a list of the pollution concentrations  $v_i$ .C collected from the corresponding nodes in the matched propagation graphs. Similarly, each pathway  $w_{ij} \\in E$ from district i to j is associated with  $w_{ij}.TT$ ,  $w_{ij}.P$ ,  $w_{ij}.TC$ ,  $w_{ij}.A$ , lists of transportation times, transportation probabilities, transported pollutant concentrations, impact factors, respectively. Please refer to the appendices for all used notations and details of pattern extraction.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.753556489944458,
            -0.7756978869438171
        ],
        "MSU_id": 1814
    },
    {
        "sentence": "We describe the design of AirVis.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 325,
        "paper_id": 4,
        "paragraph_info": "In this section, we present the design goals compiled from the aforementioned user requirements and describe the design of AirVis, a visual analytics system for analyzing the propagation of air pollution.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.26100003719329834,
            -1.144436001777649
        ],
        "MSU_id": 1817
    },
    {
        "sentence": "To address scalability issues and facilitate the effective exploration of massive patterns, we organize these patterns hierarchically with multiple coordinated views.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 327,
        "paper_id": 4,
        "paragraph_info": "**G1: Hierarchical presentation of propagation patterns.** To address scalability issues and facilitate the effective exploration of massive patterns (R1, R2, R3, and R5), we follow the *visual information-seeking mantra* [51] and organize these patterns hierarchically with multiple coordinated views. Users should be able to identify interesting topologies first  $(R1)$ , browse through the patterns with an identical topology  $(R2)$ , proceed to the analysis of a particular pattern  $(R3)$ , and finally dive into the details of the associated propagation instances  $(R5)$ . Moreover, the design should also support the intuitive filtering of patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6320585012435913,
            1.0642437934875488
        ],
        "MSU_id": 1821
    },
    {
        "sentence": "The design should also support the intuitive filtering of patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 327,
        "paper_id": 4,
        "paragraph_info": "**G1: Hierarchical presentation of propagation patterns.** To address scalability issues and facilitate the effective exploration of massive patterns (R1, R2, R3, and R5), we follow the *visual information-seeking mantra* [51] and organize these patterns hierarchically with multiple coordinated views. Users should be able to identify interesting topologies first  $(R1)$ , browse through the patterns with an identical topology  $(R2)$ , proceed to the analysis of a particular pattern  $(R3)$ , and finally dive into the details of the associated propagation instances  $(R5)$ . Moreover, the design should also support the intuitive filtering of patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2165610790252686,
            0.7148163914680481
        ],
        "MSU_id": 1826
    },
    {
        "sentence": "Uncertainty-aware visualization of pattern topologies is proposed.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 328,
        "paper_id": 4,
        "paragraph_info": "G2: Uncertainty-aware visualization of pattern topologies. Patterns with similar propagation topologies should be aggregated to provide a comprehensive overview  $(R1)$ . In particular, each edge in the aggregated topologies comprises a set of propagation probabilities associated with the corresponding edges of the pattern. These probabilities should be reflected on the topology visualizations to assist users in determining the stability of propagation structures.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8751220703125,
            0.7793987989425659
        ],
        "MSU_id": 1827
    },
    {
        "sentence": "Each edge in the aggregated topologies comprises a set of propagation probabilities associated with the corresponding edges of the pattern.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 328,
        "paper_id": 4,
        "paragraph_info": "G2: Uncertainty-aware visualization of pattern topologies. Patterns with similar propagation topologies should be aggregated to provide a comprehensive overview  $(R1)$ . In particular, each edge in the aggregated topologies comprises a set of propagation probabilities associated with the corresponding edges of the pattern. These probabilities should be reflected on the topology visualizations to assist users in determining the stability of propagation structures.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.9728243350982666,
            -0.9220084547996521
        ],
        "MSU_id": 1829
    },
    {
        "sentence": "The system should compactly present the visual summaries of patterns in terms of their spatial contexts and temporal distribution.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 329,
        "paper_id": 4,
        "paragraph_info": "G3: Spatiotemporal visual summaries of patterns. To help users intuitively learn the basic characteristics of the patterns, the system should compactly present the visual summaries of these patterns in terms of their spatial contexts and temporal distribution (R2). Glyph is a ideal candidate since many visualization studies [5] have demonstrated its effectiveness in multifaceted analysis, where complex data can be encoded with different visual channels in a space-efficient way.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6079607009887695,
            1.1919499635696411
        ],
        "MSU_id": 1831
    },
    {
        "sentence": "Glyph is an ideal candidate for visual summaries.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 329,
        "paper_id": 4,
        "paragraph_info": "G3: Spatiotemporal visual summaries of patterns. To help users intuitively learn the basic characteristics of the patterns, the system should compactly present the visual summaries of these patterns in terms of their spatial contexts and temporal distribution (R2). Glyph is a ideal candidate since many visualization studies [5] have demonstrated its effectiveness in multifaceted analysis, where complex data can be encoded with different visual channels in a space-efficient way.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9301469326019287,
            1.07554030418396
        ],
        "MSU_id": 1832
    },
    {
        "sentence": "These processes can be intuitively visualized with a node-link diagram on the map.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 330,
        "paper_id": 4,
        "paragraph_info": "**G4:** Intuitive illustrations of propagation processes. The propagation processes of a pattern  $(R2)$  are based on directed graphs, where the nodes represent the involved districts and the edges indicate the transportation of pollutants. Thus, these processes can be intuitively visualized with a node-link diagram on the map. Moreover, the probabilistic cause-effect relationship between the districts can be encoded on the node-link diagram to help users interpret the pattern of interest.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.0880348682403564,
            1.5644782781600952
        ],
        "MSU_id": 1838
    },
    {
        "sentence": "The probabilistic cause-effect relationship between the districts can be encoded on the node-link diagram.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 330,
        "paper_id": 4,
        "paragraph_info": "**G4:** Intuitive illustrations of propagation processes. The propagation processes of a pattern  $(R2)$  are based on directed graphs, where the nodes represent the involved districts and the edges indicate the transportation of pollutants. Thus, these processes can be intuitively visualized with a node-link diagram on the map. Moreover, the probabilistic cause-effect relationship between the districts can be encoded on the node-link diagram to help users interpret the pattern of interest.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8067452907562256,
            0.6157655119895935
        ],
        "MSU_id": 1839
    },
    {
        "sentence": "The proposed design should allow users to compare among multiple interesting patterns according to their topologies and attributes.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 331,
        "paper_id": 4,
        "paragraph_info": "G5: Comparative visual analysis of propagation patterns. The proposed design should allow users to compare among multiple interesting patterns according to their topologies and attributes (e.g., expected amount of propagated pollution) and find their similarities and differences (R4). This comparison can likewise be facilitated further by automated approaches, such as dimensionality reduction techniques, to enable the effective discovery of pattern clusters and outliers.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2184412479400635,
            0.9566987752914429
        ],
        "MSU_id": 1842
    },
    {
        "sentence": "The proposed design allows users to find similarities and differences in propagation patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 331,
        "paper_id": 4,
        "paragraph_info": "G5: Comparative visual analysis of propagation patterns. The proposed design should allow users to compare among multiple interesting patterns according to their topologies and attributes (e.g., expected amount of propagated pollution) and find their similarities and differences (R4). This comparison can likewise be facilitated further by automated approaches, such as dimensionality reduction techniques, to enable the effective discovery of pattern clusters and outliers.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.320674180984497,
            0.7642942667007446
        ],
        "MSU_id": 1843
    },
    {
        "sentence": "This comparison can be facilitated further by automated approaches.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 331,
        "paper_id": 4,
        "paragraph_info": "G5: Comparative visual analysis of propagation patterns. The proposed design should allow users to compare among multiple interesting patterns according to their topologies and attributes (e.g., expected amount of propagated pollution) and find their similarities and differences (R4). This comparison can likewise be facilitated further by automated approaches, such as dimensionality reduction techniques, to enable the effective discovery of pattern clusters and outliers.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9282336235046387,
            0.5518099069595337
        ],
        "MSU_id": 1844
    },
    {
        "sentence": "Dimensionality reduction techniques can enable the effective discovery of pattern clusters and outliers.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 331,
        "paper_id": 4,
        "paragraph_info": "G5: Comparative visual analysis of propagation patterns. The proposed design should allow users to compare among multiple interesting patterns according to their topologies and attributes (e.g., expected amount of propagated pollution) and find their similarities and differences (R4). This comparison can likewise be facilitated further by automated approaches, such as dimensionality reduction techniques, to enable the effective discovery of pattern clusters and outliers.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.4843957424163818,
            0.06394451856613159
        ],
        "MSU_id": 1845
    },
    {
        "sentence": "The proposed design should enable users to select a time frame of interest based on the temporal distribution of the instances.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 332,
        "paper_id": 4,
        "paragraph_info": "**G6:** Detailed inspection of relational propagation instances. To support the analysis of the propagation instances associated with a pattern (R5), the proposed design should a) enable users to select a time frame of interest on the basis of the temporal distribution of the instances and b) present the propagation relationships among involved districts in a scalable fashion. Moreover, the raw readings of air quality data should be included in the proposed design.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.650615930557251,
            0.3350147306919098
        ],
        "MSU_id": 1846
    },
    {
        "sentence": "The proposed design should present the propagation relationships among involved districts in a scalable fashion.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 332,
        "paper_id": 4,
        "paragraph_info": "**G6:** Detailed inspection of relational propagation instances. To support the analysis of the propagation instances associated with a pattern (R5), the proposed design should a) enable users to select a time frame of interest on the basis of the temporal distribution of the instances and b) present the propagation relationships among involved districts in a scalable fashion. Moreover, the raw readings of air quality data should be included in the proposed design.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0952963829040527,
            0.7110510468482971
        ],
        "MSU_id": 1847
    },
    {
        "sentence": "The raw readings of air quality data should be included in the proposed design.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 332,
        "paper_id": 4,
        "paragraph_info": "**G6:** Detailed inspection of relational propagation instances. To support the analysis of the propagation instances associated with a pattern (R5), the proposed design should a) enable users to select a time frame of interest on the basis of the temporal distribution of the instances and b) present the propagation relationships among involved districts in a scalable fashion. Moreover, the raw readings of air quality data should be included in the proposed design.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.4978032410144806,
            -0.9087790846824646
        ],
        "MSU_id": 1848
    },
    {
        "sentence": "We develop AirVis to assist expert users in visually analyzing and sensemaking the uncertain propagation of air pollution.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 333,
        "paper_id": 4,
        "paragraph_info": "Based on these design goals, we develop AirVis to assist the expert users in visually analyzing and sensemaking the uncertain propagation of air pollution at a large spatial scale. AirVis follows a hierarchical exploration scheme (G1) to facilitate the effective visual analysis:",
        "paper_info": "airvis",
        "2d_coord": [
            -2.5010387897491455,
            0.3844020366668701
        ],
        "MSU_id": 1849
    },
    {
        "sentence": "AirVis follows a hierarchical exploration scheme (G1) to facilitate effective visual analysis.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 333,
        "paper_id": 4,
        "paragraph_info": "Based on these design goals, we develop AirVis to assist the expert users in visually analyzing and sensemaking the uncertain propagation of air pollution at a large spatial scale. AirVis follows a hierarchical exploration scheme (G1) to facilitate the effective visual analysis:",
        "paper_info": "airvis",
        "2d_coord": [
            -0.5968453288078308,
            1.5073810815811157
        ],
        "MSU_id": 1851
    },
    {
        "sentence": "The topologies of the extracted propagation patterns are aggregated and visualized in the motif view.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 334,
        "paper_id": 4,
        "paragraph_info": "Topology Visualization (G2): The topologies of the extracted propagation patterns are aggregated and visualized in the *motif view* (Fig.  $1B$ ) based on the MDL principle and the idea of motifs [41]. Moreover, the uncertainties of the topology structures are encoded within the glyphs.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.371375560760498,
            0.6367709040641785
        ],
        "MSU_id": 1852
    },
    {
        "sentence": "The visualization is based on the MDL principle and the idea of motifs.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 334,
        "paper_id": 4,
        "paragraph_info": "Topology Visualization (G2): The topologies of the extracted propagation patterns are aggregated and visualized in the *motif view* (Fig.  $1B$ ) based on the MDL principle and the idea of motifs [41]. Moreover, the uncertainties of the topology structures are encoded within the glyphs.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6498205661773682,
            1.3271201848983765
        ],
        "MSU_id": 1853
    },
    {
        "sentence": "The uncertainties of the topology structures are encoded within the glyphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 334,
        "paper_id": 4,
        "paragraph_info": "Topology Visualization (G2): The topologies of the extracted propagation patterns are aggregated and visualized in the *motif view* (Fig.  $1B$ ) based on the MDL principle and the idea of motifs [41]. Moreover, the uncertainties of the topology structures are encoded within the glyphs.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7140393257141113,
            0.09916345030069351
        ],
        "MSU_id": 1854
    },
    {
        "sentence": "Users can browse through the associated pattern glyphs in the pattern view.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 335,
        "paper_id": 4,
        "paragraph_info": "Pattern Visualization (G3, G4, and G5): By expanding a motif, users can browse through the associated pattern glyphs in the *pattern* view (Fig. 1C) and learn the complex propagation processes of the selected patterns via the *inspection list* (Fig. 1C3), where the juxtaposed propagation graphs provide the support for intuitive side-by-side comparative analysis. In addition, an automatically generated projection *view* (Fig. 1A3) is incorporated to help users identify similar patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0426855087280273,
            0.9466032385826111
        ],
        "MSU_id": 1855
    },
    {
        "sentence": "Users can learn the complex propagation processes of the selected patterns via the inspection list.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 335,
        "paper_id": 4,
        "paragraph_info": "Pattern Visualization (G3, G4, and G5): By expanding a motif, users can browse through the associated pattern glyphs in the *pattern* view (Fig. 1C) and learn the complex propagation processes of the selected patterns via the *inspection list* (Fig. 1C3), where the juxtaposed propagation graphs provide the support for intuitive side-by-side comparative analysis. In addition, an automatically generated projection *view* (Fig. 1A3) is incorporated to help users identify similar patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.289933204650879,
            0.6093845963478088
        ],
        "MSU_id": 1856
    },
    {
        "sentence": "An automatically generated projection view is incorporated to help users identify similar patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 335,
        "paper_id": 4,
        "paragraph_info": "Pattern Visualization (G3, G4, and G5): By expanding a motif, users can browse through the associated pattern glyphs in the *pattern* view (Fig. 1C) and learn the complex propagation processes of the selected patterns via the *inspection list* (Fig. 1C3), where the juxtaposed propagation graphs provide the support for intuitive side-by-side comparative analysis. In addition, an automatically generated projection *view* (Fig. 1A3) is incorporated to help users identify similar patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6579582691192627,
            1.3493846654891968
        ],
        "MSU_id": 1858
    },
    {
        "sentence": "Users can explore the transportation of pollutants among the involved districts with the chord diagram.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 336,
        "paper_id": 4,
        "paragraph_info": "**Instance Visualization** (G6): The instances in the selected pattern are depicted in the *instance view* (Fig. 1D). By selecting a timeframe according to the temporal distribution of instances, users can explore the transportation of pollutants among the involved districts with the chord diagram and inspect the detailed numeric data in the table.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0376973152160645,
            0.9589197039604187
        ],
        "MSU_id": 1860
    },
    {
        "sentence": "Users can inspect the detailed numeric data in the table.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 336,
        "paper_id": 4,
        "paragraph_info": "**Instance Visualization** (G6): The instances in the selected pattern are depicted in the *instance view* (Fig. 1D). By selecting a timeframe according to the temporal distribution of instances, users can explore the transportation of pollutants among the involved districts with the chord diagram and inspect the detailed numeric data in the table.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5810089111328125,
            0.9203824996948242
        ],
        "MSU_id": 1861
    },
    {
        "sentence": "By selecting a timeframe according to the temporal distribution of instances, users can explore the transportation of pollutants.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 336,
        "paper_id": 4,
        "paragraph_info": "**Instance Visualization** (G6): The instances in the selected pattern are depicted in the *instance view* (Fig. 1D). By selecting a timeframe according to the temporal distribution of instances, users can explore the transportation of pollutants among the involved districts with the chord diagram and inspect the detailed numeric data in the table.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.029855251312256,
            -0.49276202917099
        ],
        "MSU_id": 1862
    },
    {
        "sentence": "We aggregate similar patterns based on topology into motifs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 337,
        "paper_id": 4,
        "paragraph_info": "To facilitate the topology-driven analysis of air pollution propagation  $(G2)$ , we aggregate similar patterns based on topology into motifs and visualize these motifs with uncertainty-aware visual encodings.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.136326789855957,
            0.7802827954292297
        ],
        "MSU_id": 1863
    },
    {
        "sentence": "We visualize these motifs with uncertainty-aware visual encodings.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 337,
        "paper_id": 4,
        "paragraph_info": "To facilitate the topology-driven analysis of air pollution propagation  $(G2)$ , we aggregate similar patterns based on topology into motifs and visualize these motifs with uncertainty-aware visual encodings.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9092113971710205,
            0.542461097240448
        ],
        "MSU_id": 1864
    },
    {
        "sentence": "To detect patterns with similar topologies, significant motifs can be extracted as the representations of the corresponding patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 338,
        "paper_id": 4,
        "paragraph_info": "Inspired by the concept of *motifs* in the field of network analysis [41], we denote the contextless topological substructures in the propagation graph of a pattern as motifs. To detect patterns with the similar topologies, significant motifs (Fig. 5) that are commonly shared among the patterns can be extracted as the representations of the corresponding patterns, enabling users to obtain the key topological characteristics of the underlying patterns intuitively. Therefore, such motif extraction should satisfy the following two requirements: a) *generality*: the significant motifs should be general to represent a large portion of the pattern topologies; and b) similarity: each significant motif and its corresponding patterns should be identical to avoid undesired aggregation.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.260714292526245,
            0.9150722622871399
        ],
        "MSU_id": 1867
    },
    {
        "sentence": "Motif extraction should satisfy the requirement of generality.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 338,
        "paper_id": 4,
        "paragraph_info": "Inspired by the concept of *motifs* in the field of network analysis [41], we denote the contextless topological substructures in the propagation graph of a pattern as motifs. To detect patterns with the similar topologies, significant motifs (Fig. 5) that are commonly shared among the patterns can be extracted as the representations of the corresponding patterns, enabling users to obtain the key topological characteristics of the underlying patterns intuitively. Therefore, such motif extraction should satisfy the following two requirements: a) *generality*: the significant motifs should be general to represent a large portion of the pattern topologies; and b) similarity: each significant motif and its corresponding patterns should be identical to avoid undesired aggregation.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2643115520477295,
            0.46714144945144653
        ],
        "MSU_id": 1869
    },
    {
        "sentence": "The significant motifs should be general to represent a large portion of the pattern topologies.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 338,
        "paper_id": 4,
        "paragraph_info": "Inspired by the concept of *motifs* in the field of network analysis [41], we denote the contextless topological substructures in the propagation graph of a pattern as motifs. To detect patterns with the similar topologies, significant motifs (Fig. 5) that are commonly shared among the patterns can be extracted as the representations of the corresponding patterns, enabling users to obtain the key topological characteristics of the underlying patterns intuitively. Therefore, such motif extraction should satisfy the following two requirements: a) *generality*: the significant motifs should be general to represent a large portion of the pattern topologies; and b) similarity: each significant motif and its corresponding patterns should be identical to avoid undesired aggregation.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7132458686828613,
            0.7381380200386047
        ],
        "MSU_id": 1870
    },
    {
        "sentence": "Motif extraction should satisfy the requirement of similarity.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 338,
        "paper_id": 4,
        "paragraph_info": "Inspired by the concept of *motifs* in the field of network analysis [41], we denote the contextless topological substructures in the propagation graph of a pattern as motifs. To detect patterns with the similar topologies, significant motifs (Fig. 5) that are commonly shared among the patterns can be extracted as the representations of the corresponding patterns, enabling users to obtain the key topological characteristics of the underlying patterns intuitively. Therefore, such motif extraction should satisfy the following two requirements: a) *generality*: the significant motifs should be general to represent a large portion of the pattern topologies; and b) similarity: each significant motif and its corresponding patterns should be identical to avoid undesired aggregation.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2751336097717285,
            0.7109681963920593
        ],
        "MSU_id": 1871
    },
    {
        "sentence": "Each significant motif and its corresponding patterns should be identical to avoid undesired aggregation.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 338,
        "paper_id": 4,
        "paragraph_info": "Inspired by the concept of *motifs* in the field of network analysis [41], we denote the contextless topological substructures in the propagation graph of a pattern as motifs. To detect patterns with the similar topologies, significant motifs (Fig. 5) that are commonly shared among the patterns can be extracted as the representations of the corresponding patterns, enabling users to obtain the key topological characteristics of the underlying patterns intuitively. Therefore, such motif extraction should satisfy the following two requirements: a) *generality*: the significant motifs should be general to represent a large portion of the pattern topologies; and b) similarity: each significant motif and its corresponding patterns should be identical to avoid undesired aggregation.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.3271565437316895,
            0.5194438099861145
        ],
        "MSU_id": 1872
    },
    {
        "sentence": "We extract these motifs based on the minimum description length (MDL) principle.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 339,
        "paper_id": 4,
        "paragraph_info": "We extract these motifs based on the minimum description length (MDL) principle [46], which has been demonstrated to be particularly effective in sequence summarization [13] and graph simplification [11]. The MDL principle seeks to find a common *summary*  $S_i$  for a group of data items and denote the remaining part of the  $j$ -th item in the",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2045657634735107,
            0.34590643644332886
        ],
        "MSU_id": 1873
    },
    {
        "sentence": "The MDL principle seeks to find a common summary for a group of data items.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 339,
        "paper_id": 4,
        "paragraph_info": "We extract these motifs based on the minimum description length (MDL) principle [46], which has been demonstrated to be particularly effective in sequence summarization [13] and graph simplification [11]. The MDL principle seeks to find a common *summary*  $S_i$  for a group of data items and denote the remaining part of the  $j$ -th item in the",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5284653902053833,
            0.5341414213180542
        ],
        "MSU_id": 1876
    },
    {
        "type": "figure",
        "para_id": 341,
        "paper_id": 4,
        "paragraph_info": "_page_5_Figure_0.jpeg",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3308632373809814,
            0.719923198223114
        ],
        "MSU_id": 1877,
        "sentence": "The image illustrates the extraction of motifs from structurally similar propagation graphs, highlighting the summary topology and corrections generated by the MDL principle.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "The extraction of motifs involves three structurally similar propagation graphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 341,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-5-0\"></span>Fig. 5. The extraction of motifs: (A) three structurally similar propagation graphs, where the summary topology is circled in blue; (B) the summary (i.e., significant motif) and corrections generated by the MDL principle.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3619942665100098,
            0.6328157782554626
        ],
        "MSU_id": 1878
    },
    {
        "sentence": "By minimizing the overall description length  $L = \\sum_i (|S_i| + \\sum_j |C_{ij}|)$ for all groups, we can obtain compact data representations.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 342,
        "paper_id": 4,
        "paragraph_info": "group as the correction  $C_{ij}$ . By minimizing the overall description length  $L = \\sum_i (|S_i| + \\sum_j |C_{ij}|)$  for all groups, we can obtain compact data representations that satisfy the aforementioned requirements.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.145157814025879,
            -0.9526066184043884
        ],
        "MSU_id": 1882
    },
    {
        "sentence": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 343,
        "paper_id": 4,
        "paragraph_info": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs to remove the graphs with the duplicate topologies and then use the remaining graphs as the input data items  $G_i = (V_i, E_i) \\in G$  to find a set of summaries  $S = \\{S_1, S_2, ...\\}$ , where  $S_i$ is a motif that represents a series of propagation graphs  $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length  $k_i$ , i.e.,  $S_i \\subseteq G_{s_{ij}}$ . Similarly, the correction  $C_{ij}$  is defined as  $G_{s_{ii}} \\setminus S_i$ , as illustrated in Fig. 5B. Based on the generality and similarity requirements, our goal is to minimize:",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2860825061798096,
            0.34023207426071167
        ],
        "MSU_id": 1884
    },
    {
        "sentence": "We remove the graphs with the duplicate topologies.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 343,
        "paper_id": 4,
        "paragraph_info": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs to remove the graphs with the duplicate topologies and then use the remaining graphs as the input data items  $G_i = (V_i, E_i) \\in G$  to find a set of summaries  $S = \\{S_1, S_2, ...\\}$ , where  $S_i$ is a motif that represents a series of propagation graphs  $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length  $k_i$ , i.e.,  $S_i \\subseteq G_{s_{ij}}$ . Similarly, the correction  $C_{ij}$  is defined as  $G_{s_{ii}} \\setminus S_i$ , as illustrated in Fig. 5B. Based on the generality and similarity requirements, our goal is to minimize:",
        "paper_info": "airvis",
        "2d_coord": [
            -2.293715476989746,
            0.8218594193458557
        ],
        "MSU_id": 1885
    },
    {
        "sentence": "We use the remaining graphs as the input data items $G_i = (V_i, E_i) \\in G$.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 343,
        "paper_id": 4,
        "paragraph_info": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs to remove the graphs with the duplicate topologies and then use the remaining graphs as the input data items  $G_i = (V_i, E_i) \\in G$  to find a set of summaries  $S = \\{S_1, S_2, ...\\}$ , where  $S_i$ is a motif that represents a series of propagation graphs  $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length  $k_i$ , i.e.,  $S_i \\subseteq G_{s_{ij}}$ . Similarly, the correction  $C_{ij}$  is defined as  $G_{s_{ii}} \\setminus S_i$ , as illustrated in Fig. 5B. Based on the generality and similarity requirements, our goal is to minimize:",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7609384059906006,
            -0.8948385119438171
        ],
        "MSU_id": 1886
    },
    {
        "sentence": "We find a set of summaries $S = \\{S_1, S_2, ...\\}$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 343,
        "paper_id": 4,
        "paragraph_info": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs to remove the graphs with the duplicate topologies and then use the remaining graphs as the input data items  $G_i = (V_i, E_i) \\in G$  to find a set of summaries  $S = \\{S_1, S_2, ...\\}$ , where  $S_i$ is a motif that represents a series of propagation graphs  $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length  $k_i$ , i.e.,  $S_i \\subseteq G_{s_{ij}}$ . Similarly, the correction  $C_{ij}$  is defined as  $G_{s_{ii}} \\setminus S_i$ , as illustrated in Fig. 5B. Based on the generality and similarity requirements, our goal is to minimize:",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5123069286346436,
            -0.9245100617408752
        ],
        "MSU_id": 1887
    },
    {
        "sentence": "$S_i$ is a motif that represents a series of propagation graphs $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length $k_i$.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 343,
        "paper_id": 4,
        "paragraph_info": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs to remove the graphs with the duplicate topologies and then use the remaining graphs as the input data items  $G_i = (V_i, E_i) \\in G$  to find a set of summaries  $S = \\{S_1, S_2, ...\\}$ , where  $S_i$ is a motif that represents a series of propagation graphs  $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length  $k_i$ , i.e.,  $S_i \\subseteq G_{s_{ij}}$ . Similarly, the correction  $C_{ij}$  is defined as  $G_{s_{ii}} \\setminus S_i$ , as illustrated in Fig. 5B. Based on the generality and similarity requirements, our goal is to minimize:",
        "paper_info": "airvis",
        "2d_coord": [
            -2.329967737197876,
            0.8226434588432312
        ],
        "MSU_id": 1888
    },
    {
        "sentence": "$S_i \\subseteq G_{s_{ij}}$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 343,
        "paper_id": 4,
        "paragraph_info": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs to remove the graphs with the duplicate topologies and then use the remaining graphs as the input data items  $G_i = (V_i, E_i) \\in G$  to find a set of summaries  $S = \\{S_1, S_2, ...\\}$ , where  $S_i$ is a motif that represents a series of propagation graphs  $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length  $k_i$ , i.e.,  $S_i \\subseteq G_{s_{ij}}$ . Similarly, the correction  $C_{ij}$  is defined as  $G_{s_{ii}} \\setminus S_i$ , as illustrated in Fig. 5B. Based on the generality and similarity requirements, our goal is to minimize:",
        "paper_info": "airvis",
        "2d_coord": [
            -0.6867977976799011,
            -0.8949870467185974
        ],
        "MSU_id": 1889
    },
    {
        "sentence": "The correction $C_{ij}$ is defined as $G_{s_{ii}} \\setminus S_i$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 343,
        "paper_id": 4,
        "paragraph_info": "To adapt the MDL principle to the extraction of the motifs, we first deduplicate the propagation graphs to remove the graphs with the duplicate topologies and then use the remaining graphs as the input data items  $G_i = (V_i, E_i) \\in G$  to find a set of summaries  $S = \\{S_1, S_2, ...\\}$ , where  $S_i$ is a motif that represents a series of propagation graphs  $\\{G_{s_{i1}},G_{s_{i2}},...\\}$ of length  $k_i$ , i.e.,  $S_i \\subseteq G_{s_{ij}}$ . Similarly, the correction  $C_{ij}$  is defined as  $G_{s_{ii}} \\setminus S_i$ , as illustrated in Fig. 5B. Based on the generality and similarity requirements, our goal is to minimize:",
        "paper_info": "airvis",
        "2d_coord": [
            0.9708582162857056,
            -1.5022672414779663
        ],
        "MSU_id": 1890
    },
    {
        "sentence": "The greedy algorithm proposed by Navlakha et al. can be applied to calculating S.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 344,
        "paper_id": 4,
        "paragraph_info": "where  $|S_i|$  and  $|C_{ij}|$  denote the number of edges in the respective graphs. The greedy algorithm proposed by Navlakha et al. [42] can be applied to calculating  $S$  by iteratively merging the pair of the motifs  $S_i$  and  $S_i$  that maximizes the decrease of  $L(G)$ , until no such pair exists. In addition, we introduce a constraint  $L_i(G, S_i)/k_i > L_m(G, S_m)/k_m$ and  $L_i(G, S_j)/k_j > L_m(G, S_m)/k_m$  based on the average of description lengths, where  $S_m$  is the summary after merging and  $k_m = k_i + k_j$  is the number of the patterns associated with the motif  $S_m$ . This constraint allows the resulting motifs to bias towards the similarity requirement, thereby generating more accurate topological representations. Please refer to the appendix C for more details.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9612622261047363,
            -0.4164349436759949
        ],
        "MSU_id": 1893
    },
    {
        "sentence": "The greedy algorithm works by iteratively merging the pair of the motifs S_i and S_j that maximizes the decrease of L(G), until no such pair exists.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 344,
        "paper_id": 4,
        "paragraph_info": "where  $|S_i|$  and  $|C_{ij}|$  denote the number of edges in the respective graphs. The greedy algorithm proposed by Navlakha et al. [42] can be applied to calculating  $S$  by iteratively merging the pair of the motifs  $S_i$  and  $S_i$  that maximizes the decrease of  $L(G)$ , until no such pair exists. In addition, we introduce a constraint  $L_i(G, S_i)/k_i > L_m(G, S_m)/k_m$ and  $L_i(G, S_j)/k_j > L_m(G, S_m)/k_m$  based on the average of description lengths, where  $S_m$  is the summary after merging and  $k_m = k_i + k_j$  is the number of the patterns associated with the motif  $S_m$ . This constraint allows the resulting motifs to bias towards the similarity requirement, thereby generating more accurate topological representations. Please refer to the appendix C for more details.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9899665117263794,
            0.04764427989721298
        ],
        "MSU_id": 1894
    },
    {
        "sentence": "We introduce a constraint L_i(G, S_i)/k_i > L_m(G, S_m)/k_m based on the average of description lengths.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 344,
        "paper_id": 4,
        "paragraph_info": "where  $|S_i|$  and  $|C_{ij}|$  denote the number of edges in the respective graphs. The greedy algorithm proposed by Navlakha et al. [42] can be applied to calculating  $S$  by iteratively merging the pair of the motifs  $S_i$  and  $S_i$  that maximizes the decrease of  $L(G)$ , until no such pair exists. In addition, we introduce a constraint  $L_i(G, S_i)/k_i > L_m(G, S_m)/k_m$ and  $L_i(G, S_j)/k_j > L_m(G, S_m)/k_m$  based on the average of description lengths, where  $S_m$  is the summary after merging and  $k_m = k_i + k_j$  is the number of the patterns associated with the motif  $S_m$ . This constraint allows the resulting motifs to bias towards the similarity requirement, thereby generating more accurate topological representations. Please refer to the appendix C for more details.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.210538864135742,
            0.5002894401550293
        ],
        "MSU_id": 1895
    },
    {
        "sentence": "We introduce a constraint L_i(G, S_j)/k_j > L_m(G, S_m)/k_m based on the average of description lengths.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 344,
        "paper_id": 4,
        "paragraph_info": "where  $|S_i|$  and  $|C_{ij}|$  denote the number of edges in the respective graphs. The greedy algorithm proposed by Navlakha et al. [42] can be applied to calculating  $S$  by iteratively merging the pair of the motifs  $S_i$  and  $S_i$  that maximizes the decrease of  $L(G)$ , until no such pair exists. In addition, we introduce a constraint  $L_i(G, S_i)/k_i > L_m(G, S_m)/k_m$ and  $L_i(G, S_j)/k_j > L_m(G, S_m)/k_m$  based on the average of description lengths, where  $S_m$  is the summary after merging and  $k_m = k_i + k_j$  is the number of the patterns associated with the motif  $S_m$ . This constraint allows the resulting motifs to bias towards the similarity requirement, thereby generating more accurate topological representations. Please refer to the appendix C for more details.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1937530040740967,
            0.46071818470954895
        ],
        "MSU_id": 1896
    },
    {
        "sentence": "The computation of the summary set $S$ can be further accelerated with a tree index.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 345,
        "paper_id": 4,
        "paragraph_info": "The computation of the summary set  $S$  can be further accelerated with a tree index, where we start from the root corresponding to a graph with only one vertex and generate each child node by iteratively adding an edge to the graph associated with the node's parent until the index contains all propagation graphs. Subsequently, we remove the nodes that are not a part of any propagation graph. With such index, the summary set can be efficiently approximated by selecting the node that contains the most propagation graphs and merging all of its propagation graphs greedily in batch for each level of the tree from the bottom up.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9440020322799683,
            -0.589372456073761
        ],
        "MSU_id": 1900
    },
    {
        "sentence": "We start from the root corresponding to a graph with only one vertex.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 345,
        "paper_id": 4,
        "paragraph_info": "The computation of the summary set  $S$  can be further accelerated with a tree index, where we start from the root corresponding to a graph with only one vertex and generate each child node by iteratively adding an edge to the graph associated with the node's parent until the index contains all propagation graphs. Subsequently, we remove the nodes that are not a part of any propagation graph. With such index, the summary set can be efficiently approximated by selecting the node that contains the most propagation graphs and merging all of its propagation graphs greedily in batch for each level of the tree from the bottom up.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0549027919769287,
            0.5185117721557617
        ],
        "MSU_id": 1901
    },
    {
        "sentence": "We generate each child node by iteratively adding an edge to the graph associated with the node's parent.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 345,
        "paper_id": 4,
        "paragraph_info": "The computation of the summary set  $S$  can be further accelerated with a tree index, where we start from the root corresponding to a graph with only one vertex and generate each child node by iteratively adding an edge to the graph associated with the node's parent until the index contains all propagation graphs. Subsequently, we remove the nodes that are not a part of any propagation graph. With such index, the summary set can be efficiently approximated by selecting the node that contains the most propagation graphs and merging all of its propagation graphs greedily in batch for each level of the tree from the bottom up.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1541500091552734,
            0.34981590509414673
        ],
        "MSU_id": 1902
    },
    {
        "sentence": "We remove the nodes that are not a part of any propagation graph.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 345,
        "paper_id": 4,
        "paragraph_info": "The computation of the summary set  $S$  can be further accelerated with a tree index, where we start from the root corresponding to a graph with only one vertex and generate each child node by iteratively adding an edge to the graph associated with the node's parent until the index contains all propagation graphs. Subsequently, we remove the nodes that are not a part of any propagation graph. With such index, the summary set can be efficiently approximated by selecting the node that contains the most propagation graphs and merging all of its propagation graphs greedily in batch for each level of the tree from the bottom up.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.275317668914795,
            0.06631623208522797
        ],
        "MSU_id": 1903
    },
    {
        "sentence": "We merge all of its propagation graphs greedily in batch for each level of the tree from the bottom up.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 345,
        "paper_id": 4,
        "paragraph_info": "The computation of the summary set  $S$  can be further accelerated with a tree index, where we start from the root corresponding to a graph with only one vertex and generate each child node by iteratively adding an edge to the graph associated with the node's parent until the index contains all propagation graphs. Subsequently, we remove the nodes that are not a part of any propagation graph. With such index, the summary set can be efficiently approximated by selecting the node that contains the most propagation graphs and merging all of its propagation graphs greedily in batch for each level of the tree from the bottom up.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6151965856552124,
            -1.048667550086975
        ],
        "MSU_id": 1905
    },
    {
        "sentence": "We present these motifs with node-link diagrams based on the force-directed layout algorithm.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 346,
        "paper_id": 4,
        "paragraph_info": "The extracted significant motifs are then visualized in the motif view  $(Fig. 1B)$  as the summary representations of pattern topologies. To help users identify the structures of the motifs intuitively, we present these motifs with node-link diagrams based on the force-directed layout algorithm (e.g., Fig. 1B4), where the corrections of the associated propagation graphs are superimposed on each extracted motif with the relatively smaller node size and lighter color.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8855700492858887,
            1.1069767475128174
        ],
        "MSU_id": 1907
    },
    {
        "sentence": "The corrections of the associated propagation graphs are superimposed on each extracted motif.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 346,
        "paper_id": 4,
        "paragraph_info": "The extracted significant motifs are then visualized in the motif view  $(Fig. 1B)$  as the summary representations of pattern topologies. To help users identify the structures of the motifs intuitively, we present these motifs with node-link diagrams based on the force-directed layout algorithm (e.g., Fig. 1B4), where the corrections of the associated propagation graphs are superimposed on each extracted motif with the relatively smaller node size and lighter color.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2537100315093994,
            0.20139777660369873
        ],
        "MSU_id": 1908
    },
    {
        "sentence": "The node size and color of the motifs are relatively smaller and lighter, respectively.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 346,
        "paper_id": 4,
        "paragraph_info": "The extracted significant motifs are then visualized in the motif view  $(Fig. 1B)$  as the summary representations of pattern topologies. To help users identify the structures of the motifs intuitively, we present these motifs with node-link diagrams based on the force-directed layout algorithm (e.g., Fig. 1B4), where the corrections of the associated propagation graphs are superimposed on each extracted motif with the relatively smaller node size and lighter color.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.8836071491241455,
            0.8574742674827576
        ],
        "MSU_id": 1909
    },
    {
        "sentence": "We visualize these probabilities on each edge of the motifs with an intuitive fusiform glyph.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 347,
        "paper_id": 4,
        "paragraph_info": "**Uncertainty-aware glyphs.** Each edge of the significant motifs comprises a series of propagation probabilities corresponding to each edge of the associated propagation graphs. Hence, we visualize these probabilities on each edge of the motifs with an intuitive fusiform glyph (Fig. 1B3) indicating the mean and variance of the probability distribution. The mean of the probabilities, encoded with the opacity of the glyph, reveals how likely the pollutants will be propagated along the edge, while the variance, encoded with the width of the glyph, helps users determine the stability of the edge in such propagation structure. Such glyph design allows users to quickly identify the strong and persistent propagation structures from a list of motifs. In addition, the motifs can be sorted by the average mean or variance of their edges.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0217349529266357,
            0.8359122276306152
        ],
        "MSU_id": 1911
    },
    {
        "sentence": "The glyph indicates the mean and variance of the probability distribution.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 347,
        "paper_id": 4,
        "paragraph_info": "**Uncertainty-aware glyphs.** Each edge of the significant motifs comprises a series of propagation probabilities corresponding to each edge of the associated propagation graphs. Hence, we visualize these probabilities on each edge of the motifs with an intuitive fusiform glyph (Fig. 1B3) indicating the mean and variance of the probability distribution. The mean of the probabilities, encoded with the opacity of the glyph, reveals how likely the pollutants will be propagated along the edge, while the variance, encoded with the width of the glyph, helps users determine the stability of the edge in such propagation structure. Such glyph design allows users to quickly identify the strong and persistent propagation structures from a list of motifs. In addition, the motifs can be sorted by the average mean or variance of their edges.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.02586345747113228,
            -0.8973498940467834
        ],
        "MSU_id": 1912
    },
    {
        "sentence": "The mean of the probabilities is encoded with the opacity of the glyph.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 347,
        "paper_id": 4,
        "paragraph_info": "**Uncertainty-aware glyphs.** Each edge of the significant motifs comprises a series of propagation probabilities corresponding to each edge of the associated propagation graphs. Hence, we visualize these probabilities on each edge of the motifs with an intuitive fusiform glyph (Fig. 1B3) indicating the mean and variance of the probability distribution. The mean of the probabilities, encoded with the opacity of the glyph, reveals how likely the pollutants will be propagated along the edge, while the variance, encoded with the width of the glyph, helps users determine the stability of the edge in such propagation structure. Such glyph design allows users to quickly identify the strong and persistent propagation structures from a list of motifs. In addition, the motifs can be sorted by the average mean or variance of their edges.",
        "paper_info": "airvis",
        "2d_coord": [
            0.16287195682525635,
            -1.3302315473556519
        ],
        "MSU_id": 1913
    },
    {
        "sentence": "The variance is encoded with the width of the glyph.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 347,
        "paper_id": 4,
        "paragraph_info": "**Uncertainty-aware glyphs.** Each edge of the significant motifs comprises a series of propagation probabilities corresponding to each edge of the associated propagation graphs. Hence, we visualize these probabilities on each edge of the motifs with an intuitive fusiform glyph (Fig. 1B3) indicating the mean and variance of the probability distribution. The mean of the probabilities, encoded with the opacity of the glyph, reveals how likely the pollutants will be propagated along the edge, while the variance, encoded with the width of the glyph, helps users determine the stability of the edge in such propagation structure. Such glyph design allows users to quickly identify the strong and persistent propagation structures from a list of motifs. In addition, the motifs can be sorted by the average mean or variance of their edges.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.3030664622783661,
            -1.1833702325820923
        ],
        "MSU_id": 1915
    },
    {
        "sentence": "An alternative to the aforementioned glyph design is to encode the probability distribution directly along the edges with the summarization representations like heatmaps.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 348,
        "paper_id": 4,
        "paragraph_info": "**Design alternatives.** An alternative to the aforementioned glyph design is to encode the probability distribution directly along the edges with the summarization representations like heatmaps (Fig. 6A). Users can obtain the fine-grained propagation probability information from the motifs. However, two limitations are observed in such design: a)",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7472190856933594,
            0.9886061549186707
        ],
        "MSU_id": 1919
    },
    {
        "sentence": "We have simplified the design of the glyphs.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 349,
        "paper_id": 4,
        "paragraph_info": "the conflicting directions of the edges introduce the difficulty in the readability of the glyphs, i.e., the starting points of the axis, and b) users complained that they had misinterpreted this visual encoding as the spatial distribution of pollutants among the involved districts. Hence, we have simplified the design of the glyphs and selected two representative features, the mean and the variance, to help users intuitively grasp the uncertainty in the topological structures of the significant motifs.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9871773719787598,
            0.6978511214256287
        ],
        "MSU_id": 1924
    },
    {
        "sentence": "We selected two representative features, the mean and the variance.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 349,
        "paper_id": 4,
        "paragraph_info": "the conflicting directions of the edges introduce the difficulty in the readability of the glyphs, i.e., the starting points of the axis, and b) users complained that they had misinterpreted this visual encoding as the spatial distribution of pollutants among the involved districts. Hence, we have simplified the design of the glyphs and selected two representative features, the mean and the variance, to help users intuitively grasp the uncertainty in the topological structures of the significant motifs.",
        "paper_info": "airvis",
        "2d_coord": [
            0.2651523947715759,
            -1.682481050491333
        ],
        "MSU_id": 1925
    },
    {
        "type": "figure",
        "para_id": 351,
        "paper_id": 4,
        "paragraph_info": "_page_5_Figure_12.jpeg",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8887083530426025,
            1.1609299182891846
        ],
        "MSU_id": 1927,
        "sentence": "The image illustrates design alternatives for uncertainty visualization in motif glyphs, pattern glyphs, and pattern graphs.",
        "category": "Method",
        "rank": 4
    },
    {
        "sentence": "By selecting a significant motif in the motif view, users can analyze the propagation patterns associated with the selected motif in the pattern view.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 352,
        "paper_id": 4,
        "paragraph_info": "By selecting a significant motif in the motif view, users can analyze the propagation patterns associated with the selected motif in the pattern view (Fig. 1C). However, presenting all patterns in the same spatial context will result in overlapping edges and severe visual clutters, and such method cannot provide important insights into multi-district propagation processes. Moreover, these patterns are closely related to their spatiotemporal context and associated with multiple probabilistic attributes including the contribution and impact factors, and thus the existing graph visualization methods  $[43, 48, 59]$  cannot be directly applied. To help users locate interesting patterns and inspect the detailed propagation processes, we adopt a visual representation with two levels of detail for the patterns. The first level of detail (Fig. 1C1) comprises a list of compact *pattern glyphs* that outline the spatiotemporal information of each pattern, with which users can obtain a brief overview about the spatial contexts and temporal distributions of the patterns (i.e., when and where the pattern occurred)  $(G3)$ . Thereafter, users can add a pattern to the inspection list (Fig. 1C4), where the detailed propagation processes of each added pattern will be depicted with a *pattern graph* on the map served as the second level of detail  $(G4)$ . Additionally, in the projection view, we lay out the patterns according to their similarities computed based on the word2vec model [39,40] to assist users in identifying pattern clusters and outliers efficiently  $(G5)$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3128793239593506,
            0.8877176642417908
        ],
        "MSU_id": 1931
    },
    {
        "sentence": "We adopt a visual representation with two levels of detail for the patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 352,
        "paper_id": 4,
        "paragraph_info": "By selecting a significant motif in the motif view, users can analyze the propagation patterns associated with the selected motif in the pattern view (Fig. 1C). However, presenting all patterns in the same spatial context will result in overlapping edges and severe visual clutters, and such method cannot provide important insights into multi-district propagation processes. Moreover, these patterns are closely related to their spatiotemporal context and associated with multiple probabilistic attributes including the contribution and impact factors, and thus the existing graph visualization methods  $[43, 48, 59]$  cannot be directly applied. To help users locate interesting patterns and inspect the detailed propagation processes, we adopt a visual representation with two levels of detail for the patterns. The first level of detail (Fig. 1C1) comprises a list of compact *pattern glyphs* that outline the spatiotemporal information of each pattern, with which users can obtain a brief overview about the spatial contexts and temporal distributions of the patterns (i.e., when and where the pattern occurred)  $(G3)$ . Thereafter, users can add a pattern to the inspection list (Fig. 1C4), where the detailed propagation processes of each added pattern will be depicted with a *pattern graph* on the map served as the second level of detail  $(G4)$ . Additionally, in the projection view, we lay out the patterns according to their similarities computed based on the word2vec model [39,40] to assist users in identifying pattern clusters and outliers efficiently  $(G5)$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6941494941711426,
            1.1947975158691406
        ],
        "MSU_id": 1936
    },
    {
        "sentence": "The first level of detail comprises a list of compact pattern glyphs that outline the spatiotemporal information of each pattern.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 352,
        "paper_id": 4,
        "paragraph_info": "By selecting a significant motif in the motif view, users can analyze the propagation patterns associated with the selected motif in the pattern view (Fig. 1C). However, presenting all patterns in the same spatial context will result in overlapping edges and severe visual clutters, and such method cannot provide important insights into multi-district propagation processes. Moreover, these patterns are closely related to their spatiotemporal context and associated with multiple probabilistic attributes including the contribution and impact factors, and thus the existing graph visualization methods  $[43, 48, 59]$  cannot be directly applied. To help users locate interesting patterns and inspect the detailed propagation processes, we adopt a visual representation with two levels of detail for the patterns. The first level of detail (Fig. 1C1) comprises a list of compact *pattern glyphs* that outline the spatiotemporal information of each pattern, with which users can obtain a brief overview about the spatial contexts and temporal distributions of the patterns (i.e., when and where the pattern occurred)  $(G3)$ . Thereafter, users can add a pattern to the inspection list (Fig. 1C4), where the detailed propagation processes of each added pattern will be depicted with a *pattern graph* on the map served as the second level of detail  $(G4)$ . Additionally, in the projection view, we lay out the patterns according to their similarities computed based on the word2vec model [39,40] to assist users in identifying pattern clusters and outliers efficiently  $(G5)$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1096785068511963,
            0.4409990906715393
        ],
        "MSU_id": 1937
    },
    {
        "sentence": "Users can add a pattern to the inspection list, where the detailed propagation processes of each added pattern will be depicted with a pattern graph.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 352,
        "paper_id": 4,
        "paragraph_info": "By selecting a significant motif in the motif view, users can analyze the propagation patterns associated with the selected motif in the pattern view (Fig. 1C). However, presenting all patterns in the same spatial context will result in overlapping edges and severe visual clutters, and such method cannot provide important insights into multi-district propagation processes. Moreover, these patterns are closely related to their spatiotemporal context and associated with multiple probabilistic attributes including the contribution and impact factors, and thus the existing graph visualization methods  $[43, 48, 59]$  cannot be directly applied. To help users locate interesting patterns and inspect the detailed propagation processes, we adopt a visual representation with two levels of detail for the patterns. The first level of detail (Fig. 1C1) comprises a list of compact *pattern glyphs* that outline the spatiotemporal information of each pattern, with which users can obtain a brief overview about the spatial contexts and temporal distributions of the patterns (i.e., when and where the pattern occurred)  $(G3)$ . Thereafter, users can add a pattern to the inspection list (Fig. 1C4), where the detailed propagation processes of each added pattern will be depicted with a *pattern graph* on the map served as the second level of detail  $(G4)$ . Additionally, in the projection view, we lay out the patterns according to their similarities computed based on the word2vec model [39,40] to assist users in identifying pattern clusters and outliers efficiently  $(G5)$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -2.015652656555176,
            1.0943684577941895
        ],
        "MSU_id": 1939
    },
    {
        "sentence": "In the projection view, we lay out the patterns according to their similarities computed based on the word2vec model to assist users in identifying pattern clusters and outliers efficiently.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 352,
        "paper_id": 4,
        "paragraph_info": "By selecting a significant motif in the motif view, users can analyze the propagation patterns associated with the selected motif in the pattern view (Fig. 1C). However, presenting all patterns in the same spatial context will result in overlapping edges and severe visual clutters, and such method cannot provide important insights into multi-district propagation processes. Moreover, these patterns are closely related to their spatiotemporal context and associated with multiple probabilistic attributes including the contribution and impact factors, and thus the existing graph visualization methods  $[43, 48, 59]$  cannot be directly applied. To help users locate interesting patterns and inspect the detailed propagation processes, we adopt a visual representation with two levels of detail for the patterns. The first level of detail (Fig. 1C1) comprises a list of compact *pattern glyphs* that outline the spatiotemporal information of each pattern, with which users can obtain a brief overview about the spatial contexts and temporal distributions of the patterns (i.e., when and where the pattern occurred)  $(G3)$ . Thereafter, users can add a pattern to the inspection list (Fig. 1C4), where the detailed propagation processes of each added pattern will be depicted with a *pattern graph* on the map served as the second level of detail  $(G4)$ . Additionally, in the projection view, we lay out the patterns according to their similarities computed based on the word2vec model [39,40] to assist users in identifying pattern clusters and outliers efficiently  $(G5)$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0613977909088135,
            0.6951920390129089
        ],
        "MSU_id": 1940
    },
    {
        "sentence": "The fisheye effect is applied on mouse hover to facilitate the visibility of the propagation process.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 353,
        "paper_id": 4,
        "paragraph_info": "The design of the pattern glyphs is illustrated in Fig. 1C1. The small dots enclosed in the large circle represent the districts and are laid out according to their geospatial positions. The districts and pathways involved in the propagation process are highlighted in orange, while the irrelevant dots are rendered in gray. The red arrow on the border points towards the average direction of the propagation pathways. To facilitate the visibility of the propagation process in such a compact space, the fisheye effect is applied on mouse hover (Fig. 1C3).",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6317344903945923,
            0.4753848910331726
        ],
        "MSU_id": 1947
    },
    {
        "sentence": "The temporal distribution of the propagation instances is depicted with a bucketed heatmap around the glyph.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 354,
        "paper_id": 4,
        "paragraph_info": "The temporal distribution of the propagation instances is depicted with a bucketed heatmap around the glyph. Each bucket represents a week, resulting in total 33 buckets. The top of the heatmap is explicitly made discontinuous to avoid the confusion that the distribution is cyclic.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5958311557769775,
            0.9701301455497742
        ],
        "MSU_id": 1948
    },
    {
        "sentence": "The top of the heatmap is explicitly made discontinuous to avoid confusion that the distribution is cyclic.",
        "category": "Method",
        "rank": 2,
        "type": "text",
        "para_id": 354,
        "paper_id": 4,
        "paragraph_info": "The temporal distribution of the propagation instances is depicted with a bucketed heatmap around the glyph. Each bucket represents a week, resulting in total 33 buckets. The top of the heatmap is explicitly made discontinuous to avoid the confusion that the distribution is cyclic.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.6218643188476562,
            0.5826488733291626
        ],
        "MSU_id": 1950
    },
    {
        "sentence": "An alternative is to embed a map directly in the glyph focusing on the spatial region that contains the propagation process.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 355,
        "paper_id": 4,
        "paragraph_info": "**Design alternatives.** Instead of the dot-based representation, an alternative is to embed a map directly in the glyph focusing on the spatial region that contains the propagation process (Fig. 6B). However, the readability of the map is limited because of the compact space in the glyphs, and the spatial contexts of the glyphs are difficult to compare due to the lack of a consistent spatial reference.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.4353618621826172,
            1.090732455253601
        ],
        "MSU_id": 1951
    },
    {
        "sentence": "The pattern graphs are designed to visualize the uncertain propagation processes of a pattern on the map.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 356,
        "paper_id": 4,
        "paragraph_info": "The pattern graphs are designed to visualize the uncertain propagation processes of a pattern on the map. Each transportation pathway between two districts (e.g., the source district  $A$  and the destination district  $B$ ) in the propagation processes comprises two key features, the contribution and impact, extracted from all transportation instances. The contribution of a pathway includes all expected ratios of the pollutants in  $A$ contributing to  $B$ . Similarly, the impact comprises the expected ratios of the pollutants in  $B$  received from  $A$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8783255815505981,
            0.8924391269683838
        ],
        "MSU_id": 1954
    },
    {
        "sentence": "Each transportation pathway between two districts comprises two key features, the contribution and impact.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 356,
        "paper_id": 4,
        "paragraph_info": "The pattern graphs are designed to visualize the uncertain propagation processes of a pattern on the map. Each transportation pathway between two districts (e.g., the source district  $A$  and the destination district  $B$ ) in the propagation processes comprises two key features, the contribution and impact, extracted from all transportation instances. The contribution of a pathway includes all expected ratios of the pollutants in  $A$ contributing to  $B$ . Similarly, the impact comprises the expected ratios of the pollutants in  $B$  received from  $A$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6249396800994873,
            -0.08600471168756485
        ],
        "MSU_id": 1955
    },
    {
        "sentence": "The contribution of a pathway includes all expected ratios of the pollutants in district A contributing to district B.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 356,
        "paper_id": 4,
        "paragraph_info": "The pattern graphs are designed to visualize the uncertain propagation processes of a pattern on the map. Each transportation pathway between two districts (e.g., the source district  $A$  and the destination district  $B$ ) in the propagation processes comprises two key features, the contribution and impact, extracted from all transportation instances. The contribution of a pathway includes all expected ratios of the pollutants in  $A$ contributing to  $B$ . Similarly, the impact comprises the expected ratios of the pollutants in  $B$  received from  $A$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -0.17016105353832245,
            -0.3890487551689148
        ],
        "MSU_id": 1956
    },
    {
        "sentence": "The impact comprises the expected ratios of the pollutants in district B received from district A.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 356,
        "paper_id": 4,
        "paragraph_info": "The pattern graphs are designed to visualize the uncertain propagation processes of a pattern on the map. Each transportation pathway between two districts (e.g., the source district  $A$  and the destination district  $B$ ) in the propagation processes comprises two key features, the contribution and impact, extracted from all transportation instances. The contribution of a pathway includes all expected ratios of the pollutants in  $A$ contributing to  $B$ . Similarly, the impact comprises the expected ratios of the pollutants in  $B$  received from  $A$ .",
        "paper_info": "airvis",
        "2d_coord": [
            -0.35123270750045776,
            -1.1744037866592407
        ],
        "MSU_id": 1957
    },
    {
        "sentence": "We illustrate cause-effect relationships with a tailored node-link diagram.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 357,
        "paper_id": 4,
        "paragraph_info": "We illustrate such cause-effect relationships with a tailored node-link diagram (Fig. 1C5). The districts involved in the propagation process are represented with the circles filled with yellow on the white background. Moreover, the size of these circles indicates the concentration of pollutants. Around the circle, each small pie chart in red or green is linked with an incoming or outgoing edge and encodes the median of the impact or contribution ratios with the filled part, respectively. In particular, the expected ratios are represented with their medians, since medians are less sensitive to extreme values.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9474143981933594,
            1.0748847723007202
        ],
        "MSU_id": 1958
    },
    {
        "sentence": "The districts involved in the propagation process are represented with circles filled with yellow.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 357,
        "paper_id": 4,
        "paragraph_info": "We illustrate such cause-effect relationships with a tailored node-link diagram (Fig. 1C5). The districts involved in the propagation process are represented with the circles filled with yellow on the white background. Moreover, the size of these circles indicates the concentration of pollutants. Around the circle, each small pie chart in red or green is linked with an incoming or outgoing edge and encodes the median of the impact or contribution ratios with the filled part, respectively. In particular, the expected ratios are represented with their medians, since medians are less sensitive to extreme values.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0820417404174805,
            1.1332042217254639
        ],
        "MSU_id": 1959
    },
    {
        "sentence": "Each small pie chart in red or green is linked with an incoming or outgoing edge.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 357,
        "paper_id": 4,
        "paragraph_info": "We illustrate such cause-effect relationships with a tailored node-link diagram (Fig. 1C5). The districts involved in the propagation process are represented with the circles filled with yellow on the white background. Moreover, the size of these circles indicates the concentration of pollutants. Around the circle, each small pie chart in red or green is linked with an incoming or outgoing edge and encodes the median of the impact or contribution ratios with the filled part, respectively. In particular, the expected ratios are represented with their medians, since medians are less sensitive to extreme values.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.662406086921692,
            0.3721480667591095
        ],
        "MSU_id": 1961
    },
    {
        "sentence": "The filled part of the pie chart encodes the median of the impact or contribution ratios.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 357,
        "paper_id": 4,
        "paragraph_info": "We illustrate such cause-effect relationships with a tailored node-link diagram (Fig. 1C5). The districts involved in the propagation process are represented with the circles filled with yellow on the white background. Moreover, the size of these circles indicates the concentration of pollutants. Around the circle, each small pie chart in red or green is linked with an incoming or outgoing edge and encodes the median of the impact or contribution ratios with the filled part, respectively. In particular, the expected ratios are represented with their medians, since medians are less sensitive to extreme values.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.3011915683746338,
            -0.6061685085296631
        ],
        "MSU_id": 1962
    },
    {
        "sentence": "We developed two alternative layouts, the circumferential and radial layouts.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 358,
        "paper_id": 4,
        "paragraph_info": "**Design alternatives.** Besides the *satellite* layout proposed above, we developed two alternative layouts, the *circumferential* and *radial* layouts, to encode two percentage values at both ends of each edge in the node-link diagrams. The circumferential layout (Fig. 6C) encodes the values as donut slices along the circumferential direction of the nodes. However, such encoding may result in severe occlusions between slices. The radial layout (Fig. 6D) depicts the values along the radial direction with bars. Nevertheless, such encoding has the scalability issue because each glyph requires more screen space. Hence, we chose the satellite layout to visualize the percentage values compactly and intuitively.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.9770935773849487,
            0.9300106167793274
        ],
        "MSU_id": 1965
    },
    {
        "sentence": "The circumferential layout encodes the values as donut slices along the circumferential direction of the nodes.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 358,
        "paper_id": 4,
        "paragraph_info": "**Design alternatives.** Besides the *satellite* layout proposed above, we developed two alternative layouts, the *circumferential* and *radial* layouts, to encode two percentage values at both ends of each edge in the node-link diagrams. The circumferential layout (Fig. 6C) encodes the values as donut slices along the circumferential direction of the nodes. However, such encoding may result in severe occlusions between slices. The radial layout (Fig. 6D) depicts the values along the radial direction with bars. Nevertheless, such encoding has the scalability issue because each glyph requires more screen space. Hence, we chose the satellite layout to visualize the percentage values compactly and intuitively.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.8862950801849365,
            0.4988909661769867
        ],
        "MSU_id": 1966
    },
    {
        "sentence": "The radial layout depicts the values along the radial direction with bars.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 358,
        "paper_id": 4,
        "paragraph_info": "**Design alternatives.** Besides the *satellite* layout proposed above, we developed two alternative layouts, the *circumferential* and *radial* layouts, to encode two percentage values at both ends of each edge in the node-link diagrams. The circumferential layout (Fig. 6C) encodes the values as donut slices along the circumferential direction of the nodes. However, such encoding may result in severe occlusions between slices. The radial layout (Fig. 6D) depicts the values along the radial direction with bars. Nevertheless, such encoding has the scalability issue because each glyph requires more screen space. Hence, we chose the satellite layout to visualize the percentage values compactly and intuitively.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.2157883644104004,
            0.9903035759925842
        ],
        "MSU_id": 1968
    },
    {
        "sentence": "The projection view is designed to assist users in understanding the similarities and differences among the patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 359,
        "paper_id": 4,
        "paragraph_info": "In addition to the juxtaposed comparative analysis in the inspection list, the projection view (Fig. 1A3) is designed to assist users in understanding the similarities and differences among the patterns and identifying the interesting pattern clusters and outliers efficiently.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.399932622909546,
            1.353659749031067
        ],
        "MSU_id": 1971
    },
    {
        "sentence": "The projection view helps in identifying the interesting pattern clusters and outliers efficiently.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 359,
        "paper_id": 4,
        "paragraph_info": "In addition to the juxtaposed comparative analysis in the inspection list, the projection view (Fig. 1A3) is designed to assist users in understanding the similarities and differences among the patterns and identifying the interesting pattern clusters and outliers efficiently.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.9824588298797607,
            1.1809860467910767
        ],
        "MSU_id": 1972
    },
    {
        "sentence": "To compute the similarities, we first obtain a semantic vector representation for each pattern based on the word2vec model.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 360,
        "paper_id": 4,
        "paragraph_info": "**Vector representation.** To compute the similarities, we first obtain a semantic vector representation for each pattern based on the word2vec model. The word2vec model has been demonstrated to be highly effective in generating a vector for each word in the vocabulary extracted from a series of sentences while the Euclidean distance between two vectors indicates the similarity between two corresponding words. In our scenario (Fig. 7C), we use the patterns as the words and the transactions (i.e., the propagation instances that support the patterns) as the sentences, such that we can directly feed the patterns and transactions into the word2vec model and obtain the vectors that represent the patterns. In particular, a unique ID is assigned to each pattern, and the feature vector for each transaction is generated with a list of pattern IDs the transaction belongs to (Fig. 7C1). We set the scanning window to the largest number of patterns in a transaction in order to make the patterns in the same transaction related to each other.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.016888380050659,
            -0.5516548156738281
        ],
        "MSU_id": 1974
    },
    {
        "sentence": "In our scenario, we use the patterns as the words and the transactions as the sentences.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 360,
        "paper_id": 4,
        "paragraph_info": "**Vector representation.** To compute the similarities, we first obtain a semantic vector representation for each pattern based on the word2vec model. The word2vec model has been demonstrated to be highly effective in generating a vector for each word in the vocabulary extracted from a series of sentences while the Euclidean distance between two vectors indicates the similarity between two corresponding words. In our scenario (Fig. 7C), we use the patterns as the words and the transactions (i.e., the propagation instances that support the patterns) as the sentences, such that we can directly feed the patterns and transactions into the word2vec model and obtain the vectors that represent the patterns. In particular, a unique ID is assigned to each pattern, and the feature vector for each transaction is generated with a list of pattern IDs the transaction belongs to (Fig. 7C1). We set the scanning window to the largest number of patterns in a transaction in order to make the patterns in the same transaction related to each other.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6476041078567505,
            -0.30138885974884033
        ],
        "MSU_id": 1977
    },
    {
        "sentence": "We can directly feed the patterns and transactions into the word2vec model and obtain the vectors that represent the patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 360,
        "paper_id": 4,
        "paragraph_info": "**Vector representation.** To compute the similarities, we first obtain a semantic vector representation for each pattern based on the word2vec model. The word2vec model has been demonstrated to be highly effective in generating a vector for each word in the vocabulary extracted from a series of sentences while the Euclidean distance between two vectors indicates the similarity between two corresponding words. In our scenario (Fig. 7C), we use the patterns as the words and the transactions (i.e., the propagation instances that support the patterns) as the sentences, such that we can directly feed the patterns and transactions into the word2vec model and obtain the vectors that represent the patterns. In particular, a unique ID is assigned to each pattern, and the feature vector for each transaction is generated with a list of pattern IDs the transaction belongs to (Fig. 7C1). We set the scanning window to the largest number of patterns in a transaction in order to make the patterns in the same transaction related to each other.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.816489577293396,
            -1.0103360414505005
        ],
        "MSU_id": 1978
    },
    {
        "sentence": "A unique ID is assigned to each pattern.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 360,
        "paper_id": 4,
        "paragraph_info": "**Vector representation.** To compute the similarities, we first obtain a semantic vector representation for each pattern based on the word2vec model. The word2vec model has been demonstrated to be highly effective in generating a vector for each word in the vocabulary extracted from a series of sentences while the Euclidean distance between two vectors indicates the similarity between two corresponding words. In our scenario (Fig. 7C), we use the patterns as the words and the transactions (i.e., the propagation instances that support the patterns) as the sentences, such that we can directly feed the patterns and transactions into the word2vec model and obtain the vectors that represent the patterns. In particular, a unique ID is assigned to each pattern, and the feature vector for each transaction is generated with a list of pattern IDs the transaction belongs to (Fig. 7C1). We set the scanning window to the largest number of patterns in a transaction in order to make the patterns in the same transaction related to each other.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.6068634390830994,
            0.056237366050481796
        ],
        "MSU_id": 1979
    },
    {
        "sentence": "The feature vector for each transaction is generated with a list of pattern IDs the transaction belongs to.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 360,
        "paper_id": 4,
        "paragraph_info": "**Vector representation.** To compute the similarities, we first obtain a semantic vector representation for each pattern based on the word2vec model. The word2vec model has been demonstrated to be highly effective in generating a vector for each word in the vocabulary extracted from a series of sentences while the Euclidean distance between two vectors indicates the similarity between two corresponding words. In our scenario (Fig. 7C), we use the patterns as the words and the transactions (i.e., the propagation instances that support the patterns) as the sentences, such that we can directly feed the patterns and transactions into the word2vec model and obtain the vectors that represent the patterns. In particular, a unique ID is assigned to each pattern, and the feature vector for each transaction is generated with a list of pattern IDs the transaction belongs to (Fig. 7C1). We set the scanning window to the largest number of patterns in a transaction in order to make the patterns in the same transaction related to each other.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.411850929260254,
            -0.9803311228752136
        ],
        "MSU_id": 1980
    },
    {
        "sentence": "We set the scanning window to the largest number of patterns in a transaction in order to make the patterns in the same transaction related to each other.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 360,
        "paper_id": 4,
        "paragraph_info": "**Vector representation.** To compute the similarities, we first obtain a semantic vector representation for each pattern based on the word2vec model. The word2vec model has been demonstrated to be highly effective in generating a vector for each word in the vocabulary extracted from a series of sentences while the Euclidean distance between two vectors indicates the similarity between two corresponding words. In our scenario (Fig. 7C), we use the patterns as the words and the transactions (i.e., the propagation instances that support the patterns) as the sentences, such that we can directly feed the patterns and transactions into the word2vec model and obtain the vectors that represent the patterns. In particular, a unique ID is assigned to each pattern, and the feature vector for each transaction is generated with a list of pattern IDs the transaction belongs to (Fig. 7C1). We set the scanning window to the largest number of patterns in a transaction in order to make the patterns in the same transaction related to each other.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6245250701904297,
            0.5993608236312866
        ],
        "MSU_id": 1981
    },
    {
        "sentence": "We perform dimensionality reduction with t-SNE to preserve the local similarities among the patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 361,
        "paper_id": 4,
        "paragraph_info": "**Visualization.** Given the vector representations, we perform the dimensionality reduction with t-SNE [36] to preserve the local similarities among the patterns and obtain the two-dimensional coordinates of the patterns. These patterns are subsequently plotted as a scatterplot, where the mean concentration of the estimated transported pollutants in all districts is encoded with the opacity of the points for each pattern.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6442161798477173,
            -0.8813339471817017
        ],
        "MSU_id": 1982
    },
    {
        "sentence": "These patterns are subsequently plotted as a scatterplot.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 361,
        "paper_id": 4,
        "paragraph_info": "**Visualization.** Given the vector representations, we perform the dimensionality reduction with t-SNE [36] to preserve the local similarities among the patterns and obtain the two-dimensional coordinates of the patterns. These patterns are subsequently plotted as a scatterplot, where the mean concentration of the estimated transported pollutants in all districts is encoded with the opacity of the points for each pattern.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.7991431951522827,
            1.6059421300888062
        ],
        "MSU_id": 1984
    },
    {
        "sentence": "We attempted to perform the t-SNE method directly with one-hot vectors.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 362,
        "paper_id": 4,
        "paragraph_info": "**Alternatives.** We also attempted to perform the t-SNE method directly with one-hot vectors (Fig. 7A and 7B). These one-hot vectors are generated either by concatenating the features (e.g., the time occurred, district, and pollution concentrations) or with the transactions directly. However, the results failed to capture the similarities among the patterns accurately, mainly because these vectors are too sparse.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.5870321989059448,
            -1.5803674459457397
        ],
        "MSU_id": 1986
    },
    {
        "sentence": "These one-hot vectors are generated by concatenating the features or with the transactions directly.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 362,
        "paper_id": 4,
        "paragraph_info": "**Alternatives.** We also attempted to perform the t-SNE method directly with one-hot vectors (Fig. 7A and 7B). These one-hot vectors are generated either by concatenating the features (e.g., the time occurred, district, and pollution concentrations) or with the transactions directly. However, the results failed to capture the similarities among the patterns accurately, mainly because these vectors are too sparse.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.2162073850631714,
            -1.6751559972763062
        ],
        "MSU_id": 1987
    },
    {
        "sentence": "Experts can inspect detailed propagation instances via the instance view.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 363,
        "paper_id": 4,
        "paragraph_info": "By selecting an interesting pattern, experts can inspect its detailed propagation instances (G6) via the instance view (Fig.  $1D$ ).",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3360822200775146,
            0.7245341539382935
        ],
        "MSU_id": 1990
    },
    {
        "sentence": "The transportation instances among the involved districts are visualized with a chord diagram.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 364,
        "paper_id": 4,
        "paragraph_info": "**Pollutant transportation.** The transportation instances among the involved districts within the timeframe selected on the slider are visualized with a chord diagram (Fig. 1D1), which offers the occlusion-free exploration of the instances in terms of both spatial and temporal dimensions. Each district is represented with an arc, along which the time-varying pollutant concentrations are encoded in a clockwise direction with the height and luminance of the bars. The transportation instances between pairs of districts are indicated with chords, the widths of which encode the impacts of the instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.032038450241089,
            1.028829574584961
        ],
        "MSU_id": 1992
    },
    {
        "sentence": "The chord diagram offers occlusion-free exploration of the instances in terms of both spatial and temporal dimensions.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 364,
        "paper_id": 4,
        "paragraph_info": "**Pollutant transportation.** The transportation instances among the involved districts within the timeframe selected on the slider are visualized with a chord diagram (Fig. 1D1), which offers the occlusion-free exploration of the instances in terms of both spatial and temporal dimensions. Each district is represented with an arc, along which the time-varying pollutant concentrations are encoded in a clockwise direction with the height and luminance of the bars. The transportation instances between pairs of districts are indicated with chords, the widths of which encode the impacts of the instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5273098945617676,
            1.0767831802368164
        ],
        "MSU_id": 1993
    },
    {
        "sentence": "Each district is represented with an arc in the chord diagram.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 364,
        "paper_id": 4,
        "paragraph_info": "**Pollutant transportation.** The transportation instances among the involved districts within the timeframe selected on the slider are visualized with a chord diagram (Fig. 1D1), which offers the occlusion-free exploration of the instances in terms of both spatial and temporal dimensions. Each district is represented with an arc, along which the time-varying pollutant concentrations are encoded in a clockwise direction with the height and luminance of the bars. The transportation instances between pairs of districts are indicated with chords, the widths of which encode the impacts of the instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.659545660018921,
            1.1947513818740845
        ],
        "MSU_id": 1994
    },
    {
        "sentence": "The time-varying pollutant concentrations are encoded in a clockwise direction with the height and luminance of the bars.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 364,
        "paper_id": 4,
        "paragraph_info": "**Pollutant transportation.** The transportation instances among the involved districts within the timeframe selected on the slider are visualized with a chord diagram (Fig. 1D1), which offers the occlusion-free exploration of the instances in terms of both spatial and temporal dimensions. Each district is represented with an arc, along which the time-varying pollutant concentrations are encoded in a clockwise direction with the height and luminance of the bars. The transportation instances between pairs of districts are indicated with chords, the widths of which encode the impacts of the instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.5392854809761047,
            0.001419156789779663
        ],
        "MSU_id": 1995
    },
    {
        "sentence": "The transportation instances between pairs of districts are indicated with chords.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 364,
        "paper_id": 4,
        "paragraph_info": "**Pollutant transportation.** The transportation instances among the involved districts within the timeframe selected on the slider are visualized with a chord diagram (Fig. 1D1), which offers the occlusion-free exploration of the instances in terms of both spatial and temporal dimensions. Each district is represented with an arc, along which the time-varying pollutant concentrations are encoded in a clockwise direction with the height and luminance of the bars. The transportation instances between pairs of districts are indicated with chords, the widths of which encode the impacts of the instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1550674438476562,
            0.8824831247329712
        ],
        "MSU_id": 1996
    },
    {
        "sentence": "The widths of the chords encode the impacts of the transportation instances.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 364,
        "paper_id": 4,
        "paragraph_info": "**Pollutant transportation.** The transportation instances among the involved districts within the timeframe selected on the slider are visualized with a chord diagram (Fig. 1D1), which offers the occlusion-free exploration of the instances in terms of both spatial and temporal dimensions. Each district is represented with an arc, along which the time-varying pollutant concentrations are encoded in a clockwise direction with the height and luminance of the bars. The transportation instances between pairs of districts are indicated with chords, the widths of which encode the impacts of the instances.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.165889024734497,
            0.08819356560707092
        ],
        "MSU_id": 1997
    },
    {
        "sentence": "An instance table is designed to provide the raw data of the propagation instances with numeric values and the distributions in boxplots.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 365,
        "paper_id": 4,
        "paragraph_info": "**Raw instance data.** An *instance table* (Fig. 1D2), coordinated with the chord diagram, is designed to provide the raw data of the propagation instances with numeric values and the distributions in boxplots. The raw data of each district pair in the propagation instances is depicted with a nested table (e.g., the statistics of pollutant transportation from Xinjishi to Shenzexian are shown in Fig. 1D3). These raw data include the pollutant concentrations in the districts, propagation probability, transportation time, and occurred time.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9561913013458252,
            0.5921795964241028
        ],
        "MSU_id": 1998
    },
    {
        "sentence": "The raw data of each district pair in the propagation instances is depicted with a nested table.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 365,
        "paper_id": 4,
        "paragraph_info": "**Raw instance data.** An *instance table* (Fig. 1D2), coordinated with the chord diagram, is designed to provide the raw data of the propagation instances with numeric values and the distributions in boxplots. The raw data of each district pair in the propagation instances is depicted with a nested table (e.g., the statistics of pollutant transportation from Xinjishi to Shenzexian are shown in Fig. 1D3). These raw data include the pollutant concentrations in the districts, propagation probability, transportation time, and occurred time.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1318886280059814,
            0.41290032863616943
        ],
        "MSU_id": 1999
    },
    {
        "type": "figure",
        "para_id": 367,
        "paper_id": 4,
        "paragraph_info": "_page_6_Figure_11.jpeg",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8335368633270264,
            -1.0538663864135742
        ],
        "MSU_id": 2002,
        "sentence": "Three methods to generate the vector representation of a pattern, (A) concatenating the one-hot encoded feature vectors, (B) using transactions with one-hot encodings directly, and (C) learning the vector representations of the patterns based on the word2vec model.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "Three methods to generate the vector representation of a pattern are presented.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 367,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-6-0\"></span>Fig. 7. Three methods to generate the vector representation of a pattern, (A) concatenating the one-hot encoded feature vectors, (B) using transactions with one-hot encodings directly, and (C) learning the vector representations of the patterns based on the word2vec model.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8241912126541138,
            -0.08992417901754379
        ],
        "MSU_id": 2003
    },
    {
        "sentence": "The first method is concatenating the one-hot encoded feature vectors.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 367,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-6-0\"></span>Fig. 7. Three methods to generate the vector representation of a pattern, (A) concatenating the one-hot encoded feature vectors, (B) using transactions with one-hot encodings directly, and (C) learning the vector representations of the patterns based on the word2vec model.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.3955599069595337,
            -1.7120249271392822
        ],
        "MSU_id": 2004
    },
    {
        "sentence": "The second method is using transactions with one-hot encodings directly.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 367,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-6-0\"></span>Fig. 7. Three methods to generate the vector representation of a pattern, (A) concatenating the one-hot encoded feature vectors, (B) using transactions with one-hot encodings directly, and (C) learning the vector representations of the patterns based on the word2vec model.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6064367294311523,
            -0.817840576171875
        ],
        "MSU_id": 2005
    },
    {
        "sentence": "The third method is learning the vector representations of the patterns based on the word2vec model.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 367,
        "paper_id": 4,
        "paragraph_info": "<span id=\"page-6-0\"></span>Fig. 7. Three methods to generate the vector representation of a pattern, (A) concatenating the one-hot encoded feature vectors, (B) using transactions with one-hot encodings directly, and (C) learning the vector representations of the patterns based on the word2vec model.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.8042658567428589,
            -1.2412537336349487
        ],
        "MSU_id": 2006
    },
    {
        "sentence": "The following three interactions are incorporated into the proposed system.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 368,
        "paper_id": 4,
        "paragraph_info": "The following three interactions are incorporated into the proposed system to further enhance its usability.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.20927324891090393,
            -0.43180781602859497
        ],
        "MSU_id": 2007
    },
    {
        "sentence": "Our system allows users to interactively tune the parameters in the mining model.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 369,
        "paper_id": 4,
        "paragraph_info": "Interactive mining. Our system allows users to interactively tune the parameters in the mining model, including the time span,  $\\lambda_p$ , and  $\\lambda_c$ , and obtain the generated patterns in real-time with a control panel (Fig. 1A1). These parameters default to less strict values, thereby allowing the model to produce a reasonable number of patterns. Users can customize these parameters according to their needs.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.4781651496887207,
            -0.25566399097442627
        ],
        "MSU_id": 2009
    },
    {
        "sentence": "The parameters include the time span, $\\lambda_p$, and $\\lambda_c$.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 369,
        "paper_id": 4,
        "paragraph_info": "Interactive mining. Our system allows users to interactively tune the parameters in the mining model, including the time span,  $\\lambda_p$ , and  $\\lambda_c$ , and obtain the generated patterns in real-time with a control panel (Fig. 1A1). These parameters default to less strict values, thereby allowing the model to produce a reasonable number of patterns. Users can customize these parameters according to their needs.",
        "paper_info": "airvis",
        "2d_coord": [
            0.9536937475204468,
            -1.3792165517807007
        ],
        "MSU_id": 2010
    },
    {
        "sentence": "Users can obtain the generated patterns in real-time with a control panel.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 369,
        "paper_id": 4,
        "paragraph_info": "Interactive mining. Our system allows users to interactively tune the parameters in the mining model, including the time span,  $\\lambda_p$ , and  $\\lambda_c$ , and obtain the generated patterns in real-time with a control panel (Fig. 1A1). These parameters default to less strict values, thereby allowing the model to produce a reasonable number of patterns. Users can customize these parameters according to their needs.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.784034013748169,
            1.0648468732833862
        ],
        "MSU_id": 2011
    },
    {
        "sentence": "These parameters default to less strict values.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 369,
        "paper_id": 4,
        "paragraph_info": "Interactive mining. Our system allows users to interactively tune the parameters in the mining model, including the time span,  $\\lambda_p$ , and  $\\lambda_c$ , and obtain the generated patterns in real-time with a control panel (Fig. 1A1). These parameters default to less strict values, thereby allowing the model to produce a reasonable number of patterns. Users can customize these parameters according to their needs.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.003968585282564163,
            -1.3635075092315674
        ],
        "MSU_id": 2012
    },
    {
        "sentence": "Users can customize these parameters according to their needs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 369,
        "paper_id": 4,
        "paragraph_info": "Interactive mining. Our system allows users to interactively tune the parameters in the mining model, including the time span,  $\\lambda_p$ , and  $\\lambda_c$ , and obtain the generated patterns in real-time with a control panel (Fig. 1A1). These parameters default to less strict values, thereby allowing the model to produce a reasonable number of patterns. Users can customize these parameters according to their needs.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.1015589237213135,
            -1.2456384897232056
        ],
        "MSU_id": 2014
    },
    {
        "sentence": "Users can select a district and filter out the patterns that do not involve the selected district.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 370,
        "paper_id": 4,
        "paragraph_info": "**Pattern filtering.** Users can select a district and filter out the patterns that does not involve the selected district. Moreover, the selected district will be highlighted in the motif and pattern glyphs. Users can also draw a polygon selection on the projection view to see the desired patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1884615421295166,
            0.8995790481567383
        ],
        "MSU_id": 2015
    },
    {
        "sentence": "The selected district will be highlighted in the motif and pattern glyphs.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 370,
        "paper_id": 4,
        "paragraph_info": "**Pattern filtering.** Users can select a district and filter out the patterns that does not involve the selected district. Moreover, the selected district will be highlighted in the motif and pattern glyphs. Users can also draw a polygon selection on the projection view to see the desired patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.930006504058838,
            1.2028708457946777
        ],
        "MSU_id": 2016
    },
    {
        "sentence": "Users can also draw a polygon selection on the projection view to see the desired patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 370,
        "paper_id": 4,
        "paragraph_info": "**Pattern filtering.** Users can select a district and filter out the patterns that does not involve the selected district. Moreover, the selected district will be highlighted in the motif and pattern glyphs. Users can also draw a polygon selection on the projection view to see the desired patterns.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.4000248908996582,
            1.3283077478408813
        ],
        "MSU_id": 2017
    },
    {
        "sentence": "Users can unfold the motif and pattern glyphs to reveal more details on demand.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 371,
        "paper_id": 4,
        "paragraph_info": "**Hierarchical exploration.** Users can unfold the motif and pattern glyphs to reveal more details on demand. The interesting patterns can be added to the inspection list, where these patterns can be compared side by side and further inspected in the instance view.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.124408483505249,
            0.962008535861969
        ],
        "MSU_id": 2018
    },
    {
        "sentence": "The interesting patterns can be added to the inspection list.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 371,
        "paper_id": 4,
        "paragraph_info": "**Hierarchical exploration.** Users can unfold the motif and pattern glyphs to reveal more details on demand. The interesting patterns can be added to the inspection list, where these patterns can be compared side by side and further inspected in the instance view.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9558143615722656,
            1.094256043434143
        ],
        "MSU_id": 2019
    },
    {
        "sentence": "These patterns can be compared side by side.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 371,
        "paper_id": 4,
        "paragraph_info": "**Hierarchical exploration.** Users can unfold the motif and pattern glyphs to reveal more details on demand. The interesting patterns can be added to the inspection list, where these patterns can be compared side by side and further inspected in the instance view.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.7484625577926636,
            0.7590799927711487
        ],
        "MSU_id": 2020
    },
    {
        "sentence": "These patterns can be further inspected in the instance view.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 371,
        "paper_id": 4,
        "paragraph_info": "**Hierarchical exploration.** Users can unfold the motif and pattern glyphs to reveal more details on demand. The interesting patterns can be added to the inspection list, where these patterns can be compared side by side and further inspected in the instance view.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.126209020614624,
            0.9266830086708069
        ],
        "MSU_id": 2021
    },
    {
        "sentence": "We conducted a training session to walk the experts through our system.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 372,
        "paper_id": 4,
        "paragraph_info": "We demonstrated the effectiveness and usability of AirVis via two case studies and the interviews with three domain experts (EA, EB, and EC). Before the case studies, we conducted a training session to walk the experts through our system, including the visual encodings and user interactions. Thereafter, the experts explored the propagation patterns with the system and investigated their subjects of interest: a) the propagation patterns in the North China Plain, and b) the propagation patterns that involved Beijing. In these case studies, the experts obtained valuable insights that could potentially alleviate the air pollution problem and guide the pollution control policies in China. We then interviewed the experts to collect their comments and feedback.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.6295524835586548,
            0.798585057258606
        ],
        "MSU_id": 2023
    },
    {
        "sentence": "The training session included the visual encodings and user interactions.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 372,
        "paper_id": 4,
        "paragraph_info": "We demonstrated the effectiveness and usability of AirVis via two case studies and the interviews with three domain experts (EA, EB, and EC). Before the case studies, we conducted a training session to walk the experts through our system, including the visual encodings and user interactions. Thereafter, the experts explored the propagation patterns with the system and investigated their subjects of interest: a) the propagation patterns in the North China Plain, and b) the propagation patterns that involved Beijing. In these case studies, the experts obtained valuable insights that could potentially alleviate the air pollution problem and guide the pollution control policies in China. We then interviewed the experts to collect their comments and feedback.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0804460048675537,
            0.54755699634552
        ],
        "MSU_id": 2024
    },
    {
        "sentence": "We then interviewed the experts to collect their comments and feedback.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 372,
        "paper_id": 4,
        "paragraph_info": "We demonstrated the effectiveness and usability of AirVis via two case studies and the interviews with three domain experts (EA, EB, and EC). Before the case studies, we conducted a training session to walk the experts through our system, including the visual encodings and user interactions. Thereafter, the experts explored the propagation patterns with the system and investigated their subjects of interest: a) the propagation patterns in the North China Plain, and b) the propagation patterns that involved Beijing. In these case studies, the experts obtained valuable insights that could potentially alleviate the air pollution problem and guide the pollution control policies in China. We then interviewed the experts to collect their comments and feedback.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2649309635162354,
            1.0890480279922485
        ],
        "MSU_id": 2029
    },
    {
        "sentence": "The projection view captures the similarities of the patterns based on their spatiotemporal contexts.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 374,
        "paper_id": 4,
        "paragraph_info": "The experts opened the system and immediately noticed a heavily colored pattern cluster at the top left of the projection view (Fig. 1A3), which represented a group of patterns with high pollutant concentrations. Given that the projection view captures the similarities of the patterns based on their spatiotemporal contexts, this pattern cluster indicates that the propagation of air pollution with high pollutant concentrations occurs consistently in the same spatiotemporal domain. Such an observation triggered the experts' interest. After these patterns were selected by drawing a polygon, a set of significant motifs were displayed in the motif view (Fig. 1B). Most of these motifs comprised four or even five nodes, indicating that this cluster of propagation patterns involved many districts and covered a large area.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5151928663253784,
            0.9243369698524475
        ],
        "MSU_id": 2036
    },
    {
        "sentence": "After these patterns were selected by drawing a polygon, a set of significant motifs were displayed in the motif view.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 374,
        "paper_id": 4,
        "paragraph_info": "The experts opened the system and immediately noticed a heavily colored pattern cluster at the top left of the projection view (Fig. 1A3), which represented a group of patterns with high pollutant concentrations. Given that the projection view captures the similarities of the patterns based on their spatiotemporal contexts, this pattern cluster indicates that the propagation of air pollution with high pollutant concentrations occurs consistently in the same spatiotemporal domain. Such an observation triggered the experts' interest. After these patterns were selected by drawing a polygon, a set of significant motifs were displayed in the motif view (Fig. 1B). Most of these motifs comprised four or even five nodes, indicating that this cluster of propagation patterns involved many districts and covered a large area.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.50992751121521,
            1.3034919500350952
        ],
        "MSU_id": 2038
    },
    {
        "sentence": "This hypothesis needs to be confirmed with advanced chemical reaction analysis.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 380,
        "paper_id": 4,
        "paragraph_info": "Experts further unfolded these patterns to study their propagation processes. In the pattern graphs illustrated in Fig. [1C](#page-0-0)5 and [1C](#page-0-0)6, two districts, Xinjishi and Xinleshi, were identified as the origins of air pollution. The large sizes of the inner orange circles suggested that these two districts were seriously polluted. Moreover, the pie charts in Fig. [1C](#page-0-0)5 and [1C](#page-0-0)6 indicated that the pollution propagated along two different paths was largely contributed by the pollution in these two districts, which were constantly exposed to the pollution from Shijiazhuang. EA and EB hypothesized that the coal-fired power plants could be a severe air pollution source that had a considerable impact on remote regions. This hypothesis needs to be confirmed with advanced chemical reaction analysis. Moreover, EC also indicated that the pollution in Shijiazhuang might reach northeastern districts, including Beijing and Langfang, via these two paths. Therefore, informed pollution control policies can be made with these patterns, such as suspending a few power plants in Shijiazhuang based on the forecasted wind conditions, which has been proven to be particularly effective [\\[54\\]](#page-10-27).",
        "paper_info": "airvis",
        "2d_coord": [
            1.0996878147125244,
            0.44670170545578003
        ],
        "MSU_id": 2069
    },
    {
        "sentence": "EB selected this motif to obtain the associated patterns.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 381,
        "paper_id": 4,
        "paragraph_info": "Unbalanced motif exploration. EB noticed another stable motif with an interesting structure (Fig. [1B](#page-0-0)2) wherein a district was polluted by the pollutants propagated along two different paths, one of which was relatively long. Such structure indicated that this district had a higher vulnerability to air pollution. EB selected this motif to obtain the associated patterns, where he identified an interesting pattern that occurred in two large cities, Tianjin and Tangshan (Fig. [8A](#page-7-0)1). In the corresponding pattern graph (Fig. [8A](#page-7-0)), the propagation pathways suggested that the pollution in the Binhaixinqu district was likely propagated from the downtown of Tianjin and a remote city, Tangshan. Fig. [8B](#page-7-0) shows the deterioration of air quality among the involved districts is highly correlated in the time ranges enclosed with dashed circles, which confirmed the aforementioned hypothesis. However, EB indicated that alleviating the pollution in Binhaixinqu was especially challenging because such pollution involved multiple sources.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.919227123260498,
            0.6930113434791565
        ],
        "MSU_id": 2076
    },
    {
        "sentence": "The experts tried to answer this question by exploring propagation patterns with AirVis.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 386,
        "paper_id": 4,
        "paragraph_info": "The cause of air pollution in Beijing, the capital of China, still remains controversial [\\[31\\]](#page-9-1). Some researchers concluded that regional transport of PM2*.*<sup>5</sup> is the main cause of air pollution in Beijing, while others attribute the air pollution to local production. The experts tried to answer this question by exploring propagation patterns with AirVis.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1632049083709717,
            0.40282142162323
        ],
        "MSU_id": 2102
    },
    {
        "sentence": "The experts set the time span to winter and increased the threshold of support l*c* to 0.05.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 387,
        "paper_id": 4,
        "paragraph_info": "In particular, they wanted to investigate the significant propagation patterns of air pollution in winter, which is the time when the air pollution in Beijing becomes the most serious. Therefore, the experts set the time span to winter and increased the threshold of support l*c* to 0.05. According to these constraints, a new set of more significant patterns were extracted. The representative air quality station of Beijing is located at Dongchengqu, a center district of Beijing. Hence, the experts filtered out the irrelevant patterns that do not involve Dongchengqu (Fig. [1A](#page-0-0)2). Given that a motif represents multiple topologically identical patterns, the roles of the Dongchengqu in the propagation processes are encoded with the grayness of the corresponding nodes based on the number of topological matches. The experts then identified a group of patterns in which Dongchengqu acted as both of the pollution source affecting several downstream districts and the victim exposed to the air pollutants from upstream districts (Fig. [9A](#page-7-1)). After comparing this group of patterns, the experts disclosed three main",
        "paper_info": "airvis",
        "2d_coord": [
            0.5536644458770752,
            1.048703908920288
        ],
        "MSU_id": 2105
    },
    {
        "sentence": "The experts filtered out the irrelevant patterns that do not involve Dongchengqu.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 387,
        "paper_id": 4,
        "paragraph_info": "In particular, they wanted to investigate the significant propagation patterns of air pollution in winter, which is the time when the air pollution in Beijing becomes the most serious. Therefore, the experts set the time span to winter and increased the threshold of support l*c* to 0.05. According to these constraints, a new set of more significant patterns were extracted. The representative air quality station of Beijing is located at Dongchengqu, a center district of Beijing. Hence, the experts filtered out the irrelevant patterns that do not involve Dongchengqu (Fig. [1A](#page-0-0)2). Given that a motif represents multiple topologically identical patterns, the roles of the Dongchengqu in the propagation processes are encoded with the grayness of the corresponding nodes based on the number of topological matches. The experts then identified a group of patterns in which Dongchengqu acted as both of the pollution source affecting several downstream districts and the victim exposed to the air pollutants from upstream districts (Fig. [9A](#page-7-1)). After comparing this group of patterns, the experts disclosed three main",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0885422229766846,
            0.8276990056037903
        ],
        "MSU_id": 2108
    },
    {
        "sentence": "The roles of Dongchengqu in the propagation processes are encoded with the grayness of the corresponding nodes based on the number of topological matches.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 387,
        "paper_id": 4,
        "paragraph_info": "In particular, they wanted to investigate the significant propagation patterns of air pollution in winter, which is the time when the air pollution in Beijing becomes the most serious. Therefore, the experts set the time span to winter and increased the threshold of support l*c* to 0.05. According to these constraints, a new set of more significant patterns were extracted. The representative air quality station of Beijing is located at Dongchengqu, a center district of Beijing. Hence, the experts filtered out the irrelevant patterns that do not involve Dongchengqu (Fig. [1A](#page-0-0)2). Given that a motif represents multiple topologically identical patterns, the roles of the Dongchengqu in the propagation processes are encoded with the grayness of the corresponding nodes based on the number of topological matches. The experts then identified a group of patterns in which Dongchengqu acted as both of the pollution source affecting several downstream districts and the victim exposed to the air pollutants from upstream districts (Fig. [9A](#page-7-1)). After comparing this group of patterns, the experts disclosed three main",
        "paper_info": "airvis",
        "2d_coord": [
            -0.586878776550293,
            -1.1337885856628418
        ],
        "MSU_id": 2110
    },
    {
        "sentence": "The experts carefully inspected this type of patterns in the instance view to check the detailed effects and transportation times.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 389,
        "paper_id": 4,
        "paragraph_info": "1) From Baoding to Bejing (Fig. [9B](#page-7-1)). There are some patterns starting from Baoding and ending in the downtown of Beijing. The experts learned that the external pollution in Beijing is likely from Baoding, so they carefully inspected this type of patterns in the instance view (Fig. [9E](#page-7-1)) to check the detailed effects and transportation times (Fig. [9E](#page-7-1)1).They found that such patterns would result in severe air pollution along the propagation pathway, as shown in the temporal distribution of air quality (enclosed in dashed circles in Fig. [9E](#page-7-1)). By accumulating the average of three transportation time boxplots in Fig. [9E](#page-7-1)1, the experts inferred that the pollution in Baoding will be propagated to Beijing in approximately 7 hours. This information is critical for the local authorities to issue early air quality warnings.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.103250741958618,
            0.9003216624259949
        ],
        "MSU_id": 2116
    },
    {
        "sentence": "The experts investigated this pattern extensively in the instance view.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 391,
        "paper_id": 4,
        "paragraph_info": "3) From Beijing to Huailaixian (Fig. [9D](#page-7-1)). In addition, the pollution in Beijing also affected Huailaixian in the northwest region. According to EA, Huailaixian is a clean city without heavy local emissions. The pie charts in the pattern graphs (Fig. [9D](#page-7-1)1) implied that less than the half of the pollutants from Beijing had caused a large portion of the pollution in Huailaixian. The experts also investigated this pattern extensively in the instance view and confirmed the hypothesis.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0783166885375977,
            1.1175217628479004
        ],
        "MSU_id": 2133
    },
    {
        "sentence": "AirVis uses motif glyphs, pattern glyphs, and pattern graphs to present detailed information of propagation instances.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 394,
        "paper_id": 4,
        "paragraph_info": "Visual design. All three experts agreed that AirVis could intuitively depict the complex propagation processes of air pollution with the motif glyphs, pattern glyphs, and pattern graphs, and present the detailed information of propagation instances in terms of both spatial and temporal dimensions. \"*Many interesting patterns are revealed with the topology-pattern-instance hierarchy.*\" commented EA, \"*I believe our current studies will benefit from this system.*\" EA and EB also praised our system for being \"*aesthetically appealing*\".",
        "paper_info": "airvis",
        "2d_coord": [
            -2.3909413814544678,
            0.6750083565711975
        ],
        "MSU_id": 2143
    },
    {
        "sentence": "AirVis presents information in terms of both spatial and temporal dimensions.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 394,
        "paper_id": 4,
        "paragraph_info": "Visual design. All three experts agreed that AirVis could intuitively depict the complex propagation processes of air pollution with the motif glyphs, pattern glyphs, and pattern graphs, and present the detailed information of propagation instances in terms of both spatial and temporal dimensions. \"*Many interesting patterns are revealed with the topology-pattern-instance hierarchy.*\" commented EA, \"*I believe our current studies will benefit from this system.*\" EA and EB also praised our system for being \"*aesthetically appealing*\".",
        "paper_info": "airvis",
        "2d_coord": [
            -0.3750784695148468,
            -1.9661842584609985
        ],
        "MSU_id": 2144
    },
    {
        "sentence": "EC could specify a PM2*.*<sup>5</sup> threshold and the system would return the extracted propagation patterns in real-time.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 395,
        "paper_id": 4,
        "paragraph_info": "User interactions. All three experts indicated that the interactions implemented in our system were very smooth. EC was particularly impressed by the interactive pattern mining, where he could specify a PM2*.*<sup>5</sup> threshold and the system would return the extracted propagation patterns in real-time. Moreover, EA and EB found that the district filter was highly convenient in the district-centered analysis.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.805037021636963,
            -0.054976291954517365
        ],
        "MSU_id": 2150
    },
    {
        "sentence": "EC suggested that we could further improve the transportation simulation by adopting an ensemble model.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 396,
        "paper_id": 4,
        "paragraph_info": "Usability. All three experts confirmed the usability of our system. \"*The spatial granularity is much finer than the existing approaches, which makes it possible to obtain deeper insights with this system.*\" commented EC. Furthermore, EC suggested that we could further improve the transportation simulation by adopting an ensemble model that incorporates the results generated by HYSPLIT [\\[52\\]](#page-9-3).",
        "paper_info": "airvis",
        "2d_coord": [
            -0.19725166261196136,
            -1.5619584321975708
        ],
        "MSU_id": 2155
    },
    {
        "sentence": "The ensemble model should incorporate the results generated by HYSPLIT.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 396,
        "paper_id": 4,
        "paragraph_info": "Usability. All three experts confirmed the usability of our system. \"*The spatial granularity is much finer than the existing approaches, which makes it possible to obtain deeper insights with this system.*\" commented EC. Furthermore, EC suggested that we could further improve the transportation simulation by adopting an ensemble model that incorporates the results generated by HYSPLIT [\\[52\\]](#page-9-3).",
        "paper_info": "airvis",
        "2d_coord": [
            -0.20624025166034698,
            -2.1177258491516113
        ],
        "MSU_id": 2156
    },
    {
        "sentence": "Our work improves the spatial granularity of air pollution propagation analysis to the station level.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 398,
        "paper_id": 4,
        "paragraph_info": "Implications. To the best of our knowledge, AirVis is the first visual analytics system that efficiently incorporates users' expertise in the domain of air pollution propagation analysis. The availability of AirVis significantly promotes the efficient exploration of large-scale pollution propagation data and the acquisition of deep insights into the uncertain propagation patterns. Moreover, our work is largely distinguished from the state-of-the-art approaches by improving the spatial granularity of air pollution propagation analysis to the station level and the temporal granularity to an hourly resolution, and the topology detection and",
        "paper_info": "airvis",
        "2d_coord": [
            -2.409940242767334,
            0.09502315521240234
        ],
        "MSU_id": 2162
    },
    {
        "sentence": "Our work improves the temporal granularity of air pollution propagation analysis to an hourly resolution.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 398,
        "paper_id": 4,
        "paragraph_info": "Implications. To the best of our knowledge, AirVis is the first visual analytics system that efficiently incorporates users' expertise in the domain of air pollution propagation analysis. The availability of AirVis significantly promotes the efficient exploration of large-scale pollution propagation data and the acquisition of deep insights into the uncertain propagation patterns. Moreover, our work is largely distinguished from the state-of-the-art approaches by improving the spatial granularity of air pollution propagation analysis to the station level and the temporal granularity to an hourly resolution, and the topology detection and",
        "paper_info": "airvis",
        "2d_coord": [
            -2.4323902130126953,
            -0.0017783790826797485
        ],
        "MSU_id": 2163
    },
    {
        "sentence": "Our system provides uncertainty analysis features.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 399,
        "paper_id": 4,
        "paragraph_info": "uncertainty analysis features provided by our system enable experts to identify and analyze new propagation patterns more effectively compared with the existing tools. Such fine-grained analysis allows our system to precisely capture the continuous propagation of air pollution and facilitate the development of timely and accurate pollution control policies, which may help reduce economic losses and even save lives.",
        "paper_info": "airvis",
        "2d_coord": [
            0.02984188124537468,
            -1.4063689708709717
        ],
        "MSU_id": 2165
    },
    {
        "sentence": "Applying the MDL principle in extracting motifs effectively reduces the number of graphs.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 400,
        "paper_id": 4,
        "paragraph_info": "Our approach can be generalized to address the similar problems that involve the topology-driven analysis of massive small graphs. Applying the MDL principle in extracting motifs effectively reduces the number of graphs and summarizes these graphs by their corresponding topological representations with the corrections as visual hints. In addition, the hierarchical exploration scheme we followed while designing our system largely allievates users' cognitive load in analyzing numerous graphs and enables users to progressively obtain the overview of the patterns and analyze the interesting details on demand.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.2446038722991943,
            0.7817173004150391
        ],
        "MSU_id": 2171
    },
    {
        "sentence": "The MDL principle summarizes these graphs by their corresponding topological representations with corrections as visual hints.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 400,
        "paper_id": 4,
        "paragraph_info": "Our approach can be generalized to address the similar problems that involve the topology-driven analysis of massive small graphs. Applying the MDL principle in extracting motifs effectively reduces the number of graphs and summarizes these graphs by their corresponding topological representations with the corrections as visual hints. In addition, the hierarchical exploration scheme we followed while designing our system largely allievates users' cognitive load in analyzing numerous graphs and enables users to progressively obtain the overview of the patterns and analyze the interesting details on demand.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0857644081115723,
            0.9752461314201355
        ],
        "MSU_id": 2172
    },
    {
        "sentence": "The hierarchical exploration scheme we followed while designing our system alleviates users' cognitive load in analyzing numerous graphs.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 400,
        "paper_id": 4,
        "paragraph_info": "Our approach can be generalized to address the similar problems that involve the topology-driven analysis of massive small graphs. Applying the MDL principle in extracting motifs effectively reduces the number of graphs and summarizes these graphs by their corresponding topological representations with the corrections as visual hints. In addition, the hierarchical exploration scheme we followed while designing our system largely allievates users' cognitive load in analyzing numerous graphs and enables users to progressively obtain the overview of the patterns and analyze the interesting details on demand.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0008418560028076,
            1.2087734937667847
        ],
        "MSU_id": 2173
    },
    {
        "sentence": "The hierarchical exploration scheme enables users to progressively obtain an overview of the patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 400,
        "paper_id": 4,
        "paragraph_info": "Our approach can be generalized to address the similar problems that involve the topology-driven analysis of massive small graphs. Applying the MDL principle in extracting motifs effectively reduces the number of graphs and summarizes these graphs by their corresponding topological representations with the corrections as visual hints. In addition, the hierarchical exploration scheme we followed while designing our system largely allievates users' cognitive load in analyzing numerous graphs and enables users to progressively obtain the overview of the patterns and analyze the interesting details on demand.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.714187741279602,
            1.2807096242904663
        ],
        "MSU_id": 2174
    },
    {
        "sentence": "The hierarchical exploration scheme allows users to analyze interesting details on demand.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 400,
        "paper_id": 4,
        "paragraph_info": "Our approach can be generalized to address the similar problems that involve the topology-driven analysis of massive small graphs. Applying the MDL principle in extracting motifs effectively reduces the number of graphs and summarizes these graphs by their corresponding topological representations with the corrections as visual hints. In addition, the hierarchical exploration scheme we followed while designing our system largely allievates users' cognitive load in analyzing numerous graphs and enables users to progressively obtain the overview of the patterns and analyze the interesting details on demand.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5581238269805908,
            1.1822959184646606
        ],
        "MSU_id": 2175
    },
    {
        "sentence": "A vectorized wind field is reconstructed from sparse meteorological samples to simulate the air pollutant transportation.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 401,
        "paper_id": 4,
        "paragraph_info": "Limitations. Three limitations are observed in our work. First, a vectorized wind field is reconstructed from sparse meteorological samples to simulate the air pollutant transportation. The sparsity may result in noticeable inaccuracies in the simulation, particularly in the areas with complex geographical conditions. This limitation can be addressed by incorporating the fine-grained wind field data or a more sophisticated interpolation method based on the terrain data. Second, the distance thresholds used in the pollutant transportation modelling is determined in advance based on the experts' knowledge and the density of monitoring stations. To establish more accurate modelling, an interactive interface can be incorporated in the future work to allow users to fine-tune the thresholds. Third, our approach simply estimates the transported pollutants as a quantitative value, while the experts are also interested in breaking down the value to find the actual sources of air pollution (e.g., vehicles or factories). Source apportionment methods [\\[7\\]](#page-9-52) can be incorporated in the future for such functionality.",
        "paper_info": "airvis",
        "2d_coord": [
            0.2318887859582901,
            -1.1171916723251343
        ],
        "MSU_id": 2177
    },
    {
        "sentence": "This limitation can be addressed by incorporating the fine-grained wind field data or a more sophisticated interpolation method based on the terrain data.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 401,
        "paper_id": 4,
        "paragraph_info": "Limitations. Three limitations are observed in our work. First, a vectorized wind field is reconstructed from sparse meteorological samples to simulate the air pollutant transportation. The sparsity may result in noticeable inaccuracies in the simulation, particularly in the areas with complex geographical conditions. This limitation can be addressed by incorporating the fine-grained wind field data or a more sophisticated interpolation method based on the terrain data. Second, the distance thresholds used in the pollutant transportation modelling is determined in advance based on the experts' knowledge and the density of monitoring stations. To establish more accurate modelling, an interactive interface can be incorporated in the future work to allow users to fine-tune the thresholds. Third, our approach simply estimates the transported pollutants as a quantitative value, while the experts are also interested in breaking down the value to find the actual sources of air pollution (e.g., vehicles or factories). Source apportionment methods [\\[7\\]](#page-9-52) can be incorporated in the future for such functionality.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.832112729549408,
            -0.4239034652709961
        ],
        "MSU_id": 2179
    },
    {
        "sentence": "The distance thresholds used in the pollutant transportation modelling are determined in advance based on the experts' knowledge and the density of monitoring stations.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 401,
        "paper_id": 4,
        "paragraph_info": "Limitations. Three limitations are observed in our work. First, a vectorized wind field is reconstructed from sparse meteorological samples to simulate the air pollutant transportation. The sparsity may result in noticeable inaccuracies in the simulation, particularly in the areas with complex geographical conditions. This limitation can be addressed by incorporating the fine-grained wind field data or a more sophisticated interpolation method based on the terrain data. Second, the distance thresholds used in the pollutant transportation modelling is determined in advance based on the experts' knowledge and the density of monitoring stations. To establish more accurate modelling, an interactive interface can be incorporated in the future work to allow users to fine-tune the thresholds. Third, our approach simply estimates the transported pollutants as a quantitative value, while the experts are also interested in breaking down the value to find the actual sources of air pollution (e.g., vehicles or factories). Source apportionment methods [\\[7\\]](#page-9-52) can be incorporated in the future for such functionality.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.5058908462524414,
            -0.16385704278945923
        ],
        "MSU_id": 2180
    },
    {
        "sentence": "An interactive interface can be incorporated in the future work to allow users to fine-tune the thresholds.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 401,
        "paper_id": 4,
        "paragraph_info": "Limitations. Three limitations are observed in our work. First, a vectorized wind field is reconstructed from sparse meteorological samples to simulate the air pollutant transportation. The sparsity may result in noticeable inaccuracies in the simulation, particularly in the areas with complex geographical conditions. This limitation can be addressed by incorporating the fine-grained wind field data or a more sophisticated interpolation method based on the terrain data. Second, the distance thresholds used in the pollutant transportation modelling is determined in advance based on the experts' knowledge and the density of monitoring stations. To establish more accurate modelling, an interactive interface can be incorporated in the future work to allow users to fine-tune the thresholds. Third, our approach simply estimates the transported pollutants as a quantitative value, while the experts are also interested in breaking down the value to find the actual sources of air pollution (e.g., vehicles or factories). Source apportionment methods [\\[7\\]](#page-9-52) can be incorporated in the future for such functionality.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.109816789627075,
            0.13380002975463867
        ],
        "MSU_id": 2181
    },
    {
        "sentence": "Source apportionment methods can be incorporated in the future for such functionality.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 401,
        "paper_id": 4,
        "paragraph_info": "Limitations. Three limitations are observed in our work. First, a vectorized wind field is reconstructed from sparse meteorological samples to simulate the air pollutant transportation. The sparsity may result in noticeable inaccuracies in the simulation, particularly in the areas with complex geographical conditions. This limitation can be addressed by incorporating the fine-grained wind field data or a more sophisticated interpolation method based on the terrain data. Second, the distance thresholds used in the pollutant transportation modelling is determined in advance based on the experts' knowledge and the density of monitoring stations. To establish more accurate modelling, an interactive interface can be incorporated in the future work to allow users to fine-tune the thresholds. Third, our approach simply estimates the transported pollutants as a quantitative value, while the experts are also interested in breaking down the value to find the actual sources of air pollution (e.g., vehicles or factories). Source apportionment methods [\\[7\\]](#page-9-52) can be incorporated in the future for such functionality.",
        "paper_info": "airvis",
        "2d_coord": [
            0.13717961311340332,
            -0.979619562625885
        ],
        "MSU_id": 2184
    },
    {
        "sentence": "We address the scalability issue that impedes the perception of significant patterns.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 402,
        "paper_id": 4,
        "paragraph_info": "Design lessons. We conclude our design lessons learned from the presentation of massive propagation networks. To address the scalability issue that impedes the perception of significant patterns therein, we organize the propagation graphs in a stratified way that utilizes their innate hierarchy of common topology, frequent patterns, and instances, and design visualizations accordingly to support leveled exploration that imposes less cognitive load on users. Moreover, we visualize the frequent motifs and patterns with carefully designed glyphs that compactly summarize their attributes, empowering users to effectively analyze data from multiple perspectives. The detailed instances are expanded on demand. This approach coincides in spirit with the visual information-seeking mantra [\\[51\\]](#page-9-4) and once again confirms its effectiveness in guiding the exploration of complex datasets.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.1945416927337646,
            0.7461376190185547
        ],
        "MSU_id": 2186
    },
    {
        "sentence": "We organize the propagation graphs in a stratified way that utilizes their innate hierarchy.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 402,
        "paper_id": 4,
        "paragraph_info": "Design lessons. We conclude our design lessons learned from the presentation of massive propagation networks. To address the scalability issue that impedes the perception of significant patterns therein, we organize the propagation graphs in a stratified way that utilizes their innate hierarchy of common topology, frequent patterns, and instances, and design visualizations accordingly to support leveled exploration that imposes less cognitive load on users. Moreover, we visualize the frequent motifs and patterns with carefully designed glyphs that compactly summarize their attributes, empowering users to effectively analyze data from multiple perspectives. The detailed instances are expanded on demand. This approach coincides in spirit with the visual information-seeking mantra [\\[51\\]](#page-9-4) and once again confirms its effectiveness in guiding the exploration of complex datasets.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.0461490154266357,
            0.10491659492254257
        ],
        "MSU_id": 2187
    },
    {
        "sentence": "We design visualizations accordingly to support leveled exploration that imposes less cognitive load on users.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 402,
        "paper_id": 4,
        "paragraph_info": "Design lessons. We conclude our design lessons learned from the presentation of massive propagation networks. To address the scalability issue that impedes the perception of significant patterns therein, we organize the propagation graphs in a stratified way that utilizes their innate hierarchy of common topology, frequent patterns, and instances, and design visualizations accordingly to support leveled exploration that imposes less cognitive load on users. Moreover, we visualize the frequent motifs and patterns with carefully designed glyphs that compactly summarize their attributes, empowering users to effectively analyze data from multiple perspectives. The detailed instances are expanded on demand. This approach coincides in spirit with the visual information-seeking mantra [\\[51\\]](#page-9-4) and once again confirms its effectiveness in guiding the exploration of complex datasets.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.984591007232666,
            1.6239200830459595
        ],
        "MSU_id": 2188
    },
    {
        "sentence": "We visualize the frequent motifs and patterns with carefully designed glyphs.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 402,
        "paper_id": 4,
        "paragraph_info": "Design lessons. We conclude our design lessons learned from the presentation of massive propagation networks. To address the scalability issue that impedes the perception of significant patterns therein, we organize the propagation graphs in a stratified way that utilizes their innate hierarchy of common topology, frequent patterns, and instances, and design visualizations accordingly to support leveled exploration that imposes less cognitive load on users. Moreover, we visualize the frequent motifs and patterns with carefully designed glyphs that compactly summarize their attributes, empowering users to effectively analyze data from multiple perspectives. The detailed instances are expanded on demand. This approach coincides in spirit with the visual information-seeking mantra [\\[51\\]](#page-9-4) and once again confirms its effectiveness in guiding the exploration of complex datasets.",
        "paper_info": "airvis",
        "2d_coord": [
            -1.9830408096313477,
            1.2053896188735962
        ],
        "MSU_id": 2189
    },
    {
        "sentence": "The detailed instances are expanded on demand.",
        "category": "Method",
        "rank": 3,
        "type": "text",
        "para_id": 402,
        "paper_id": 4,
        "paragraph_info": "Design lessons. We conclude our design lessons learned from the presentation of massive propagation networks. To address the scalability issue that impedes the perception of significant patterns therein, we organize the propagation graphs in a stratified way that utilizes their innate hierarchy of common topology, frequent patterns, and instances, and design visualizations accordingly to support leveled exploration that imposes less cognitive load on users. Moreover, we visualize the frequent motifs and patterns with carefully designed glyphs that compactly summarize their attributes, empowering users to effectively analyze data from multiple perspectives. The detailed instances are expanded on demand. This approach coincides in spirit with the visual information-seeking mantra [\\[51\\]](#page-9-4) and once again confirms its effectiveness in guiding the exploration of complex datasets.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.7765517234802246,
            0.4500519335269928
        ],
        "MSU_id": 2192
    },
    {
        "sentence": "We propose a novel visual analytics approach to incorporate domain knowledge in analyzing the uncertain propagation of air pollution.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 403,
        "paper_id": 4,
        "paragraph_info": "In this study, we propose a novel visual analytics approach to incorporate domain knowledge in analyzing the uncertain propagation of air pollution. By closely collaborating with the experts, we characterized the user requirements in the topology-driven analysis of propagation processes and derived a set of extensive design goals accordingly to guide the subsequent visual design. Based on the requirements and design goals, we developed AirVis, a visual analytics system that assists users in hierarchically exploring and interpreting massive propagation patterns extracted with a novel FSM-based pattern mining framework. The effectiveness of our system is demonstrated via two case studies conducted on the real-world dataset and the positive feedback received from the experts. Our approach is also generalizable to other similar problems that involve the topology-driven analysis of massive small graphs. In the future, we would like to incorporate fine-grained atmospheric data to obtain more accurate results and deploy our system in the field to reveal the insights in pollution propagation to a wider audience, including environmental scientists and government officials.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.4821205139160156,
            0.3174891769886017
        ],
        "MSU_id": 2195
    },
    {
        "sentence": "We derived a set of extensive design goals to guide the subsequent visual design.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 403,
        "paper_id": 4,
        "paragraph_info": "In this study, we propose a novel visual analytics approach to incorporate domain knowledge in analyzing the uncertain propagation of air pollution. By closely collaborating with the experts, we characterized the user requirements in the topology-driven analysis of propagation processes and derived a set of extensive design goals accordingly to guide the subsequent visual design. Based on the requirements and design goals, we developed AirVis, a visual analytics system that assists users in hierarchically exploring and interpreting massive propagation patterns extracted with a novel FSM-based pattern mining framework. The effectiveness of our system is demonstrated via two case studies conducted on the real-world dataset and the positive feedback received from the experts. Our approach is also generalizable to other similar problems that involve the topology-driven analysis of massive small graphs. In the future, we would like to incorporate fine-grained atmospheric data to obtain more accurate results and deploy our system in the field to reveal the insights in pollution propagation to a wider audience, including environmental scientists and government officials.",
        "paper_info": "airvis",
        "2d_coord": [
            -0.9994440078735352,
            0.9431571364402771
        ],
        "MSU_id": 2197
    },
    {
        "sentence": "We developed AirVis, a visual analytics system that assists users in hierarchically exploring and interpreting massive propagation patterns.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 403,
        "paper_id": 4,
        "paragraph_info": "In this study, we propose a novel visual analytics approach to incorporate domain knowledge in analyzing the uncertain propagation of air pollution. By closely collaborating with the experts, we characterized the user requirements in the topology-driven analysis of propagation processes and derived a set of extensive design goals accordingly to guide the subsequent visual design. Based on the requirements and design goals, we developed AirVis, a visual analytics system that assists users in hierarchically exploring and interpreting massive propagation patterns extracted with a novel FSM-based pattern mining framework. The effectiveness of our system is demonstrated via two case studies conducted on the real-world dataset and the positive feedback received from the experts. Our approach is also generalizable to other similar problems that involve the topology-driven analysis of massive small graphs. In the future, we would like to incorporate fine-grained atmospheric data to obtain more accurate results and deploy our system in the field to reveal the insights in pollution propagation to a wider audience, including environmental scientists and government officials.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.4440298080444336,
            0.7836429476737976
        ],
        "MSU_id": 2198
    },
    {
        "sentence": "The propagation patterns are extracted with a novel FSM-based pattern mining framework.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 403,
        "paper_id": 4,
        "paragraph_info": "In this study, we propose a novel visual analytics approach to incorporate domain knowledge in analyzing the uncertain propagation of air pollution. By closely collaborating with the experts, we characterized the user requirements in the topology-driven analysis of propagation processes and derived a set of extensive design goals accordingly to guide the subsequent visual design. Based on the requirements and design goals, we developed AirVis, a visual analytics system that assists users in hierarchically exploring and interpreting massive propagation patterns extracted with a novel FSM-based pattern mining framework. The effectiveness of our system is demonstrated via two case studies conducted on the real-world dataset and the positive feedback received from the experts. Our approach is also generalizable to other similar problems that involve the topology-driven analysis of massive small graphs. In the future, we would like to incorporate fine-grained atmospheric data to obtain more accurate results and deploy our system in the field to reveal the insights in pollution propagation to a wider audience, including environmental scientists and government officials.",
        "paper_info": "airvis",
        "2d_coord": [
            -2.246121644973755,
            0.22022217512130737
        ],
        "MSU_id": 2199
    },
    {
        "sentence": "This study proposed an efficient visualization method to represent spatio-temporal information in air pollution data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 405,
        "paper_id": 5,
        "paragraph_info": "**Abstract:** In recent years, frequent occurrences of significant air pollution events in China have routinely caused panic and are a major topic of discussion by the public and air pollution experts in government and academia. Therefore, this study proposed an efficient visualization method to represent directly, quickly, and clearly the spatio-temporal information contained in air pollution data. Data quality check and cleansing during a preliminary visual analysis is presented in tabular form, heat matrix, or line chart, upon which hypotheses can be deduced. Further visualizations were designed to verify the hypotheses and obtain useful findings. This method was tested and validated in a year-long case study of the air quality index (AQI of PM2.5) in Beijing, China. We found that PM2.5, PM10, and NO<sup>2</sup> may be emitted by the same sources, and strong winds may accelerate the spread of pollutants. The average concentration of PM2.5 in Beijing was greater than the AQI value of 50 over the six-year study period. Furthermore, arable lands exhibited considerably higher concentrations of air pollutants than vegetation-covered areas. The findings of this study showed that our visualization method is intuitive and reliable through data quality checking and information sharing with multi-perspective air pollution graphs. This method allows the data to be easily understood by the public and inspire or aid further studies in other fields.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.9905593395233154,
            0.4917536973953247
        ],
        "MSU_id": 2212
    },
    {
        "sentence": "Data quality check and cleansing during a preliminary visual analysis is presented in tabular form, heat matrix, or line chart.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 405,
        "paper_id": 5,
        "paragraph_info": "**Abstract:** In recent years, frequent occurrences of significant air pollution events in China have routinely caused panic and are a major topic of discussion by the public and air pollution experts in government and academia. Therefore, this study proposed an efficient visualization method to represent directly, quickly, and clearly the spatio-temporal information contained in air pollution data. Data quality check and cleansing during a preliminary visual analysis is presented in tabular form, heat matrix, or line chart, upon which hypotheses can be deduced. Further visualizations were designed to verify the hypotheses and obtain useful findings. This method was tested and validated in a year-long case study of the air quality index (AQI of PM2.5) in Beijing, China. We found that PM2.5, PM10, and NO<sup>2</sup> may be emitted by the same sources, and strong winds may accelerate the spread of pollutants. The average concentration of PM2.5 in Beijing was greater than the AQI value of 50 over the six-year study period. Furthermore, arable lands exhibited considerably higher concentrations of air pollutants than vegetation-covered areas. The findings of this study showed that our visualization method is intuitive and reliable through data quality checking and information sharing with multi-perspective air pollution graphs. This method allows the data to be easily understood by the public and inspire or aid further studies in other fields.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.5473074913024902,
            1.6073178052902222
        ],
        "MSU_id": 2213
    },
    {
        "sentence": "Further visualizations were designed to verify the hypotheses and obtain useful findings.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 405,
        "paper_id": 5,
        "paragraph_info": "**Abstract:** In recent years, frequent occurrences of significant air pollution events in China have routinely caused panic and are a major topic of discussion by the public and air pollution experts in government and academia. Therefore, this study proposed an efficient visualization method to represent directly, quickly, and clearly the spatio-temporal information contained in air pollution data. Data quality check and cleansing during a preliminary visual analysis is presented in tabular form, heat matrix, or line chart, upon which hypotheses can be deduced. Further visualizations were designed to verify the hypotheses and obtain useful findings. This method was tested and validated in a year-long case study of the air quality index (AQI of PM2.5) in Beijing, China. We found that PM2.5, PM10, and NO<sup>2</sup> may be emitted by the same sources, and strong winds may accelerate the spread of pollutants. The average concentration of PM2.5 in Beijing was greater than the AQI value of 50 over the six-year study period. Furthermore, arable lands exhibited considerably higher concentrations of air pollutants than vegetation-covered areas. The findings of this study showed that our visualization method is intuitive and reliable through data quality checking and information sharing with multi-perspective air pollution graphs. This method allows the data to be easily understood by the public and inspire or aid further studies in other fields.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.9115761518478394,
            1.492677092552185
        ],
        "MSU_id": 2215
    },
    {
        "sentence": "Different approaches have been attempted to solve the problem of air pollution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 407,
        "paper_id": 5,
        "paragraph_info": "Since 2011, frequent occurrences of haze in China have become a cause for panic and routinely appear as a major topic in the media and on climate websites [\\[1,](#page-17-0)[2\\]](#page-17-1). Thus, considerable research in various fields has focused on air pollution, attempting to solve the problem with different approaches [\\[3\u2013](#page-17-2)[8\\]](#page-18-0). Nevertheless, in many instances, the methods are not completely intuitive and are difficult for governmental officials and the general public to understand. Visual exploration [\\[9](#page-18-1)[\u201314\\]](#page-18-2) of air pollution with spatio-temporal data is a solution that makes complex data understandable because graphical representation is relatively intuitive.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.4847780466079712,
            1.2012659311294556
        ],
        "MSU_id": 2227
    },
    {
        "sentence": "Visual exploration of air pollution with spatio-temporal data is a solution.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 407,
        "paper_id": 5,
        "paragraph_info": "Since 2011, frequent occurrences of haze in China have become a cause for panic and routinely appear as a major topic in the media and on climate websites [\\[1,](#page-17-0)[2\\]](#page-17-1). Thus, considerable research in various fields has focused on air pollution, attempting to solve the problem with different approaches [\\[3\u2013](#page-17-2)[8\\]](#page-18-0). Nevertheless, in many instances, the methods are not completely intuitive and are difficult for governmental officials and the general public to understand. Visual exploration [\\[9](#page-18-1)[\u201314\\]](#page-18-2) of air pollution with spatio-temporal data is a solution that makes complex data understandable because graphical representation is relatively intuitive.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -2.1185836791992188,
            0.3843756318092346
        ],
        "MSU_id": 2230
    },
    {
        "sentence": "These parameters are usually measured using air quality index (AQI).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 408,
        "paper_id": 5,
        "paragraph_info": "Atmospheric particulate matter is a commonly used criterion to evaluate air quality [\\[7](#page-17-3)[,15,](#page-18-3)[16\\]](#page-18-4). The degree of adverse health effects depends on the size and composition of the particles [\\[16\\]](#page-18-4). PM2.5 and PM<sup>10</sup> are defined as particles with diameters of 2.5 \u00b5m or less and 10 \u00b5m or less, respectively; these parameters are usually measured using air quality index (AQI). AQIs are calculated from the particle concentration at monitoring stations expressed as micrograms per cubic meter [\\[17\\]](#page-18-5). According to the technical regulation on ambient air quality index (on trial) [\\[18\\]](#page-18-6), the air pollution index for PM2.5 is divided into six levels, namely, 0\u201350, 51\u2013100, 101\u2013150, 151\u2013200, 201\u2013300, and greater than 300. With these levels, we can identify the severity of air pollution.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.7313427925109863,
            -1.8118970394134521
        ],
        "MSU_id": 2236
    },
    {
        "sentence": "AQIs are calculated from the particle concentration at monitoring stations expressed as micrograms per cubic meter.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 408,
        "paper_id": 5,
        "paragraph_info": "Atmospheric particulate matter is a commonly used criterion to evaluate air quality [\\[7](#page-17-3)[,15,](#page-18-3)[16\\]](#page-18-4). The degree of adverse health effects depends on the size and composition of the particles [\\[16\\]](#page-18-4). PM2.5 and PM<sup>10</sup> are defined as particles with diameters of 2.5 \u00b5m or less and 10 \u00b5m or less, respectively; these parameters are usually measured using air quality index (AQI). AQIs are calculated from the particle concentration at monitoring stations expressed as micrograms per cubic meter [\\[17\\]](#page-18-5). According to the technical regulation on ambient air quality index (on trial) [\\[18\\]](#page-18-6), the air pollution index for PM2.5 is divided into six levels, namely, 0\u201350, 51\u2013100, 101\u2013150, 151\u2013200, 201\u2013300, and greater than 300. With these levels, we can identify the severity of air pollution.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.9616520404815674,
            -0.18960800766944885
        ],
        "MSU_id": 2237
    },
    {
        "sentence": "Examining air composition with related chemometric techniques can achieve effective analysis of pollutant sources.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 409,
        "paper_id": 5,
        "paragraph_info": "Literature on chemical and remote-sensing fields greatly contributes to air pollution analysis. Examining air composition with related chemometric techniques can achieve effective analysis of pollutant sources [\\[19\\]](#page-18-7), which is suitable for micro and local level analyses but is not satisfactory for spatio-temporal pattern exploration of larger areas. Satellite remote-sensing assessment, subsequent mapping of the spatial distribution of aerosols [\\[4,](#page-17-4)[20\\]](#page-18-8), and air pollution data measured by satellite-borne sensors or ground-based monitoring stations [\\[21,](#page-18-9)[22\\]](#page-18-10) identified a strong relationship between PM2.5 and PM10. However, complicated calibration and data processing are executed with professional software, most of which are standalone and specialized and thus cannot be easily understood or shared with the general public.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            1.0979220867156982,
            -1.3610634803771973
        ],
        "MSU_id": 2242
    },
    {
        "sentence": "Satellite remote-sensing assessment maps the spatial distribution of aerosols.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 409,
        "paper_id": 5,
        "paragraph_info": "Literature on chemical and remote-sensing fields greatly contributes to air pollution analysis. Examining air composition with related chemometric techniques can achieve effective analysis of pollutant sources [\\[19\\]](#page-18-7), which is suitable for micro and local level analyses but is not satisfactory for spatio-temporal pattern exploration of larger areas. Satellite remote-sensing assessment, subsequent mapping of the spatial distribution of aerosols [\\[4,](#page-17-4)[20\\]](#page-18-8), and air pollution data measured by satellite-borne sensors or ground-based monitoring stations [\\[21,](#page-18-9)[22\\]](#page-18-10) identified a strong relationship between PM2.5 and PM10. However, complicated calibration and data processing are executed with professional software, most of which are standalone and specialized and thus cannot be easily understood or shared with the general public.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.21486102044582367,
            -0.10180339962244034
        ],
        "MSU_id": 2244
    },
    {
        "sentence": "Air pollution data is measured by satellite-borne sensors or ground-based monitoring stations.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 409,
        "paper_id": 5,
        "paragraph_info": "Literature on chemical and remote-sensing fields greatly contributes to air pollution analysis. Examining air composition with related chemometric techniques can achieve effective analysis of pollutant sources [\\[19\\]](#page-18-7), which is suitable for micro and local level analyses but is not satisfactory for spatio-temporal pattern exploration of larger areas. Satellite remote-sensing assessment, subsequent mapping of the spatial distribution of aerosols [\\[4,](#page-17-4)[20\\]](#page-18-8), and air pollution data measured by satellite-borne sensors or ground-based monitoring stations [\\[21,](#page-18-9)[22\\]](#page-18-10) identified a strong relationship between PM2.5 and PM10. However, complicated calibration and data processing are executed with professional software, most of which are standalone and specialized and thus cannot be easily understood or shared with the general public.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.9802051782608032,
            -1.7223585844039917
        ],
        "MSU_id": 2245
    },
    {
        "sentence": "Complicated calibration and data processing are executed with professional software.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 409,
        "paper_id": 5,
        "paragraph_info": "Literature on chemical and remote-sensing fields greatly contributes to air pollution analysis. Examining air composition with related chemometric techniques can achieve effective analysis of pollutant sources [\\[19\\]](#page-18-7), which is suitable for micro and local level analyses but is not satisfactory for spatio-temporal pattern exploration of larger areas. Satellite remote-sensing assessment, subsequent mapping of the spatial distribution of aerosols [\\[4,](#page-17-4)[20\\]](#page-18-8), and air pollution data measured by satellite-borne sensors or ground-based monitoring stations [\\[21,](#page-18-9)[22\\]](#page-18-10) identified a strong relationship between PM2.5 and PM10. However, complicated calibration and data processing are executed with professional software, most of which are standalone and specialized and thus cannot be easily understood or shared with the general public.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.3810417354106903,
            -0.8008372187614441
        ],
        "MSU_id": 2247
    },
    {
        "sentence": "Technologies used in interactive visualizations include HTML for page content, CSS for aesthetics, JavaScript for interaction, and SVG for vector graphics.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 410,
        "paper_id": 5,
        "paragraph_info": "By dealing with graphical representations of complex data, conventional plots, such as scatter plot, are used to analyze time-series data and show the correlation among various factors in air pollution exploration [\\[7,](#page-17-3)[23\\]](#page-18-11). These plots are simple and have been widely used for a long time, but they cannot effectively express spatial relationships and are less attractive than the newer multi-perspective visualizations and graphs. Moreover, the rapid development of web technology allows interactive visualizations to combine various technologies [\\[24\\]](#page-18-12), such as HTML for page content, CSS for aesthetics, JavaScript for interaction, and SVG for vector graphics. These technologies render sharing intuitive information highly convenient.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5229878425598145,
            1.2085944414138794
        ],
        "MSU_id": 2255
    },
    {
        "sentence": "VIS-STAMP is a software that provides tools for users to generate self-organizing maps, parallel coordinate maps, map matrices, and reorderable matrices.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 411,
        "paper_id": 5,
        "paragraph_info": "Many spatial distribution explorations and complex representations of air pollution [\\[3](#page-17-2)[,8](#page-18-0)[,25\\]](#page-18-13) rely on standalone or proprietary software products like ArcGIS. VIS-STAMP [\\[26\\]](#page-18-14) is a software that provides tools for users to generate self-organizing maps, parallel coordinate maps, map matrices, and reorderable matrices (a type of heat map). This software allows users to visualize multivariate statistical analysis intuitively, as well as explore and understand spatio-temporal and multivariate patterns. Nevertheless, this type of exploration does not consider the extendable and sharable functions that are important for the public to acquire multi-perspectives and latest information on air pollution.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.2988252639770508,
            0.2677578032016754
        ],
        "MSU_id": 2258
    },
    {
        "sentence": "This software allows users to visualize multivariate statistical analysis intuitively.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 411,
        "paper_id": 5,
        "paragraph_info": "Many spatial distribution explorations and complex representations of air pollution [\\[3](#page-17-2)[,8](#page-18-0)[,25\\]](#page-18-13) rely on standalone or proprietary software products like ArcGIS. VIS-STAMP [\\[26\\]](#page-18-14) is a software that provides tools for users to generate self-organizing maps, parallel coordinate maps, map matrices, and reorderable matrices (a type of heat map). This software allows users to visualize multivariate statistical analysis intuitively, as well as explore and understand spatio-temporal and multivariate patterns. Nevertheless, this type of exploration does not consider the extendable and sharable functions that are important for the public to acquire multi-perspectives and latest information on air pollution.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.3806157112121582,
            1.2655845880508423
        ],
        "MSU_id": 2259
    },
    {
        "sentence": "The software enables users to explore and understand spatio-temporal and multivariate patterns.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 411,
        "paper_id": 5,
        "paragraph_info": "Many spatial distribution explorations and complex representations of air pollution [\\[3](#page-17-2)[,8](#page-18-0)[,25\\]](#page-18-13) rely on standalone or proprietary software products like ArcGIS. VIS-STAMP [\\[26\\]](#page-18-14) is a software that provides tools for users to generate self-organizing maps, parallel coordinate maps, map matrices, and reorderable matrices (a type of heat map). This software allows users to visualize multivariate statistical analysis intuitively, as well as explore and understand spatio-temporal and multivariate patterns. Nevertheless, this type of exploration does not consider the extendable and sharable functions that are important for the public to acquire multi-perspectives and latest information on air pollution.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5567363500595093,
            0.491280198097229
        ],
        "MSU_id": 2260
    },
    {
        "sentence": "The idea of a generic scenario extends the idea of geovisualization following the schema developed.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 412,
        "paper_id": 5,
        "paragraph_info": "Numerous researchers focus on systematic theories of visual exploration for spatio-temporal data. Kraak [\\[12\\]](#page-18-15) claims that graphics can reveal patterns that are not necessarily visible when conventional map display methods are applied, demonstrating the usefulness of geovisualization. The idea of a generic scenario extends the idea of geovisualization following the schema developed [\\[9,](#page-18-1)[13\\]](#page-18-16). A general framework was proposed then for using aggregation in visual exploration of massive movement data [\\[27\\]](#page-18-17). Similarly, another framework [\\[28\\]](#page-18-18) was discussed for spatio-temporal visualization with the visual method space\u2013time cube. However, these frameworks must be extended further and adapted for the visual exploration of air pollution data considering data quality, correlations in multivariate data, and spatio-temporal pattern analysis.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.5937614440917969,
            1.561827540397644
        ],
        "MSU_id": 2266
    },
    {
        "sentence": "A general framework was proposed for using aggregation in visual exploration of massive movement data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 412,
        "paper_id": 5,
        "paragraph_info": "Numerous researchers focus on systematic theories of visual exploration for spatio-temporal data. Kraak [\\[12\\]](#page-18-15) claims that graphics can reveal patterns that are not necessarily visible when conventional map display methods are applied, demonstrating the usefulness of geovisualization. The idea of a generic scenario extends the idea of geovisualization following the schema developed [\\[9,](#page-18-1)[13\\]](#page-18-16). A general framework was proposed then for using aggregation in visual exploration of massive movement data [\\[27\\]](#page-18-17). Similarly, another framework [\\[28\\]](#page-18-18) was discussed for spatio-temporal visualization with the visual method space\u2013time cube. However, these frameworks must be extended further and adapted for the visual exploration of air pollution data considering data quality, correlations in multivariate data, and spatio-temporal pattern analysis.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.1383751481771469,
            1.5839179754257202
        ],
        "MSU_id": 2267
    },
    {
        "sentence": "Another framework was discussed for spatio-temporal visualization with the visual method space\u2013time cube.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 412,
        "paper_id": 5,
        "paragraph_info": "Numerous researchers focus on systematic theories of visual exploration for spatio-temporal data. Kraak [\\[12\\]](#page-18-15) claims that graphics can reveal patterns that are not necessarily visible when conventional map display methods are applied, demonstrating the usefulness of geovisualization. The idea of a generic scenario extends the idea of geovisualization following the schema developed [\\[9,](#page-18-1)[13\\]](#page-18-16). A general framework was proposed then for using aggregation in visual exploration of massive movement data [\\[27\\]](#page-18-17). Similarly, another framework [\\[28\\]](#page-18-18) was discussed for spatio-temporal visualization with the visual method space\u2013time cube. However, these frameworks must be extended further and adapted for the visual exploration of air pollution data considering data quality, correlations in multivariate data, and spatio-temporal pattern analysis.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.29506799578666687,
            1.4806455373764038
        ],
        "MSU_id": 2268
    },
    {
        "sentence": "Our paper presents a visualization exploration method that realizes the process of observation\u2013hypothesis\u2013verification.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 413,
        "paper_id": 5,
        "paragraph_info": "Air composition analysis and remote-sensing methods require complex computations and are time consuming. Moreover, the current graphical approaches for air pollution analysis lack interactive and sharable multi-perspective visualizations. The public urgently needs rapid and reliable knowledge on air pollution to make daily decisions. Similarly, most of the government staff are not professionals and need intuitive understanding of the conditions before they can execute any actions against the increasingly serious air pollutants. Thus, a visual methodology is needed for efficient and reliable exploration, particularly in the case of air pollution data, to improve the depth, readability, and accuracy of data analysis. We were motivated by the idea of visual thinking and the geovisualization concept [\\[12\\]](#page-18-15), which may be well suited for the exploration of air pollution data. Building on the extensive body of previous work, our paper presents a visualization exploration method that realizes the process of observation\u2013hypothesis\u2013verification. This method was tested and validated in a year-long case study of the air quality index (AQI of  $PM_{2.5}$ ) in Beijing, China. The useful findings of air pollution in Beijing show that our new method extends the existing work and fills a gap in the research, focusing on visual exploration to support various applications, such as knowledge-based decision making and aided research of air pollution.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.29359155893325806,
            1.5737085342407227
        ],
        "MSU_id": 2278
    },
    {
        "sentence": "Data are checked and analyzed by the Preliminary analysis block through various basic visual methods, such as bar charts, heat tables, and line charts.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 414,
        "paper_id": 5,
        "paragraph_info": "Workflow for visualizing air pollution data is shown in Figure 1 and consists of five blocks, namely, Database, Preliminary analysis, Hypotheses, Verification, and Application. Our previous work, a Real-time Sensor Data Provision system (ReSDaP) [29-31], achieved the on-demand data provision for the Database. Data are then checked and analyzed by the Preliminary analysis block through various basic visual methods, such as bar charts, heat tables, and line charts. Based on these data, hypotheses can be built and verified through further visual analytics. Finally, the findings of previous steps can be used for applications.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.36459681391716003,
            1.5613809823989868
        ],
        "MSU_id": 2284
    },
    {
        "sentence": "Hypotheses can be built and verified through further visual analytics based on the analyzed data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 414,
        "paper_id": 5,
        "paragraph_info": "Workflow for visualizing air pollution data is shown in Figure 1 and consists of five blocks, namely, Database, Preliminary analysis, Hypotheses, Verification, and Application. Our previous work, a Real-time Sensor Data Provision system (ReSDaP) [29-31], achieved the on-demand data provision for the Database. Data are then checked and analyzed by the Preliminary analysis block through various basic visual methods, such as bar charts, heat tables, and line charts. Based on these data, hypotheses can be built and verified through further visual analytics. Finally, the findings of previous steps can be used for applications.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.7112363576889038,
            1.6064952611923218
        ],
        "MSU_id": 2285
    },
    {
        "type": "figure",
        "para_id": 416,
        "paper_id": 5,
        "paragraph_info": "_page_2_Figure_4.jpeg",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.7832908630371094,
            0.9925612807273865
        ],
        "MSU_id": 2287,
        "sentence": "Figure 1 illustrates a workflow for visualizing air pollution data, starting from database access, through preliminary analysis, hypothesis generation, verification, and application.",
        "category": "Method",
        "rank": 5
    },
    {
        "sentence": "The backend data are acquired from our previous work through the real-time data provision system architecture for sensor webs (ReSDaP).",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 417,
        "paper_id": 5,
        "paragraph_info": "Data accessing and storage are displayed as Step (1) in Figure 1. The backend data are acquired from our previous work through the real-time data provision system architecture for sensor webs (ReSDaP) [29]. Air pollution data often contain time and geographic location and can include an AQI, a  $PM_{2.5}$  concentration measurement. The data may also include other information related to air pollution, such as weather and economic development data. These data exist in various formats and are stored based on these formats in different types of databases. Data similar to tab-separated values, comma-separated values, spreadsheets, and other types of data tables can be directly stored in a relational database, such as the open source database MySQL. For unstructured data, such as text, pictures, and videos, the NoSQL (not only SQL) database can be used for storage, such as the MongoDB open source database that can also store structured data. Through ReSDaP [29], air pollution data are directly stored in the database, providing support for data access and storage.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.25257670879364014,
            1.5837100744247437
        ],
        "MSU_id": 2290
    },
    {
        "sentence": "Data similar to tab-separated values, comma-separated values, spreadsheets, and other types of data tables can be directly stored in a relational database, such as the open source database MySQL.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 417,
        "paper_id": 5,
        "paragraph_info": "Data accessing and storage are displayed as Step (1) in Figure 1. The backend data are acquired from our previous work through the real-time data provision system architecture for sensor webs (ReSDaP) [29]. Air pollution data often contain time and geographic location and can include an AQI, a  $PM_{2.5}$  concentration measurement. The data may also include other information related to air pollution, such as weather and economic development data. These data exist in various formats and are stored based on these formats in different types of databases. Data similar to tab-separated values, comma-separated values, spreadsheets, and other types of data tables can be directly stored in a relational database, such as the open source database MySQL. For unstructured data, such as text, pictures, and videos, the NoSQL (not only SQL) database can be used for storage, such as the MongoDB open source database that can also store structured data. Through ReSDaP [29], air pollution data are directly stored in the database, providing support for data access and storage.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.9807538986206055,
            0.27001675963401794
        ],
        "MSU_id": 2294
    },
    {
        "sentence": "For unstructured data, such as text, pictures, and videos, the NoSQL (not only SQL) database can be used for storage, such as the MongoDB open source database that can also store structured data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 417,
        "paper_id": 5,
        "paragraph_info": "Data accessing and storage are displayed as Step (1) in Figure 1. The backend data are acquired from our previous work through the real-time data provision system architecture for sensor webs (ReSDaP) [29]. Air pollution data often contain time and geographic location and can include an AQI, a  $PM_{2.5}$  concentration measurement. The data may also include other information related to air pollution, such as weather and economic development data. These data exist in various formats and are stored based on these formats in different types of databases. Data similar to tab-separated values, comma-separated values, spreadsheets, and other types of data tables can be directly stored in a relational database, such as the open source database MySQL. For unstructured data, such as text, pictures, and videos, the NoSQL (not only SQL) database can be used for storage, such as the MongoDB open source database that can also store structured data. Through ReSDaP [29], air pollution data are directly stored in the database, providing support for data access and storage.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.7926025390625,
            -0.4757481813430786
        ],
        "MSU_id": 2295
    },
    {
        "sentence": "Verification is shown in Step (4), which is used to verify previously tested hypotheses.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 418,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is shown as Step (2) in Figure 1. The main goal of this layer is to carry out an overall analysis of the data, perform basic data cleansing, and obtain several elementary discoveries. The next block shows the Hypotheses as Step (3). Verification is shown in Step (4), which is used to verify previously tested hypotheses. The main processes in this block include visualization design, data preprocessing, and visual analytics to achieve visualization flexibility with various methods, such as heat maps, parallel coordinate plots, heat circles, and calendar views. The last step is the application block seen as Step (5) in Figure [1.](#page-2-0) The following subsections will describe these four blocks in detail.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.13006989657878876,
            1.1604082584381104
        ],
        "MSU_id": 2302
    },
    {
        "sentence": "The main processes in the verification block include visualization design.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 418,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is shown as Step (2) in Figure 1. The main goal of this layer is to carry out an overall analysis of the data, perform basic data cleansing, and obtain several elementary discoveries. The next block shows the Hypotheses as Step (3). Verification is shown in Step (4), which is used to verify previously tested hypotheses. The main processes in this block include visualization design, data preprocessing, and visual analytics to achieve visualization flexibility with various methods, such as heat maps, parallel coordinate plots, heat circles, and calendar views. The last step is the application block seen as Step (5) in Figure [1.](#page-2-0) The following subsections will describe these four blocks in detail.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.6101793050765991,
            1.3001258373260498
        ],
        "MSU_id": 2303
    },
    {
        "sentence": "The main processes in the verification block include data preprocessing.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 418,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is shown as Step (2) in Figure 1. The main goal of this layer is to carry out an overall analysis of the data, perform basic data cleansing, and obtain several elementary discoveries. The next block shows the Hypotheses as Step (3). Verification is shown in Step (4), which is used to verify previously tested hypotheses. The main processes in this block include visualization design, data preprocessing, and visual analytics to achieve visualization flexibility with various methods, such as heat maps, parallel coordinate plots, heat circles, and calendar views. The last step is the application block seen as Step (5) in Figure [1.](#page-2-0) The following subsections will describe these four blocks in detail.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.6690223217010498,
            1.0045055150985718
        ],
        "MSU_id": 2304
    },
    {
        "sentence": "The main processes in the verification block include visual analytics to achieve visualization flexibility.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 418,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is shown as Step (2) in Figure 1. The main goal of this layer is to carry out an overall analysis of the data, perform basic data cleansing, and obtain several elementary discoveries. The next block shows the Hypotheses as Step (3). Verification is shown in Step (4), which is used to verify previously tested hypotheses. The main processes in this block include visualization design, data preprocessing, and visual analytics to achieve visualization flexibility with various methods, such as heat maps, parallel coordinate plots, heat circles, and calendar views. The last step is the application block seen as Step (5) in Figure [1.](#page-2-0) The following subsections will describe these four blocks in detail.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.4028986990451813,
            1.4859484434127808
        ],
        "MSU_id": 2305
    },
    {
        "sentence": "Various methods used for visualization include heat maps, parallel coordinate plots, heat circles, and calendar views.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 418,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is shown as Step (2) in Figure 1. The main goal of this layer is to carry out an overall analysis of the data, perform basic data cleansing, and obtain several elementary discoveries. The next block shows the Hypotheses as Step (3). Verification is shown in Step (4), which is used to verify previously tested hypotheses. The main processes in this block include visualization design, data preprocessing, and visual analytics to achieve visualization flexibility with various methods, such as heat maps, parallel coordinate plots, heat circles, and calendar views. The last step is the application block seen as Step (5) in Figure [1.](#page-2-0) The following subsections will describe these four blocks in detail.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.340261310338974,
            1.6567434072494507
        ],
        "MSU_id": 2306
    },
    {
        "sentence": "The Preliminary analysis block allows users to perform preliminary global visualization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 419,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block allows users to perform preliminary global visualization, explore the data to examine possible inferences, and provide clues and guides for the next block, Hypotheses. This block enables global analysis to verify the correctness and the completeness of the data, which permits preliminary data visualization with basic graphs, such as heat tables, line charts, and bar graphs, for a simple and rough overview of the data. If necessary, this step can be repeated to perform new data inspection and processing. A reliable process for data quality checking and cleaning is needed before information extraction from the original data. An inspection of the raw data reveals defects; thus, more reliable results can be acquired after visual support. Rearranging the rows and columns with drag-and-drop and partially selecting some data items through check boxes are highly convenient, which make finding missing data and logical errors in the data easier.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.7728481292724609,
            1.4141885042190552
        ],
        "MSU_id": 2309
    },
    {
        "sentence": "The Preliminary analysis block enables global analysis to verify the correctness and completeness of the data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 419,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block allows users to perform preliminary global visualization, explore the data to examine possible inferences, and provide clues and guides for the next block, Hypotheses. This block enables global analysis to verify the correctness and the completeness of the data, which permits preliminary data visualization with basic graphs, such as heat tables, line charts, and bar graphs, for a simple and rough overview of the data. If necessary, this step can be repeated to perform new data inspection and processing. A reliable process for data quality checking and cleaning is needed before information extraction from the original data. An inspection of the raw data reveals defects; thus, more reliable results can be acquired after visual support. Rearranging the rows and columns with drag-and-drop and partially selecting some data items through check boxes are highly convenient, which make finding missing data and logical errors in the data easier.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.17718398571014404,
            1.3255774974822998
        ],
        "MSU_id": 2310
    },
    {
        "sentence": "The block permits preliminary data visualization with basic graphs, such as heat tables, line charts, and bar graphs.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 419,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block allows users to perform preliminary global visualization, explore the data to examine possible inferences, and provide clues and guides for the next block, Hypotheses. This block enables global analysis to verify the correctness and the completeness of the data, which permits preliminary data visualization with basic graphs, such as heat tables, line charts, and bar graphs, for a simple and rough overview of the data. If necessary, this step can be repeated to perform new data inspection and processing. A reliable process for data quality checking and cleaning is needed before information extraction from the original data. An inspection of the raw data reveals defects; thus, more reliable results can be acquired after visual support. Rearranging the rows and columns with drag-and-drop and partially selecting some data items through check boxes are highly convenient, which make finding missing data and logical errors in the data easier.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.9006322622299194,
            1.444747805595398
        ],
        "MSU_id": 2311
    },
    {
        "sentence": "This step can be repeated to perform new data inspection and processing if necessary.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 419,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block allows users to perform preliminary global visualization, explore the data to examine possible inferences, and provide clues and guides for the next block, Hypotheses. This block enables global analysis to verify the correctness and the completeness of the data, which permits preliminary data visualization with basic graphs, such as heat tables, line charts, and bar graphs, for a simple and rough overview of the data. If necessary, this step can be repeated to perform new data inspection and processing. A reliable process for data quality checking and cleaning is needed before information extraction from the original data. An inspection of the raw data reveals defects; thus, more reliable results can be acquired after visual support. Rearranging the rows and columns with drag-and-drop and partially selecting some data items through check boxes are highly convenient, which make finding missing data and logical errors in the data easier.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.14220060408115387,
            1.405381202697754
        ],
        "MSU_id": 2312
    },
    {
        "sentence": "Rearranging the rows and columns with drag-and-drop and partially selecting some data items through check boxes are highly convenient.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 419,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block allows users to perform preliminary global visualization, explore the data to examine possible inferences, and provide clues and guides for the next block, Hypotheses. This block enables global analysis to verify the correctness and the completeness of the data, which permits preliminary data visualization with basic graphs, such as heat tables, line charts, and bar graphs, for a simple and rough overview of the data. If necessary, this step can be repeated to perform new data inspection and processing. A reliable process for data quality checking and cleaning is needed before information extraction from the original data. An inspection of the raw data reveals defects; thus, more reliable results can be acquired after visual support. Rearranging the rows and columns with drag-and-drop and partially selecting some data items through check boxes are highly convenient, which make finding missing data and logical errors in the data easier.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.9631418585777283,
            0.8745492100715637
        ],
        "MSU_id": 2316
    },
    {
        "sentence": "Complicated algorithms for accessing data and chemical analysis of air require proprietary software and knowledge to interpret the data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 420,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is rapid and easy with visualization tools. The complicated algorithms for accessing data, chemical analysis [\\[19\\]](#page-18-7) of air, and remote-sensing [\\[4,](#page-17-4)[20\\]](#page-18-8) methods require proprietary software and knowledge to interpret the data or are time consuming and difficult to understand. The same is true regarding the analysis of the spatio-temporal distribution of air pollution values in space and time [\\[3](#page-17-2)[,7](#page-17-3)[,23,](#page-18-11)[25,](#page-18-13)[26,](#page-18-14)[32\\]](#page-19-1). An Online interaction user interface can perform rapid basic visualizations to find preliminary results and inspect data defects with its flexible data formatting and special functions. Many visualization tools are free, open source, easy to acquire, and extendable. JavaScript is one of the techniques that make it convenient for the public to access and understand the data.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.043044090270996,
            -0.9072851538658142
        ],
        "MSU_id": 2319
    },
    {
        "sentence": "An Online interaction user interface can perform rapid basic visualizations to find preliminary results and inspect data defects.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 420,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is rapid and easy with visualization tools. The complicated algorithms for accessing data, chemical analysis [\\[19\\]](#page-18-7) of air, and remote-sensing [\\[4,](#page-17-4)[20\\]](#page-18-8) methods require proprietary software and knowledge to interpret the data or are time consuming and difficult to understand. The same is true regarding the analysis of the spatio-temporal distribution of air pollution values in space and time [\\[3](#page-17-2)[,7](#page-17-3)[,23,](#page-18-11)[25,](#page-18-13)[26,](#page-18-14)[32\\]](#page-19-1). An Online interaction user interface can perform rapid basic visualizations to find preliminary results and inspect data defects with its flexible data formatting and special functions. Many visualization tools are free, open source, easy to acquire, and extendable. JavaScript is one of the techniques that make it convenient for the public to access and understand the data.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.8692810535430908,
            1.209202766418457
        ],
        "MSU_id": 2322
    },
    {
        "sentence": "The Online interaction user interface has flexible data formatting and special functions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 420,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is rapid and easy with visualization tools. The complicated algorithms for accessing data, chemical analysis [\\[19\\]](#page-18-7) of air, and remote-sensing [\\[4,](#page-17-4)[20\\]](#page-18-8) methods require proprietary software and knowledge to interpret the data or are time consuming and difficult to understand. The same is true regarding the analysis of the spatio-temporal distribution of air pollution values in space and time [\\[3](#page-17-2)[,7](#page-17-3)[,23,](#page-18-11)[25,](#page-18-13)[26,](#page-18-14)[32\\]](#page-19-1). An Online interaction user interface can perform rapid basic visualizations to find preliminary results and inspect data defects with its flexible data formatting and special functions. Many visualization tools are free, open source, easy to acquire, and extendable. JavaScript is one of the techniques that make it convenient for the public to access and understand the data.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5757465362548828,
            -0.221589595079422
        ],
        "MSU_id": 2323
    },
    {
        "sentence": "JavaScript is one of the techniques that make it convenient for the public to access and understand the data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 420,
        "paper_id": 5,
        "paragraph_info": "The Preliminary analysis block is rapid and easy with visualization tools. The complicated algorithms for accessing data, chemical analysis [\\[19\\]](#page-18-7) of air, and remote-sensing [\\[4,](#page-17-4)[20\\]](#page-18-8) methods require proprietary software and knowledge to interpret the data or are time consuming and difficult to understand. The same is true regarding the analysis of the spatio-temporal distribution of air pollution values in space and time [\\[3](#page-17-2)[,7](#page-17-3)[,23,](#page-18-11)[25,](#page-18-13)[26,](#page-18-14)[32\\]](#page-19-1). An Online interaction user interface can perform rapid basic visualizations to find preliminary results and inspect data defects with its flexible data formatting and special functions. Many visualization tools are free, open source, easy to acquire, and extendable. JavaScript is one of the techniques that make it convenient for the public to access and understand the data.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.33062744140625,
            0.9963096976280212
        ],
        "MSU_id": 2325
    },
    {
        "sentence": "After proposing the hypotheses, verification is needed.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 421,
        "paper_id": 5,
        "paragraph_info": "Basing on basic visualization and data cleansing, possible patterns in air pollution data can be hypothesized, such as relationships among multiple variables, time-related fluctuation of pollutant concentrations, and spatial distributions. This part is based on adequate basic visualization to find specific characteristics or trends shown in the charts. After proposing the hypotheses, verification is needed as described in the succeeding section.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.4850795865058899,
            1.2359178066253662
        ],
        "MSU_id": 2331
    },
    {
        "sentence": "Specific visualization methods were designed for testing and verification of possible inferences.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 422,
        "paper_id": 5,
        "paragraph_info": "Specific visualization methods were designed for testing and verification of possible inferences. To verify the hypotheses by visual analytics, a visualization design will help users determine the next steps for further analysis. The Visual analytics with more refined visualization and analysis can be used to verify the thoughts in the Hypotheses block. If hot spots were found in this part, more hypotheses could be built and further verification would be needed. Thus, this can be a recursive process.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.28704652190208435,
            1.5989240407943726
        ],
        "MSU_id": 2332
    },
    {
        "sentence": "A visualization design will help users determine the next steps for further analysis.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 422,
        "paper_id": 5,
        "paragraph_info": "Specific visualization methods were designed for testing and verification of possible inferences. To verify the hypotheses by visual analytics, a visualization design will help users determine the next steps for further analysis. The Visual analytics with more refined visualization and analysis can be used to verify the thoughts in the Hypotheses block. If hot spots were found in this part, more hypotheses could be built and further verification would be needed. Thus, this can be a recursive process.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5540251731872559,
            1.289050817489624
        ],
        "MSU_id": 2333
    },
    {
        "sentence": "Visual analytics with more refined visualization and analysis can be used to verify the thoughts in the Hypotheses block.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 422,
        "paper_id": 5,
        "paragraph_info": "Specific visualization methods were designed for testing and verification of possible inferences. To verify the hypotheses by visual analytics, a visualization design will help users determine the next steps for further analysis. The Visual analytics with more refined visualization and analysis can be used to verify the thoughts in the Hypotheses block. If hot spots were found in this part, more hypotheses could be built and further verification would be needed. Thus, this can be a recursive process.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.8838449716567993,
            1.5600858926773071
        ],
        "MSU_id": 2334
    },
    {
        "sentence": "We used the geovisualization graphs to represent the spatial distribution of air pollution data clearly.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 423,
        "paper_id": 5,
        "paragraph_info": "We achieved a better visual effect from multi-perspective visualization for spatio-temporal analysis. Conventional plots, such as scatter and line plots, are usually used for the time-series data exploration of air pollution [\\[7\\]](#page-17-3) without spatial analysis and do not include the new attractive graphs. We analyzed the characteristics of various types of graphs and found that the circular heat map is extremely suitable to display time series data and calendar view [\\[33\\]](#page-19-2) is useful for displaying years of daily data. This method provides a new perspective on time series data and a means to comprehensively understand the conventional line charts or matrix plots that fail to deliver because they separate the data into several parts according to seasons or years. We also used the geovisualization graphs to represent the spatial distribution of air pollution data clearly.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.2015210390090942,
            1.4538655281066895
        ],
        "MSU_id": 2346
    },
    {
        "sentence": "In the Application layer, relevant findings are summarized from the visual analytics of the Preliminary analysis and Verification blocks to the appropriate treatment programs.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 424,
        "paper_id": 5,
        "paragraph_info": "Visualization highlights the regularities in the data to be verified by later statistical analysis. Both basic visualization and visual analytics lead to discovery and provide support for applications. In the Application layer, relevant findings are summarized from the visual analytics of the Preliminary analysis and Verification blocks to the appropriate treatment programs. For example, if long-term positive correlations were found between carbon dioxide concentrations and temperatures all over the world, controlling the irregular emission of carbon dioxide may be an approach to address global warming. Thus, the visual display of data supports decision-making by experts and non-experts alike. However, anomalies seen in the charts that illustrate data hot spots and allow users to identify data for further statistical analysis. At the same time, data visualization can act as aided research of other methods in the air pollution field, and sharing interactive findings through the web. Therefore, the application block in the workflow can be coordinated with other systems, providing a basis for a comprehensive model of a phenomenon.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.212792158126831,
            1.350803256034851
        ],
        "MSU_id": 2349
    },
    {
        "sentence": "The application block in the workflow can be coordinated with other systems, providing a basis for a comprehensive model of a phenomenon.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 424,
        "paper_id": 5,
        "paragraph_info": "Visualization highlights the regularities in the data to be verified by later statistical analysis. Both basic visualization and visual analytics lead to discovery and provide support for applications. In the Application layer, relevant findings are summarized from the visual analytics of the Preliminary analysis and Verification blocks to the appropriate treatment programs. For example, if long-term positive correlations were found between carbon dioxide concentrations and temperatures all over the world, controlling the irregular emission of carbon dioxide may be an approach to address global warming. Thus, the visual display of data supports decision-making by experts and non-experts alike. However, anomalies seen in the charts that illustrate data hot spots and allow users to identify data for further statistical analysis. At the same time, data visualization can act as aided research of other methods in the air pollution field, and sharing interactive findings through the web. Therefore, the application block in the workflow can be coordinated with other systems, providing a basis for a comprehensive model of a phenomenon.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.08541363477706909,
            0.0922999456524849
        ],
        "MSU_id": 2355
    },
    {
        "sentence": "Andrienko and Andrienko proposed a general framework using aggregation in visual exploration of massive movement data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 425,
        "paper_id": 5,
        "paragraph_info": "We can further stress the advantages of our method by comparing them with previous methods for visual analytics. The simple model of visualization for visual analytics [\\[9\\]](#page-18-1) was too abstract and coarse to be used for the analysis of air pollution data with graphs. Andrienko and Andrienko [\\[27\\]](#page-18-17) proposed a general framework using aggregation in visual exploration of massive movement data. A similar framework for spatio-temporal visualization was suitable for movement data with the visual method space\u2013time cube [\\[28\\]](#page-18-18). It was a problem-driven process with domain experts as users. Nevertheless, our method contains a data-driven process with multi-perspective spatio-temporal visualization that is easily understood by expert and non-expert users alike. Moreover, we described an efficient visual method to check data quality and enable our method to acquire more reliable results.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.05008474364876747,
            1.5502699613571167
        ],
        "MSU_id": 2358
    },
    {
        "sentence": "A similar framework for spatio-temporal visualization was suitable for movement data with the visual method space\u2013time cube.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 425,
        "paper_id": 5,
        "paragraph_info": "We can further stress the advantages of our method by comparing them with previous methods for visual analytics. The simple model of visualization for visual analytics [\\[9\\]](#page-18-1) was too abstract and coarse to be used for the analysis of air pollution data with graphs. Andrienko and Andrienko [\\[27\\]](#page-18-17) proposed a general framework using aggregation in visual exploration of massive movement data. A similar framework for spatio-temporal visualization was suitable for movement data with the visual method space\u2013time cube [\\[28\\]](#page-18-18). It was a problem-driven process with domain experts as users. Nevertheless, our method contains a data-driven process with multi-perspective spatio-temporal visualization that is easily understood by expert and non-expert users alike. Moreover, we described an efficient visual method to check data quality and enable our method to acquire more reliable results.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.09995663166046143,
            1.6478976011276245
        ],
        "MSU_id": 2359
    },
    {
        "sentence": "Our method contains a data-driven process with multi-perspective spatio-temporal visualization that is easily understood by expert and non-expert users alike.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 425,
        "paper_id": 5,
        "paragraph_info": "We can further stress the advantages of our method by comparing them with previous methods for visual analytics. The simple model of visualization for visual analytics [\\[9\\]](#page-18-1) was too abstract and coarse to be used for the analysis of air pollution data with graphs. Andrienko and Andrienko [\\[27\\]](#page-18-17) proposed a general framework using aggregation in visual exploration of massive movement data. A similar framework for spatio-temporal visualization was suitable for movement data with the visual method space\u2013time cube [\\[28\\]](#page-18-18). It was a problem-driven process with domain experts as users. Nevertheless, our method contains a data-driven process with multi-perspective spatio-temporal visualization that is easily understood by expert and non-expert users alike. Moreover, we described an efficient visual method to check data quality and enable our method to acquire more reliable results.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.8797979354858398,
            1.4362214803695679
        ],
        "MSU_id": 2361
    },
    {
        "sentence": "We described an efficient visual method to check data quality and enable our method to acquire more reliable results.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 425,
        "paper_id": 5,
        "paragraph_info": "We can further stress the advantages of our method by comparing them with previous methods for visual analytics. The simple model of visualization for visual analytics [\\[9\\]](#page-18-1) was too abstract and coarse to be used for the analysis of air pollution data with graphs. Andrienko and Andrienko [\\[27\\]](#page-18-17) proposed a general framework using aggregation in visual exploration of massive movement data. A similar framework for spatio-temporal visualization was suitable for movement data with the visual method space\u2013time cube [\\[28\\]](#page-18-18). It was a problem-driven process with domain experts as users. Nevertheless, our method contains a data-driven process with multi-perspective spatio-temporal visualization that is easily understood by expert and non-expert users alike. Moreover, we described an efficient visual method to check data quality and enable our method to acquire more reliable results.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.3952445983886719,
            1.513633131980896
        ],
        "MSU_id": 2362
    },
    {
        "sentence": "Our method is efficient and extendable from the technological viewpoint.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 426,
        "paper_id": 5,
        "paragraph_info": "Visualization value can be assessed from three viewpoints: technology, art, and empiric science [\\[9\\]](#page-18-1). Our method is efficient and extendable from the technological viewpoint and beautiful from the artistic viewpoint. Meanwhile, it follows the \"observation\u2013hypothesis\u2013verification\" process of the scientific method and thus complies with the demands of empirical science. In Section [3,](#page-5-0) this method will be tested and validated in a year-long case study of the AQI of PM2.5 in Beijing, China.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.18920394778251648,
            0.24630123376846313
        ],
        "MSU_id": 2364
    },
    {
        "sentence": "Our method is beautiful from the artistic viewpoint.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 426,
        "paper_id": 5,
        "paragraph_info": "Visualization value can be assessed from three viewpoints: technology, art, and empiric science [\\[9\\]](#page-18-1). Our method is efficient and extendable from the technological viewpoint and beautiful from the artistic viewpoint. Meanwhile, it follows the \"observation\u2013hypothesis\u2013verification\" process of the scientific method and thus complies with the demands of empirical science. In Section [3,](#page-5-0) this method will be tested and validated in a year-long case study of the AQI of PM2.5 in Beijing, China.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.006593216210603714,
            1.2578083276748657
        ],
        "MSU_id": 2365
    },
    {
        "sentence": "Our method follows the 'observation\u2013hypothesis\u2013verification' process of the scientific method.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 426,
        "paper_id": 5,
        "paragraph_info": "Visualization value can be assessed from three viewpoints: technology, art, and empiric science [\\[9\\]](#page-18-1). Our method is efficient and extendable from the technological viewpoint and beautiful from the artistic viewpoint. Meanwhile, it follows the \"observation\u2013hypothesis\u2013verification\" process of the scientific method and thus complies with the demands of empirical science. In Section [3,](#page-5-0) this method will be tested and validated in a year-long case study of the AQI of PM2.5 in Beijing, China.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.3670339286327362,
            1.2915892601013184
        ],
        "MSU_id": 2366
    },
    {
        "sentence": "Observation values include PM2.5 concentration, with parameter concentration units in micrograms per cubic meter (\u00b5g/m\u00b3) transformed to AQI values.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 427,
        "paper_id": 5,
        "paragraph_info": "Two datasets are utilized for the case study of air quality in Beijing, the capital of China. The first dataset is historical hourly PM2.5 data (2009\u20132014) of Beijing obtained from the US Department of State air quality files available on its website [\\[34\\]](#page-19-3) as measured at the US Embassy in Beijing. Observation values include PM2.5 concentration, with parameter concentration units in micrograms per cubic meter (\u00b5g/m\u00b3) transformed to AQI values for our case study. However, these data are not completely verified or validated as indicated in the data statement. These data were used to demonstrate a practical application of the visualization approach, as well as its feasibility and efficiency. The data are referred to as the USE data in the rest of this paper.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            1.0034259557724,
            -1.5059651136398315
        ],
        "MSU_id": 2372
    },
    {
        "sentence": "We decided to explore the relationship between pollution and the rainy weather with precipitation data only.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 428,
        "paper_id": 5,
        "paragraph_info": "The second dataset was created from the U-Air project [\\[35\\]](#page-19-4) and comprises one year (8 February 2013 to 8 February 2014) of air quality data from 36 air quality monitoring stations in Beijing, all with geographic coordinates. The stations are shown in Figure [2.](#page-5-1) The observation data include time, AQI of PM2.5, PM10, NO2, temperature, humidity, wind speed, and weather. Notably, the original weather data have several anomalies; thus, we decided to explore the relationship between pollution and the rainy weather with precipitation data only [\\[36\\]](#page-19-5). These data are termed the U-Air data in the rest of this paper.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5974514484405518,
            -0.041039980947971344
        ],
        "MSU_id": 2380
    },
    {
        "sentence": "Visual analytics is an intuitive and clear method for data inspection.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 431,
        "paper_id": 5,
        "paragraph_info": "Before original data records could be used to convey information, preliminary analyses are necessary to evaluate data quality and find general facts in the data itself. Moreover, data-driven hypotheses could be built to guide further analysis. In this section, we will cover these steps without going into details. Readers can find more details in the Supplementary Materials as the main goal of this paper is the flexible visual exploration method for air pollution. Missing data and logic errors may occur in the original data. Therefore, rapid data inspection is needed before they can be used to acquire reliable findings. Visual analytics is an intuitive and clear method for this purpose. Data misreads can be avoided to some extent if these defects are found and processed through graphs. We will show how the data quality of the original U-Air data can be verified and validated with visualization methods.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.8977435827255249,
            1.576229453086853
        ],
        "MSU_id": 2389
    },
    {
        "sentence": "With tables or scatter plots, missing data can be easily found.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 432,
        "paper_id": 5,
        "paragraph_info": "With tables or scatter plots, missing data can be easily found. As presented in Figure 3, stations 23\u201336 from March to October have no observations, which clearly show the missing blocks to be handled. Moreover, logic errors could be found with this visualization type. For example, when setting rows as months and columns as weather, the evident relationship between weather and seasons could be observed intuitively. Beijing has a sub-humid warm temperate continental monsoon climate [37] on the northern hemisphere; thus, it is unlikely to snow in summer.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.1142748594284058,
            1.3141330480575562
        ],
        "MSU_id": 2392
    },
    {
        "sentence": "This visualization type can help find logic errors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 432,
        "paper_id": 5,
        "paragraph_info": "With tables or scatter plots, missing data can be easily found. As presented in Figure 3, stations 23\u201336 from March to October have no observations, which clearly show the missing blocks to be handled. Moreover, logic errors could be found with this visualization type. For example, when setting rows as months and columns as weather, the evident relationship between weather and seasons could be observed intuitively. Beijing has a sub-humid warm temperate continental monsoon climate [37] on the northern hemisphere; thus, it is unlikely to snow in summer.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.7833688259124756,
            1.0998690128326416
        ],
        "MSU_id": 2394
    },
    {
        "sentence": "Multi-source data fusion may supplement the missing data and replace the part with logic errors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 433,
        "paper_id": 5,
        "paragraph_info": "These problems can be handled in several ways. Multi-source data fusion may supplement the missing data and replace the part with logic errors. In this case study, the precipitation data were integrated to determine whether rainy weather can affect pollutant concentration. Interpolation for missing or coarse records is another commonly used method [23]. In addition, data could be divided into parts and analyzed separately to be used for the missing data problem in this case study.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.4763000011444092,
            -1.975270390510559
        ],
        "MSU_id": 2399
    },
    {
        "sentence": "Interpolation for missing or coarse records is another commonly used method.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 433,
        "paper_id": 5,
        "paragraph_info": "These problems can be handled in several ways. Multi-source data fusion may supplement the missing data and replace the part with logic errors. In this case study, the precipitation data were integrated to determine whether rainy weather can affect pollutant concentration. Interpolation for missing or coarse records is another commonly used method [23]. In addition, data could be divided into parts and analyzed separately to be used for the missing data problem in this case study.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5604221820831299,
            -0.8866223692893982
        ],
        "MSU_id": 2401
    },
    {
        "sentence": "Data could be divided into parts and analyzed separately to be used for the missing data problem in this case study.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 433,
        "paper_id": 5,
        "paragraph_info": "These problems can be handled in several ways. Multi-source data fusion may supplement the missing data and replace the part with logic errors. In this case study, the precipitation data were integrated to determine whether rainy weather can affect pollutant concentration. Interpolation for missing or coarse records is another commonly used method [23]. In addition, data could be divided into parts and analyzed separately to be used for the missing data problem in this case study.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.0197566747665405,
            0.027669943869113922
        ],
        "MSU_id": 2402
    },
    {
        "sentence": "To minimize the effect of these missing data in the analysis, we separated the data into two parts.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 434,
        "paper_id": 5,
        "paragraph_info": "Figure 4 shows the missing data in stations 23\u201336 from March to October. To minimize the effect of these missing data in the analysis, we separated the data into two parts and outlined them in Table 1. The first strategy involves the time pattern analysis of  $PM_{2.5}$  for stations 01\u201322 for all months. This analysis includes visualizing the average AQI of  $PM_{2.5}$  by month, day, and hour. The second strategy is spatial distribution analysis of  $PM_{2.5}$  for observations in January, February, November, and December because all stations in these months have complete data records. With this separated analysis, more reliable exploration can be performed.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.2820281386375427,
            -1.056235671043396
        ],
        "MSU_id": 2404
    },
    {
        "sentence": "The first strategy involves the time pattern analysis of $PM_{2.5}$ for stations 01\u201322 for all months.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 434,
        "paper_id": 5,
        "paragraph_info": "Figure 4 shows the missing data in stations 23\u201336 from March to October. To minimize the effect of these missing data in the analysis, we separated the data into two parts and outlined them in Table 1. The first strategy involves the time pattern analysis of  $PM_{2.5}$  for stations 01\u201322 for all months. This analysis includes visualizing the average AQI of  $PM_{2.5}$  by month, day, and hour. The second strategy is spatial distribution analysis of  $PM_{2.5}$  for observations in January, February, November, and December because all stations in these months have complete data records. With this separated analysis, more reliable exploration can be performed.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.6200722455978394,
            1.292039394378662
        ],
        "MSU_id": 2405
    },
    {
        "sentence": "This analysis includes visualizing the average AQI of $PM_{2.5}$ by month, day, and hour.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 434,
        "paper_id": 5,
        "paragraph_info": "Figure 4 shows the missing data in stations 23\u201336 from March to October. To minimize the effect of these missing data in the analysis, we separated the data into two parts and outlined them in Table 1. The first strategy involves the time pattern analysis of  $PM_{2.5}$  for stations 01\u201322 for all months. This analysis includes visualizing the average AQI of  $PM_{2.5}$  by month, day, and hour. The second strategy is spatial distribution analysis of  $PM_{2.5}$  for observations in January, February, November, and December because all stations in these months have complete data records. With this separated analysis, more reliable exploration can be performed.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.13411809504032135,
            0.3804212808609009
        ],
        "MSU_id": 2406
    },
    {
        "sentence": "The second strategy is spatial distribution analysis of $PM_{2.5}$ for observations in January, February, November, and December.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 434,
        "paper_id": 5,
        "paragraph_info": "Figure 4 shows the missing data in stations 23\u201336 from March to October. To minimize the effect of these missing data in the analysis, we separated the data into two parts and outlined them in Table 1. The first strategy involves the time pattern analysis of  $PM_{2.5}$  for stations 01\u201322 for all months. This analysis includes visualizing the average AQI of  $PM_{2.5}$  by month, day, and hour. The second strategy is spatial distribution analysis of  $PM_{2.5}$  for observations in January, February, November, and December because all stations in these months have complete data records. With this separated analysis, more reliable exploration can be performed.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.22849689424037933,
            1.4016835689544678
        ],
        "MSU_id": 2407
    },
    {
        "sentence": "We performed the global visualization of data using basic charts.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 438,
        "paper_id": 5,
        "paragraph_info": "We performed the global visualization of data using basic charts. Based on these visualizations, possible hypotheses were generated for the visualization design program. We used the U-Air data. According to Table 1, the first strategy is used to determine whether a temporal pattern is evident in the data from stations  $01-22$  for all months. Through basic visualization, as shown in the heat table in Figure 4, higher PM<sub>2.5</sub> concentrations are observed from Friday to Sunday from February to March than during other times in this period.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.0156561136245728,
            1.4234611988067627
        ],
        "MSU_id": 2413
    },
    {
        "sentence": "The first strategy is used to determine whether a temporal pattern is evident in the data from stations 01-22 for all months.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 438,
        "paper_id": 5,
        "paragraph_info": "We performed the global visualization of data using basic charts. Based on these visualizations, possible hypotheses were generated for the visualization design program. We used the U-Air data. According to Table 1, the first strategy is used to determine whether a temporal pattern is evident in the data from stations  $01-22$  for all months. Through basic visualization, as shown in the heat table in Figure 4, higher PM<sub>2.5</sub> concentrations are observed from Friday to Sunday from February to March than during other times in this period.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.0017663352191448212,
            1.35676908493042
        ],
        "MSU_id": 2416
    },
    {
        "sentence": "The correlation value is calculated using Equation (1) given a series of *n* measurements of variables *X* and *Y* written as $x_i$ and $y_i$, where $i = 1, 2, \\ldots, n$.",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 444,
        "paper_id": 5,
        "paragraph_info": "A heat matrix is a representation of the correlations between the data with a color matrix. The correlation value is a Pearson product moment correlation coefficient,  $r$  (Pearson's  $r$  for short, with the range of  $-1$  to 1), which is calculated using Equation (1) given a series of *n* measurements of variables *X* and *Y* written as  $x_i$  and  $y_i$ , where  $i = 1, 2, \\ldots, n$ . This computation yields a correlation matrix in which each *i*, *j* element is equal to the  $r$  value between the  $X$  and  $Y$  variables.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.6203896403312683,
            -1.6552098989486694
        ],
        "MSU_id": 2434
    },
    {
        "sentence": "Colors in the heat matrix represent Pearson's $r$.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 445,
        "paper_id": 5,
        "paragraph_info": "A heat matrix can be used to intuitively discover the overall relevance of data; thus, it can be used for preliminary analysis of the data. As shown in Figure 7, colors represent Pearson's  $r$ , and color ranges from red to blue by gradient. The area marked with red dotted boxes in Figure 7 indicates several primary results. The AQIs of  $PM_2$  5,  $PM_{10}$ , and  $NO_2$  showed strong positive correlations, whereas the wind had a negative correlation with the AQIs of  $PM_{2.5}$ ,  $PM_{10}$ ,  $NO_{2}$ , and humidity. When the AQI of  $PM_{2.5}$  is high, high AQI of  $PM_{10}$  and  $NO_2$  are obtained, and the wind speed may be low. Through the general analysis, we constructed three hypotheses and the corresponding visualization design for the air pollution exploration. The first hypothesis is that a correlation exists among the AQI of  $PM_{2.5}$ ,  $PM_{10}$ , and  $NO_2$ , and wind speed. This correlation can be visualized through scatter plots that show the relationship between any two factors. The second hypothesis is that a regular time pattern exists for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map and a calendar view. The third hypothesis is that air contaminants possess a geographical",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.19363608956336975,
            -1.023146390914917
        ],
        "MSU_id": 2438
    },
    {
        "sentence": "Color ranges from red to blue by gradient.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 445,
        "paper_id": 5,
        "paragraph_info": "A heat matrix can be used to intuitively discover the overall relevance of data; thus, it can be used for preliminary analysis of the data. As shown in Figure 7, colors represent Pearson's  $r$ , and color ranges from red to blue by gradient. The area marked with red dotted boxes in Figure 7 indicates several primary results. The AQIs of  $PM_2$  5,  $PM_{10}$ , and  $NO_2$  showed strong positive correlations, whereas the wind had a negative correlation with the AQIs of  $PM_{2.5}$ ,  $PM_{10}$ ,  $NO_{2}$ , and humidity. When the AQI of  $PM_{2.5}$  is high, high AQI of  $PM_{10}$  and  $NO_2$  are obtained, and the wind speed may be low. Through the general analysis, we constructed three hypotheses and the corresponding visualization design for the air pollution exploration. The first hypothesis is that a correlation exists among the AQI of  $PM_{2.5}$ ,  $PM_{10}$ , and  $NO_2$ , and wind speed. This correlation can be visualized through scatter plots that show the relationship between any two factors. The second hypothesis is that a regular time pattern exists for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map and a calendar view. The third hypothesis is that air contaminants possess a geographical",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.9714153409004211,
            0.5066853165626526
        ],
        "MSU_id": 2439
    },
    {
        "sentence": "We constructed three hypotheses and the corresponding visualization design for the air pollution exploration.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 445,
        "paper_id": 5,
        "paragraph_info": "A heat matrix can be used to intuitively discover the overall relevance of data; thus, it can be used for preliminary analysis of the data. As shown in Figure 7, colors represent Pearson's  $r$ , and color ranges from red to blue by gradient. The area marked with red dotted boxes in Figure 7 indicates several primary results. The AQIs of  $PM_2$  5,  $PM_{10}$ , and  $NO_2$  showed strong positive correlations, whereas the wind had a negative correlation with the AQIs of  $PM_{2.5}$ ,  $PM_{10}$ ,  $NO_{2}$ , and humidity. When the AQI of  $PM_{2.5}$  is high, high AQI of  $PM_{10}$  and  $NO_2$  are obtained, and the wind speed may be low. Through the general analysis, we constructed three hypotheses and the corresponding visualization design for the air pollution exploration. The first hypothesis is that a correlation exists among the AQI of  $PM_{2.5}$ ,  $PM_{10}$ , and  $NO_2$ , and wind speed. This correlation can be visualized through scatter plots that show the relationship between any two factors. The second hypothesis is that a regular time pattern exists for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map and a calendar view. The third hypothesis is that air contaminants possess a geographical",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.9325666427612305,
            0.9680868983268738
        ],
        "MSU_id": 2444
    },
    {
        "sentence": "This correlation can be visualized through scatter plots that show the relationship between any two factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 445,
        "paper_id": 5,
        "paragraph_info": "A heat matrix can be used to intuitively discover the overall relevance of data; thus, it can be used for preliminary analysis of the data. As shown in Figure 7, colors represent Pearson's  $r$ , and color ranges from red to blue by gradient. The area marked with red dotted boxes in Figure 7 indicates several primary results. The AQIs of  $PM_2$  5,  $PM_{10}$ , and  $NO_2$  showed strong positive correlations, whereas the wind had a negative correlation with the AQIs of  $PM_{2.5}$ ,  $PM_{10}$ ,  $NO_{2}$ , and humidity. When the AQI of  $PM_{2.5}$  is high, high AQI of  $PM_{10}$  and  $NO_2$  are obtained, and the wind speed may be low. Through the general analysis, we constructed three hypotheses and the corresponding visualization design for the air pollution exploration. The first hypothesis is that a correlation exists among the AQI of  $PM_{2.5}$ ,  $PM_{10}$ , and  $NO_2$ , and wind speed. This correlation can be visualized through scatter plots that show the relationship between any two factors. The second hypothesis is that a regular time pattern exists for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map and a calendar view. The third hypothesis is that air contaminants possess a geographical",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.6942083835601807,
            1.846699833869934
        ],
        "MSU_id": 2446
    },
    {
        "sentence": "Heat maps would be an ideal visualization method, including a circle heat map and a calendar view.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 445,
        "paper_id": 5,
        "paragraph_info": "A heat matrix can be used to intuitively discover the overall relevance of data; thus, it can be used for preliminary analysis of the data. As shown in Figure 7, colors represent Pearson's  $r$ , and color ranges from red to blue by gradient. The area marked with red dotted boxes in Figure 7 indicates several primary results. The AQIs of  $PM_2$  5,  $PM_{10}$ , and  $NO_2$  showed strong positive correlations, whereas the wind had a negative correlation with the AQIs of  $PM_{2.5}$ ,  $PM_{10}$ ,  $NO_{2}$ , and humidity. When the AQI of  $PM_{2.5}$  is high, high AQI of  $PM_{10}$  and  $NO_2$  are obtained, and the wind speed may be low. Through the general analysis, we constructed three hypotheses and the corresponding visualization design for the air pollution exploration. The first hypothesis is that a correlation exists among the AQI of  $PM_{2.5}$ ,  $PM_{10}$ , and  $NO_2$ , and wind speed. This correlation can be visualized through scatter plots that show the relationship between any two factors. The second hypothesis is that a regular time pattern exists for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map and a calendar view. The third hypothesis is that air contaminants possess a geographical",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.34203147888183594,
            1.6003819704055786
        ],
        "MSU_id": 2448
    },
    {
        "sentence": "This distribution can be represented appropriately by geovisualization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 446,
        "paper_id": 5,
        "paragraph_info": "<span id=\"page-8-0\"></span>distribution. This distribution can be represented appropriately by geovisualization, a method suitable for illustrating continuous spatial distributions.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.39703530073165894,
            1.8393341302871704
        ],
        "MSU_id": 2450
    },
    {
        "sentence": "Geovisualization is a method suitable for illustrating continuous spatial distributions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 446,
        "paper_id": 5,
        "paragraph_info": "<span id=\"page-8-0\"></span>distribution. This distribution can be represented appropriately by geovisualization, a method suitable for illustrating continuous spatial distributions.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.2777215838432312,
            1.8240025043487549
        ],
        "MSU_id": 2451
    },
    {
        "sentence": "Plots are used to visualize and explore the relationships between the pollutants and weather using the U-Air data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 452,
        "paper_id": 5,
        "paragraph_info": "Section 2.2 introduces the hypothesis that a relationship exists among pollutants and wind speed. In this section, plots are used to visualize and explore the relationships between the pollutants and weather using the U-Air data. Figure 8 shows that the three pollutants are strongly positively correlated because the Pearson's  $r$  values are rather high. However, wind speed has a negative correlation with  $PM_{2.5}$ ,  $PM_{10}$ , and  $NO_2$ , which have high negative *r* values. Precipitation exhibits an extremely weak negative correlation with the pollutants. The strong positive correlation between  $PM_{2.5}$  and  $PM_{10}$ shown in Figure 8 verifies the findings in [7]. Because  $PM_{2.5}$  and  $PM_{10}$  are defined as particles with diameters of 2.5 \u00b5m or less and 10 \u00b5m or less, respectively, the relationship reveals that the particle density distributed stably according to their sizes. The positive correlation between pollutants indicates that  $PM_{2.5}$ ,  $PM_{10}$ , and  $NO_2$  may be emitted by the same sources, or one may be emitted by the transformation of another through some type of chemical mechanism [38]. To determine the specific reasons, a combined physical and chemical analysis of pollutants is desirable [19].",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.7521926164627075,
            1.426465392112732
        ],
        "MSU_id": 2464
    },
    {
        "sentence": "Different colors represent four seasons.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 454,
        "paper_id": 5,
        "paragraph_info": "**Figure 8.** Scatter plots showing relationships among  $PM_{2.5}$ ,  $PM_{10}$ ,  $NO_{2}$ , wind, and precipitation. Different colors represent four seasons, where  $r$  is the correlation coefficient of two factors. Red circle marks a special point that is markedly different from the others.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.13358692824840546,
            1.3655511140823364
        ],
        "MSU_id": 2475
    },
    {
        "sentence": "The USE data, which had long-term observations, were used to determine the temporal characteristics of the mean AQI values of $PM_{2.5}$.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 457,
        "paper_id": 5,
        "paragraph_info": "The USE data, which had long-term observations, were used in this section to determine the temporal characteristics of the mean AQI values of  $PM_{2.5}$ . The average AQI of  $PM_{2.5}$  in five years is visualized through two circular heat maps; one map is a monthly variation and the other is an hourly variation. A daily concentration of  $PM_{2.5}$  is presented as a calendar map, which is useful for an intuitive inspection of the severity of pollutants. As shown in Figure 9, pollutant concentrations are extremely high from 2010 to 2014. Figure 9a shows a circular heat map with average AQI for every month in selected years, whereas Figure 9b represents 24-h periods for selected years. Basing on the charts, AQIs of not less than 150 apparently occurred in January and February, whereas AQIs of more than 100 occurred in September, October, January, and February. Moreover, the AQIs of more than 100 were concentrated from 6:00 p.m. to 4:00 a.m. during the selected years.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.7190772294998169,
            -1.1259585618972778
        ],
        "MSU_id": 2493
    },
    {
        "sentence": "The average AQI of $PM_{2.5}$ in five years is visualized through two circular heat maps.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 457,
        "paper_id": 5,
        "paragraph_info": "The USE data, which had long-term observations, were used in this section to determine the temporal characteristics of the mean AQI values of  $PM_{2.5}$ . The average AQI of  $PM_{2.5}$  in five years is visualized through two circular heat maps; one map is a monthly variation and the other is an hourly variation. A daily concentration of  $PM_{2.5}$  is presented as a calendar map, which is useful for an intuitive inspection of the severity of pollutants. As shown in Figure 9, pollutant concentrations are extremely high from 2010 to 2014. Figure 9a shows a circular heat map with average AQI for every month in selected years, whereas Figure 9b represents 24-h periods for selected years. Basing on the charts, AQIs of not less than 150 apparently occurred in January and February, whereas AQIs of more than 100 occurred in September, October, January, and February. Moreover, the AQIs of more than 100 were concentrated from 6:00 p.m. to 4:00 a.m. during the selected years.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.6393570303916931,
            0.5601937770843506
        ],
        "MSU_id": 2494
    },
    {
        "sentence": "One map shows the monthly variation of AQI, and the other shows the hourly variation.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 457,
        "paper_id": 5,
        "paragraph_info": "The USE data, which had long-term observations, were used in this section to determine the temporal characteristics of the mean AQI values of  $PM_{2.5}$ . The average AQI of  $PM_{2.5}$  in five years is visualized through two circular heat maps; one map is a monthly variation and the other is an hourly variation. A daily concentration of  $PM_{2.5}$  is presented as a calendar map, which is useful for an intuitive inspection of the severity of pollutants. As shown in Figure 9, pollutant concentrations are extremely high from 2010 to 2014. Figure 9a shows a circular heat map with average AQI for every month in selected years, whereas Figure 9b represents 24-h periods for selected years. Basing on the charts, AQIs of not less than 150 apparently occurred in January and February, whereas AQIs of more than 100 occurred in September, October, January, and February. Moreover, the AQIs of more than 100 were concentrated from 6:00 p.m. to 4:00 a.m. during the selected years.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.803742527961731,
            -1.2346254587173462
        ],
        "MSU_id": 2495
    },
    {
        "sentence": "A daily concentration of $PM_{2.5}$ is presented as a calendar map.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 457,
        "paper_id": 5,
        "paragraph_info": "The USE data, which had long-term observations, were used in this section to determine the temporal characteristics of the mean AQI values of  $PM_{2.5}$ . The average AQI of  $PM_{2.5}$  in five years is visualized through two circular heat maps; one map is a monthly variation and the other is an hourly variation. A daily concentration of  $PM_{2.5}$  is presented as a calendar map, which is useful for an intuitive inspection of the severity of pollutants. As shown in Figure 9, pollutant concentrations are extremely high from 2010 to 2014. Figure 9a shows a circular heat map with average AQI for every month in selected years, whereas Figure 9b represents 24-h periods for selected years. Basing on the charts, AQIs of not less than 150 apparently occurred in January and February, whereas AQIs of more than 100 occurred in September, October, January, and February. Moreover, the AQIs of more than 100 were concentrated from 6:00 p.m. to 4:00 a.m. during the selected years.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.09281449019908905,
            1.4571062326431274
        ],
        "MSU_id": 2496
    },
    {
        "sentence": "We first interpolate the AQI surface through the values of those stations by Ordinary Kriging (OK).",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 463,
        "paper_id": 5,
        "paragraph_info": "Spatial distribution of the mean AQI of  $PM_{2.5}$  is analyzed in this section. Observations of the 36 stations from November 2013 to February 2014 are used. We first interpolate the AQI surface through the values of those stations by Ordinary Kriging (OK) [40], which is a geostatistical method where the weights for interpolation are computed by the neighboring values called \"semivariances\" ( $\\gamma$ ). In Equation (2), *n* is the number of pairs of sample points *z* separated by distance *h*, and  $\\hat{\\gamma}(h)$  is the semivariogram which is a function of distance [41].The basic formula for OK is Equation (3), in which the  $\\lambda_i$  is the kriging weight and  $Z(x_0)$  is the observed value at point  $x_0$ .",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.36255979537963867,
            -1.4034496545791626
        ],
        "MSU_id": 2520
    },
    {
        "sentence": "Ordinary Kriging (OK) is a geostatistical method where the weights for interpolation are computed by the neighboring values called 'semivariances' ($\\gamma$).",
        "category": "Method",
        "rank": 5,
        "type": "text",
        "para_id": 463,
        "paper_id": 5,
        "paragraph_info": "Spatial distribution of the mean AQI of  $PM_{2.5}$  is analyzed in this section. Observations of the 36 stations from November 2013 to February 2014 are used. We first interpolate the AQI surface through the values of those stations by Ordinary Kriging (OK) [40], which is a geostatistical method where the weights for interpolation are computed by the neighboring values called \"semivariances\" ( $\\gamma$ ). In Equation (2), *n* is the number of pairs of sample points *z* separated by distance *h*, and  $\\hat{\\gamma}(h)$  is the semivariogram which is a function of distance [41].The basic formula for OK is Equation (3), in which the  $\\lambda_i$  is the kriging weight and  $Z(x_0)$  is the observed value at point  $x_0$ .",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.8640296459197998,
            -0.5959519743919373
        ],
        "MSU_id": 2521
    },
    {
        "sentence": "In Equation (2), *n* is the number of pairs of sample points *z* separated by distance *h*, and $\\hat{\\gamma}(h)$ is the semivariogram which is a function of distance.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 463,
        "paper_id": 5,
        "paragraph_info": "Spatial distribution of the mean AQI of  $PM_{2.5}$  is analyzed in this section. Observations of the 36 stations from November 2013 to February 2014 are used. We first interpolate the AQI surface through the values of those stations by Ordinary Kriging (OK) [40], which is a geostatistical method where the weights for interpolation are computed by the neighboring values called \"semivariances\" ( $\\gamma$ ). In Equation (2), *n* is the number of pairs of sample points *z* separated by distance *h*, and  $\\hat{\\gamma}(h)$  is the semivariogram which is a function of distance [41].The basic formula for OK is Equation (3), in which the  $\\lambda_i$  is the kriging weight and  $Z(x_0)$  is the observed value at point  $x_0$ .",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.4262959063053131,
            -0.42734742164611816
        ],
        "MSU_id": 2522
    },
    {
        "sentence": "The basic formula for OK is Equation (3), in which the $\\lambda_i$ is the kriging weight and $Z(x_0)$ is the observed value at point $x_0$.",
        "category": "Method",
        "rank": 4,
        "type": "text",
        "para_id": 463,
        "paper_id": 5,
        "paragraph_info": "Spatial distribution of the mean AQI of  $PM_{2.5}$  is analyzed in this section. Observations of the 36 stations from November 2013 to February 2014 are used. We first interpolate the AQI surface through the values of those stations by Ordinary Kriging (OK) [40], which is a geostatistical method where the weights for interpolation are computed by the neighboring values called \"semivariances\" ( $\\gamma$ ). In Equation (2), *n* is the number of pairs of sample points *z* separated by distance *h*, and  $\\hat{\\gamma}(h)$  is the semivariogram which is a function of distance [41].The basic formula for OK is Equation (3), in which the  $\\lambda_i$  is the kriging weight and  $Z(x_0)$  is the observed value at point  $x_0$ .",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.7898163795471191,
            -0.984950840473175
        ],
        "MSU_id": 2523
    },
    {
        "sentence": "A visual exploration method was proposed to analyze air pollution data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 471,
        "paper_id": 5,
        "paragraph_info": "A visual exploration method was proposed to analyze air pollution data, which enables rapid processing and multi-perspective exploration of air pollution data to reveal spatio-temporal patterns and basic relationships among multiple variables. The developed method follows the observation-hypothesis-verification process of the scientific method and thus complies with the demands of empirical science. The proposed visual exploration method achieved rapid processing and accurate air pollution results for Beijing to guide the daily lives of residents and government decisions. Based on a series of multi-perspective visualizations of  $PM_{2.5}$  data for Beijing, we conclude that the following propositions are suitable topics for further empirical study:",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.7959811687469482,
            1.0069104433059692
        ],
        "MSU_id": 2554
    },
    {
        "sentence": "The method enables rapid processing and multi-perspective exploration of air pollution data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 471,
        "paper_id": 5,
        "paragraph_info": "A visual exploration method was proposed to analyze air pollution data, which enables rapid processing and multi-perspective exploration of air pollution data to reveal spatio-temporal patterns and basic relationships among multiple variables. The developed method follows the observation-hypothesis-verification process of the scientific method and thus complies with the demands of empirical science. The proposed visual exploration method achieved rapid processing and accurate air pollution results for Beijing to guide the daily lives of residents and government decisions. Based on a series of multi-perspective visualizations of  $PM_{2.5}$  data for Beijing, we conclude that the following propositions are suitable topics for further empirical study:",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.8917124271392822,
            -0.5940737128257751
        ],
        "MSU_id": 2555
    },
    {
        "sentence": "The developed method follows the observation-hypothesis-verification process of the scientific method.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 471,
        "paper_id": 5,
        "paragraph_info": "A visual exploration method was proposed to analyze air pollution data, which enables rapid processing and multi-perspective exploration of air pollution data to reveal spatio-temporal patterns and basic relationships among multiple variables. The developed method follows the observation-hypothesis-verification process of the scientific method and thus complies with the demands of empirical science. The proposed visual exploration method achieved rapid processing and accurate air pollution results for Beijing to guide the daily lives of residents and government decisions. Based on a series of multi-perspective visualizations of  $PM_{2.5}$  data for Beijing, we conclude that the following propositions are suitable topics for further empirical study:",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.2876889109611511,
            1.4256364107131958
        ],
        "MSU_id": 2557
    },
    {
        "sentence": "Spatial distribution of air pollutants was determined through geovisualization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 474,
        "paper_id": 5,
        "paragraph_info": "(3) Spatial distribution of air pollutants was also determined through geovisualization. Vegetation, terrain, and land use influenced air contamination. Vegetation could reduce the diffusion of atmospheric pollutants and absorb some pollutants. Arable lands had considerably higher concentrations of air pollutants than vegetation-covered areas.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.5561287999153137,
            1.3016210794448853
        ],
        "MSU_id": 2571
    },
    {
        "sentence": "By incorporating remote-sensing data, AQI data can be used to evaluate air quality at a regional or global extent.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 475,
        "paper_id": 5,
        "paragraph_info": "The findings obtained in this study can be used as reference for further statistical analysis. By incorporating remote-sensing data, AQI data can be used to evaluate air quality at a regional or global extent. With the hot spots identified by our method, the severely polluted periods could be easily determined for air composition and transformation analysis from the physical and chemical perspectives; thus, the emission source could be more easily confirmed. Our future work will combine passive remote sensing and Mie/Raman LiDAR and incorporate extra models for more comprehensive analysis based on our previous studies [\\[44\\]](#page-19-13). Moreover, our method can be extended to visual analyses in other domains, such as soil pollution, climate change, and urban sprawl.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.04795920476317406,
            -1.8482586145401
        ],
        "MSU_id": 2577
    },
    {
        "sentence": "Our future work will combine passive remote sensing and Mie/Raman LiDAR and incorporate extra models for more comprehensive analysis based on our previous studies.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 475,
        "paper_id": 5,
        "paragraph_info": "The findings obtained in this study can be used as reference for further statistical analysis. By incorporating remote-sensing data, AQI data can be used to evaluate air quality at a regional or global extent. With the hot spots identified by our method, the severely polluted periods could be easily determined for air composition and transformation analysis from the physical and chemical perspectives; thus, the emission source could be more easily confirmed. Our future work will combine passive remote sensing and Mie/Raman LiDAR and incorporate extra models for more comprehensive analysis based on our previous studies [\\[44\\]](#page-19-13). Moreover, our method can be extended to visual analyses in other domains, such as soil pollution, climate change, and urban sprawl.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.0732967853546143,
            -1.6528226137161255
        ],
        "MSU_id": 2580
    },
    {
        "sentence": "The open source tools were used to realize the visualization in the paper.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 479,
        "paper_id": 5,
        "paragraph_info": "The open source tools were used to realize the visualization in the paper. Because open source software is free, it is easily accessible by researchers in developing countries or young scientists who may not have enough funds to support their studies. In addition, the open codes are modifiable and extendable for custom usage. Moreover, open communities like Github, provide an abundance of example plots, which are updated in real-time for multi-perspective spatio-temporal visualization exploration. Therefore, it is reasonable and suitable to use those tools for visual analytics. In this appendix, we introduce two tools used for our paper: PivotTable.js and D3.js.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.9799563884735107,
            1.50006902217865
        ],
        "MSU_id": 2594
    },
    {
        "sentence": "PivotTable's core function is to import structured data as a summary table.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 480,
        "paper_id": 5,
        "paragraph_info": "PivotTable.js [\\[45\\]](#page-19-14) is an open source JavaScript library with drag-and-drop functionality based on jQuery and jQueryUI. PivotTable's core function is to import structured data as a summary table that displays specific attribute data with a drag-and-drop interface. The summary table can be rendered into various charts, transforming the table directly into figures. PivotTable has the following characteristics.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.1819648742675781,
            -0.27431851625442505
        ],
        "MSU_id": 2601
    },
    {
        "sentence": "The summary table displays specific attribute data with a drag-and-drop interface.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 480,
        "paper_id": 5,
        "paragraph_info": "PivotTable.js [\\[45\\]](#page-19-14) is an open source JavaScript library with drag-and-drop functionality based on jQuery and jQueryUI. PivotTable's core function is to import structured data as a summary table that displays specific attribute data with a drag-and-drop interface. The summary table can be rendered into various charts, transforming the table directly into figures. PivotTable has the following characteristics.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.67002272605896,
            0.48194900155067444
        ],
        "MSU_id": 2602
    },
    {
        "sentence": "The summary table can be rendered into various charts.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 480,
        "paper_id": 5,
        "paragraph_info": "PivotTable.js [\\[45\\]](#page-19-14) is an open source JavaScript library with drag-and-drop functionality based on jQuery and jQueryUI. PivotTable's core function is to import structured data as a summary table that displays specific attribute data with a drag-and-drop interface. The summary table can be rendered into various charts, transforming the table directly into figures. PivotTable has the following characteristics.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.2338534593582153,
            0.7713600397109985
        ],
        "MSU_id": 2603
    },
    {
        "sentence": "The table can be transformed directly into figures.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 480,
        "paper_id": 5,
        "paragraph_info": "PivotTable.js [\\[45\\]](#page-19-14) is an open source JavaScript library with drag-and-drop functionality based on jQuery and jQueryUI. PivotTable's core function is to import structured data as a summary table that displays specific attribute data with a drag-and-drop interface. The summary table can be rendered into various charts, transforming the table directly into figures. PivotTable has the following characteristics.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5113691091537476,
            0.022236697375774384
        ],
        "MSU_id": 2604
    },
    {
        "sentence": "The function $.pivotUtilities.derivers.dateFormat can reformat complicated date or date-time values into day, hour, minute, week, month values.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 482,
        "paper_id": 5,
        "paragraph_info": "Second, it can be used for formatted data extraction. Through PivotTable, the function \\$.pivotUtilities.derivers.dateFormat can reformat complicated date or date-time values into day, hour, minute, week, month values. Thus, time data can be easily extracted; for example, the time data format, \"2/8/2013 9:10:30 PM\", can be reformatted as shown in Table [A1.](#page-15-0) This is a very useful function when working with temporal data. Derived attributes can be created on the fly based on the whole input record by passing it through a function.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.061524320393800735,
            -1.8261851072311401
        ],
        "MSU_id": 2611
    },
    {
        "sentence": "Derived attributes can be created on the fly based on the whole input record by passing it through a function.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 482,
        "paper_id": 5,
        "paragraph_info": "Second, it can be used for formatted data extraction. Through PivotTable, the function \\$.pivotUtilities.derivers.dateFormat can reformat complicated date or date-time values into day, hour, minute, week, month values. Thus, time data can be easily extracted; for example, the time data format, \"2/8/2013 9:10:30 PM\", can be reformatted as shown in Table [A1.](#page-15-0) This is a very useful function when working with temporal data. Derived attributes can be created on the fly based on the whole input record by passing it through a function.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.2573182284832001,
            -1.594736933708191
        ],
        "MSU_id": 2615
    },
    {
        "sentence": "The tool includes the capacity to create heat maps.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 483,
        "paper_id": 5,
        "paragraph_info": "Third, it is an efficient and intuitive basic visual analysis tool that includes the capacity to create heat maps and bar, line, and pie charts using interactive drag-and-drop operations.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.2967016398906708,
            1.3394278287887573
        ],
        "MSU_id": 2617
    },
    {
        "sentence": "The tool includes the capacity to create bar charts.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 483,
        "paper_id": 5,
        "paragraph_info": "Third, it is an efficient and intuitive basic visual analysis tool that includes the capacity to create heat maps and bar, line, and pie charts using interactive drag-and-drop operations.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.6079455614089966,
            1.1703813076019287
        ],
        "MSU_id": 2618
    },
    {
        "sentence": "The tool includes the capacity to create line charts.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 483,
        "paper_id": 5,
        "paragraph_info": "Third, it is an efficient and intuitive basic visual analysis tool that includes the capacity to create heat maps and bar, line, and pie charts using interactive drag-and-drop operations.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.6167992353439331,
            1.288488745689392
        ],
        "MSU_id": 2619
    },
    {
        "sentence": "The tool includes the capacity to create pie charts.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 483,
        "paper_id": 5,
        "paragraph_info": "Third, it is an efficient and intuitive basic visual analysis tool that includes the capacity to create heat maps and bar, line, and pie charts using interactive drag-and-drop operations.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.6279543042182922,
            1.295488715171814
        ],
        "MSU_id": 2620
    },
    {
        "sentence": "The tool allows for interactive drag-and-drop operations.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 483,
        "paper_id": 5,
        "paragraph_info": "Third, it is an efficient and intuitive basic visual analysis tool that includes the capacity to create heat maps and bar, line, and pie charts using interactive drag-and-drop operations.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.8521223664283752,
            0.9217955470085144
        ],
        "MSU_id": 2621
    },
    {
        "sentence": "Users can easily use PivotTable to perform basic statistical analysis.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 484,
        "paper_id": 5,
        "paragraph_info": "Finally, users can easily use PivotTable to perform basic statistical analysis, such as calculating mean, sum and median. If necessary, customized TSV data can be outputted as data for inputting into the next layer for further visualization and analysis.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.0889254808425903,
            0.8538165092468262
        ],
        "MSU_id": 2622
    },
    {
        "sentence": "Customized TSV data can be outputted for inputting into the next layer for further visualization and analysis.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 484,
        "paper_id": 5,
        "paragraph_info": "Finally, users can easily use PivotTable to perform basic statistical analysis, such as calculating mean, sum and median. If necessary, customized TSV data can be outputted as data for inputting into the next layer for further visualization and analysis.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.6144490242004395,
            0.11683355271816254
        ],
        "MSU_id": 2624
    },
    {
        "sentence": "A is the renderer, used to select the type of visualization, such as table, heat map, and line chart.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 485,
        "paper_id": 5,
        "paragraph_info": "Figure [A1](#page-2-0) is the PivotTable GUI, showing its basic function areas. As seen in the figure, A and B are drop-down boxes that display options for users. A is the renderer, used to select the type of visualization, such as table, heat map, and line chart. B is the aggregator, used for selecting data for display, like mean AQI of PM2.5. C is the container for the attributes, and D is the Row attribute. E is the Column, to which attributes are dragged from C for visualization. The attribute data can be selected for analysis; for example, we can choose January from the 'month' attribute for analysis. F is the Data Visualization area, where the renderer builds an appropriate visualization.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.8060215711593628,
            1.0432345867156982
        ],
        "MSU_id": 2627
    },
    {
        "sentence": "B is the aggregator, used for selecting data for display, like mean AQI of PM2.5.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 485,
        "paper_id": 5,
        "paragraph_info": "Figure [A1](#page-2-0) is the PivotTable GUI, showing its basic function areas. As seen in the figure, A and B are drop-down boxes that display options for users. A is the renderer, used to select the type of visualization, such as table, heat map, and line chart. B is the aggregator, used for selecting data for display, like mean AQI of PM2.5. C is the container for the attributes, and D is the Row attribute. E is the Column, to which attributes are dragged from C for visualization. The attribute data can be selected for analysis; for example, we can choose January from the 'month' attribute for analysis. F is the Data Visualization area, where the renderer builds an appropriate visualization.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.9080451130867004,
            -1.2572797536849976
        ],
        "MSU_id": 2628
    },
    {
        "sentence": "E is the Column, to which attributes are dragged from C for visualization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 485,
        "paper_id": 5,
        "paragraph_info": "Figure [A1](#page-2-0) is the PivotTable GUI, showing its basic function areas. As seen in the figure, A and B are drop-down boxes that display options for users. A is the renderer, used to select the type of visualization, such as table, heat map, and line chart. B is the aggregator, used for selecting data for display, like mean AQI of PM2.5. C is the container for the attributes, and D is the Row attribute. E is the Column, to which attributes are dragged from C for visualization. The attribute data can be selected for analysis; for example, we can choose January from the 'month' attribute for analysis. F is the Data Visualization area, where the renderer builds an appropriate visualization.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5593899488449097,
            0.07774046808481216
        ],
        "MSU_id": 2631
    },
    {
        "sentence": "F is the Data Visualization area, where the renderer builds an appropriate visualization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 485,
        "paper_id": 5,
        "paragraph_info": "Figure [A1](#page-2-0) is the PivotTable GUI, showing its basic function areas. As seen in the figure, A and B are drop-down boxes that display options for users. A is the renderer, used to select the type of visualization, such as table, heat map, and line chart. B is the aggregator, used for selecting data for display, like mean AQI of PM2.5. C is the container for the attributes, and D is the Row attribute. E is the Column, to which attributes are dragged from C for visualization. The attribute data can be selected for analysis; for example, we can choose January from the 'month' attribute for analysis. F is the Data Visualization area, where the renderer builds an appropriate visualization.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.4907657504081726,
            1.3464676141738892
        ],
        "MSU_id": 2633
    },
    {
        "sentence": "A global analysis visualization program can be used to preprocess data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 486,
        "paper_id": 5,
        "paragraph_info": "PivotTable has data preprocessing capabilities. A global analysis visualization program can be used to preprocess data. By dragging and dropping attributes to the rows and columns and selecting TSV output in the renderer, the corresponding data are shown in the Data Visualization Area. This custom function makes it very easy and efficient to export data that can be directly used for further analysis applications.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.34676849842071533,
            1.6344276666641235
        ],
        "MSU_id": 2635
    },
    {
        "sentence": "By dragging and dropping attributes to the rows and columns and selecting TSV output in the renderer, the corresponding data are shown in the Data Visualization Area.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 486,
        "paper_id": 5,
        "paragraph_info": "PivotTable has data preprocessing capabilities. A global analysis visualization program can be used to preprocess data. By dragging and dropping attributes to the rows and columns and selecting TSV output in the renderer, the corresponding data are shown in the Data Visualization Area. This custom function makes it very easy and efficient to export data that can be directly used for further analysis applications.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.071536660194397,
            1.2003804445266724
        ],
        "MSU_id": 2636
    },
    {
        "sentence": "We use another visualization to show the data missing.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 489,
        "paper_id": 5,
        "paragraph_info": "It has been noted in the paper that the U-Air data used in the cased study has some defects. This supplement file is to strengthen the idea and give more inspection to the original data. We use another visualization to show the data missing and a table to present the anomaly weather data in it.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.730616569519043,
            0.48024672269821167
        ],
        "MSU_id": 2648
    },
    {
        "sentence": "We present a table to show the anomaly weather data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 489,
        "paper_id": 5,
        "paragraph_info": "It has been noted in the paper that the U-Air data used in the cased study has some defects. This supplement file is to strengthen the idea and give more inspection to the original data. We use another visualization to show the data missing and a table to present the anomaly weather data in it.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.0315072536468506,
            -0.6358954310417175
        ],
        "MSU_id": 2649
    },
    {
        "sentence": "The scatter plot is another kind of visual method for missing data check.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 492,
        "paper_id": 5,
        "paragraph_info": "In Figure A2, the red dot rectangle marks the missing data area. The black line is the regression line of the observations. The scatter plot is another kind of visual methods for missing data check. It confirms the results shown in Figure 3 in Section 3.1, identifying that data are missing from some stations from March to October.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.6756187677383423,
            1.6499279737472534
        ],
        "MSU_id": 2654
    },
    {
        "sentence": "We decided to replace the weather records in the U-Air data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 493,
        "paper_id": 5,
        "paragraph_info": "As seen in Figure A3, snowy weather occurred from April to June, showing incorrect records because this is impossible in Beijing (39.92N, 116.44E); there was no sunny weather from June to October, also suggesting data anomalies. Considering the defects identified in this figure, we decided to replace the weather records in the U-Air data.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            0.6923342347145081,
            -2.047377586364746
        ],
        "MSU_id": 2660
    },
    {
        "sentence": "With PivotTable.js, this table can be reproduced by making the row as 'month name' and the column with 'weather name'.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 494,
        "paper_id": 5,
        "paragraph_info": "**Figure A3.** The average AQI of  $PM_{2.5}$  as shown in PivotTable; rows represents months, and columns contain the weather data. With PivotTable.js, this table can be reproduced by making the row as \"month name\", and the column with \"weather name\".",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.5004411935806274,
            -1.3500518798828125
        ],
        "MSU_id": 2664
    },
    {
        "sentence": "We developed three hypotheses.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 495,
        "paper_id": 5,
        "paragraph_info": "This part focuses on the design for visualization and data preprocessing. Through the, we developed three hypotheses and a corresponding visualized design and implementation tools to test these propositions. Data preprocessing is also considered.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.7505199313163757,
            0.40127915143966675
        ],
        "MSU_id": 2666
    },
    {
        "sentence": "We developed a corresponding visualized design and implementation tools to test these propositions.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 495,
        "paper_id": 5,
        "paragraph_info": "This part focuses on the design for visualization and data preprocessing. Through the, we developed three hypotheses and a corresponding visualized design and implementation tools to test these propositions. Data preprocessing is also considered.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.6286725997924805,
            1.3813711404800415
        ],
        "MSU_id": 2667
    },
    {
        "sentence": "This correlation can be visualized by scatterplots showing the relationship between any two factors.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 496,
        "paper_id": 5,
        "paragraph_info": "Three hypotheses are shown in Table [A2.](#page-17-5) The first hypothesis is that there is a correlation among the AQI of PM2.5, PM10, NO<sup>2</sup> and wind speed. This can be visualized by scatterplots showing the relationship between any two factors. The second is that there is a regular time pattern for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map, calendar view, and heat matrix, as generated using D3. The third hypothesis is that air contaminants have a geographical distribution. This can be represented appropriately by geovisualization, a method suitable for illustrating continuous spatial distributions. There are different ways to achieve Geovisualization with D3 or OpenLayers.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.7592200636863708,
            1.792014718055725
        ],
        "MSU_id": 2671
    },
    {
        "sentence": "Heat maps would be an ideal visualization method for this hypothesis.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 496,
        "paper_id": 5,
        "paragraph_info": "Three hypotheses are shown in Table [A2.](#page-17-5) The first hypothesis is that there is a correlation among the AQI of PM2.5, PM10, NO<sup>2</sup> and wind speed. This can be visualized by scatterplots showing the relationship between any two factors. The second is that there is a regular time pattern for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map, calendar view, and heat matrix, as generated using D3. The third hypothesis is that air contaminants have a geographical distribution. This can be represented appropriately by geovisualization, a method suitable for illustrating continuous spatial distributions. There are different ways to achieve Geovisualization with D3 or OpenLayers.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.2946934103965759,
            1.6533976793289185
        ],
        "MSU_id": 2673
    },
    {
        "sentence": "Heat maps can include a circle heat map, calendar view, and heat matrix, as generated using D3.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 496,
        "paper_id": 5,
        "paragraph_info": "Three hypotheses are shown in Table [A2.](#page-17-5) The first hypothesis is that there is a correlation among the AQI of PM2.5, PM10, NO<sup>2</sup> and wind speed. This can be visualized by scatterplots showing the relationship between any two factors. The second is that there is a regular time pattern for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map, calendar view, and heat matrix, as generated using D3. The third hypothesis is that air contaminants have a geographical distribution. This can be represented appropriately by geovisualization, a method suitable for illustrating continuous spatial distributions. There are different ways to achieve Geovisualization with D3 or OpenLayers.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.12507367134094238,
            0.340323269367218
        ],
        "MSU_id": 2674
    },
    {
        "sentence": "This geographical distribution can be represented appropriately by geovisualization.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 496,
        "paper_id": 5,
        "paragraph_info": "Three hypotheses are shown in Table [A2.](#page-17-5) The first hypothesis is that there is a correlation among the AQI of PM2.5, PM10, NO<sup>2</sup> and wind speed. This can be visualized by scatterplots showing the relationship between any two factors. The second is that there is a regular time pattern for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map, calendar view, and heat matrix, as generated using D3. The third hypothesis is that air contaminants have a geographical distribution. This can be represented appropriately by geovisualization, a method suitable for illustrating continuous spatial distributions. There are different ways to achieve Geovisualization with D3 or OpenLayers.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.41736531257629395,
            1.8535162210464478
        ],
        "MSU_id": 2676
    },
    {
        "sentence": "There are different ways to achieve geovisualization with D3 or OpenLayers.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 496,
        "paper_id": 5,
        "paragraph_info": "Three hypotheses are shown in Table [A2.](#page-17-5) The first hypothesis is that there is a correlation among the AQI of PM2.5, PM10, NO<sup>2</sup> and wind speed. This can be visualized by scatterplots showing the relationship between any two factors. The second is that there is a regular time pattern for air pollutants. Heat maps would be an ideal visualization method, including a circle heat map, calendar view, and heat matrix, as generated using D3. The third hypothesis is that air contaminants have a geographical distribution. This can be represented appropriately by geovisualization, a method suitable for illustrating continuous spatial distributions. There are different ways to achieve Geovisualization with D3 or OpenLayers.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.2263330221176147,
            0.8109789490699768
        ],
        "MSU_id": 2678
    },
    {
        "sentence": "Data pretreatment in PivotTable is efficient because of its built-in deriver generators.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 497,
        "paper_id": 5,
        "paragraph_info": "Data preprocessing precedes visualization. Data pretreatment in PivotTable is efficient because of its built-in deriver generators. After preprocessing, data can be used for visualization. As analyzed in Appendix B, weather data has some anomalies, so we replace that part with rainy weather in which the precipitation in mm [\\[36\\]](#page-19-5). With this correction, we can analyze the correlation between the severity of air pollution and the precipitation.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.362572193145752,
            -0.9411816000938416
        ],
        "MSU_id": 2680
    },
    {
        "sentence": "Weather data has some anomalies, so we replace that part with rainy weather in which the precipitation in mm.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 497,
        "paper_id": 5,
        "paragraph_info": "Data preprocessing precedes visualization. Data pretreatment in PivotTable is efficient because of its built-in deriver generators. After preprocessing, data can be used for visualization. As analyzed in Appendix B, weather data has some anomalies, so we replace that part with rainy weather in which the precipitation in mm [\\[36\\]](#page-19-5). With this correction, we can analyze the correlation between the severity of air pollution and the precipitation.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.6981476545333862,
            -0.8153733015060425
        ],
        "MSU_id": 2682
    },
    {
        "sentence": "The data production for Figures [9] and [10] in the paper is by PivotTable with USE data.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 498,
        "paper_id": 5,
        "paragraph_info": "The data production for Figures [9](#page-10-0) and [10](#page-11-0) in the paper is by PivotTable with USE data. The Figure [9a](#page-10-0) is produced by setting rows with \"Year\" and \"Month\", while Figure [9b](#page-10-0) is produced by setting rows with \"Year\" and \"Hour\", both choosing \"TSV Export\" in the Aggregator of PivotTable. Then the data in Tab separated values (TSV) form can be easily visualized by D3.js without additional data processing.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -1.2064447402954102,
            -0.43598663806915283
        ],
        "MSU_id": 2684
    },
    {
        "sentence": "Figure [9a] is produced by setting rows with 'Year' and 'Month'.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 498,
        "paper_id": 5,
        "paragraph_info": "The data production for Figures [9](#page-10-0) and [10](#page-11-0) in the paper is by PivotTable with USE data. The Figure [9a](#page-10-0) is produced by setting rows with \"Year\" and \"Month\", while Figure [9b](#page-10-0) is produced by setting rows with \"Year\" and \"Hour\", both choosing \"TSV Export\" in the Aggregator of PivotTable. Then the data in Tab separated values (TSV) form can be easily visualized by D3.js without additional data processing.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.20002484321594238,
            1.5182636976242065
        ],
        "MSU_id": 2685
    },
    {
        "sentence": "Figure [9b] is produced by setting rows with 'Year' and 'Hour'.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 498,
        "paper_id": 5,
        "paragraph_info": "The data production for Figures [9](#page-10-0) and [10](#page-11-0) in the paper is by PivotTable with USE data. The Figure [9a](#page-10-0) is produced by setting rows with \"Year\" and \"Month\", while Figure [9b](#page-10-0) is produced by setting rows with \"Year\" and \"Hour\", both choosing \"TSV Export\" in the Aggregator of PivotTable. Then the data in Tab separated values (TSV) form can be easily visualized by D3.js without additional data processing.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.5149825811386108,
            1.1787139177322388
        ],
        "MSU_id": 2686
    },
    {
        "sentence": "Both figures choose 'TSV Export' in the Aggregator of PivotTable.",
        "category": "Method",
        "rank": -1,
        "type": "text",
        "para_id": 498,
        "paper_id": 5,
        "paragraph_info": "The data production for Figures [9](#page-10-0) and [10](#page-11-0) in the paper is by PivotTable with USE data. The Figure [9a](#page-10-0) is produced by setting rows with \"Year\" and \"Month\", while Figure [9b](#page-10-0) is produced by setting rows with \"Year\" and \"Hour\", both choosing \"TSV Export\" in the Aggregator of PivotTable. Then the data in Tab separated values (TSV) form can be easily visualized by D3.js without additional data processing.",
        "paper_info": "atmosphere-07-00035",
        "2d_coord": [
            -0.36902156472206116,
            -0.8069908618927002
        ],
        "MSU_id": 2687
    }
]