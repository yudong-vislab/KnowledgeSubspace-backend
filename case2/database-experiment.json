[
  {
    "sentence": "The effectiveness of Compass is evaluated with two case studies conducted on the real-world urban datasets, including the air pollution and traffic speed datasets.",
    "subtitle": "Compass: Towards Better Causal Analysis of Urban Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 23,
    "para_id": 2,
    "paper_id": 0,
    "2d_coord": [
      0.49816352128982544,
      -0.09247046709060669
    ],
    "MSU_id": 23,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Abstract— The spatial time series generated by city sensors allow us to observe urban phenomena like environmental pollution and traffic congestion at an unprecedented scale. However, recovering causal relations from these observations to explain the sources of urban phenomena remains a challenging task because these causal relations tend to be time- varying and demand proper time series partitioning for effective analyses. The prior approaches extract one causal graph given long- time observations, which cannot be directly applied to capturing, interpreting, and validating dynamic urban causality. This paper presents Compass, a novel visual analytics approach for in- depth analyses of the dynamic causality in urban time series. To develop Compass, we identify and address three challenges: detecting urban causality, interpreting dynamic causal relations, and unveiling suspicious causal relations. First, multiple causal graphs over time among urban time series are obtained with a causal detection framework extended from the Granger causality test. Then, a dynamic causal graph visualization is designed to reveal the time- varying causal relations across these causal graphs and facilitate the exploration of the graphs along the time. Finally, a tailored multi- dimensional visualization is developed to support the identification of spurious causal relations, thereby improving the reliability of causal analyses. The effectiveness of Compass is evaluated with two case studies conducted on the real- world urban datasets, including the air pollution and traffic speed datasets, and positive feedback was received from domain experts."
  },
  {
    "sentence": "We evaluate our approach through two real-world case studies.",
    "subtitle": "1 INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 74,
    "para_id": 10,
    "paper_id": 0,
    "2d_coord": [
      0.2230953872203827,
      0.04434853792190552
    ],
    "MSU_id": 74,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "$\\hat{\\zeta}$  We propose a causal detection framework for urban time series by extending the Granger causality test.  $\\hat{\\zeta}$  We design and implement a novel visual analytics system called Compass for causal analysis of urban time series. Compass incorporates the causal detection framework and a set of effective visualizations for analyzing dynamic causalities.  $\\hat{\\zeta}$  We evaluate our approach through two real- world case studies."
  },
  {
    "sentence": "In the past six months, we collaborated closely with three experts (EA, EB, and EC).",
    "subtitle": "3.1 Problem Formulation",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 159,
    "para_id": 26,
    "paper_id": 0,
    "2d_coord": [
      1.0562900304794312,
      0.7580351233482361
    ],
    "MSU_id": 159,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This study is the result of cooperation with multiple domains. On the one hand, rapid urbanization has resulted in many notorious urban problems, such as noise [9], traffic congestion [53], and water/air pollution [46]. On the other hand, various applications have proven the utility of causal analysis in providing valuable implications. In the past six months, we collaborated closely with three experts (EA, EB and EC). EA and EB are urban computing experts who have decades of experience studying data- driven solutions for urban problems. EC is a researcher with expertise in causal analyses. We together attempt to apply causal analysis to solve the urban problems. As a statistical analysis method, causal analysis is not limited to computer scientists but can be accepted by urban practitioners with statistical knowledge."
  },
  {
    "sentence": "EA and EB are urban computing experts who have decades of experience studying data-driven solutions for urban problems.",
    "subtitle": "3.1 Problem Formulation",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 160,
    "para_id": 26,
    "paper_id": 0,
    "2d_coord": [
      0.5130283832550049,
      -0.04678159952163696
    ],
    "MSU_id": 160,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This study is the result of cooperation with multiple domains. On the one hand, rapid urbanization has resulted in many notorious urban problems, such as noise [9], traffic congestion [53], and water/air pollution [46]. On the other hand, various applications have proven the utility of causal analysis in providing valuable implications. In the past six months, we collaborated closely with three experts (EA, EB and EC). EA and EB are urban computing experts who have decades of experience studying data- driven solutions for urban problems. EC is a researcher with expertise in causal analyses. We together attempt to apply causal analysis to solve the urban problems. As a statistical analysis method, causal analysis is not limited to computer scientists but can be accepted by urban practitioners with statistical knowledge."
  },
  {
    "sentence": "EC is a researcher with expertise in causal analyses.",
    "subtitle": "3.1 Problem Formulation",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 161,
    "para_id": 26,
    "paper_id": 0,
    "2d_coord": [
      1.1503998041152954,
      0.021785825490951538
    ],
    "MSU_id": 161,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This study is the result of cooperation with multiple domains. On the one hand, rapid urbanization has resulted in many notorious urban problems, such as noise [9], traffic congestion [53], and water/air pollution [46]. On the other hand, various applications have proven the utility of causal analysis in providing valuable implications. In the past six months, we collaborated closely with three experts (EA, EB and EC). EA and EB are urban computing experts who have decades of experience studying data- driven solutions for urban problems. EC is a researcher with expertise in causal analyses. We together attempt to apply causal analysis to solve the urban problems. As a statistical analysis method, causal analysis is not limited to computer scientists but can be accepted by urban practitioners with statistical knowledge."
  },
  {
    "sentence": "Suppose a time-varying system has N variables, and each one collects a time series v.",
    "subtitle": "4.1 Granger causality",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 235,
    "para_id": 41,
    "paper_id": 0,
    "2d_coord": [
      0.9780259132385254,
      0.8608653545379639
    ],
    "MSU_id": 235,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Prediction. The Granger causality test applies the vector autoregressive (VAR) model [61] as the prediction model. In VAR, the current state of a system can be predicted by the past  $K$  states in different time series across the system. Suppose a time- varying system has  $N$  variables, and each one collects a time series  $\\mathbf{v}$ .  $\\mathbf{v}_t^n$  denotes the record at time  $t$  in the  $n$ - th variable. The VAR model of this system is written as"
  },
  {
    "sentence": "v_t^n denotes the record at time t in the n-th variable.",
    "subtitle": "4.1 Granger causality",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 236,
    "para_id": 41,
    "paper_id": 0,
    "2d_coord": [
      0.1264987587928772,
      1.4902520179748535
    ],
    "MSU_id": 236,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Prediction. The Granger causality test applies the vector autoregressive (VAR) model [61] as the prediction model. In VAR, the current state of a system can be predicted by the past  $K$  states in different time series across the system. Suppose a time- varying system has  $N$  variables, and each one collects a time series  $\\mathbf{v}$ .  $\\mathbf{v}_t^n$  denotes the record at time  $t$  in the  $n$ - th variable. The VAR model of this system is written as"
  },
  {
    "sentence": "Multiple tests need to be executed under every K ≤ K⁺.",
    "subtitle": "4.1 Granger causality",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 246,
    "para_id": 45,
    "paper_id": 0,
    "2d_coord": [
      0.5389982461929321,
      -0.1412028670310974
    ],
    "MSU_id": 246,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Given a maximum time lag  $K^+$ , multiple tests need to be executed under every  $K\\leq K^{+}$  to determine the best result based on the p- value."
  },
  {
    "sentence": "The tests are executed to determine the best result based on the p-value.",
    "subtitle": "4.1 Granger causality",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 247,
    "para_id": 45,
    "paper_id": 0,
    "2d_coord": [
      0.8229517936706543,
      -0.1365695595741272
    ],
    "MSU_id": 247,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Given a maximum time lag  $K^+$ , multiple tests need to be executed under every  $K\\leq K^{+}$  to determine the best result based on the p- value."
  },
  {
    "sentence": "This procedure is accomplished using Python find peaks imported from a well-known library.",
    "subtitle": "4.2.1 Data Pre-processing",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 266,
    "para_id": 49,
    "paper_id": 0,
    "2d_coord": [
      1.341909408569336,
      1.4196727275848389
    ],
    "MSU_id": 266,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Partitioning time. Two strategies for time partitioning can be used based on whether the time series is periodic. For periodic time series, they can be directly partitioned by their period. For example, traffic time series can be naturally partitioned by 24 hours. Otherwise, the peaks of the time series will be extracted automatically, and thereby the time windows can be identified based on these peaks. This procedure is accomplished using Python find peaks imported from a well-"
  },
  {
    "sentence": "Fig. 5e summarizes the causal directions in the bottom-right edge (i.e., e2) across the three causal graphs.",
    "subtitle": "5.1 Map View",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 356,
    "para_id": 64,
    "paper_id": 0,
    "2d_coord": [
      0.618030309677124,
      -0.18068617582321167
    ],
    "MSU_id": 356,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "causal graph on the map (R1). The causal directions across multiple graphs are first aggregated according to the edge. The aggregation is then encoded with a revisited compass glyph (Fig. 5e). For example, Fig. 5e summarizes the causal directions in the bottom- right edge (i.e., e2) across the three causal graphs. In a revisited compass glyph, arrows still convey the causal directions within a spatial context. The glyph is revised to incorporate the temporal information as follows. The arrow's size encodes the frequency of the causal links with this direction. An offset between the two opposite arrows can be observed if bi- directional relations exist. The overlapping part of the two arrows encodes the frequency of bi- directional relations."
  },
  {
    "sentence": "This section presents the evaluation of the system.",
    "subtitle": "6 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 485,
    "para_id": 83,
    "paper_id": 0,
    "2d_coord": [
      0.5838258862495422,
      0.07390671968460083
    ],
    "MSU_id": 485,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This section presents the evaluation of the system. We first invited the experts and performed a training session to introduce the system. We ensured that the experts understood the system, including the visual encodings and user interactions. Afterward, the experts freely used our system to perform causal analyses on two real- world time series datasets, namely, air pollution and traffic datasets. We also interviewed the experts one- on- one to collect their feedback after the case studies."
  },
  {
    "sentence": "We first invited the experts and performed a training session to introduce the system.",
    "subtitle": "6 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 486,
    "para_id": 83,
    "paper_id": 0,
    "2d_coord": [
      0.5362014174461365,
      -0.03572911024093628
    ],
    "MSU_id": 486,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This section presents the evaluation of the system. We first invited the experts and performed a training session to introduce the system. We ensured that the experts understood the system, including the visual encodings and user interactions. Afterward, the experts freely used our system to perform causal analyses on two real- world time series datasets, namely, air pollution and traffic datasets. We also interviewed the experts one- on- one to collect their feedback after the case studies."
  },
  {
    "sentence": "We ensured that the experts understood the system, including the visual encodings and user interactions.",
    "subtitle": "6 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 487,
    "para_id": 83,
    "paper_id": 0,
    "2d_coord": [
      0.2774403393268585,
      0.5643789768218994
    ],
    "MSU_id": 487,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This section presents the evaluation of the system. We first invited the experts and performed a training session to introduce the system. We ensured that the experts understood the system, including the visual encodings and user interactions. Afterward, the experts freely used our system to perform causal analyses on two real- world time series datasets, namely, air pollution and traffic datasets. We also interviewed the experts one- on- one to collect their feedback after the case studies."
  },
  {
    "sentence": "The experts freely used our system to perform causal analyses on two real-world time series datasets, namely, air pollution and traffic datasets.",
    "subtitle": "6 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 4,
    "msuid": 488,
    "para_id": 83,
    "paper_id": 0,
    "2d_coord": [
      0.4641166925430298,
      -0.1018139123916626
    ],
    "MSU_id": 488,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This section presents the evaluation of the system. We first invited the experts and performed a training session to introduce the system. We ensured that the experts understood the system, including the visual encodings and user interactions. Afterward, the experts freely used our system to perform causal analyses on two real- world time series datasets, namely, air pollution and traffic datasets. We also interviewed the experts one- on- one to collect their feedback after the case studies."
  },
  {
    "sentence": "We also interviewed the experts one-on-one to collect their feedback after the case studies.",
    "subtitle": "6 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 489,
    "para_id": 83,
    "paper_id": 0,
    "2d_coord": [
      0.4183041453361511,
      -0.016415655612945557
    ],
    "MSU_id": 489,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "This section presents the evaluation of the system. We first invited the experts and performed a training session to introduce the system. We ensured that the experts understood the system, including the visual encodings and user interactions. Afterward, the experts freely used our system to perform causal analyses on two real- world time series datasets, namely, air pollution and traffic datasets. We also interviewed the experts one- on- one to collect their feedback after the case studies."
  },
  {
    "sentence": "The air pollution dataset comprises the hourly readings of the PM2.5 concentration from 448 major air quality sensors in China between January 8 and March 23, 2018.",
    "subtitle": "6.1 Causal Analysis of Air Pollution Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 490,
    "para_id": 84,
    "paper_id": 0,
    "2d_coord": [
      1.7641609907150269,
      1.2016355991363525
    ],
    "MSU_id": 490,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Data description. The air pollution dataset we used comprises the hourly readings of the PM2.5 concentration from 448 major air quality sensors in China between January 8 and March 23, 2018. Each sensor comprises a time series with 1800 recorded values. This dataset has a total of 806,400 records and a size of 2.99 MB. We constructed a neighbor index based on the sensors' spatial proximity (Sec. 4.2.1)."
  },
  {
    "sentence": "Each sensor comprises a time series with 1800 recorded values.",
    "subtitle": "6.1 Causal Analysis of Air Pollution Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 491,
    "para_id": 84,
    "paper_id": 0,
    "2d_coord": [
      0.604543149471283,
      -0.1136510968208313
    ],
    "MSU_id": 491,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Data description. The air pollution dataset we used comprises the hourly readings of the PM2.5 concentration from 448 major air quality sensors in China between January 8 and March 23, 2018. Each sensor comprises a time series with 1800 recorded values. This dataset has a total of 806,400 records and a size of 2.99 MB. We constructed a neighbor index based on the sensors' spatial proximity (Sec. 4.2.1)."
  },
  {
    "sentence": "This dataset has a total of 806,400 records and a size of 2.99 MB.",
    "subtitle": "6.1 Causal Analysis of Air Pollution Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 492,
    "para_id": 84,
    "paper_id": 0,
    "2d_coord": [
      0.5135486125946045,
      0.05422186851501465
    ],
    "MSU_id": 492,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Data description. The air pollution dataset we used comprises the hourly readings of the PM2.5 concentration from 448 major air quality sensors in China between January 8 and March 23, 2018. Each sensor comprises a time series with 1800 recorded values. This dataset has a total of 806,400 records and a size of 2.99 MB. We constructed a neighbor index based on the sensors' spatial proximity (Sec. 4.2.1)."
  },
  {
    "sentence": "They set the range of pollution influence speed as 16 km/h, 38 km/h based on the typical wind speeds in Beijing via the slider of Fig. 1a-4.",
    "subtitle": "6.1 Causal Analysis of Air Pollution Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 509,
    "para_id": 87,
    "paper_id": 0,
    "2d_coord": [
      1.1192368268966675,
      1.7043821811676025
    ],
    "MSU_id": 509,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "ego- graph. All edges were gray. These neighbor sensors belong to both the downstream and upstream because the spread of air pollutants has no explicit directions. The time series of the ego sensor was shown in the time view (Fig. 1b). The experts applied the automatic peak identification because of no periodicity. We defaulted a set of suitable parameters after multiple trials to alleviate the user's interaction burden: height  $= 180$ , distance  $= 100$ , prominence  $= 100$ , and wlen  $= 210$ . Seven time windows were generated in Fig. 1b. These windows each cover the prominent peak with a proper duration. Thus, the experts were satisfied with this result and did not adjust them. They set the range of pollution influence speed as  $16\\mathrm{km / h}$ ,  $38\\mathrm{km / h}$  based on the typical wind speeds in Beijing via the slider of Fig. 1a- 4. Seven causal graphs were then accordingly detected in these windows by the model."
  },
  {
    "sentence": "The experts first obtained the spatiotemporal summary.",
    "subtitle": "6.1 Causal Analysis of Air Pollution Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 511,
    "para_id": 88,
    "paper_id": 0,
    "2d_coord": [
      -0.007001936435699463,
      1.1057195663452148
    ],
    "MSU_id": 511,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "The experts first obtained the spatiotemporal summary (Fig. 1a). Fig. 1a- 1 showed that the sensors of Beijing strongly influenced each other because the large arrows and obvious overlaps were observed in the revised compass glyphs. EB explained that the pollutants transported back and forth in Beijing because of its terrain surrounded by mountains on three sides. EA commented \"all districts in Beijing should be treated as a whole for better air pollution control.\" The experts also learned that air pollutants of Beijing could be from Zhangjiakou and could propagate to Langfang (Fig. 1a- 2). They decided to analyze the fine- grained causality revealed by causal graphs after briefly understanding the detected causalities through this summary."
  },
  {
    "sentence": "The experts first wanted to confirm the conclusion drawn by Fig. 1a-1.",
    "subtitle": "6.1 Causal Analysis of Air Pollution Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 519,
    "para_id": 89,
    "paper_id": 0,
    "2d_coord": [
      1.173485279083252,
      0.6254659295082092
    ],
    "MSU_id": 519,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "The graph view presented all causal graphs and causal relations along the time (Fig. 1c). The experts first wanted to confirm the conclusion drawn by Fig. 1a- 1 further. They highlighted all bi- directional causal relations by checking the gray check box (Fig. 1d- 1). Not surprisingly, the causal relations among Beijing sensors enclosed in Fig. 1c- 3 were frequently bi- directional."
  },
  {
    "sentence": "The traffic dataset used in this study was from the released Q-Traffic dataset.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 569,
    "para_id": 99,
    "paper_id": 0,
    "2d_coord": [
      0.6331470012664795,
      -0.18840521574020386
    ],
    "MSU_id": 569,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Data description. The traffic dataset we used was from the released Q- Traffic dataset [39]. This dataset includes subparts of the road network"
  },
  {
    "sentence": "The Q-Traffic dataset includes subparts of the road network.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 570,
    "para_id": 99,
    "paper_id": 0,
    "2d_coord": [
      0.5740221738815308,
      -0.1767142415046692
    ],
    "MSU_id": 570,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "Data description. The traffic dataset we used was from the released Q- Traffic dataset [39]. This dataset includes subparts of the road network"
  },
  {
    "sentence": "The dataset includes traffic speed data for every 15 minutes for every road segment in Beijing.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 571,
    "para_id": 100,
    "paper_id": 0,
    "2d_coord": [
      0.5939700603485107,
      -0.09518152475357056
    ],
    "MSU_id": 571,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "in Beijing and the traffic speed for every 15 minutes for every road segment. We first sampled 511 high- level roads, such as highways. Each road segment is regarded as a road sensor. We also sampled the readings from May 9, 2017 to May 18, 2017. Finally, this dataset totally comprises 490,560 records and has a size of  $1.89\\mathrm{MB}$"
  },
  {
    "sentence": "The dataset sampled 511 high-level roads, such as highways.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 572,
    "para_id": 100,
    "paper_id": 0,
    "2d_coord": [
      0.7657149434089661,
      0.36232903599739075
    ],
    "MSU_id": 572,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "in Beijing and the traffic speed for every 15 minutes for every road segment. We first sampled 511 high- level roads, such as highways. Each road segment is regarded as a road sensor. We also sampled the readings from May 9, 2017 to May 18, 2017. Finally, this dataset totally comprises 490,560 records and has a size of  $1.89\\mathrm{MB}$"
  },
  {
    "sentence": "Each road segment is regarded as a road sensor.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 573,
    "para_id": 100,
    "paper_id": 0,
    "2d_coord": [
      0.7070533037185669,
      0.06973090767860413
    ],
    "MSU_id": 573,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "in Beijing and the traffic speed for every 15 minutes for every road segment. We first sampled 511 high- level roads, such as highways. Each road segment is regarded as a road sensor. We also sampled the readings from May 9, 2017 to May 18, 2017. Finally, this dataset totally comprises 490,560 records and has a size of  $1.89\\mathrm{MB}$"
  },
  {
    "sentence": "The dataset includes readings from May 9, 2017, to May 18, 2017.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 574,
    "para_id": 100,
    "paper_id": 0,
    "2d_coord": [
      0.34222152829170227,
      1.1101164817810059
    ],
    "MSU_id": 574,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "in Beijing and the traffic speed for every 15 minutes for every road segment. We first sampled 511 high- level roads, such as highways. Each road segment is regarded as a road sensor. We also sampled the readings from May 9, 2017 to May 18, 2017. Finally, this dataset totally comprises 490,560 records and has a size of  $1.89\\mathrm{MB}$"
  },
  {
    "sentence": "The dataset comprises a total of 490,560 records.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 575,
    "para_id": 100,
    "paper_id": 0,
    "2d_coord": [
      -0.028236865997314453,
      0.9026784896850586
    ],
    "MSU_id": 575,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "in Beijing and the traffic speed for every 15 minutes for every road segment. We first sampled 511 high- level roads, such as highways. Each road segment is regarded as a road sensor. We also sampled the readings from May 9, 2017 to May 18, 2017. Finally, this dataset totally comprises 490,560 records and has a size of  $1.89\\mathrm{MB}$"
  },
  {
    "sentence": "The dataset has a size of $1.89\\mathrm{MB}$.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 576,
    "para_id": 100,
    "paper_id": 0,
    "2d_coord": [
      0.6636710166931152,
      -0.1380710005760193
    ],
    "MSU_id": 576,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "in Beijing and the traffic speed for every 15 minutes for every road segment. We first sampled 511 high- level roads, such as highways. Each road segment is regarded as a road sensor. We also sampled the readings from May 9, 2017 to May 18, 2017. Finally, this dataset totally comprises 490,560 records and has a size of  $1.89\\mathrm{MB}$"
  },
  {
    "sentence": "A busy traffic area with elevated roads was selected for this case study.",
    "subtitle": "6.2 Causal Analysis of Traffic Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 581,
    "para_id": 101,
    "paper_id": 0,
    "2d_coord": [
      1.069482684135437,
      0.2745996117591858
    ],
    "MSU_id": 581,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "The experts stated that traffic congestion events always propagate backward and cause other congestion events. Thus, the causal directions are opposite to the traffic directions. Based on this prior knowledge, we recovered the downstream and upstream relations of the roads based on the road network and constructed a neighbor index (Sec. 4.2.1). A busy traffic area with elevated roads was selected for this case study."
  },
  {
    "sentence": "We conducted informal interviews with the experts.",
    "subtitle": "6.3 Expert Interviews",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 607,
    "para_id": 106,
    "paper_id": 0,
    "2d_coord": [
      0.4684649109840393,
      -0.013615608215332031
    ],
    "MSU_id": 607,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "We conducted informal interviews with the experts and collected their feedback after the case studies. The feedback is summarized as follows."
  },
  {
    "sentence": "We collected their feedback after the case studies.",
    "subtitle": "6.3 Expert Interviews",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 608,
    "para_id": 106,
    "paper_id": 0,
    "2d_coord": [
      0.38804060220718384,
      -0.0726584792137146
    ],
    "MSU_id": 608,
    "paper_info": "Compass Towards Better Causal Analysis of Urban Time Series",
    "paragraph_info": "We conducted informal interviews with the experts and collected their feedback after the case studies. The feedback is summarized as follows."
  },
  {
    "sentence": "Four parallel experiments were conducted during winter 2019.",
    "subtitle": "ABSTRACT",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 663,
    "para_id": 113,
    "paper_id": 1,
    "2d_coord": [
      2.190173387527466,
      0.8505606055259705
    ],
    "MSU_id": 663,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In numerical model simulations, data assimilation (DA) on the initial conditions and bias correction (BC) of model outputs have been proven to be promising approaches to improving  $\\mathrm{PM}{2.5}$  (particulate matter with an aerodynamic equivalent diameter of  $\\leq 2.5\\mu \\mathrm{m}$ ) predictions. This study compared the optimization effects of these two methods and developed a new scheme that combines DA and BC simultaneously. Four parallel experiments were conducted during winter 2019: a control experiment directly forecasted by WRF- Chem (experiment name: WRF- Chem); an experiment that assimilated in situ observations based on the GSI (Gridpoint Statistical Interpolation) system (WRF- Chem_DA); an experiment with deep- learning- based BC (WRF- Chem_BC); and an experiment considering the combination of DA on the initial conditions and BC (WRF- Chem_DA_BC). Statistically, the accuracy of  $\\mathrm{PM}{2.5}$  predictions could be optimized by both DA and BC for the first 24- h period, and WRF- Chem_BC performed better than WRF- Chem_DA in the initial field, especially in the period of 10–24 h, while the best performance was achieved by combining BC and DA. Throughout the initial 24- h period, compared with the control experiment, the results of WRF- Chem_DA_BC (WRF- Chem_DA, WRF- Chem_BC) showed an improvement in terms of root- mean- square error, with reduction proportions varying from 38.90% to 48.86% (18.88% to 32.44%, 30.10% to 46.08%). Besides having the best optimization effect over the whole domain, the combined method also performed well in different regions: during the forecasting period of 0–24 h, the RMSEs decreased from 32% to 62%, 39% to 57%, 28% to 40%, and 30% to 49% in the Beijing- Tianjin- Hebei, Yangtze River Delta, Central China, and Sichuan Basin urban agglomerations, respectively."
  },
  {
    "sentence": "The control experiment was directly forecasted by WRF-Chem.",
    "subtitle": "ABSTRACT",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 664,
    "para_id": 113,
    "paper_id": 1,
    "2d_coord": [
      2.305406093597412,
      1.0486929416656494
    ],
    "MSU_id": 664,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In numerical model simulations, data assimilation (DA) on the initial conditions and bias correction (BC) of model outputs have been proven to be promising approaches to improving  $\\mathrm{PM}{2.5}$  (particulate matter with an aerodynamic equivalent diameter of  $\\leq 2.5\\mu \\mathrm{m}$ ) predictions. This study compared the optimization effects of these two methods and developed a new scheme that combines DA and BC simultaneously. Four parallel experiments were conducted during winter 2019: a control experiment directly forecasted by WRF- Chem (experiment name: WRF- Chem); an experiment that assimilated in situ observations based on the GSI (Gridpoint Statistical Interpolation) system (WRF- Chem_DA); an experiment with deep- learning- based BC (WRF- Chem_BC); and an experiment considering the combination of DA on the initial conditions and BC (WRF- Chem_DA_BC). Statistically, the accuracy of  $\\mathrm{PM}{2.5}$  predictions could be optimized by both DA and BC for the first 24- h period, and WRF- Chem_BC performed better than WRF- Chem_DA in the initial field, especially in the period of 10–24 h, while the best performance was achieved by combining BC and DA. Throughout the initial 24- h period, compared with the control experiment, the results of WRF- Chem_DA_BC (WRF- Chem_DA, WRF- Chem_BC) showed an improvement in terms of root- mean- square error, with reduction proportions varying from 38.90% to 48.86% (18.88% to 32.44%, 30.10% to 46.08%). Besides having the best optimization effect over the whole domain, the combined method also performed well in different regions: during the forecasting period of 0–24 h, the RMSEs decreased from 32% to 62%, 39% to 57%, 28% to 40%, and 30% to 49% in the Beijing- Tianjin- Hebei, Yangtze River Delta, Central China, and Sichuan Basin urban agglomerations, respectively."
  },
  {
    "sentence": "An experiment assimilated in situ observations based on the GSI system, named WRF-Chem_DA.",
    "subtitle": "ABSTRACT",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 665,
    "para_id": 113,
    "paper_id": 1,
    "2d_coord": [
      2.2760579586029053,
      1.0487170219421387
    ],
    "MSU_id": 665,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In numerical model simulations, data assimilation (DA) on the initial conditions and bias correction (BC) of model outputs have been proven to be promising approaches to improving  $\\mathrm{PM}{2.5}$  (particulate matter with an aerodynamic equivalent diameter of  $\\leq 2.5\\mu \\mathrm{m}$ ) predictions. This study compared the optimization effects of these two methods and developed a new scheme that combines DA and BC simultaneously. Four parallel experiments were conducted during winter 2019: a control experiment directly forecasted by WRF- Chem (experiment name: WRF- Chem); an experiment that assimilated in situ observations based on the GSI (Gridpoint Statistical Interpolation) system (WRF- Chem_DA); an experiment with deep- learning- based BC (WRF- Chem_BC); and an experiment considering the combination of DA on the initial conditions and BC (WRF- Chem_DA_BC). Statistically, the accuracy of  $\\mathrm{PM}{2.5}$  predictions could be optimized by both DA and BC for the first 24- h period, and WRF- Chem_BC performed better than WRF- Chem_DA in the initial field, especially in the period of 10–24 h, while the best performance was achieved by combining BC and DA. Throughout the initial 24- h period, compared with the control experiment, the results of WRF- Chem_DA_BC (WRF- Chem_DA, WRF- Chem_BC) showed an improvement in terms of root- mean- square error, with reduction proportions varying from 38.90% to 48.86% (18.88% to 32.44%, 30.10% to 46.08%). Besides having the best optimization effect over the whole domain, the combined method also performed well in different regions: during the forecasting period of 0–24 h, the RMSEs decreased from 32% to 62%, 39% to 57%, 28% to 40%, and 30% to 49% in the Beijing- Tianjin- Hebei, Yangtze River Delta, Central China, and Sichuan Basin urban agglomerations, respectively."
  },
  {
    "sentence": "An experiment used deep-learning-based BC, named WRF-Chem_BC.",
    "subtitle": "ABSTRACT",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 666,
    "para_id": 113,
    "paper_id": 1,
    "2d_coord": [
      2.2332091331481934,
      1.086426854133606
    ],
    "MSU_id": 666,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In numerical model simulations, data assimilation (DA) on the initial conditions and bias correction (BC) of model outputs have been proven to be promising approaches to improving  $\\mathrm{PM}{2.5}$  (particulate matter with an aerodynamic equivalent diameter of  $\\leq 2.5\\mu \\mathrm{m}$ ) predictions. This study compared the optimization effects of these two methods and developed a new scheme that combines DA and BC simultaneously. Four parallel experiments were conducted during winter 2019: a control experiment directly forecasted by WRF- Chem (experiment name: WRF- Chem); an experiment that assimilated in situ observations based on the GSI (Gridpoint Statistical Interpolation) system (WRF- Chem_DA); an experiment with deep- learning- based BC (WRF- Chem_BC); and an experiment considering the combination of DA on the initial conditions and BC (WRF- Chem_DA_BC). Statistically, the accuracy of  $\\mathrm{PM}{2.5}$  predictions could be optimized by both DA and BC for the first 24- h period, and WRF- Chem_BC performed better than WRF- Chem_DA in the initial field, especially in the period of 10–24 h, while the best performance was achieved by combining BC and DA. Throughout the initial 24- h period, compared with the control experiment, the results of WRF- Chem_DA_BC (WRF- Chem_DA, WRF- Chem_BC) showed an improvement in terms of root- mean- square error, with reduction proportions varying from 38.90% to 48.86% (18.88% to 32.44%, 30.10% to 46.08%). Besides having the best optimization effect over the whole domain, the combined method also performed well in different regions: during the forecasting period of 0–24 h, the RMSEs decreased from 32% to 62%, 39% to 57%, 28% to 40%, and 30% to 49% in the Beijing- Tianjin- Hebei, Yangtze River Delta, Central China, and Sichuan Basin urban agglomerations, respectively."
  },
  {
    "sentence": "An experiment considered the combination of DA on the initial conditions and BC, named WRF-Chem_DA_BC.",
    "subtitle": "ABSTRACT",
    "category": "EXPERIMENT/SETUP",
    "rank": 4,
    "msuid": 667,
    "para_id": 113,
    "paper_id": 1,
    "2d_coord": [
      2.258293867111206,
      1.023161768913269
    ],
    "MSU_id": 667,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In numerical model simulations, data assimilation (DA) on the initial conditions and bias correction (BC) of model outputs have been proven to be promising approaches to improving  $\\mathrm{PM}{2.5}$  (particulate matter with an aerodynamic equivalent diameter of  $\\leq 2.5\\mu \\mathrm{m}$ ) predictions. This study compared the optimization effects of these two methods and developed a new scheme that combines DA and BC simultaneously. Four parallel experiments were conducted during winter 2019: a control experiment directly forecasted by WRF- Chem (experiment name: WRF- Chem); an experiment that assimilated in situ observations based on the GSI (Gridpoint Statistical Interpolation) system (WRF- Chem_DA); an experiment with deep- learning- based BC (WRF- Chem_BC); and an experiment considering the combination of DA on the initial conditions and BC (WRF- Chem_DA_BC). Statistically, the accuracy of  $\\mathrm{PM}{2.5}$  predictions could be optimized by both DA and BC for the first 24- h period, and WRF- Chem_BC performed better than WRF- Chem_DA in the initial field, especially in the period of 10–24 h, while the best performance was achieved by combining BC and DA. Throughout the initial 24- h period, compared with the control experiment, the results of WRF- Chem_DA_BC (WRF- Chem_DA, WRF- Chem_BC) showed an improvement in terms of root- mean- square error, with reduction proportions varying from 38.90% to 48.86% (18.88% to 32.44%, 30.10% to 46.08%). Besides having the best optimization effect over the whole domain, the combined method also performed well in different regions: during the forecasting period of 0–24 h, the RMSEs decreased from 32% to 62%, 39% to 57%, 28% to 40%, and 30% to 49% in the Beijing- Tianjin- Hebei, Yangtze River Delta, Central China, and Sichuan Basin urban agglomerations, respectively."
  },
  {
    "sentence": "Ran et al. (2023) performed BC based on a multiple linear regression modeling approach to reduce the global PM2.5 prediction bias.",
    "subtitle": "1. Introduction",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 733,
    "para_id": 122,
    "paper_id": 1,
    "2d_coord": [
      2.237962245941162,
      1.0692429542541504
    ],
    "MSU_id": 733,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "BC is a statistical method that improves model predictions by establishing a relationship between historical observations and the corresponding model forecasts, from which the forecast bias can be extracted and the systematic errors corrected. With the advancements made in this line of research, BC methods have been developed from the earlier complete forecast method (Klein et al., 1959) to the model output statistical method (Glahn and Lowry, 1972), and then gradually evolved into different BC schemes. Frequency matching, Bayesian averaging, least- squares regression, multiple linear regression, and other statistical methods have been used to establish BC models, which significantly reduce systematic errors by learning the empirical relationships between historical forecasts and observations to realize BC (Raftery et al., 2005; Zhu and Luo, 2015; Xie et al., 2012; Chen et al., 2012; You, 2014). Recently, artificial- intelligence machine- learning techniques have emerged. Subsequently, BC based on machine- learning methods has been shown to better express the auxiliary links between various facets of the atmosphere, including, for instance, the different elements involved in atmospheric chemistry and key basic meteorological variables such as temperature and winds (Marzban, 2003; Zhang et al., 2022). Machine- learning models have been used in the BC of model outputs to improve  $\\mathrm{PM}{2.5}$  forecasts. For example, Ran et al. (2023) performed BC based on a multiple linear regression modeling approach to reduce the global  $\\mathrm{PM}{2.5}$  prediction bias; and Liu and Xing (2022a), Liu and Xing (2022b) designed a fully connected deep neural network to correct the  $\\mathrm{PM}{2.5}$  concentration bias in the outputs of chemical models, achieving better results than without the correction method applied. Ma et al. (2020) applied a time series model to correct  $\\mathrm{PM}{2.5}$  forecasts, which achieved good results. Different machine- learning methods were utilized by Li et al. (2021) as bias adjustment for postprocessing forecasts of  $\\mathrm{PM}{2.5}$  and  $\\mathrm{O}_3$ , showing the optimal approach to be the Random Forest model. Lu et al. (2020) utilized machine- learning methods to improve the accuracy of  $\\mathrm{PM}{2.5}$  forecasts through WRF- Chem in the Chengdu- Chongqing region. Overall, machine- learning methods have shown strong advantages in mining nonlinear relationships, enabling them to perform well in the BC of numerical predictions. However, they usually require massive, multi- source data inputs, which can limit their applicability in specific scenarios."
  },
  {
    "sentence": "The winter of 2019 was selected as the study period.",
    "subtitle": "1. Introduction",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 754,
    "para_id": 124,
    "paper_id": 1,
    "2d_coord": [
      1.1130890846252441,
      1.3293945789337158
    ],
    "MSU_id": 754,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The application of DA to adjust the initial field can improve the accuracy of forecasts from the input perspective of the model by reducing the uncertainty of the initial conditions, and then applying BC to the assimilated forecast results can further optimize the model forecast from the output perspective, which when combined simultaneously could be of great significance for prediction improvement. Therefore, in this study, we considered the two different techniques of DA on the initial conditions and BC separately, and compared their abilities to optimize and enhance the forecasting of  $\\mathrm{PM}{2.5}$  concentrations. Besides, a new scheme that combines DA on the initial conditions and BC simultaneously was developed to further improve  $\\mathrm{PM}{2.5}$  predictions. The winter of 2019 was selected as the study period, and different comparative experiments were designed to evaluate and analyze the effects on optimizing the  $\\mathrm{PM}_{2.5}$  concentration forecasts."
  },
  {
    "sentence": "Different comparative experiments were designed to evaluate and analyze the effects on optimizing the PM2.5 concentration forecasts.",
    "subtitle": "1. Introduction",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 755,
    "para_id": 124,
    "paper_id": 1,
    "2d_coord": [
      2.1526405811309814,
      1.1329421997070312
    ],
    "MSU_id": 755,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The application of DA to adjust the initial field can improve the accuracy of forecasts from the input perspective of the model by reducing the uncertainty of the initial conditions, and then applying BC to the assimilated forecast results can further optimize the model forecast from the output perspective, which when combined simultaneously could be of great significance for prediction improvement. Therefore, in this study, we considered the two different techniques of DA on the initial conditions and BC separately, and compared their abilities to optimize and enhance the forecasting of  $\\mathrm{PM}{2.5}$  concentrations. Besides, a new scheme that combines DA on the initial conditions and BC simultaneously was developed to further improve  $\\mathrm{PM}{2.5}$  predictions. The winter of 2019 was selected as the study period, and different comparative experiments were designed to evaluate and analyze the effects on optimizing the  $\\mathrm{PM}_{2.5}$  concentration forecasts."
  },
  {
    "sentence": "Measurements of PM2.5 concentrations were recorded from 1 January 2017 to 28 February 2019 at approximately 1691 stations in China.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 756,
    "para_id": 125,
    "paper_id": 1,
    "2d_coord": [
      1.695530652999878,
      1.5662877559661865
    ],
    "MSU_id": 756,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In this study, measurements of  $\\mathrm{PM}{2.5}$  concentrations recorded from 1 January 2017 to 28 February 2019, at approximately 1691 stations in China, were collected from the website of the China National Environmental Monitoring Center. The hourly averages of  $\\mathrm{PM}{2.5}$  concentrations during this study period were used as the real values for correction and evaluation of bias, and the missing data values and those values higher than  $1000\\mu \\mathrm{g} / \\mathrm{m}^3$  were removed."
  },
  {
    "sentence": "The data were collected from the website of the China National Environmental Monitoring Center.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 757,
    "para_id": 125,
    "paper_id": 1,
    "2d_coord": [
      2.2158679962158203,
      0.7965494394302368
    ],
    "MSU_id": 757,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In this study, measurements of  $\\mathrm{PM}{2.5}$  concentrations recorded from 1 January 2017 to 28 February 2019, at approximately 1691 stations in China, were collected from the website of the China National Environmental Monitoring Center. The hourly averages of  $\\mathrm{PM}{2.5}$  concentrations during this study period were used as the real values for correction and evaluation of bias, and the missing data values and those values higher than  $1000\\mu \\mathrm{g} / \\mathrm{m}^3$  were removed."
  },
  {
    "sentence": "The hourly averages of PM2.5 concentrations during this study period were used as the real values for correction and evaluation of bias.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 758,
    "para_id": 125,
    "paper_id": 1,
    "2d_coord": [
      2.2960238456726074,
      1.0213887691497803
    ],
    "MSU_id": 758,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In this study, measurements of  $\\mathrm{PM}{2.5}$  concentrations recorded from 1 January 2017 to 28 February 2019, at approximately 1691 stations in China, were collected from the website of the China National Environmental Monitoring Center. The hourly averages of  $\\mathrm{PM}{2.5}$  concentrations during this study period were used as the real values for correction and evaluation of bias, and the missing data values and those values higher than  $1000\\mu \\mathrm{g} / \\mathrm{m}^3$  were removed."
  },
  {
    "sentence": "Missing data values and those values higher than 1000 μg/m³ were removed.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 759,
    "para_id": 125,
    "paper_id": 1,
    "2d_coord": [
      2.2686376571655273,
      1.018747329711914
    ],
    "MSU_id": 759,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In this study, measurements of  $\\mathrm{PM}{2.5}$  concentrations recorded from 1 January 2017 to 28 February 2019, at approximately 1691 stations in China, were collected from the website of the China National Environmental Monitoring Center. The hourly averages of  $\\mathrm{PM}{2.5}$  concentrations during this study period were used as the real values for correction and evaluation of bias, and the missing data values and those values higher than  $1000\\mu \\mathrm{g} / \\mathrm{m}^3$  were removed."
  },
  {
    "sentence": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 760,
    "para_id": 126,
    "paper_id": 1,
    "2d_coord": [
      2.0986108779907227,
      1.224532127380371
    ],
    "MSU_id": 760,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data, with a spatial resolution of  $0.25^{\\circ}x$ $0.25^{\\circ}$  and temporal resolution of  $\\textrm{\\scriptsize 6h}$  For the model matching, the Multiresolution Emission Inventory of China in 2016 (https://meicmod el.org.cn), with grid spacing of  $0.25^{\\circ}$  and temporal resolution of 1 month, was processed into gridded data to match the grid spacing of the model. The emission source contained nine major pollutants, including  $\\mathrm{SO_2}$  NOx,CO, NMVOC,  $\\mathrm{NH_3}$ $\\mathrm{PM}{10}$ $\\mathrm{PM}{2.5}$  BC,OC,and  $\\mathrm{CO_2}$  Li et al., 2017; Zheng et al., 2018). Besides, the biogenic emissions were also calculated, using the Model of Emissions of Gases and Aerosols from Nature inventory (Guenther et al., 2006). The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM (Whole Atmosphere Community Climate Model; https://www.acom.ucar.edu/waccm/download.shtml)."
  },
  {
    "sentence": "The data had a spatial resolution of 0.25° x 0.25° and temporal resolution of 6 hours.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 761,
    "para_id": 126,
    "paper_id": 1,
    "2d_coord": [
      0.39259594678878784,
      0.906237781047821
    ],
    "MSU_id": 761,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data, with a spatial resolution of  $0.25^{\\circ}x$ $0.25^{\\circ}$  and temporal resolution of  $\\textrm{\\scriptsize 6h}$  For the model matching, the Multiresolution Emission Inventory of China in 2016 (https://meicmod el.org.cn), with grid spacing of  $0.25^{\\circ}$  and temporal resolution of 1 month, was processed into gridded data to match the grid spacing of the model. The emission source contained nine major pollutants, including  $\\mathrm{SO_2}$  NOx,CO, NMVOC,  $\\mathrm{NH_3}$ $\\mathrm{PM}{10}$ $\\mathrm{PM}{2.5}$  BC,OC,and  $\\mathrm{CO_2}$  Li et al., 2017; Zheng et al., 2018). Besides, the biogenic emissions were also calculated, using the Model of Emissions of Gases and Aerosols from Nature inventory (Guenther et al., 2006). The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM (Whole Atmosphere Community Climate Model; https://www.acom.ucar.edu/waccm/download.shtml)."
  },
  {
    "sentence": "The Multiresolution Emission Inventory of China in 2016 was processed into gridded data to match the grid spacing of the model.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 762,
    "para_id": 126,
    "paper_id": 1,
    "2d_coord": [
      2.3314545154571533,
      1.0463924407958984
    ],
    "MSU_id": 762,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data, with a spatial resolution of  $0.25^{\\circ}x$ $0.25^{\\circ}$  and temporal resolution of  $\\textrm{\\scriptsize 6h}$  For the model matching, the Multiresolution Emission Inventory of China in 2016 (https://meicmod el.org.cn), with grid spacing of  $0.25^{\\circ}$  and temporal resolution of 1 month, was processed into gridded data to match the grid spacing of the model. The emission source contained nine major pollutants, including  $\\mathrm{SO_2}$  NOx,CO, NMVOC,  $\\mathrm{NH_3}$ $\\mathrm{PM}{10}$ $\\mathrm{PM}{2.5}$  BC,OC,and  $\\mathrm{CO_2}$  Li et al., 2017; Zheng et al., 2018). Besides, the biogenic emissions were also calculated, using the Model of Emissions of Gases and Aerosols from Nature inventory (Guenther et al., 2006). The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM (Whole Atmosphere Community Climate Model; https://www.acom.ucar.edu/waccm/download.shtml)."
  },
  {
    "sentence": "The Multiresolution Emission Inventory of China had a grid spacing of 0.25° and temporal resolution of 1 month.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 763,
    "para_id": 126,
    "paper_id": 1,
    "2d_coord": [
      2.2228505611419678,
      1.1384615898132324
    ],
    "MSU_id": 763,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data, with a spatial resolution of  $0.25^{\\circ}x$ $0.25^{\\circ}$  and temporal resolution of  $\\textrm{\\scriptsize 6h}$  For the model matching, the Multiresolution Emission Inventory of China in 2016 (https://meicmod el.org.cn), with grid spacing of  $0.25^{\\circ}$  and temporal resolution of 1 month, was processed into gridded data to match the grid spacing of the model. The emission source contained nine major pollutants, including  $\\mathrm{SO_2}$  NOx,CO, NMVOC,  $\\mathrm{NH_3}$ $\\mathrm{PM}{10}$ $\\mathrm{PM}{2.5}$  BC,OC,and  $\\mathrm{CO_2}$  Li et al., 2017; Zheng et al., 2018). Besides, the biogenic emissions were also calculated, using the Model of Emissions of Gases and Aerosols from Nature inventory (Guenther et al., 2006). The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM (Whole Atmosphere Community Climate Model; https://www.acom.ucar.edu/waccm/download.shtml)."
  },
  {
    "sentence": "The emission source contained nine major pollutants, including SO2, NOx, CO, NMVOC, NH3, PM10, PM2.5, BC, OC, and CO2.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 764,
    "para_id": 126,
    "paper_id": 1,
    "2d_coord": [
      1.888153076171875,
      1.328873634338379
    ],
    "MSU_id": 764,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data, with a spatial resolution of  $0.25^{\\circ}x$ $0.25^{\\circ}$  and temporal resolution of  $\\textrm{\\scriptsize 6h}$  For the model matching, the Multiresolution Emission Inventory of China in 2016 (https://meicmod el.org.cn), with grid spacing of  $0.25^{\\circ}$  and temporal resolution of 1 month, was processed into gridded data to match the grid spacing of the model. The emission source contained nine major pollutants, including  $\\mathrm{SO_2}$  NOx,CO, NMVOC,  $\\mathrm{NH_3}$ $\\mathrm{PM}{10}$ $\\mathrm{PM}{2.5}$  BC,OC,and  $\\mathrm{CO_2}$  Li et al., 2017; Zheng et al., 2018). Besides, the biogenic emissions were also calculated, using the Model of Emissions of Gases and Aerosols from Nature inventory (Guenther et al., 2006). The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM (Whole Atmosphere Community Climate Model; https://www.acom.ucar.edu/waccm/download.shtml)."
  },
  {
    "sentence": "Biogenic emissions were calculated using the Model of Emissions of Gases and Aerosols from Nature inventory.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 765,
    "para_id": 126,
    "paper_id": 1,
    "2d_coord": [
      2.048248767852783,
      0.09388908743858337
    ],
    "MSU_id": 765,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data, with a spatial resolution of  $0.25^{\\circ}x$ $0.25^{\\circ}$  and temporal resolution of  $\\textrm{\\scriptsize 6h}$  For the model matching, the Multiresolution Emission Inventory of China in 2016 (https://meicmod el.org.cn), with grid spacing of  $0.25^{\\circ}$  and temporal resolution of 1 month, was processed into gridded data to match the grid spacing of the model. The emission source contained nine major pollutants, including  $\\mathrm{SO_2}$  NOx,CO, NMVOC,  $\\mathrm{NH_3}$ $\\mathrm{PM}{10}$ $\\mathrm{PM}{2.5}$  BC,OC,and  $\\mathrm{CO_2}$  Li et al., 2017; Zheng et al., 2018). Besides, the biogenic emissions were also calculated, using the Model of Emissions of Gases and Aerosols from Nature inventory (Guenther et al., 2006). The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM (Whole Atmosphere Community Climate Model; https://www.acom.ucar.edu/waccm/download.shtml)."
  },
  {
    "sentence": "The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM.",
    "subtitle": "2.1.Data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 766,
    "para_id": 126,
    "paper_id": 1,
    "2d_coord": [
      2.206047534942627,
      1.1835031509399414
    ],
    "MSU_id": 766,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The meteorological boundary conditions and initial field were provided by the National Centers for Environmental Prediction Final operational global analysis data, with a spatial resolution of  $0.25^{\\circ}x$ $0.25^{\\circ}$  and temporal resolution of  $\\textrm{\\scriptsize 6h}$  For the model matching, the Multiresolution Emission Inventory of China in 2016 (https://meicmod el.org.cn), with grid spacing of  $0.25^{\\circ}$  and temporal resolution of 1 month, was processed into gridded data to match the grid spacing of the model. The emission source contained nine major pollutants, including  $\\mathrm{SO_2}$  NOx,CO, NMVOC,  $\\mathrm{NH_3}$ $\\mathrm{PM}{10}$ $\\mathrm{PM}{2.5}$  BC,OC,and  $\\mathrm{CO_2}$  Li et al., 2017; Zheng et al., 2018). Besides, the biogenic emissions were also calculated, using the Model of Emissions of Gases and Aerosols from Nature inventory (Guenther et al., 2006). The boundary conditions and initial fields of the atmospheric chemistry were derived from a simulation with WACCM (Whole Atmosphere Community Climate Model; https://www.acom.ucar.edu/waccm/download.shtml)."
  },
  {
    "sentence": "The Weather Research and Forecasting (WRF) model coupled with chemistry, WRF-Chem v3.8, was used in this study.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 767,
    "para_id": 127,
    "paper_id": 1,
    "2d_coord": [
      2.2948873043060303,
      1.074508786201477
    ],
    "MSU_id": 767,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The Weather Research and Forecasting (WRF) model coupled with chemistry, WRF- Chem v3.8, developed collaboratively by various atmospheric research institutes, was used in this study (Grell et al., 2005). WRF- Chem has been used in many previous studies for forecasting pollution, and proved to perform well in the simulation of  $\\mathrm{PM}_{2.5}$  (Hong et al., 2022; Jiang et al., 2013; Tie et al., 2009; Zhou et al., 2015)."
  },
  {
    "sentence": "The Rapid Radiative Transfer Model scheme was used for longwave radiation.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 771,
    "para_id": 128,
    "paper_id": 1,
    "2d_coord": [
      1.6669824123382568,
      1.145747184753418
    ],
    "MSU_id": 771,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The Rapid Radiative Transfer Model scheme (Mlawer et al., 1997) was used for longwave radiation, and the Dudhia scheme (Dudhia, 1989) for shortwave radiation. The pavement process scheme and boundary layer parameterization scheme were set as the Noah scheme (Chen and Dudhia, 2001) and Yonsei University scheme, respectively"
  },
  {
    "sentence": "The Dudhia scheme was used for shortwave radiation.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 772,
    "para_id": 128,
    "paper_id": 1,
    "2d_coord": [
      1.5735403299331665,
      1.4827265739440918
    ],
    "MSU_id": 772,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The Rapid Radiative Transfer Model scheme (Mlawer et al., 1997) was used for longwave radiation, and the Dudhia scheme (Dudhia, 1989) for shortwave radiation. The pavement process scheme and boundary layer parameterization scheme were set as the Noah scheme (Chen and Dudhia, 2001) and Yonsei University scheme, respectively"
  },
  {
    "sentence": "The pavement process scheme was set as the Noah scheme.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 773,
    "para_id": 128,
    "paper_id": 1,
    "2d_coord": [
      -0.07419043779373169,
      0.968930184841156
    ],
    "MSU_id": 773,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The Rapid Radiative Transfer Model scheme (Mlawer et al., 1997) was used for longwave radiation, and the Dudhia scheme (Dudhia, 1989) for shortwave radiation. The pavement process scheme and boundary layer parameterization scheme were set as the Noah scheme (Chen and Dudhia, 2001) and Yonsei University scheme, respectively"
  },
  {
    "sentence": "The boundary layer parameterization scheme was set as the Yonsei University scheme.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 774,
    "para_id": 128,
    "paper_id": 1,
    "2d_coord": [
      1.7757458686828613,
      1.5304203033447266
    ],
    "MSU_id": 774,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The Rapid Radiative Transfer Model scheme (Mlawer et al., 1997) was used for longwave radiation, and the Dudhia scheme (Dudhia, 1989) for shortwave radiation. The pavement process scheme and boundary layer parameterization scheme were set as the Noah scheme (Chen and Dudhia, 2001) and Yonsei University scheme, respectively"
  },
  {
    "sentence": "The Morrison 2-moment scheme was used for the microphysics parameterization.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 775,
    "para_id": 129,
    "paper_id": 1,
    "2d_coord": [
      1.418660044670105,
      0.20804086327552795
    ],
    "MSU_id": 775,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "(Hong et al., 2006). The Morrison 2- moment scheme was used for the microphysics parameterization (Morrison et al., 2009). In addition, we used the Regional Acid Deposition Mechanism for the chemical mechanisms, and Global Ozone Chemistry Aerosol Radiation and Transport was the aerosol scheme (Stockwell et al., 1990; Chin et al., 2002)."
  },
  {
    "sentence": "The Regional Acid Deposition Mechanism was used for the chemical mechanisms.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 776,
    "para_id": 129,
    "paper_id": 1,
    "2d_coord": [
      1.938974142074585,
      0.7578616142272949
    ],
    "MSU_id": 776,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "(Hong et al., 2006). The Morrison 2- moment scheme was used for the microphysics parameterization (Morrison et al., 2009). In addition, we used the Regional Acid Deposition Mechanism for the chemical mechanisms, and Global Ozone Chemistry Aerosol Radiation and Transport was the aerosol scheme (Stockwell et al., 1990; Chin et al., 2002)."
  },
  {
    "sentence": "Global Ozone Chemistry Aerosol Radiation and Transport was the aerosol scheme.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 777,
    "para_id": 129,
    "paper_id": 1,
    "2d_coord": [
      1.9114381074905396,
      1.0870962142944336
    ],
    "MSU_id": 777,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "(Hong et al., 2006). The Morrison 2- moment scheme was used for the microphysics parameterization (Morrison et al., 2009). In addition, we used the Regional Acid Deposition Mechanism for the chemical mechanisms, and Global Ozone Chemistry Aerosol Radiation and Transport was the aerosol scheme (Stockwell et al., 1990; Chin et al., 2002)."
  },
  {
    "sentence": "The model was set as a 27-km grid resolution with 232x182 horizontal grid spacing and 35 vertical levels.",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 778,
    "para_id": 130,
    "paper_id": 1,
    "2d_coord": [
      1.3899837732315063,
      1.509749174118042
    ],
    "MSU_id": 778,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The model was set as a  $27 - \\mathrm{km}$  grid resolution with  $232\\times 182$  horizontal grid spacing and 35 vertical levels. The simulation domain in China is shown in Fig. 1, with the center of the model at  $(32^{\\circ}\\mathrm{N},110^{\\circ}\\mathrm{E})$  including four typical urban agglomerations: Beijing- Tianjin- Hebei (BTH), Central China (CC), the Sichuan Basin (SCB), and Yangtze River Delta (YRD). These regions, chosen as they were in Chen et al. (2022), are of broad concern owing to their relatively more severe pollution related to their high levels of urbanization and dense populations."
  },
  {
    "sentence": "The center of the model is at (32°N, 110°E) including four typical urban agglomerations: Beijing-Tianjin-Hebei (BTH), Central China (CC), the Sichuan Basin (SCB), and Yangtze River Delta (YRD).",
    "subtitle": "2.2.WRF-Chem model configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 780,
    "para_id": 130,
    "paper_id": 1,
    "2d_coord": [
      1.9108378887176514,
      1.3784675598144531
    ],
    "MSU_id": 780,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The model was set as a  $27 - \\mathrm{km}$  grid resolution with  $232\\times 182$  horizontal grid spacing and 35 vertical levels. The simulation domain in China is shown in Fig. 1, with the center of the model at  $(32^{\\circ}\\mathrm{N},110^{\\circ}\\mathrm{E})$  including four typical urban agglomerations: Beijing- Tianjin- Hebei (BTH), Central China (CC), the Sichuan Basin (SCB), and Yangtze River Delta (YRD). These regions, chosen as they were in Chen et al. (2022), are of broad concern owing to their relatively more severe pollution related to their high levels of urbanization and dense populations."
  },
  {
    "sentence": "In this paper, the data assimilation of the initial field is based on the GSI system at 00:00 UTC each day.",
    "subtitle": "2.3.GSI 3DVAR system",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 789,
    "para_id": 131,
    "paper_id": 1,
    "2d_coord": [
      2.293583869934082,
      1.1175243854522705
    ],
    "MSU_id": 789,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Grid Statistical Interpolation (GsI) is a data analysis system that integrates global and regional variational assimilation techniques developed by NCEP (National Centers for Environmental Prediction), and it has been used for DA in operational forecasting in recent decades (Chen et al., 2023; Feng, 2018). GSI 3DVAR is almost the same as traditional 3D variational methods, which are based on the idea of variational DA. However, it shows advantages in its ability to deal with observations that have complex nonlinear relationships with atmospheric state model variables, thus making it possible to assimilate observations with nonlinear relations to atmospheric state quantities. In order to improve aerosol predictions, an aerosol assimilation module was integrated systematically into the GSI 3DVAR system (Pagowski et al., 2014). In this paper, the DA of the initial field is based on the GSI system at 00:00 UTC each day. The GSI system is fitted to the observation and model background field by minimizing the objective function, and the analytical field is the optimal solution for the minimal value of the objective function in equation (1)."
  },
  {
    "sentence": "In equations (3) and (4), B is the batch size.",
    "subtitle": "2.4. Deep-learning-based BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 824,
    "para_id": 139,
    "paper_id": 1,
    "2d_coord": [
      2.263821601867676,
      1.0435761213302612
    ],
    "MSU_id": 824,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In equations (3) and (4),  $B$  is the batch size,  $Bn$  is the number of samples in the current batch,  $p\\left(\\vec{y}{b,m}\\right)$  denotes the probability of the true labeled value,  $q\\left(\\vec{y}{b,m}\\right)$  denotes the probability value of the model prediction,  $b$  represents the batch sample, and  $m$  represents the sample number in batch  $b$ ."
  },
  {
    "sentence": "Bn is the number of samples in the current batch.",
    "subtitle": "2.4. Deep-learning-based BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 825,
    "para_id": 139,
    "paper_id": 1,
    "2d_coord": [
      1.7671229839324951,
      1.0378940105438232
    ],
    "MSU_id": 825,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In equations (3) and (4),  $B$  is the batch size,  $Bn$  is the number of samples in the current batch,  $p\\left(\\vec{y}{b,m}\\right)$  denotes the probability of the true labeled value,  $q\\left(\\vec{y}{b,m}\\right)$  denotes the probability value of the model prediction,  $b$  represents the batch sample, and  $m$  represents the sample number in batch  $b$ ."
  },
  {
    "sentence": "b represents the batch sample.",
    "subtitle": "2.4. Deep-learning-based BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 828,
    "para_id": 139,
    "paper_id": 1,
    "2d_coord": [
      2.2449193000793457,
      1.0838743448257446
    ],
    "MSU_id": 828,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In equations (3) and (4),  $B$  is the batch size,  $Bn$  is the number of samples in the current batch,  $p\\left(\\vec{y}{b,m}\\right)$  denotes the probability of the true labeled value,  $q\\left(\\vec{y}{b,m}\\right)$  denotes the probability value of the model prediction,  $b$  represents the batch sample, and  $m$  represents the sample number in batch  $b$ ."
  },
  {
    "sentence": "m represents the sample number in batch b.",
    "subtitle": "2.4. Deep-learning-based BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 829,
    "para_id": 139,
    "paper_id": 1,
    "2d_coord": [
      2.2503256797790527,
      1.0971300601959229
    ],
    "MSU_id": 829,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In equations (3) and (4),  $B$  is the batch size,  $Bn$  is the number of samples in the current batch,  $p\\left(\\vec{y}{b,m}\\right)$  denotes the probability of the true labeled value,  $q\\left(\\vec{y}{b,m}\\right)$  denotes the probability value of the model prediction,  $b$  represents the batch sample, and  $m$  represents the sample number in batch  $b$ ."
  },
  {
    "sentence": "Case 1 involves the WRF-Chem experiment.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 835,
    "para_id": 142,
    "paper_id": 1,
    "2d_coord": [
      2.2231504917144775,
      0.9904405474662781
    ],
    "MSU_id": 835,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 2. Flow charts of the four different experiments. Case 1: WRF-Chem; Case 2: WRF-Chem_DA; Case 3: WRF-Chem_BC; Case 4: WRF-Chem_DA_BC."
  },
  {
    "sentence": "Case 2 involves the WRF-Chem_DA experiment.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 836,
    "para_id": 142,
    "paper_id": 1,
    "2d_coord": [
      2.224734306335449,
      0.9889658689498901
    ],
    "MSU_id": 836,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 2. Flow charts of the four different experiments. Case 1: WRF-Chem; Case 2: WRF-Chem_DA; Case 3: WRF-Chem_BC; Case 4: WRF-Chem_DA_BC."
  },
  {
    "sentence": "Case 3 involves the WRF-Chem_BC experiment.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 837,
    "para_id": 142,
    "paper_id": 1,
    "2d_coord": [
      2.2308096885681152,
      1.0857410430908203
    ],
    "MSU_id": 837,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 2. Flow charts of the four different experiments. Case 1: WRF-Chem; Case 2: WRF-Chem_DA; Case 3: WRF-Chem_BC; Case 4: WRF-Chem_DA_BC."
  },
  {
    "sentence": "Case 4 involves the WRF-Chem_DA_BC experiment.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 838,
    "para_id": 142,
    "paper_id": 1,
    "2d_coord": [
      2.2841100692749023,
      1.0679442882537842
    ],
    "MSU_id": 838,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 2. Flow charts of the four different experiments. Case 1: WRF-Chem; Case 2: WRF-Chem_DA; Case 3: WRF-Chem_BC; Case 4: WRF-Chem_DA_BC."
  },
  {
    "sentence": "$\\mathrm{PM}_{2.5}$ predictions from WRF-Chem during January 2017 to November 2018 were collected as the training dataset for experiment WRF-Chem_BC and WRF-Chem_DA_BC.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 839,
    "para_id": 143,
    "paper_id": 1,
    "2d_coord": [
      2.2655045986175537,
      1.0229625701904297
    ],
    "MSU_id": 839,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "$\\mathrm{PM}_{2.5}$  predictions with a dimension of 241 and 281 from WRF- Chem (WRF- Chem/GSI) during January 2017 to November 2018 were collected as the training dataset for experiment WRF- Chem_BC (WRF- Chem_DA_BC). The training dataset number was 13,982 with a temporal resolution of  $1\\mathrm{~h}$ , and the testing dataset number was 1703 with the same temporal resolution. Besides, the observational dataset for the same period was interpolated using the \"inverse distance weight\" to form as the grid dataset. The numerical model output data was also interpolated to the equal latitude and longitude dataset to match with above obtained observation grid dataset."
  },
  {
    "sentence": "The $\\mathrm{PM}_{2.5}$ predictions had a dimension of 241 and 281.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 840,
    "para_id": 143,
    "paper_id": 1,
    "2d_coord": [
      2.01865553855896,
      0.8142189979553223
    ],
    "MSU_id": 840,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "$\\mathrm{PM}_{2.5}$  predictions with a dimension of 241 and 281 from WRF- Chem (WRF- Chem/GSI) during January 2017 to November 2018 were collected as the training dataset for experiment WRF- Chem_BC (WRF- Chem_DA_BC). The training dataset number was 13,982 with a temporal resolution of  $1\\mathrm{~h}$ , and the testing dataset number was 1703 with the same temporal resolution. Besides, the observational dataset for the same period was interpolated using the \"inverse distance weight\" to form as the grid dataset. The numerical model output data was also interpolated to the equal latitude and longitude dataset to match with above obtained observation grid dataset."
  },
  {
    "sentence": "The training dataset number was 13,982 with a temporal resolution of $1\\mathrm{~h}$. ",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 841,
    "para_id": 143,
    "paper_id": 1,
    "2d_coord": [
      2.254544258117676,
      1.1749827861785889
    ],
    "MSU_id": 841,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "$\\mathrm{PM}_{2.5}$  predictions with a dimension of 241 and 281 from WRF- Chem (WRF- Chem/GSI) during January 2017 to November 2018 were collected as the training dataset for experiment WRF- Chem_BC (WRF- Chem_DA_BC). The training dataset number was 13,982 with a temporal resolution of  $1\\mathrm{~h}$ , and the testing dataset number was 1703 with the same temporal resolution. Besides, the observational dataset for the same period was interpolated using the \"inverse distance weight\" to form as the grid dataset. The numerical model output data was also interpolated to the equal latitude and longitude dataset to match with above obtained observation grid dataset."
  },
  {
    "sentence": "The testing dataset number was 1703 with a temporal resolution of $1\\mathrm{~h}$. ",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 842,
    "para_id": 143,
    "paper_id": 1,
    "2d_coord": [
      2.1330695152282715,
      0.7227510809898376
    ],
    "MSU_id": 842,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "$\\mathrm{PM}_{2.5}$  predictions with a dimension of 241 and 281 from WRF- Chem (WRF- Chem/GSI) during January 2017 to November 2018 were collected as the training dataset for experiment WRF- Chem_BC (WRF- Chem_DA_BC). The training dataset number was 13,982 with a temporal resolution of  $1\\mathrm{~h}$ , and the testing dataset number was 1703 with the same temporal resolution. Besides, the observational dataset for the same period was interpolated using the \"inverse distance weight\" to form as the grid dataset. The numerical model output data was also interpolated to the equal latitude and longitude dataset to match with above obtained observation grid dataset."
  },
  {
    "sentence": "The observational dataset was interpolated using the inverse distance weight method to form a grid dataset.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 843,
    "para_id": 143,
    "paper_id": 1,
    "2d_coord": [
      2.371413469314575,
      1.0299434661865234
    ],
    "MSU_id": 843,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "$\\mathrm{PM}_{2.5}$  predictions with a dimension of 241 and 281 from WRF- Chem (WRF- Chem/GSI) during January 2017 to November 2018 were collected as the training dataset for experiment WRF- Chem_BC (WRF- Chem_DA_BC). The training dataset number was 13,982 with a temporal resolution of  $1\\mathrm{~h}$ , and the testing dataset number was 1703 with the same temporal resolution. Besides, the observational dataset for the same period was interpolated using the \"inverse distance weight\" to form as the grid dataset. The numerical model output data was also interpolated to the equal latitude and longitude dataset to match with above obtained observation grid dataset."
  },
  {
    "sentence": "The numerical model output data was interpolated to match the observation grid dataset in latitude and longitude.",
    "subtitle": "2.5. Experimental design",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 844,
    "para_id": 143,
    "paper_id": 1,
    "2d_coord": [
      2.2478179931640625,
      1.0121653079986572
    ],
    "MSU_id": 844,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "$\\mathrm{PM}_{2.5}$  predictions with a dimension of 241 and 281 from WRF- Chem (WRF- Chem/GSI) during January 2017 to November 2018 were collected as the training dataset for experiment WRF- Chem_BC (WRF- Chem_DA_BC). The training dataset number was 13,982 with a temporal resolution of  $1\\mathrm{~h}$ , and the testing dataset number was 1703 with the same temporal resolution. Besides, the observational dataset for the same period was interpolated using the \"inverse distance weight\" to form as the grid dataset. The numerical model output data was also interpolated to the equal latitude and longitude dataset to match with above obtained observation grid dataset."
  },
  {
    "sentence": "The different improvements on the predictions achieved through DA and BC were evaluated with different error indicators.",
    "subtitle": "3.1. Comparison of forecast errors by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 848,
    "para_id": 144,
    "paper_id": 1,
    "2d_coord": [
      2.290499448776245,
      1.0387399196624756
    ],
    "MSU_id": 848,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "DA on the initial conditions improved the prediction accuracy by adjusting the initial field to optimize the model input, and BC made improvements by correcting the biases of the model output, which realized model optimization from different perspectives. The different improvements on the predictions achieved through DA and BC were evaluated with different error indicators. Fig. 3 shows the spatial performances of  $\\mathrm{PM}{2.5}$  prediction RMSEs averaged in winter produced by the different experiments. The prediction RMSEs in the control experiment were larger than those in the other three experiments, with high values mainly in BTH, YRD, CC, and some southwestern regions, and the RMSE even reached  $100\\mu \\mathrm{g} / \\mathrm{m}^3$  in some northern areas. By comparing Fig. 3a, 3b and 3c, it can be seen that both DA and BC were able to reduce the  $\\mathrm{PM}{2.5}$  prediction RMSE, despite different performances over different regions. Compared with the control experiment, the prediction RMSE in WRF- Chem_DA was  $20 - 40\\mu \\mathrm{g} / \\mathrm{m}^3$  lower over CC and YRD, while the DA improvements were small over BTH, where large RMSE values could still be seen. In contrast, the performances of BC were much better than those of DA, showing RMSE reductions over most areas in China, and the RMSE values were less than  $80\\mu \\mathrm{g} / \\mathrm{m}^3$  in the WRF- Chem_BC experiment. Thus, by combining DA and BC, the best improvements were yielded, showing the largest reductions in prediction RMSE, with values less than  $60\\mu \\mathrm{g} / \\mathrm{m}^3$ , in the WRF- Chem_DA_BC"
  },
  {
    "sentence": "Fig. 4 presents the mean bias distributions of PM2.5 predictions produced by the different experiments.",
    "subtitle": "3.1. Comparison of forecast errors by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 864,
    "para_id": 146,
    "paper_id": 1,
    "2d_coord": [
      2.2829933166503906,
      1.0706390142440796
    ],
    "MSU_id": 864,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 4 presents the mean bias distributions of  $\\mathrm{PM}{2.5}$  predictions produced by the different experiments. As can be seen, WRF- Chem overestimated the  $\\mathrm{PM}{2.5}$  concentrations over some areas of SCB, CC, and YRD, with the prediction MB values reaching  $60\\mu \\mathrm{g} / \\mathrm{m}^3$  in some areas. A reason for this might be that the emissions inventory overestimated the winter emissions in the above regions and the model simulation was relatively more uncertain due to the complex terrain (Wei et al., 2022). In contrast, the  $\\mathrm{PM}{2.5}$  concentrations were underestimated in BTH, with the prediction MB ranging from  $- 60$  to  $- 20\\mu \\mathrm{g} / \\mathrm{m}^3$ . This performance whereby WRF- Chem always underestimates  $\\mathrm{PM}{2.5}$  concentrations over northern areas in China is a common problem, caused by not simulating secondary aerosols or the transformation mechanisms with their gaseous precursors (Ma, 2020; Wei et al., 2022; Qin et al., 2020; Wang et al., 2016). The prediction MB values were reduced by the DA and BC methods, but BC had better effects in terms of prediction improvement. Consistent with the results shown in Fig. 3, despite the adjustment to the original overestimation by DA in WRF- Chem_DA over some regions of SCB and CC, the prediction MB values could still reach  $60\\mu \\mathrm{g} / \\mathrm{m}^3$  in some areas, thus demonstrating some advantages of DA, but with limitations. Compared with the direct predictions of WRF- Chem, the prediction MB values in the WRF- Chem_BC experiment were reduced over most areas due to BC effects. It is worth noting that the original overestimation changed to an underestimation in the WRF- Chem_BC experiment over some regions of YRD and the Shandong Peninsula, which indicated overcorrection by BC. For WRF- Chem_DA_BC, the prediction MB was the smallest among all the experiments, with values less than  $20\\mu \\mathrm{g} / \\mathrm{m}^3$  over most areas. WRF- Chem_DA_BC showed a smaller prediction MB than WRF- Chem_BC, especially over the Shandong Peninsula and YRD regions."
  },
  {
    "sentence": "The RMSE is measured in micrograms per cubic meter (μg/m³).",
    "subtitle": "3.1. Comparison of forecast errors by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 877,
    "para_id": 147,
    "paper_id": 1,
    "2d_coord": [
      2.344717025756836,
      1.0562477111816406
    ],
    "MSU_id": 877,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 3. Spatial distribution of the  $\\mathrm{PM}_{2.5}$  prediction RMSE  $(\\mu \\mathrm{g} / \\mathrm{m}^3)$  during winter produced by the four experiments: (a) WRF-Chem, (b) WRF-Chem_BC, (c) WRF-Chem_DA, and (d) WRF-Chem_DA_BC."
  },
  {
    "sentence": "The RMSE results are produced by four experiments: WRF-Chem, WRF-Chem_BC, WRF-Chem_DA, and WRF-Chem_DA_BC.",
    "subtitle": "3.1. Comparison of forecast errors by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 878,
    "para_id": 147,
    "paper_id": 1,
    "2d_coord": [
      2.2381508350372314,
      1.0542128086090088
    ],
    "MSU_id": 878,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 3. Spatial distribution of the  $\\mathrm{PM}_{2.5}$  prediction RMSE  $(\\mu \\mathrm{g} / \\mathrm{m}^3)$  during winter produced by the four experiments: (a) WRF-Chem, (b) WRF-Chem_BC, (c) WRF-Chem_DA, and (d) WRF-Chem_DA_BC."
  },
  {
    "sentence": "The spatial distributions are produced by four experiments.",
    "subtitle": "3.1. Comparison of forecast errors by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 880,
    "para_id": 148,
    "paper_id": 1,
    "2d_coord": [
      2.1826186180114746,
      0.7514262199401855
    ],
    "MSU_id": 880,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 4. Spatial distributions of the  $\\mathrm{PM}_{2.5}$  prediction MB  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  during winter produced by the four experiments: (a) WRF-Chem, (b) WRF-Chem_BC, (c) WRF-Chem_DA, and (d) WRF-Chem_DA_BC."
  },
  {
    "sentence": "The four experiments are WRF-Chem, WRF-Chem_BC, WRF-Chem_DA, and WRF-Chem_DA_BC.",
    "subtitle": "3.1. Comparison of forecast errors by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 881,
    "para_id": 148,
    "paper_id": 1,
    "2d_coord": [
      2.2218213081359863,
      1.0614808797836304
    ],
    "MSU_id": 881,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 4. Spatial distributions of the  $\\mathrm{PM}_{2.5}$  prediction MB  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  during winter produced by the four experiments: (a) WRF-Chem, (b) WRF-Chem_BC, (c) WRF-Chem_DA, and (d) WRF-Chem_DA_BC."
  },
  {
    "sentence": "The predictions are produced by four experiments: WRF-Chem, WRF-Chem_DA, WRF-Chem_BC, and WRF-Chem_DA_BC.",
    "subtitle": "3.2. Comparison of the forecast consistency with observations achieved by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 883,
    "para_id": 149,
    "paper_id": 1,
    "2d_coord": [
      2.2278151512145996,
      1.0619897842407227
    ],
    "MSU_id": 883,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 5. Temporal variation of the  $R$  between observations and the predictions produced by the four experiments: (a) WRF-Chem, (b) WRF-Chem_DA, (c) WRF-Chem_BC, and (d) WRF-Chem_DA_BC."
  },
  {
    "sentence": "The average PM2.5 concentrations predicted by the four experiments and observed in the study period are given in Fig. 6.",
    "subtitle": "3.2. Comparison of the forecast consistency with observations achieved by different optimization methods",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 891,
    "para_id": 151,
    "paper_id": 1,
    "2d_coord": [
      2.0751218795776367,
      1.2665150165557861
    ],
    "MSU_id": 891,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The average  $\\mathrm{PM}{2.5}$  concentrations predicted by the four experiments and observed in the study period are given in Fig. 6. From the scatter fitting analysis results, WRF- Chem_DA_BC performed best in its consistency with observations following optimization. The results predicted directly by WRF- Chem in the control experiment were dispersed, with some isolated overestimation and underestimation scatter points fitted along the slope of 0.56, which demonstrates poor ability in simulating the high- pollution zones. By applying DA, the predictions of WRF- Chem_DA were partially improved, with an increased fitting slope of 0.69, showing less overestimation and underestimation through the adjustment of the initial field. The optimization of WRF- Chem_BC was much more evident than that of WRF- Chem_DA compared with the control experiment since the overestimation of the model was adjusted and the overall scatter distributions were more concentrated. However, there still existed an overall underestimation trend, with a slope of 0.73 after BC, which may not be sufficient for the simulation of strong pollution processes. It can be seen from Fig. 6a and 6d that the results of WRF- Chem_DA_BC were greatly improved by combining the two optimization methods, with the fitted slope of 1.04 being close to the straight line of  $k = 1$ . In this experiment, the  $\\mathrm{PM}{2.5}$  predictions were well adjusted and almost all of the high pollution could be captured, showing the best agreement with the observations. Overall, through adjustment of the model input field and correction of the model output, the predictions were effectively improved. It should be noted that the slope values in the control experiment and WRF- Chem_DA are close to those of previous results (Feng et al., 2018; Ma et al., 2024)."
  },
  {
    "sentence": "The scatter plots compare PM2.5 mass concentrations in four experiments: WRF-Chem, WRF-Chem_DA, WRF-Chem_BC, and WRF-Chem_DA_BC.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 907,
    "para_id": 153,
    "paper_id": 1,
    "2d_coord": [
      2.232470750808716,
      1.0839579105377197
    ],
    "MSU_id": 907,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 6. Scatter plots of simulated versus observed  $\\mathrm{PM}_{2.5}$  mass concentrations  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  during winter in the four experiments: (a) WRF-Chem, (b) WRF-Chem_DA, (c) WRF-Chem_BC, and (d) WRF-Chem_DA_BC."
  },
  {
    "sentence": "The black line in Fig. 7 represents the control experiment.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 910,
    "para_id": 154,
    "paper_id": 1,
    "2d_coord": [
      2.2635250091552734,
      1.0136997699737549
    ],
    "MSU_id": 910,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 7. Hourly averaged (a) RMSE and (b) normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over the entire domain. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "The blue line in Fig. 7 represents the WRF-Chem_BC experiment.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 911,
    "para_id": 154,
    "paper_id": 1,
    "2d_coord": [
      2.1231842041015625,
      1.0458221435546875
    ],
    "MSU_id": 911,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 7. Hourly averaged (a) RMSE and (b) normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over the entire domain. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "The green line in Fig. 7 represents the WRF-Chem_DA experiment.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 912,
    "para_id": 154,
    "paper_id": 1,
    "2d_coord": [
      2.2698283195495605,
      1.0900256633758545
    ],
    "MSU_id": 912,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 7. Hourly averaged (a) RMSE and (b) normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over the entire domain. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "The red line in Fig. 7 represents the WRF-Chem_DA_BC experiment.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 913,
    "para_id": 154,
    "paper_id": 1,
    "2d_coord": [
      2.2583746910095215,
      1.1516391038894653
    ],
    "MSU_id": 913,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 7. Hourly averaged (a) RMSE and (b) normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over the entire domain. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "RMSEs of the different experiments were divided by the RMSE of the control experiment for a series of PM2.5 predictions with 0-24 h forecasts.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 915,
    "para_id": 155,
    "paper_id": 1,
    "2d_coord": [
      2.2409379482269287,
      1.132803201675415
    ],
    "MSU_id": 915,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "(RMSEs of the different experiments divided by the RMSE of the control experiment) series of  $\\mathrm{PM}{2.5}$  predictions with 0- 24- h forecasts. It is evident that all three experiments were able to improve the  $\\mathrm{PM}{2.5}$  predictions in terms of their RMSEs compared with the control experiment. The variations of the RMSE values produced by WRF- Chem and WRF- Chem_DA were similar to those in the results of previous studies (Hong et al., 2022; Peng et al., 2018a; Peng et al., 2018b; Ma et al., 2024). Both BC and DA reduced the  $\\mathrm{PM}{2.5}$  prediction RMSEs throughout the entire 24- h forecasting period, with reductions of  $17.89 - 33.61\\mu \\mathrm{g} / \\mathrm{m}^3$  and  $13.27 - 21.82\\mu \\mathrm{g} / \\mathrm{m}^3$ , respectively. During the first  $0 - 10\\mathrm{h}$ , the optimization effects of DA and BC were similar, but then BC started to perform better during 10- 24 h due to the timeliness of the DA in the initial field, which has also been reported in previous research (Jiang et al., 2013; Ma et al., 2024). Since the optimization of BC was not sensitive to time, the improvement effects could then be maintained, with a normalized RMSE of 0.54 to 0.70, during the 0- 24- h forecasting period. Comparatively, WRF- Chem_DA_BC produced more accurate  $\\mathrm{PM}{2.5}$  predictions than WRF- Chem_DA and WRF- Chem_BC during the first 24- h period, with an RMSE reduction of 23.52 to  $35.95\\mu \\mathrm{g} / \\mathrm{m}^3$  owing to the adjustment of the initial field for the model input and the correction of the output at the same time to achieve a double optimization. Overall, despite the positive effects on  $\\mathrm{PM}_{2.5}$  predictions, the optimization achieved by the different experiments varied; specifically, WRF- Chem_DA_BC was best, followed by WRF- Chem_BC, and then finally WRF- Chem_DA. The error values of predictions produced by WRF- Chem and WRF- Chem_DA were close to some previous DA results in China (Peng et al., 2018a; Peng et al., 2018b; Ma et al., 2024)."
  },
  {
    "sentence": "The analysis was made from the perspective of the whole domain in China.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 926,
    "para_id": 156,
    "paper_id": 1,
    "2d_coord": [
      0.862073540687561,
      1.2144688367843628
    ],
    "MSU_id": 926,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The above analysis was made from the perspective of the whole domain in China, and the conclusions reached are that WRF Chem - DA- BC adjusted the initial field of the model input on the one hand, while on the other hand it corrected the systematic errors of the model output, thereby evidently improving the  $\\mathrm{PM}{2.5}$  predictions by simultaneously combining DA and BC. Since the performances of the numerical model varied among different regions, we selected representative urban agglomerations for further analysis that have received attention in previous research (Chen et al., 2022). The RMSE of  $\\mathrm{PM}{2.5}$  predictions was calculated in each urban agglomeration averaged over the study period, and all the experiments showed improvements compared with the control experiment over these regions. Fig. 8 reveals that the predictions of WRF- Chem_DA_BC showed better effects than those of WRF- Chem_DA and WRF- Chem_BC over different urban agglomerations, with a similar trend as in Fig. 7. Notably, the RMSE variations of the  $\\mathrm{PM}_{2.5}$  predictions by WRF- Chem_DA and the control experiment were similar during the 0- 24- h forecast period, while the daily trend disappeared by adding the BC in WRF- Chem_BC and WRF- Chem_DA_BC."
  },
  {
    "sentence": "Representative urban agglomerations were selected for further analysis.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 931,
    "para_id": 156,
    "paper_id": 1,
    "2d_coord": [
      2.2965662479400635,
      0.7714333534240723
    ],
    "MSU_id": 931,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The above analysis was made from the perspective of the whole domain in China, and the conclusions reached are that WRF Chem - DA- BC adjusted the initial field of the model input on the one hand, while on the other hand it corrected the systematic errors of the model output, thereby evidently improving the  $\\mathrm{PM}{2.5}$  predictions by simultaneously combining DA and BC. Since the performances of the numerical model varied among different regions, we selected representative urban agglomerations for further analysis that have received attention in previous research (Chen et al., 2022). The RMSE of  $\\mathrm{PM}{2.5}$  predictions was calculated in each urban agglomeration averaged over the study period, and all the experiments showed improvements compared with the control experiment over these regions. Fig. 8 reveals that the predictions of WRF- Chem_DA_BC showed better effects than those of WRF- Chem_DA and WRF- Chem_BC over different urban agglomerations, with a similar trend as in Fig. 7. Notably, the RMSE variations of the  $\\mathrm{PM}_{2.5}$  predictions by WRF- Chem_DA and the control experiment were similar during the 0- 24- h forecast period, while the daily trend disappeared by adding the BC in WRF- Chem_BC and WRF- Chem_DA_BC."
  },
  {
    "sentence": "The RMSE of PM2.5 predictions was calculated in each urban agglomeration averaged over the study period.",
    "subtitle": "3.3. Influences of the different experimental configurations",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 933,
    "para_id": 156,
    "paper_id": 1,
    "2d_coord": [
      2.1146230697631836,
      1.178743600845337
    ],
    "MSU_id": 933,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "The above analysis was made from the perspective of the whole domain in China, and the conclusions reached are that WRF Chem - DA- BC adjusted the initial field of the model input on the one hand, while on the other hand it corrected the systematic errors of the model output, thereby evidently improving the  $\\mathrm{PM}{2.5}$  predictions by simultaneously combining DA and BC. Since the performances of the numerical model varied among different regions, we selected representative urban agglomerations for further analysis that have received attention in previous research (Chen et al., 2022). The RMSE of  $\\mathrm{PM}{2.5}$  predictions was calculated in each urban agglomeration averaged over the study period, and all the experiments showed improvements compared with the control experiment over these regions. Fig. 8 reveals that the predictions of WRF- Chem_DA_BC showed better effects than those of WRF- Chem_DA and WRF- Chem_BC over different urban agglomerations, with a similar trend as in Fig. 7. Notably, the RMSE variations of the  $\\mathrm{PM}_{2.5}$  predictions by WRF- Chem_DA and the control experiment were similar during the 0- 24- h forecast period, while the daily trend disappeared by adding the BC in WRF- Chem_BC and WRF- Chem_DA_BC."
  },
  {
    "sentence": "The prediction results produced by the WRF-Chem_DA_BC experiment are analyzed in the following.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 955,
    "para_id": 158,
    "paper_id": 1,
    "2d_coord": [
      2.1696159839630127,
      1.053248643875122
    ],
    "MSU_id": 955,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Section 3.3 confirmed the greater improvement in  $\\mathrm{PM}{2.5}$  prediction realized by combining the DA and BC methods. Thus, the prediction results produced by the WRF- Chem_DA_BC experiment are analyzed in the following. Fig. 9a- 9c show the results from the control experiment, observation, and WRF- Chem_DA_BC experiment, respectively. In winter 2019,  $\\mathrm{PM}{2.5}$  was mainly concentrated over the central- eastern and west- southern regions of China, especially in BTH, Shandong, YRD, CC, and SCB, with the highest values reaching  $120\\mu \\mathrm{g} / \\mathrm{m}^3$ , consistent with the distributions reported in other studies (Feng, 2018; Hong et al., 2022). Compared with the in situ observations, the overall distributions produced by the control and WRF- Chem_DA_BC experiments were similar"
  },
  {
    "sentence": "The black line in Fig. 8 represents the control experiment.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 962,
    "para_id": 159,
    "paper_id": 1,
    "2d_coord": [
      2.262230157852173,
      1.0164389610290527
    ],
    "MSU_id": 962,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 8. Hourly averaged RMSE and normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over (a1, b1) BTH, (a2, b2) YRD, (a3, b3) CC, and (a4, b4) SCB. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "The blue line in Fig. 8 represents the WRF-Chem_BC experiment.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 963,
    "para_id": 159,
    "paper_id": 1,
    "2d_coord": [
      2.153644561767578,
      1.1109699010849
    ],
    "MSU_id": 963,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 8. Hourly averaged RMSE and normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over (a1, b1) BTH, (a2, b2) YRD, (a3, b3) CC, and (a4, b4) SCB. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "The green line in Fig. 8 represents the WRF-Chem_DA experiment.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 964,
    "para_id": 159,
    "paper_id": 1,
    "2d_coord": [
      2.2708702087402344,
      1.1017544269561768
    ],
    "MSU_id": 964,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 8. Hourly averaged RMSE and normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over (a1, b1) BTH, (a2, b2) YRD, (a3, b3) CC, and (a4, b4) SCB. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "The red line in Fig. 8 represents the WRF-Chem_DA_BC experiment.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 965,
    "para_id": 159,
    "paper_id": 1,
    "2d_coord": [
      2.2405009269714355,
      1.1847245693206787
    ],
    "MSU_id": 965,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 8. Hourly averaged RMSE and normalized RMSE of  $\\mathrm{PM}_{2.5}$  predictions with forecasting hour averaged over (a1, b1) BTH, (a2, b2) YRD, (a3, b3) CC, and (a4, b4) SCB. The black line represents the control experiment; blue, green and red lines represent the WRF-Chem_BC, WRF-Chem_DA and WRF-Chem_DA_BC experiments, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)"
  },
  {
    "sentence": "The control experiment predicts the spatial distributions of average hourly PM2.5 concentrations.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 969,
    "para_id": 160,
    "paper_id": 1,
    "2d_coord": [
      2.2247719764709473,
      1.0442454814910889
    ],
    "MSU_id": 969,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 9. Spatial distributions of average hourly  $\\mathrm{PM}_{2.5}$  concentrations  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  predicted in the (a) control experiment, (b) observations, and (c) WRF-Chem_DA_BC experiment."
  },
  {
    "sentence": "The observations provide the spatial distributions of average hourly PM2.5 concentrations.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 970,
    "para_id": 160,
    "paper_id": 1,
    "2d_coord": [
      2.2805044651031494,
      0.9483687877655029
    ],
    "MSU_id": 970,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 9. Spatial distributions of average hourly  $\\mathrm{PM}_{2.5}$  concentrations  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  predicted in the (a) control experiment, (b) observations, and (c) WRF-Chem_DA_BC experiment."
  },
  {
    "sentence": "The WRF-Chem_DA_BC experiment predicts the spatial distributions of average hourly PM2.5 concentrations.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 971,
    "para_id": 160,
    "paper_id": 1,
    "2d_coord": [
      2.2590951919555664,
      1.061336874961853
    ],
    "MSU_id": 971,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 9. Spatial distributions of average hourly  $\\mathrm{PM}_{2.5}$  concentrations  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  predicted in the (a) control experiment, (b) observations, and (c) WRF-Chem_DA_BC experiment."
  },
  {
    "sentence": "Fig. 10 shows the average atmospheric PM2.5 concentration distributions of the four large urban agglomerations in winter over China investigated in this study.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 982,
    "para_id": 162,
    "paper_id": 1,
    "2d_coord": [
      2.1505069732666016,
      1.1004984378814697
    ],
    "MSU_id": 982,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Urban agglomerations can be severely polluted due to their elevated levels of human activity and other factors, and thus attention to pollution forecasting in these regions is necessary for the management of urban pollution and the development of appropriate strategies. Fig. 10 shows the average atmospheric  $\\mathrm{PM}{2.5}$  concentration distributions of the four large urban agglomerations in winter over China investigated in this study. The results show that the concentrations averaged over BTH, YRD, CC, and SBC were 54.53, 55.93, 60.34, and  $41.93\\mu \\mathrm{g} / \\mathrm{m}^3$  respectively. In total, the concentration of  $\\mathrm{PM}{2.5}$  in SBC was relatively low. According to the distributions of  $\\mathrm{PM}{2.5}$  areas of high  $\\mathrm{PM}{2.5}$  concentrations in each region were generally in large cities and surrounding areas, close to related emissions linked with human activities."
  },
  {
    "sentence": "The PM2.5 concentrations are measured in micrograms per cubic meter (μg/m³).",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 996,
    "para_id": 164,
    "paper_id": 1,
    "2d_coord": [
      2.2655742168426514,
      1.0017762184143066
    ],
    "MSU_id": 996,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 10. Distributions of  $\\mathrm{PM}_{2.5}$  concentrations  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  predicted in WRF-Chem_DA_BC in four large urban agglomerations in China: (a) BTH; (b) YRD; (c) CC; and (d) SCB."
  },
  {
    "sentence": "The predictions are made for four large urban agglomerations in China.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 997,
    "para_id": 164,
    "paper_id": 1,
    "2d_coord": [
      2.2320361137390137,
      1.0632784366607666
    ],
    "MSU_id": 997,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 10. Distributions of  $\\mathrm{PM}_{2.5}$  concentrations  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  predicted in WRF-Chem_DA_BC in four large urban agglomerations in China: (a) BTH; (b) YRD; (c) CC; and (d) SCB."
  },
  {
    "sentence": "The urban agglomerations include BTH, YRD, CC, and SCB.",
    "subtitle": "3.4. 2.5.  $\\mathrm{PM}_{2.5}$  prediction results of WRF-Chem_DA_BC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 998,
    "para_id": 164,
    "paper_id": 1,
    "2d_coord": [
      2.1423730850219727,
      1.0652049779891968
    ],
    "MSU_id": 998,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Fig. 10. Distributions of  $\\mathrm{PM}_{2.5}$  concentrations  $(\\mu \\mathrm{g} / \\mathrm{m}^{3})$  predicted in WRF-Chem_DA_BC in four large urban agglomerations in China: (a) BTH; (b) YRD; (c) CC; and (d) SCB."
  },
  {
    "sentence": "We only considered the DA at 00:00 UTC.",
    "subtitle": "4.1. Discussion",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1012,
    "para_id": 167,
    "paper_id": 1,
    "2d_coord": [
      1.6723570823669434,
      0.797575831413269
    ],
    "MSU_id": 1012,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "In addition, we mainly focused on the effects of the new scheme combing DA on the initial conditions and BC and only considered the DA at 00:00 UTC. To make our findings more robust through further comparisons, we intend to also apply the DA at 06:00, 12:00 and 18:00 in the future research."
  },
  {
    "sentence": "We mainly compared and analyzed the results of the different experiments in a 0-24-hour forecasting period.",
    "subtitle": "4.1. Discussion",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1014,
    "para_id": 168,
    "paper_id": 1,
    "2d_coord": [
      2.162062168121338,
      1.1356604099273682
    ],
    "MSU_id": 1014,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Lastly, it should be acknowledged that we mainly compared and analyzed the results of the different experiments in a 0- 24- h forecasting period. Since BC is not sensitive to the length of the forecast, long- term predictions can be analyzed in future work. Also, since many methods have been used in the bias correction of numerical models, work will be carried out with other models in the future to make further comparisons with the results reported here."
  },
  {
    "sentence": "Four parallel experiments were conducted during winter 2019.",
    "subtitle": "4.2. Summary",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1024,
    "para_id": 169,
    "paper_id": 1,
    "2d_coord": [
      2.190173387527466,
      0.8505606055259705
    ],
    "MSU_id": 1024,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Although many methods have been applied in the adjustment of the initial field and output field to improve  $\\mathrm{PM}{2.5}$  concentration predictions, few have considered the combination of DA adjustment and post- processing correction. In this study, the optimization effects of DA in the adjustment of the initial field, and of BC in post- processing, were compared and a new scheme that combined DA and BC simultaneously was developed, showing great advantages in the improvement of  $\\mathrm{PM}{2.5}$  concentration predictions. Four parallel experiments were conducted during winter 2019, including a control experiment directly forecasted by WRF- Chem, an experiment that assimilated in situ observations based on GSI, an experiment with BC based on MDS- UNet, and an experiment that combined DA and BC."
  },
  {
    "sentence": "The experiments included a control experiment directly forecasted by WRF-Chem.",
    "subtitle": "4.2. Summary",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1025,
    "para_id": 169,
    "paper_id": 1,
    "2d_coord": [
      2.2875845432281494,
      1.0417354106903076
    ],
    "MSU_id": 1025,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Although many methods have been applied in the adjustment of the initial field and output field to improve  $\\mathrm{PM}{2.5}$  concentration predictions, few have considered the combination of DA adjustment and post- processing correction. In this study, the optimization effects of DA in the adjustment of the initial field, and of BC in post- processing, were compared and a new scheme that combined DA and BC simultaneously was developed, showing great advantages in the improvement of  $\\mathrm{PM}{2.5}$  concentration predictions. Four parallel experiments were conducted during winter 2019, including a control experiment directly forecasted by WRF- Chem, an experiment that assimilated in situ observations based on GSI, an experiment with BC based on MDS- UNet, and an experiment that combined DA and BC."
  },
  {
    "sentence": "One experiment assimilated in situ observations based on GSI.",
    "subtitle": "4.2. Summary",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1026,
    "para_id": 169,
    "paper_id": 1,
    "2d_coord": [
      2.23649263381958,
      0.870320737361908
    ],
    "MSU_id": 1026,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Although many methods have been applied in the adjustment of the initial field and output field to improve  $\\mathrm{PM}{2.5}$  concentration predictions, few have considered the combination of DA adjustment and post- processing correction. In this study, the optimization effects of DA in the adjustment of the initial field, and of BC in post- processing, were compared and a new scheme that combined DA and BC simultaneously was developed, showing great advantages in the improvement of  $\\mathrm{PM}{2.5}$  concentration predictions. Four parallel experiments were conducted during winter 2019, including a control experiment directly forecasted by WRF- Chem, an experiment that assimilated in situ observations based on GSI, an experiment with BC based on MDS- UNet, and an experiment that combined DA and BC."
  },
  {
    "sentence": "Another experiment used BC based on MDS-UNet.",
    "subtitle": "4.2. Summary",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1027,
    "para_id": 169,
    "paper_id": 1,
    "2d_coord": [
      2.0881969928741455,
      0.9335758090019226
    ],
    "MSU_id": 1027,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Although many methods have been applied in the adjustment of the initial field and output field to improve  $\\mathrm{PM}{2.5}$  concentration predictions, few have considered the combination of DA adjustment and post- processing correction. In this study, the optimization effects of DA in the adjustment of the initial field, and of BC in post- processing, were compared and a new scheme that combined DA and BC simultaneously was developed, showing great advantages in the improvement of  $\\mathrm{PM}{2.5}$  concentration predictions. Four parallel experiments were conducted during winter 2019, including a control experiment directly forecasted by WRF- Chem, an experiment that assimilated in situ observations based on GSI, an experiment with BC based on MDS- UNet, and an experiment that combined DA and BC."
  },
  {
    "sentence": "An experiment combined DA and BC.",
    "subtitle": "4.2. Summary",
    "category": "EXPERIMENT/SETUP",
    "rank": 4,
    "msuid": 1028,
    "para_id": 169,
    "paper_id": 1,
    "2d_coord": [
      2.3051788806915283,
      1.093273639678955
    ],
    "MSU_id": 1028,
    "paper_info": "Improving WRF-Chem PM2.5 predictions by combining data assimilation and deep-learning-based bias correction",
    "paragraph_info": "Although many methods have been applied in the adjustment of the initial field and output field to improve  $\\mathrm{PM}{2.5}$  concentration predictions, few have considered the combination of DA adjustment and post- processing correction. In this study, the optimization effects of DA in the adjustment of the initial field, and of BC in post- processing, were compared and a new scheme that combined DA and BC simultaneously was developed, showing great advantages in the improvement of  $\\mathrm{PM}{2.5}$  concentration predictions. Four parallel experiments were conducted during winter 2019, including a control experiment directly forecasted by WRF- Chem, an experiment that assimilated in situ observations based on GSI, an experiment with BC based on MDS- UNet, and an experiment that combined DA and BC."
  },
  {
    "sentence": "Recent flight campaigns have paid particular attention to biomass burning aerosols (BBA) over tropical regions.",
    "subtitle": "INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1077,
    "para_id": 175,
    "paper_id": 2,
    "2d_coord": [
      2.088160276412964,
      0.1498589813709259
    ],
    "MSU_id": 1077,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Biomass burning (BB) is a leading contributor to global emissions of carbonaceous aerosols that can potentially exacerbate climate warming by absorbing solar radiation at visible to ultraviolet (UV) wavelengths [i.e., black carbon (BC) and organic aerosol (OA), the absorbing component of OA is also referred to as brown carbon] (1, 2). Therefore, these absorbing BB aerosols (BBAs) can essentially affect radiation balance (2, 3), cloud formation and properties (4, 5), precipitation (6, 7), and regional circulation patterns (8, 9). To better understand these impacts, recent flight campaigns have paid particular attention to the BBA over tropical regions where large amounts of BBA are injected into the atmosphere every year (10- 13)."
  },
  {
    "sentence": "Uncertainty analysis is conducted for all constraining processes.",
    "subtitle": "INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1116,
    "para_id": 180,
    "paper_id": 2,
    "2d_coord": [
      1.9809459447860718,
      0.22813528776168823
    ],
    "MSU_id": 1116,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "The overall procedure for constraining the above three components is somewhat similar to strategies commonly used in the context of \"emergent constraints,\" but we have introduced a closure relation (based on a simple box model) that allows estimating three components from two modeled relationships. It is similar to the methodology applied in a previous study (31), in which we analyze AOD and considered all aerosols instead of carbonaceous aerosols only. Briefly, we linearly regressed modeled MAC against modeled SSA and modeled  $\\tau$  against modeled precipitation and the angstrom exponent (AE; an indicator of ambient particle size) using the model data from the AeroCom (Aerosol Comparisons between Observations and Models; see table S1) project. Then, we applied satellite observations of SSA to estimate the constrained MAC and similarly constrain  $\\tau$  from observations of precipitation and AE. Last, we used Eq. 1 to constrain  $E$  The constrained values of  $E,\\tau ,$  and MAC allow us to attribute AAOD errors to contributions from these three factors for individual models. Uncertainty analysis is conducted for all these constraining processes as shown in Fig. 1. Notably, the constrained results are only effective on a regional and seasonal scale, and caution must be exercised when directly applying these results to smaller scales. This work presents advancements upon the foundation of (31) as it constrains MAC instead of MEC (mass extinction coefficient). In addition, we implement in situ data in the interpretation of satellite observations that allows a disaggregation of BC and OC emissions. Furthermore, in our seasonal, regional analysis, we find that SOA formation is important for fire aerosols over the Amazon but not over Africa."
  },
  {
    "sentence": "The varying configurations in Mie calculations include mixing state, refractive index, and particle size.",
    "subtitle": "Constraining total emission, lifetime, and MAC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1126,
    "para_id": 181,
    "paper_id": 2,
    "2d_coord": [
      1.9169909954071045,
      0.22537793219089508
    ],
    "MSU_id": 1126,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Despite the substantial variation in MAC values in the AeroCom models, we find a linear relationship between the modeled MAC and SSA (Fig. 2); both variables depend strongly on the BC mass mixing ratio within the total aerosols. Such a linear relationship compares favorably with in situ and laboratory observations (Fig. 2) (24). The relationship is also confirmed by Mie calculations with varying configurations (e.g., mixing state, refractive index, and particle size; fig. S2). This suggests that the modeled relationship between MAC and SSA in AeroCom is robust. We then combine satellite observation of SSA with the linear relationship to constrain the MAC."
  },
  {
    "sentence": "Each dot in Fig. 2 represents the seasonally averaged data from a single model, with colors indicating the two fire regions.",
    "subtitle": "Constraining total emission, lifetime, and MAC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1148,
    "para_id": 185,
    "paper_id": 2,
    "2d_coord": [
      0.32809916138648987,
      0.174017995595932
    ],
    "MSU_id": 1148,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 2. Relationships between modeled MAC and modeled SSA in the Amazon and Southern Africa. Each dot represents the seasonally averaged data from a single model, with colors indicating the two fire regions. MAC is calculated as  $\\mathrm{AOD / (BC + OA)}$ . SSA is for total aerosols. The solid color lines indicate the linear regressions with  $95\\%$  confidence intervals (shaded areas). Vertical dashed lines denote the regional SSA observations from satellite (see Materials and Methods), and the horizontal dashed lines show the constrained MAC with  $95\\%$  confidence intervals (horizontal dotted lines). The in situ relationship (24) is shown as the mean (black solid line) and  $95\\%$  confidence interval (gray shaded area). Note that the in situ relationship is built for aerosols with a high carbonaceous content ( $\\geq 85\\%$  of the total aerosol mass). For AeroCom models, we show that the fire-season averaged SSA well represents such a conditional SSA for BBA given the prevailing abundance of carbonaceous aerosols (see Materials and Methods)."
  },
  {
    "sentence": "Vertical dashed lines denote the regional SSA observations from satellite.",
    "subtitle": "Constraining total emission, lifetime, and MAC",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1152,
    "para_id": 185,
    "paper_id": 2,
    "2d_coord": [
      1.9177097082138062,
      0.07079970836639404
    ],
    "MSU_id": 1152,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 2. Relationships between modeled MAC and modeled SSA in the Amazon and Southern Africa. Each dot represents the seasonally averaged data from a single model, with colors indicating the two fire regions. MAC is calculated as  $\\mathrm{AOD / (BC + OA)}$ . SSA is for total aerosols. The solid color lines indicate the linear regressions with  $95\\%$  confidence intervals (shaded areas). Vertical dashed lines denote the regional SSA observations from satellite (see Materials and Methods), and the horizontal dashed lines show the constrained MAC with  $95\\%$  confidence intervals (horizontal dotted lines). The in situ relationship (24) is shown as the mean (black solid line) and  $95\\%$  confidence interval (gray shaded area). Note that the in situ relationship is built for aerosols with a high carbonaceous content ( $\\geq 85\\%$  of the total aerosol mass). For AeroCom models, we show that the fire-season averaged SSA well represents such a conditional SSA for BBA given the prevailing abundance of carbonaceous aerosols (see Materials and Methods)."
  },
  {
    "sentence": "To verify the reliability of the constrained results, we predict the African outflow AAOD for the AeroCom models through a metamodel analysis.",
    "subtitle": "Constraining total emission, lifetime, and MAC",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1159,
    "para_id": 187,
    "paper_id": 2,
    "2d_coord": [
      2.0647974014282227,
      0.09954750537872314
    ],
    "MSU_id": 1159,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "To verify the reliability of the constrained results, we predict the African outflow AAOD for the AeroCom models through a metamodel analysis (see text S2). We show that adopting the constrained results  $(E,\\tau ,$  and MAC) allows an accurate prediction of the AAOD over the African outflow region (fig. S7), providing independent confirmation on the above constraining analysis and error attribution."
  },
  {
    "sentence": "The calculation of the errors due to emission, aerosol lifetime, MAC, and cross terms is described in the Materials and Methods.",
    "subtitle": "Contribution of SOA formation to total OA",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1195,
    "para_id": 193,
    "paper_id": 2,
    "2d_coord": [
      2.0353617668151855,
      0.1501559615135193
    ],
    "MSU_id": 1195,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 3. Absolute AAOD errors due to individual components in AeroCom models. Results are shown individually for the Amazon (A) and Southern Africa (B). The calculation of the errors due to emission (E), aerosol lifetime (τ), MAC, and cross terms (Cross) is described in the Materials and Methods. The numbers in the legend indicate the average contribution of each component for all the AeroCom models.Fig.3.  t  t  t indicate the average contribution of each component for all the AeroCom models"
  },
  {
    "sentence": "The thin error bars for EI_OA indicate the ranges of the OA/OC ratio ranging from 1.5 to 1.9, with the dot showing the mean emission (i.e., OA/OC = 1.7).",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1228,
    "para_id": 197,
    "paper_id": 2,
    "2d_coord": [
      2.0076122283935547,
      0.0519978404045105
    ],
    "MSU_id": 1228,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 4. The constrained emissions for BC and total OA. The constrained emissions (Cons_BC, Cons_OA) over the Amazon (A) and Southern Africa (B) are shown with interquartile ranges (blue dots with thick error bars). Note that Cons_OA indicates total OA, which is further separated into primary BB emission (Cons_POA) and SOA formation (SOA). The constrained results are compared with four BB emission inventories (EI_BC and EI_OA). The thin error bars for EI_OA indicate the ranges of the OA/OC ratio ranging from 1.5 to 1.9, with the dot showing the mean emission (i.e., OA/OC = 1.7). Bottom: Correlations between satellite AOD and formaldehyde column for the Amazon (C) and Southern Africa (D) to support our constrained SOA, given that formaldehyde is an indicator of SOA formation. The AOD and SSA data are from Polarization and Directionality of the Earth's Reflectances with the Generalized Retrieval of Aerosol and Surface Properties algorithm (POLDER-GRASP), and the formaldehyde column is from Ozone Monitoring Instrument (OMI). Both satellite products are collocated with each other at  $1^{\\circ} \\times 1^{\\circ} \\times$  daily grid cells during fire seasons. Each dot represents the daily average of AOD and the formaldehyde column after collocation. The color scale denotes the SSA observation. Correlations between formaldehyde and AOD  $(r_{\\mathrm{AOD}})$  and between formaldehyde and SSA  $(r_{\\mathrm{SSA}})$  are shown with  $P$  values. In (C), the solid line indicates the regression based on the data points as shown. The dashed line is a regression derived from in situ measurements of formaldehyde and OC (45), here converted to formaldehyde column and AOD, assuming similar vertical profiles and an MEC of  $5.9 \\mathrm{~m}^{2} \\mathrm{~g}^{-1}$  (31)."
  },
  {
    "sentence": "The AOD and SSA data are from POLDER-GRASP, and the formaldehyde column is from Ozone Monitoring Instrument (OMI).",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1231,
    "para_id": 197,
    "paper_id": 2,
    "2d_coord": [
      2.0668630599975586,
      0.1859380453824997
    ],
    "MSU_id": 1231,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 4. The constrained emissions for BC and total OA. The constrained emissions (Cons_BC, Cons_OA) over the Amazon (A) and Southern Africa (B) are shown with interquartile ranges (blue dots with thick error bars). Note that Cons_OA indicates total OA, which is further separated into primary BB emission (Cons_POA) and SOA formation (SOA). The constrained results are compared with four BB emission inventories (EI_BC and EI_OA). The thin error bars for EI_OA indicate the ranges of the OA/OC ratio ranging from 1.5 to 1.9, with the dot showing the mean emission (i.e., OA/OC = 1.7). Bottom: Correlations between satellite AOD and formaldehyde column for the Amazon (C) and Southern Africa (D) to support our constrained SOA, given that formaldehyde is an indicator of SOA formation. The AOD and SSA data are from Polarization and Directionality of the Earth's Reflectances with the Generalized Retrieval of Aerosol and Surface Properties algorithm (POLDER-GRASP), and the formaldehyde column is from Ozone Monitoring Instrument (OMI). Both satellite products are collocated with each other at  $1^{\\circ} \\times 1^{\\circ} \\times$  daily grid cells during fire seasons. Each dot represents the daily average of AOD and the formaldehyde column after collocation. The color scale denotes the SSA observation. Correlations between formaldehyde and AOD  $(r_{\\mathrm{AOD}})$  and between formaldehyde and SSA  $(r_{\\mathrm{SSA}})$  are shown with  $P$  values. In (C), the solid line indicates the regression based on the data points as shown. The dashed line is a regression derived from in situ measurements of formaldehyde and OC (45), here converted to formaldehyde column and AOD, assuming similar vertical profiles and an MEC of  $5.9 \\mathrm{~m}^{2} \\mathrm{~g}^{-1}$  (31)."
  },
  {
    "sentence": "Both satellite products are collocated with each other at 1° × 1° daily grid cells during fire seasons.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1232,
    "para_id": 197,
    "paper_id": 2,
    "2d_coord": [
      2.0240280628204346,
      0.4172903895378113
    ],
    "MSU_id": 1232,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 4. The constrained emissions for BC and total OA. The constrained emissions (Cons_BC, Cons_OA) over the Amazon (A) and Southern Africa (B) are shown with interquartile ranges (blue dots with thick error bars). Note that Cons_OA indicates total OA, which is further separated into primary BB emission (Cons_POA) and SOA formation (SOA). The constrained results are compared with four BB emission inventories (EI_BC and EI_OA). The thin error bars for EI_OA indicate the ranges of the OA/OC ratio ranging from 1.5 to 1.9, with the dot showing the mean emission (i.e., OA/OC = 1.7). Bottom: Correlations between satellite AOD and formaldehyde column for the Amazon (C) and Southern Africa (D) to support our constrained SOA, given that formaldehyde is an indicator of SOA formation. The AOD and SSA data are from Polarization and Directionality of the Earth's Reflectances with the Generalized Retrieval of Aerosol and Surface Properties algorithm (POLDER-GRASP), and the formaldehyde column is from Ozone Monitoring Instrument (OMI). Both satellite products are collocated with each other at  $1^{\\circ} \\times 1^{\\circ} \\times$  daily grid cells during fire seasons. Each dot represents the daily average of AOD and the formaldehyde column after collocation. The color scale denotes the SSA observation. Correlations between formaldehyde and AOD  $(r_{\\mathrm{AOD}})$  and between formaldehyde and SSA  $(r_{\\mathrm{SSA}})$  are shown with  $P$  values. In (C), the solid line indicates the regression based on the data points as shown. The dashed line is a regression derived from in situ measurements of formaldehyde and OC (45), here converted to formaldehyde column and AOD, assuming similar vertical profiles and an MEC of  $5.9 \\mathrm{~m}^{2} \\mathrm{~g}^{-1}$  (31)."
  },
  {
    "sentence": "Each dot represents the daily average of AOD and the formaldehyde column after collocation.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1233,
    "para_id": 197,
    "paper_id": 2,
    "2d_coord": [
      1.8993473052978516,
      0.7061883211135864
    ],
    "MSU_id": 1233,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 4. The constrained emissions for BC and total OA. The constrained emissions (Cons_BC, Cons_OA) over the Amazon (A) and Southern Africa (B) are shown with interquartile ranges (blue dots with thick error bars). Note that Cons_OA indicates total OA, which is further separated into primary BB emission (Cons_POA) and SOA formation (SOA). The constrained results are compared with four BB emission inventories (EI_BC and EI_OA). The thin error bars for EI_OA indicate the ranges of the OA/OC ratio ranging from 1.5 to 1.9, with the dot showing the mean emission (i.e., OA/OC = 1.7). Bottom: Correlations between satellite AOD and formaldehyde column for the Amazon (C) and Southern Africa (D) to support our constrained SOA, given that formaldehyde is an indicator of SOA formation. The AOD and SSA data are from Polarization and Directionality of the Earth's Reflectances with the Generalized Retrieval of Aerosol and Surface Properties algorithm (POLDER-GRASP), and the formaldehyde column is from Ozone Monitoring Instrument (OMI). Both satellite products are collocated with each other at  $1^{\\circ} \\times 1^{\\circ} \\times$  daily grid cells during fire seasons. Each dot represents the daily average of AOD and the formaldehyde column after collocation. The color scale denotes the SSA observation. Correlations between formaldehyde and AOD  $(r_{\\mathrm{AOD}})$  and between formaldehyde and SSA  $(r_{\\mathrm{SSA}})$  are shown with  $P$  values. In (C), the solid line indicates the regression based on the data points as shown. The dashed line is a regression derived from in situ measurements of formaldehyde and OC (45), here converted to formaldehyde column and AOD, assuming similar vertical profiles and an MEC of  $5.9 \\mathrm{~m}^{2} \\mathrm{~g}^{-1}$  (31)."
  },
  {
    "sentence": "The color scale denotes the SSA observation.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 1234,
    "para_id": 197,
    "paper_id": 2,
    "2d_coord": [
      0.5609115362167358,
      0.38897284865379333
    ],
    "MSU_id": 1234,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 4. The constrained emissions for BC and total OA. The constrained emissions (Cons_BC, Cons_OA) over the Amazon (A) and Southern Africa (B) are shown with interquartile ranges (blue dots with thick error bars). Note that Cons_OA indicates total OA, which is further separated into primary BB emission (Cons_POA) and SOA formation (SOA). The constrained results are compared with four BB emission inventories (EI_BC and EI_OA). The thin error bars for EI_OA indicate the ranges of the OA/OC ratio ranging from 1.5 to 1.9, with the dot showing the mean emission (i.e., OA/OC = 1.7). Bottom: Correlations between satellite AOD and formaldehyde column for the Amazon (C) and Southern Africa (D) to support our constrained SOA, given that formaldehyde is an indicator of SOA formation. The AOD and SSA data are from Polarization and Directionality of the Earth's Reflectances with the Generalized Retrieval of Aerosol and Surface Properties algorithm (POLDER-GRASP), and the formaldehyde column is from Ozone Monitoring Instrument (OMI). Both satellite products are collocated with each other at  $1^{\\circ} \\times 1^{\\circ} \\times$  daily grid cells during fire seasons. Each dot represents the daily average of AOD and the formaldehyde column after collocation. The color scale denotes the SSA observation. Correlations between formaldehyde and AOD  $(r_{\\mathrm{AOD}})$  and between formaldehyde and SSA  $(r_{\\mathrm{SSA}})$  are shown with  $P$  values. In (C), the solid line indicates the regression based on the data points as shown. The dashed line is a regression derived from in situ measurements of formaldehyde and OC (45), here converted to formaldehyde column and AOD, assuming similar vertical profiles and an MEC of  $5.9 \\mathrm{~m}^{2} \\mathrm{~g}^{-1}$  (31)."
  },
  {
    "sentence": "Results are shown for ECHAM-HAM and SPRINTARS models over the Amazon and Southern Africa.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1261,
    "para_id": 201,
    "paper_id": 2,
    "2d_coord": [
      2.0595312118530273,
      0.06278911232948303
    ],
    "MSU_id": 1261,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 5. Seasonal mean modeling errors for default and corrected simulations in global models. Results are shown for ECHAM-HAM and SPRINTARS models over the Amazon (A) and Southern Africa (B). The two global models produce the most absorbing (ECHAM-HAM) and most scattering aerosols (SPRINTARS) in the AeroCom model ensemble (see fig. S6). The target variables include AAOD, AOD, and SSA. The normalized mean bias for AAOD and AOD and the mean bias of SSA (doubled to match axis scale) are shown for the whole fire season. Two configurations are considered for each model, including the default (bars with solid edges) and corrected simulations (bars without solid edges) based on constrained aerosol properties. Details of the model settings can be found in Materials and Methods and table S2. All the model data are collocated and validated with POLDER-GRASP. The vertical solid lines indicate the observation uncertainties of AAOD, AOD, and SSA for POLDER-GRASP. The observation uncertainty is calculated as the average of the absolute errors for POLDER-GRASP compared with AERONET sites, as shown in fig. S1. The POLDER-GRASP and AERONET datasets are collocated with each other before calculating these observation uncertainties."
  },
  {
    "sentence": "The target variables include AAOD, AOD, and SSA.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1264,
    "para_id": 201,
    "paper_id": 2,
    "2d_coord": [
      1.6944124698638916,
      0.039680272340774536
    ],
    "MSU_id": 1264,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 5. Seasonal mean modeling errors for default and corrected simulations in global models. Results are shown for ECHAM-HAM and SPRINTARS models over the Amazon (A) and Southern Africa (B). The two global models produce the most absorbing (ECHAM-HAM) and most scattering aerosols (SPRINTARS) in the AeroCom model ensemble (see fig. S6). The target variables include AAOD, AOD, and SSA. The normalized mean bias for AAOD and AOD and the mean bias of SSA (doubled to match axis scale) are shown for the whole fire season. Two configurations are considered for each model, including the default (bars with solid edges) and corrected simulations (bars without solid edges) based on constrained aerosol properties. Details of the model settings can be found in Materials and Methods and table S2. All the model data are collocated and validated with POLDER-GRASP. The vertical solid lines indicate the observation uncertainties of AAOD, AOD, and SSA for POLDER-GRASP. The observation uncertainty is calculated as the average of the absolute errors for POLDER-GRASP compared with AERONET sites, as shown in fig. S1. The POLDER-GRASP and AERONET datasets are collocated with each other before calculating these observation uncertainties."
  },
  {
    "sentence": "The mean bias of SSA is doubled to match the axis scale.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1266,
    "para_id": 201,
    "paper_id": 2,
    "2d_coord": [
      1.457694172859192,
      0.3176557719707489
    ],
    "MSU_id": 1266,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 5. Seasonal mean modeling errors for default and corrected simulations in global models. Results are shown for ECHAM-HAM and SPRINTARS models over the Amazon (A) and Southern Africa (B). The two global models produce the most absorbing (ECHAM-HAM) and most scattering aerosols (SPRINTARS) in the AeroCom model ensemble (see fig. S6). The target variables include AAOD, AOD, and SSA. The normalized mean bias for AAOD and AOD and the mean bias of SSA (doubled to match axis scale) are shown for the whole fire season. Two configurations are considered for each model, including the default (bars with solid edges) and corrected simulations (bars without solid edges) based on constrained aerosol properties. Details of the model settings can be found in Materials and Methods and table S2. All the model data are collocated and validated with POLDER-GRASP. The vertical solid lines indicate the observation uncertainties of AAOD, AOD, and SSA for POLDER-GRASP. The observation uncertainty is calculated as the average of the absolute errors for POLDER-GRASP compared with AERONET sites, as shown in fig. S1. The POLDER-GRASP and AERONET datasets are collocated with each other before calculating these observation uncertainties."
  },
  {
    "sentence": "All the model data are collocated and validated with POLDER-GRASP.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1269,
    "para_id": 201,
    "paper_id": 2,
    "2d_coord": [
      2.0496435165405273,
      0.18672025203704834
    ],
    "MSU_id": 1269,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 5. Seasonal mean modeling errors for default and corrected simulations in global models. Results are shown for ECHAM-HAM and SPRINTARS models over the Amazon (A) and Southern Africa (B). The two global models produce the most absorbing (ECHAM-HAM) and most scattering aerosols (SPRINTARS) in the AeroCom model ensemble (see fig. S6). The target variables include AAOD, AOD, and SSA. The normalized mean bias for AAOD and AOD and the mean bias of SSA (doubled to match axis scale) are shown for the whole fire season. Two configurations are considered for each model, including the default (bars with solid edges) and corrected simulations (bars without solid edges) based on constrained aerosol properties. Details of the model settings can be found in Materials and Methods and table S2. All the model data are collocated and validated with POLDER-GRASP. The vertical solid lines indicate the observation uncertainties of AAOD, AOD, and SSA for POLDER-GRASP. The observation uncertainty is calculated as the average of the absolute errors for POLDER-GRASP compared with AERONET sites, as shown in fig. S1. The POLDER-GRASP and AERONET datasets are collocated with each other before calculating these observation uncertainties."
  },
  {
    "sentence": "The observation uncertainty is calculated as the average of the absolute errors for POLDER-GRASP compared with AERONET sites.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1271,
    "para_id": 201,
    "paper_id": 2,
    "2d_coord": [
      2.0247812271118164,
      0.17117643356323242
    ],
    "MSU_id": 1271,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 5. Seasonal mean modeling errors for default and corrected simulations in global models. Results are shown for ECHAM-HAM and SPRINTARS models over the Amazon (A) and Southern Africa (B). The two global models produce the most absorbing (ECHAM-HAM) and most scattering aerosols (SPRINTARS) in the AeroCom model ensemble (see fig. S6). The target variables include AAOD, AOD, and SSA. The normalized mean bias for AAOD and AOD and the mean bias of SSA (doubled to match axis scale) are shown for the whole fire season. Two configurations are considered for each model, including the default (bars with solid edges) and corrected simulations (bars without solid edges) based on constrained aerosol properties. Details of the model settings can be found in Materials and Methods and table S2. All the model data are collocated and validated with POLDER-GRASP. The vertical solid lines indicate the observation uncertainties of AAOD, AOD, and SSA for POLDER-GRASP. The observation uncertainty is calculated as the average of the absolute errors for POLDER-GRASP compared with AERONET sites, as shown in fig. S1. The POLDER-GRASP and AERONET datasets are collocated with each other before calculating these observation uncertainties."
  },
  {
    "sentence": "The POLDER-GRASP and AERONET datasets are collocated with each other before calculating these observation uncertainties.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1272,
    "para_id": 201,
    "paper_id": 2,
    "2d_coord": [
      2.1043343544006348,
      0.17690548300743103
    ],
    "MSU_id": 1272,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 5. Seasonal mean modeling errors for default and corrected simulations in global models. Results are shown for ECHAM-HAM and SPRINTARS models over the Amazon (A) and Southern Africa (B). The two global models produce the most absorbing (ECHAM-HAM) and most scattering aerosols (SPRINTARS) in the AeroCom model ensemble (see fig. S6). The target variables include AAOD, AOD, and SSA. The normalized mean bias for AAOD and AOD and the mean bias of SSA (doubled to match axis scale) are shown for the whole fire season. Two configurations are considered for each model, including the default (bars with solid edges) and corrected simulations (bars without solid edges) based on constrained aerosol properties. Details of the model settings can be found in Materials and Methods and table S2. All the model data are collocated and validated with POLDER-GRASP. The vertical solid lines indicate the observation uncertainties of AAOD, AOD, and SSA for POLDER-GRASP. The observation uncertainty is calculated as the average of the absolute errors for POLDER-GRASP compared with AERONET sites, as shown in fig. S1. The POLDER-GRASP and AERONET datasets are collocated with each other before calculating these observation uncertainties."
  },
  {
    "sentence": "Data from the default and corrected simulations are shown as bars with and without edges, respectively.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1275,
    "para_id": 202,
    "paper_id": 2,
    "2d_coord": [
      1.1953225135803223,
      0.21394206583499908
    ],
    "MSU_id": 1275,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 6. Modeled all-sky instantaneous direct radiative effect (AS-IDRE) on top of the atmosphere. The results are shown for ECHAM-HAM (orange) and SPRINTARS models (green) over the Amazon and Southern Africa source (A) and outflow regions (B). Data from the default and corrected simulations are shown as bars with and without edges, respectively. The IDRE is averaged for all fire seasons and regions, with error bars indicating the SEs of the daily variation during fire seasons."
  },
  {
    "sentence": "The IDRE is averaged for all fire seasons and regions.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1276,
    "para_id": 202,
    "paper_id": 2,
    "2d_coord": [
      0.5306298732757568,
      0.5871071815490723
    ],
    "MSU_id": 1276,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 6. Modeled all-sky instantaneous direct radiative effect (AS-IDRE) on top of the atmosphere. The results are shown for ECHAM-HAM (orange) and SPRINTARS models (green) over the Amazon and Southern Africa source (A) and outflow regions (B). Data from the default and corrected simulations are shown as bars with and without edges, respectively. The IDRE is averaged for all fire seasons and regions, with error bars indicating the SEs of the daily variation during fire seasons."
  },
  {
    "sentence": "Error bars indicate the standard errors of the daily variation during fire seasons.",
    "subtitle": "DISCUSSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1277,
    "para_id": 202,
    "paper_id": 2,
    "2d_coord": [
      0.8076459765434265,
      0.25093016028404236
    ],
    "MSU_id": 1277,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Fig. 6. Modeled all-sky instantaneous direct radiative effect (AS-IDRE) on top of the atmosphere. The results are shown for ECHAM-HAM (orange) and SPRINTARS models (green) over the Amazon and Southern Africa source (A) and outflow regions (B). Data from the default and corrected simulations are shown as bars with and without edges, respectively. The IDRE is averaged for all fire seasons and regions, with error bars indicating the SEs of the daily variation during fire seasons."
  },
  {
    "sentence": "We base our analysis on data from 17 AeroCom models, collected from two control experiments conducted in 2016 (CTRL2016) and 2019 (CTL2019).",
    "subtitle": "Models and variables over fire regions",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1278,
    "para_id": 203,
    "paper_id": 2,
    "2d_coord": [
      2.032895565032959,
      0.46523526310920715
    ],
    "MSU_id": 1278,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We base our analysis on data from 17 AeroCom models, collected from two control experiments conducted in 2016 (CTRL2016) and 2019 (CTL2019). Both experiments perform model simulations for 2010 with default model configurations (table S1). The selected variables from these models include AOD at 440 and  $550\\mathrm{nm}$ , AAOD at  $550\\mathrm{nm}$ , emissions, column burdens, and precipitation. AE (550 versus  $440\\mathrm{nm}$ ), SSA (550 nm), and MAC (550 nm) are calculated from these fields. We focus our analysis on two major BB emission regions, the Amazon and Southern Africa (see fig. S1), as defined by model emissions. We consider the data during fire seasons only (July to October and June to September for Amazon and Southern Africa, respectively)."
  },
  {
    "sentence": "Both experiments perform model simulations for 2010 with default model configurations.",
    "subtitle": "Models and variables over fire regions",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1279,
    "para_id": 203,
    "paper_id": 2,
    "2d_coord": [
      1.9472911357879639,
      0.0800839364528656
    ],
    "MSU_id": 1279,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We base our analysis on data from 17 AeroCom models, collected from two control experiments conducted in 2016 (CTRL2016) and 2019 (CTL2019). Both experiments perform model simulations for 2010 with default model configurations (table S1). The selected variables from these models include AOD at 440 and  $550\\mathrm{nm}$ , AAOD at  $550\\mathrm{nm}$ , emissions, column burdens, and precipitation. AE (550 versus  $440\\mathrm{nm}$ ), SSA (550 nm), and MAC (550 nm) are calculated from these fields. We focus our analysis on two major BB emission regions, the Amazon and Southern Africa (see fig. S1), as defined by model emissions. We consider the data during fire seasons only (July to October and June to September for Amazon and Southern Africa, respectively)."
  },
  {
    "sentence": "The selected variables from these models include AOD at 440 and 550 nm, AAOD at 550 nm, emissions, column burdens, and precipitation.",
    "subtitle": "Models and variables over fire regions",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1280,
    "para_id": 203,
    "paper_id": 2,
    "2d_coord": [
      1.9768702983856201,
      0.11613380908966064
    ],
    "MSU_id": 1280,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We base our analysis on data from 17 AeroCom models, collected from two control experiments conducted in 2016 (CTRL2016) and 2019 (CTL2019). Both experiments perform model simulations for 2010 with default model configurations (table S1). The selected variables from these models include AOD at 440 and  $550\\mathrm{nm}$ , AAOD at  $550\\mathrm{nm}$ , emissions, column burdens, and precipitation. AE (550 versus  $440\\mathrm{nm}$ ), SSA (550 nm), and MAC (550 nm) are calculated from these fields. We focus our analysis on two major BB emission regions, the Amazon and Southern Africa (see fig. S1), as defined by model emissions. We consider the data during fire seasons only (July to October and June to September for Amazon and Southern Africa, respectively)."
  },
  {
    "sentence": "AE (550 versus 440 nm), SSA (550 nm), and MAC (550 nm) are calculated from these fields.",
    "subtitle": "Models and variables over fire regions",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1281,
    "para_id": 203,
    "paper_id": 2,
    "2d_coord": [
      2.0322160720825195,
      0.08400875329971313
    ],
    "MSU_id": 1281,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We base our analysis on data from 17 AeroCom models, collected from two control experiments conducted in 2016 (CTRL2016) and 2019 (CTL2019). Both experiments perform model simulations for 2010 with default model configurations (table S1). The selected variables from these models include AOD at 440 and  $550\\mathrm{nm}$ , AAOD at  $550\\mathrm{nm}$ , emissions, column burdens, and precipitation. AE (550 versus  $440\\mathrm{nm}$ ), SSA (550 nm), and MAC (550 nm) are calculated from these fields. We focus our analysis on two major BB emission regions, the Amazon and Southern Africa (see fig. S1), as defined by model emissions. We consider the data during fire seasons only (July to October and June to September for Amazon and Southern Africa, respectively)."
  },
  {
    "sentence": "We focus our analysis on two major BB emission regions, the Amazon and Southern Africa, as defined by model emissions.",
    "subtitle": "Models and variables over fire regions",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1282,
    "para_id": 203,
    "paper_id": 2,
    "2d_coord": [
      2.034761428833008,
      0.08182311058044434
    ],
    "MSU_id": 1282,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We base our analysis on data from 17 AeroCom models, collected from two control experiments conducted in 2016 (CTRL2016) and 2019 (CTL2019). Both experiments perform model simulations for 2010 with default model configurations (table S1). The selected variables from these models include AOD at 440 and  $550\\mathrm{nm}$ , AAOD at  $550\\mathrm{nm}$ , emissions, column burdens, and precipitation. AE (550 versus  $440\\mathrm{nm}$ ), SSA (550 nm), and MAC (550 nm) are calculated from these fields. We focus our analysis on two major BB emission regions, the Amazon and Southern Africa (see fig. S1), as defined by model emissions. We consider the data during fire seasons only (July to October and June to September for Amazon and Southern Africa, respectively)."
  },
  {
    "sentence": "We consider the data during fire seasons only (July to October and June to September for Amazon and Southern Africa, respectively).",
    "subtitle": "Models and variables over fire regions",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1283,
    "para_id": 203,
    "paper_id": 2,
    "2d_coord": [
      1.4676133394241333,
      0.14144563674926758
    ],
    "MSU_id": 1283,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We base our analysis on data from 17 AeroCom models, collected from two control experiments conducted in 2016 (CTRL2016) and 2019 (CTL2019). Both experiments perform model simulations for 2010 with default model configurations (table S1). The selected variables from these models include AOD at 440 and  $550\\mathrm{nm}$ , AAOD at  $550\\mathrm{nm}$ , emissions, column burdens, and precipitation. AE (550 versus  $440\\mathrm{nm}$ ), SSA (550 nm), and MAC (550 nm) are calculated from these fields. We focus our analysis on two major BB emission regions, the Amazon and Southern Africa (see fig. S1), as defined by model emissions. We consider the data during fire seasons only (July to October and June to September for Amazon and Southern Africa, respectively)."
  },
  {
    "sentence": "We validate the three datasets against AERONET data following the procedure in previous studies.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1286,
    "para_id": 204,
    "paper_id": 2,
    "2d_coord": [
      1.8720687627792358,
      0.3572767972946167
    ],
    "MSU_id": 1286,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Previous studies have suggested large and diverse errors in the satellite- based observations of AAOD and SSA (47). To characterize satellite errors, we consider three datasets: the Polarization and Directionality of the Earth's Reflectances with the Generalized Retrieval of Aerosol and Surface Properties (POLDER- GRASP) algorithm, the Ozone Monitoring Instrument (OMI) with UV aerosol algorithm (OMAERUV), and the Advanced Along- Track Scanning Radiometer with Optimal Retrieval of Aerosol and Cloud algorithm (AATSR- ORAC). We validate the three datasets against AERONET data (the locations of the AERONET sites used in this study are shown in fig. S1) following the procedure in (47) and find that POLDER- GRASP exhibits the lowest error and has the highest correlations with AERONET data for both AAOD and SSA (fig. S16). Therefore, we use POLDER- GRASP as the satellite observation (including AE) during 2010 fire seasons throughout the analysis. However, even for POLDER- GRASP, large retrieval errors exist, which contribute substantially to the overall uncertainties presented in this work."
  },
  {
    "sentence": "The POLDER-GRASP sampling is averaged over the region and fire season.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1294,
    "para_id": 205,
    "paper_id": 2,
    "2d_coord": [
      1.4624119997024536,
      0.023264586925506592
    ],
    "MSU_id": 1294,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "To apply Eq. 1 in our analysis, a regional estimation of AAOD is required, which cannot be obtained directly from the sparsely sampled raw satellite data. Following the homogenization method in our previous work (31), we perform a linear regression between the modeled regional AAOD and modeled AAOD with POLDER- GRASP sampling (averaged over the region and fire season; fig. S17). The raw POLDER- GRASP data are then applied to the regression to estimate the regional AAOD. A similar method is also used to estimate the regional SSA. The robustness of the method is verified through a jackknife test by removing the models one by one, which produces small relative variations in the predicted regional AAOD and SSA (<1%), suggesting that the construction of regional values is independent of the models used. The regional observations of AAOD and SSA are also used to validate the models on a seasonal scale (see fig. S18), showing a varying degree of error per model. Broadly, models tend to underestimate SSA over the Amazon (by 0.05 on average) and underestimate AAOD over Southern Africa (by 32% on average)."
  },
  {
    "sentence": "The robustness of the method is verified through a jackknife test by removing the models one by one.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1297,
    "para_id": 205,
    "paper_id": 2,
    "2d_coord": [
      1.9330840110778809,
      0.7106696963310242
    ],
    "MSU_id": 1297,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "To apply Eq. 1 in our analysis, a regional estimation of AAOD is required, which cannot be obtained directly from the sparsely sampled raw satellite data. Following the homogenization method in our previous work (31), we perform a linear regression between the modeled regional AAOD and modeled AAOD with POLDER- GRASP sampling (averaged over the region and fire season; fig. S17). The raw POLDER- GRASP data are then applied to the regression to estimate the regional AAOD. A similar method is also used to estimate the regional SSA. The robustness of the method is verified through a jackknife test by removing the models one by one, which produces small relative variations in the predicted regional AAOD and SSA (<1%), suggesting that the construction of regional values is independent of the models used. The regional observations of AAOD and SSA are also used to validate the models on a seasonal scale (see fig. S18), showing a varying degree of error per model. Broadly, models tend to underestimate SSA over the Amazon (by 0.05 on average) and underestimate AAOD over Southern Africa (by 32% on average)."
  },
  {
    "sentence": "Regional observations of AAOD and SSA are used to validate the models on a seasonal scale.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1300,
    "para_id": 205,
    "paper_id": 2,
    "2d_coord": [
      1.9798847436904907,
      0.21985702216625214
    ],
    "MSU_id": 1300,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "To apply Eq. 1 in our analysis, a regional estimation of AAOD is required, which cannot be obtained directly from the sparsely sampled raw satellite data. Following the homogenization method in our previous work (31), we perform a linear regression between the modeled regional AAOD and modeled AAOD with POLDER- GRASP sampling (averaged over the region and fire season; fig. S17). The raw POLDER- GRASP data are then applied to the regression to estimate the regional AAOD. A similar method is also used to estimate the regional SSA. The robustness of the method is verified through a jackknife test by removing the models one by one, which produces small relative variations in the predicted regional AAOD and SSA (<1%), suggesting that the construction of regional values is independent of the models used. The regional observations of AAOD and SSA are also used to validate the models on a seasonal scale (see fig. S18), showing a varying degree of error per model. Broadly, models tend to underestimate SSA over the Amazon (by 0.05 on average) and underestimate AAOD over Southern Africa (by 32% on average)."
  },
  {
    "sentence": "Daily precipitation data are taken from the global precipitation climatology project (GPCP).",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1304,
    "para_id": 206,
    "paper_id": 2,
    "2d_coord": [
      1.769931435585022,
      0.24732108414173126
    ],
    "MSU_id": 1304,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "In addition to aerosol observations, daily precipitation data are taken from the global precipitation climatology project (GPCP), which has been proven to be superior to other reanalysis datasets (48). The formaldehyde column is obtained from the OMI onboard the Aura satellite (49). Field measurements of fire EFs are also collected for the prevailing tropical forest/deforestation fires in the Amazon and the savanna/grassland fires in Southern Africa (table S2). All these observations are collected for the fire seasons during 2010."
  },
  {
    "sentence": "The formaldehyde column is obtained from the OMI onboard the Aura satellite.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1306,
    "para_id": 206,
    "paper_id": 2,
    "2d_coord": [
      2.071253538131714,
      0.1870473027229309
    ],
    "MSU_id": 1306,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "In addition to aerosol observations, daily precipitation data are taken from the global precipitation climatology project (GPCP), which has been proven to be superior to other reanalysis datasets (48). The formaldehyde column is obtained from the OMI onboard the Aura satellite (49). Field measurements of fire EFs are also collected for the prevailing tropical forest/deforestation fires in the Amazon and the savanna/grassland fires in Southern Africa (table S2). All these observations are collected for the fire seasons during 2010."
  },
  {
    "sentence": "Field measurements of fire emission factors (EFs) are collected for the prevailing tropical forest/deforestation fires in the Amazon.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1307,
    "para_id": 206,
    "paper_id": 2,
    "2d_coord": [
      2.0514261722564697,
      0.06616079807281494
    ],
    "MSU_id": 1307,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "In addition to aerosol observations, daily precipitation data are taken from the global precipitation climatology project (GPCP), which has been proven to be superior to other reanalysis datasets (48). The formaldehyde column is obtained from the OMI onboard the Aura satellite (49). Field measurements of fire EFs are also collected for the prevailing tropical forest/deforestation fires in the Amazon and the savanna/grassland fires in Southern Africa (table S2). All these observations are collected for the fire seasons during 2010."
  },
  {
    "sentence": "Field measurements of fire emission factors (EFs) are collected for the savanna/grassland fires in Southern Africa.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1308,
    "para_id": 206,
    "paper_id": 2,
    "2d_coord": [
      1.9945101737976074,
      0.09962201118469238
    ],
    "MSU_id": 1308,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "In addition to aerosol observations, daily precipitation data are taken from the global precipitation climatology project (GPCP), which has been proven to be superior to other reanalysis datasets (48). The formaldehyde column is obtained from the OMI onboard the Aura satellite (49). Field measurements of fire EFs are also collected for the prevailing tropical forest/deforestation fires in the Amazon and the savanna/grassland fires in Southern Africa (table S2). All these observations are collected for the fire seasons during 2010."
  },
  {
    "sentence": "All these observations are collected for the fire seasons during 2010.",
    "subtitle": "Observation data",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1309,
    "para_id": 206,
    "paper_id": 2,
    "2d_coord": [
      1.0028419494628906,
      -0.008253872394561768
    ],
    "MSU_id": 1309,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "In addition to aerosol observations, daily precipitation data are taken from the global precipitation climatology project (GPCP), which has been proven to be superior to other reanalysis datasets (48). The formaldehyde column is obtained from the OMI onboard the Aura satellite (49). Field measurements of fire EFs are also collected for the prevailing tropical forest/deforestation fires in the Amazon and the savanna/grassland fires in Southern Africa (table S2). All these observations are collected for the fire seasons during 2010."
  },
  {
    "sentence": "All the variables are calculated as regional fire-season averages.",
    "subtitle": "Constraining BB carbonaceous aerosols in models",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1315,
    "para_id": 207,
    "paper_id": 2,
    "2d_coord": [
      1.4466956853866577,
      0.12686729431152344
    ],
    "MSU_id": 1315,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "The overall constraining procedure is displayed in Fig. 1. The basic idea is to decompose AAOD into three interpretable factors: emission, lifetime, and MAC (see Eq. 1). The emission is calculated as the total of the BC and OA emissions; lifetime is calculated as the (burden of  $\\mathrm{BC + OA}$ )/emission of  $\\mathrm{BC + OA}$ , and MAC is AAOD/(burden of  $\\mathrm{BC + OA}$ ). All the variables are calculated as regional fire- season averages. Other absorbing components (e.g., dust) are assumed to have negligible impacts given the small contribution indicated by the observations (50) and AeroCom models (4%) for the two regions. In addition, we find a small absorption AE from POLDER- GRASP observations (fig. S19), suggesting that brown carbon is not important (51, 52). Note that the emission in Eq. 1 includes both primary emissions and those from secondary formation (SOA), as the latter happens on a much smaller time scale than the seasonal average that we are working with."
  },
  {
    "sentence": "For the AeroCom models, we compare the SSA for total aerosols and the SSA of grid cells with ≥ 85% carbonaceous aerosol components.",
    "subtitle": "Constraining BB carbonaceous aerosols in models",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1333,
    "para_id": 211,
    "paper_id": 2,
    "2d_coord": [
      2.051504135131836,
      0.13815581798553467
    ],
    "MSU_id": 1333,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "In addition to the total emissions for  $\\mathrm{BC + OA}$ , the rBC ratio is constrained in this work by using the observational relationship between SSA and ambient rBC at  $550~\\mathrm{nm}$  wavelength from (24). Here, we do not use the modeled relationship between rBC and SSA, as we find that it contains a large error (see fig. S6). It should be noted that the relationship by (24) was established under the criteria that OA and BC accounted for more than  $85\\%$  of the total aerosol mass (to focus on BBAs). For the AeroCom models, we compare the SSA for total aerosols and the SSA of grid cells with  $\\geq 85\\%$  carbonaceous aerosol components, with small differences being found for most models, especially within the range of the SSA observations (see fig. S20A). This suggests that the SSA for total aerosols during fire seasons could sufficiently represent the aerosol criteria by (24), which allows us to constrain the rBC in the ambient aerosols from SSA on the basis of the observed relationship. Using another regression to link the rBC from ambient aerosols to the emissions (see fig. S20B), we lastly obtain the constrained rBC in emissions and estimate the separate emissions for BC and OA."
  },
  {
    "sentence": "We use individual AeroCom models to serve as a truth and generate perfect synthetic observations from it to assess the robustness of our constraining procedure.",
    "subtitle": "Constraining BB carbonaceous aerosols in models",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1339,
    "para_id": 212,
    "paper_id": 2,
    "2d_coord": [
      2.043531894683838,
      0.14710453152656555
    ],
    "MSU_id": 1339,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "To assess the robustness of our constraining procedure, we use individual AeroCom models to serve as a truth and generate perfect (i.e., errorless) synthetic observations from it. The remaining models are then used to predict the emission, lifetime, and MAC of the truth run following the same procedure as described above (the regression between SSA and ambient rBC is replaced with the modeled relationship; see fig. S6). As shown in fig. S21, the predicted values agree well with truth model data, demonstrating the robustness of the methodology. In particular, the average of the absolute relative errors for predicted BC emissions are 17 and  $14\\%$  for the Amazon and Southern Africa, respectively, which are much smaller than the uncertainty in our main analysis using real observations. This suggests that the overall uncertainty of our constraining analysis is primarily affected by observational errors, as corroborated by our uncertainty analysis shown in fig. S15."
  },
  {
    "sentence": "The remaining models are used to predict the emission, lifetime, and MAC of the truth run following the same procedure as described above.",
    "subtitle": "Constraining BB carbonaceous aerosols in models",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1340,
    "para_id": 212,
    "paper_id": 2,
    "2d_coord": [
      0.9508062601089478,
      1.0241599082946777
    ],
    "MSU_id": 1340,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "To assess the robustness of our constraining procedure, we use individual AeroCom models to serve as a truth and generate perfect (i.e., errorless) synthetic observations from it. The remaining models are then used to predict the emission, lifetime, and MAC of the truth run following the same procedure as described above (the regression between SSA and ambient rBC is replaced with the modeled relationship; see fig. S6). As shown in fig. S21, the predicted values agree well with truth model data, demonstrating the robustness of the methodology. In particular, the average of the absolute relative errors for predicted BC emissions are 17 and  $14\\%$  for the Amazon and Southern Africa, respectively, which are much smaller than the uncertainty in our main analysis using real observations. This suggests that the overall uncertainty of our constraining analysis is primarily affected by observational errors, as corroborated by our uncertainty analysis shown in fig. S15."
  },
  {
    "sentence": "We conduct simulations in two global models that produce the most negative (ECHAM-HAM) and positive (SPRINTARS) SSA errors in the AeroCom ensemble.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1371,
    "para_id": 216,
    "paper_id": 2,
    "2d_coord": [
      2.050673246383667,
      0.07995784282684326
    ],
    "MSU_id": 1371,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We conduct simulations in two global models that produce the most negative (ECHAM- HAM) and positive (SPRINTARS) SSA errors in the AeroCom ensemble (fig. S6). The latest version of ECHAM- HAM (ECHAM6.3.0- HAMMOZ2.3) is run at a T63 horizontal resolution  $(\\sim 1.875^{\\circ})$  and 47 vertical level (54). The SPRINTARS model presents simulations at the T213 horizontal grid  $(0.5625^{\\circ})$  with 40 vertical hybrid layers (55). Both simulations start in January 2010 with runs before the fire seasons as spin- up, and validations are made during the fire seasons. The ECHAM- HAM model includes inactive SOA following the prescribed emissions in (56), while SPRINTARS calculates the oxidation of precursors (terpene and isoprene) at a prescribed emission level over land according to the Global Emissions Initiative dataset. With default configurations, the differences in modeled SSA and direct radiative effects between two models are likely associated with the very different particle size distribution and refractive index, the two factors that affect SSA the most in the AeroCom models (text S1). Accordingly, we modify the modeled particle size and BC refractive index in the two models. In addition, emission and lifetime are corrected on the basis of our constrained results (table S3). The detailed corrections are listed below for MAC (1 and 2), lifetime (1 and 3), and emission (4)."
  },
  {
    "sentence": "The latest version of ECHAM-HAM (ECHAM6.3.0-HAMMOZ2.3) is run at a T63 horizontal resolution (∼1.875°) and 47 vertical levels.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1372,
    "para_id": 216,
    "paper_id": 2,
    "2d_coord": [
      1.301537036895752,
      1.7075543403625488
    ],
    "MSU_id": 1372,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We conduct simulations in two global models that produce the most negative (ECHAM- HAM) and positive (SPRINTARS) SSA errors in the AeroCom ensemble (fig. S6). The latest version of ECHAM- HAM (ECHAM6.3.0- HAMMOZ2.3) is run at a T63 horizontal resolution  $(\\sim 1.875^{\\circ})$  and 47 vertical level (54). The SPRINTARS model presents simulations at the T213 horizontal grid  $(0.5625^{\\circ})$  with 40 vertical hybrid layers (55). Both simulations start in January 2010 with runs before the fire seasons as spin- up, and validations are made during the fire seasons. The ECHAM- HAM model includes inactive SOA following the prescribed emissions in (56), while SPRINTARS calculates the oxidation of precursors (terpene and isoprene) at a prescribed emission level over land according to the Global Emissions Initiative dataset. With default configurations, the differences in modeled SSA and direct radiative effects between two models are likely associated with the very different particle size distribution and refractive index, the two factors that affect SSA the most in the AeroCom models (text S1). Accordingly, we modify the modeled particle size and BC refractive index in the two models. In addition, emission and lifetime are corrected on the basis of our constrained results (table S3). The detailed corrections are listed below for MAC (1 and 2), lifetime (1 and 3), and emission (4)."
  },
  {
    "sentence": "The SPRINTARS model presents simulations at the T213 horizontal grid (0.5625°) with 40 vertical hybrid layers.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1373,
    "para_id": 216,
    "paper_id": 2,
    "2d_coord": [
      1.563873052597046,
      1.3502657413482666
    ],
    "MSU_id": 1373,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We conduct simulations in two global models that produce the most negative (ECHAM- HAM) and positive (SPRINTARS) SSA errors in the AeroCom ensemble (fig. S6). The latest version of ECHAM- HAM (ECHAM6.3.0- HAMMOZ2.3) is run at a T63 horizontal resolution  $(\\sim 1.875^{\\circ})$  and 47 vertical level (54). The SPRINTARS model presents simulations at the T213 horizontal grid  $(0.5625^{\\circ})$  with 40 vertical hybrid layers (55). Both simulations start in January 2010 with runs before the fire seasons as spin- up, and validations are made during the fire seasons. The ECHAM- HAM model includes inactive SOA following the prescribed emissions in (56), while SPRINTARS calculates the oxidation of precursors (terpene and isoprene) at a prescribed emission level over land according to the Global Emissions Initiative dataset. With default configurations, the differences in modeled SSA and direct radiative effects between two models are likely associated with the very different particle size distribution and refractive index, the two factors that affect SSA the most in the AeroCom models (text S1). Accordingly, we modify the modeled particle size and BC refractive index in the two models. In addition, emission and lifetime are corrected on the basis of our constrained results (table S3). The detailed corrections are listed below for MAC (1 and 2), lifetime (1 and 3), and emission (4)."
  },
  {
    "sentence": "Both simulations start in January 2010 with runs before the fire seasons as spin-up, and validations are made during the fire seasons.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1374,
    "para_id": 216,
    "paper_id": 2,
    "2d_coord": [
      0.7848678231239319,
      0.16203513741493225
    ],
    "MSU_id": 1374,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We conduct simulations in two global models that produce the most negative (ECHAM- HAM) and positive (SPRINTARS) SSA errors in the AeroCom ensemble (fig. S6). The latest version of ECHAM- HAM (ECHAM6.3.0- HAMMOZ2.3) is run at a T63 horizontal resolution  $(\\sim 1.875^{\\circ})$  and 47 vertical level (54). The SPRINTARS model presents simulations at the T213 horizontal grid  $(0.5625^{\\circ})$  with 40 vertical hybrid layers (55). Both simulations start in January 2010 with runs before the fire seasons as spin- up, and validations are made during the fire seasons. The ECHAM- HAM model includes inactive SOA following the prescribed emissions in (56), while SPRINTARS calculates the oxidation of precursors (terpene and isoprene) at a prescribed emission level over land according to the Global Emissions Initiative dataset. With default configurations, the differences in modeled SSA and direct radiative effects between two models are likely associated with the very different particle size distribution and refractive index, the two factors that affect SSA the most in the AeroCom models (text S1). Accordingly, we modify the modeled particle size and BC refractive index in the two models. In addition, emission and lifetime are corrected on the basis of our constrained results (table S3). The detailed corrections are listed below for MAC (1 and 2), lifetime (1 and 3), and emission (4)."
  },
  {
    "sentence": "The ECHAM-HAM model includes inactive SOA following the prescribed emissions.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1375,
    "para_id": 216,
    "paper_id": 2,
    "2d_coord": [
      1.953702688217163,
      0.1039305329322815
    ],
    "MSU_id": 1375,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We conduct simulations in two global models that produce the most negative (ECHAM- HAM) and positive (SPRINTARS) SSA errors in the AeroCom ensemble (fig. S6). The latest version of ECHAM- HAM (ECHAM6.3.0- HAMMOZ2.3) is run at a T63 horizontal resolution  $(\\sim 1.875^{\\circ})$  and 47 vertical level (54). The SPRINTARS model presents simulations at the T213 horizontal grid  $(0.5625^{\\circ})$  with 40 vertical hybrid layers (55). Both simulations start in January 2010 with runs before the fire seasons as spin- up, and validations are made during the fire seasons. The ECHAM- HAM model includes inactive SOA following the prescribed emissions in (56), while SPRINTARS calculates the oxidation of precursors (terpene and isoprene) at a prescribed emission level over land according to the Global Emissions Initiative dataset. With default configurations, the differences in modeled SSA and direct radiative effects between two models are likely associated with the very different particle size distribution and refractive index, the two factors that affect SSA the most in the AeroCom models (text S1). Accordingly, we modify the modeled particle size and BC refractive index in the two models. In addition, emission and lifetime are corrected on the basis of our constrained results (table S3). The detailed corrections are listed below for MAC (1 and 2), lifetime (1 and 3), and emission (4)."
  },
  {
    "sentence": "SPRINTARS calculates the oxidation of precursors (terpene and isoprene) at a prescribed emission level over land according to the Global Emissions Initiative dataset.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1376,
    "para_id": 216,
    "paper_id": 2,
    "2d_coord": [
      1.945946455001831,
      0.6551234722137451
    ],
    "MSU_id": 1376,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "We conduct simulations in two global models that produce the most negative (ECHAM- HAM) and positive (SPRINTARS) SSA errors in the AeroCom ensemble (fig. S6). The latest version of ECHAM- HAM (ECHAM6.3.0- HAMMOZ2.3) is run at a T63 horizontal resolution  $(\\sim 1.875^{\\circ})$  and 47 vertical level (54). The SPRINTARS model presents simulations at the T213 horizontal grid  $(0.5625^{\\circ})$  with 40 vertical hybrid layers (55). Both simulations start in January 2010 with runs before the fire seasons as spin- up, and validations are made during the fire seasons. The ECHAM- HAM model includes inactive SOA following the prescribed emissions in (56), while SPRINTARS calculates the oxidation of precursors (terpene and isoprene) at a prescribed emission level over land according to the Global Emissions Initiative dataset. With default configurations, the differences in modeled SSA and direct radiative effects between two models are likely associated with the very different particle size distribution and refractive index, the two factors that affect SSA the most in the AeroCom models (text S1). Accordingly, we modify the modeled particle size and BC refractive index in the two models. In addition, emission and lifetime are corrected on the basis of our constrained results (table S3). The detailed corrections are listed below for MAC (1 and 2), lifetime (1 and 3), and emission (4)."
  },
  {
    "sentence": "We conduct a sensitivity test on the imaginary part ranging from 0.1 to 0.5 with the corrected ECHAM-HAM model.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1389,
    "para_id": 217,
    "paper_id": 2,
    "2d_coord": [
      2.047558069229126,
      0.24370145797729492
    ],
    "MSU_id": 1389,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "1) Particle size. The modeled ambient particle size is modified to match the observed AE. For ECHAM-HAM, we increase the emitted/ambient particle size by referring to our previous study (31). In SPRINTARS, we switch off the hygroscopic growth for OA which is likely too strong (57). Modifications to both models produce better agreement with the AE observations from POLDER-GRASP (fig. S22A). The AE bias in the default simulations and the corresponding improvement through corrections are further supported by AERONET observations (fig. S22B).\n2) Refractive index for BC. According to field measurements (58, 59), the imaginary part of refractive index of BC in the two models is changed to  $0.3i$ . Note that this value is lower than those used in the AeroCom models (0.44 to 0.79 for the imaginary part; see table S1). We conduct a sensitivity test on the imaginary part ranging from 0.1 to 0.5 with the corrected ECHAM-HAM model and find that the modified particle size with a value of 0.3 agrees the best with SSA observations from (24), suggesting that the observation-based refractive index is more suitable than those used in the AeroCom models (see fig. S23). In addition to SSA, this correction also results in better agreement with our constrained MAC for the two models (fig. S24). This refractive index is also used in a previous model study (60). Moreover, we also test different real parts of refractive index by changing values from 1.4 to 1.95 encompassing both observed values (61) and model-recommended values (see table S1). The resulting changes in AAOD are negligible  $(< 1\\%)$  and we maintain the default model values.\n3) Precipitation. A scaling factor is directly added to the modeled wet deposition based on the default precipitation error. This will correct the lifetime together with the modified particle size as stated above.\n4) Emissions. BC and total OA emissions (both primary emissions and those from secondary formation) are scaled to our constrained results."
  },
  {
    "sentence": "We also test different real parts of refractive index by changing values from 1.4 to 1.95.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1393,
    "para_id": 217,
    "paper_id": 2,
    "2d_coord": [
      1.9661781787872314,
      0.16630221903324127
    ],
    "MSU_id": 1393,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "1) Particle size. The modeled ambient particle size is modified to match the observed AE. For ECHAM-HAM, we increase the emitted/ambient particle size by referring to our previous study (31). In SPRINTARS, we switch off the hygroscopic growth for OA which is likely too strong (57). Modifications to both models produce better agreement with the AE observations from POLDER-GRASP (fig. S22A). The AE bias in the default simulations and the corresponding improvement through corrections are further supported by AERONET observations (fig. S22B).\n2) Refractive index for BC. According to field measurements (58, 59), the imaginary part of refractive index of BC in the two models is changed to  $0.3i$ . Note that this value is lower than those used in the AeroCom models (0.44 to 0.79 for the imaginary part; see table S1). We conduct a sensitivity test on the imaginary part ranging from 0.1 to 0.5 with the corrected ECHAM-HAM model and find that the modified particle size with a value of 0.3 agrees the best with SSA observations from (24), suggesting that the observation-based refractive index is more suitable than those used in the AeroCom models (see fig. S23). In addition to SSA, this correction also results in better agreement with our constrained MAC for the two models (fig. S24). This refractive index is also used in a previous model study (60). Moreover, we also test different real parts of refractive index by changing values from 1.4 to 1.95 encompassing both observed values (61) and model-recommended values (see table S1). The resulting changes in AAOD are negligible  $(< 1\\%)$  and we maintain the default model values.\n3) Precipitation. A scaling factor is directly added to the modeled wet deposition based on the default precipitation error. This will correct the lifetime together with the modified particle size as stated above.\n4) Emissions. BC and total OA emissions (both primary emissions and those from secondary formation) are scaled to our constrained results."
  },
  {
    "sentence": "The corrected simulations are validated against POLDER-GRASP.",
    "subtitle": "Global model simulations and corrections",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1401,
    "para_id": 218,
    "paper_id": 2,
    "2d_coord": [
      2.049112558364868,
      0.1306144893169403
    ],
    "MSU_id": 1401,
    "paper_info": "Threefold reduction of modeled uncertainty in direct radiative effects over biomass burning regions by constraining absorbing aerosols",
    "paragraph_info": "Details of the parameterizations can be found in table S3, and the impacts of the modifications on SSA and MAC are shown in fig. S24. The corrected simulations are validated against POLDER- GRASP (Fig. 5 and figs. S10 and S11), showing better agreement than the default simulations. Please note that the above modifications are conducted specifically over the selected regions during fire seasons and may not be directly applicable to different times or domains."
  },
  {
    "sentence": "We evaluate GeoChron with two case studies, an informal user study, an ablation study, parameter analysis, and running time analysis.",
    "subtitle": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1429,
    "para_id": 221,
    "paper_id": 4,
    "2d_coord": [
      -0.26047003269195557,
      0.9725844860076904
    ],
    "MSU_id": 1429,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Abstract- In geo- related fields such as urban informatics, atmospheric science, and geography, large- scale spatial time (ST) series (i.e., geo- referred time series) are collected for monitoring and understanding important spatiotemporal phenomena. ST series visualization is an effective means of understanding the data and reviewing spatiotemporal phenomena, which is a prerequisite for in- depth data analysis. However, visualizing these series is challenging due to their large scales, inherent dynamics, and spatiotemporal nature. In this study, we introduce the notion of patterns of evolution in ST series. Each evolution pattern is characterized by 1) a set of ST series that are close in space and 2) a time period when the trends of these ST series are correlated. We then leverage Storyline techniques by considering an analogy between evolution patterns and sessions, and finally design a novel visualization called GeoChron, which is capable of visualizing large- scale ST series in an evolution pattern- aware and narrative- preserving manner. GeoChron includes a mining framework to extract evolution patterns and two- level visualizations to enhance its visual scalability. We evaluate GeoChron with two case studies, an informal user study, an ablation study, parameter analysis, and running time analysis."
  },
  {
    "sentence": "GeoChron is comprehensively evaluated by a series of studies and analyses.",
    "subtitle": "1 INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1487,
    "para_id": 228,
    "paper_id": 4,
    "2d_coord": [
      -0.25345945358276367,
      0.9240604639053345
    ],
    "MSU_id": 1487,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We propose GeoChron (chronicle of geo- space), an interactive visualization for large- scale ST series. For the first challenge, GeoChron includes a carefully- designed data mining framework. The framework slices the time span and captures reliable correlation relations between ST series in each time slice. Afterward, it employs a network formulation to fuse the correlation relations above and the spatial proximity in a semantic- preserving way and detect communities as evolution patterns. Consequently, the Storyline layout algorithm can be applied by considering each ST series as an entity and considering an evolution pattern as a session. For the second challenge, GeoChron supports a novel two- level visualization mechanism to present the spatiotemporal information of large- scale ST series. At the first level, we revise the Storyline with new interactions and visual encodings, and link it with a geographic map, to present evolution patterns from a high level of perspective. At the second level, we employ an EvoLens, a lens placed on the Storyline, to display more details regarding the temporal trends of evolution patterns in a narrative- preserving manner. The map is coordinated with the EvoLens to provide the detailed spatial context of evolution patterns. GeoChron is comprehensively evaluated by a series of studies and analyses. In sum, our contributions are as follows:"
  },
  {
    "sentence": "We formed a team to study this problem, including visualization researchers as well as three spatiotemporal analysis experts.",
    "subtitle": "3.2 Background and Research Problem",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1579,
    "para_id": 245,
    "paper_id": 4,
    "2d_coord": [
      0.6824132204055786,
      1.4746711254119873
    ],
    "MSU_id": 1579,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We formed a team to study this problem, including visualization researchers as well as three spatiotemporal analysis experts. Each of the three experts has at least five years of experience in spatiotemporal data analysis. The target users, including the experts, are any analysts who need to review, monitor, or analyze ST time series. The team participates in iterating the design. As we are studying a general and fundamental visualization problem, no additional experts in the specific fields are involved in design iteration and evaluation."
  },
  {
    "sentence": "Each of the three experts has at least five years of experience in spatiotemporal data analysis.",
    "subtitle": "3.2 Background and Research Problem",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1580,
    "para_id": 245,
    "paper_id": 4,
    "2d_coord": [
      -0.2044411301612854,
      1.1364915370941162
    ],
    "MSU_id": 1580,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We formed a team to study this problem, including visualization researchers as well as three spatiotemporal analysis experts. Each of the three experts has at least five years of experience in spatiotemporal data analysis. The target users, including the experts, are any analysts who need to review, monitor, or analyze ST time series. The team participates in iterating the design. As we are studying a general and fundamental visualization problem, no additional experts in the specific fields are involved in design iteration and evaluation."
  },
  {
    "sentence": "The target users, including the experts, are any analysts who need to review, monitor, or analyze ST time series.",
    "subtitle": "3.2 Background and Research Problem",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1581,
    "para_id": 245,
    "paper_id": 4,
    "2d_coord": [
      0.4090523421764374,
      1.3147246837615967
    ],
    "MSU_id": 1581,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We formed a team to study this problem, including visualization researchers as well as three spatiotemporal analysis experts. Each of the three experts has at least five years of experience in spatiotemporal data analysis. The target users, including the experts, are any analysts who need to review, monitor, or analyze ST time series. The team participates in iterating the design. As we are studying a general and fundamental visualization problem, no additional experts in the specific fields are involved in design iteration and evaluation."
  },
  {
    "sentence": "We perform tentative explorations on an air quality dataset via this prototype.",
    "subtitle": "6.1 Design Goals",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1686,
    "para_id": 269,
    "paper_id": 4,
    "2d_coord": [
      0.8506327271461487,
      0.6726115345954895
    ],
    "MSU_id": 1686,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We conduct an iterative design process. In each iteration, we develop a prototype and perform tentative explorations on an air quality dataset (Soc. 8.1.1) via this prototype. Then, we summarize the observed"
  },
  {
    "sentence": "The air quality dataset used is Soc. 8.1.1.",
    "subtitle": "6.1 Design Goals",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1687,
    "para_id": 269,
    "paper_id": 4,
    "2d_coord": [
      1.2411929368972778,
      1.0679309368133545
    ],
    "MSU_id": 1687,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We conduct an iterative design process. In each iteration, we develop a prototype and perform tentative explorations on an air quality dataset (Soc. 8.1.1) via this prototype. Then, we summarize the observed"
  },
  {
    "sentence": "We set $d_{in}$ (the space between the adjacent entities in a session) as 0.",
    "subtitle": "6.3.1 Tracking Overall Evolution Patterns",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1761,
    "para_id": 284,
    "paper_id": 4,
    "2d_coord": [
      -0.057304203510284424,
      1.0894970893859863
    ],
    "MSU_id": 1761,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Moreover, we set  $d_{in}$  (the space between the adjacent entities in a session) as 0. In this way, the trends of the ST series in a session can be clearly revealed (G1). For example, the session in Fig. 5A5 clearly indicates that multiple ST series have correlated upward trends during the period. In addition, the layout is further compressed to save space."
  },
  {
    "sentence": "Initially, all curves and dots have the same default color.",
    "subtitle": "6.3.1 Tracking Overall Evolution Patterns",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1772,
    "para_id": 286,
    "paper_id": 4,
    "2d_coord": [
      -0.15860959887504578,
      0.9560976624488831
    ],
    "MSU_id": 1772,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Initially, all curves and dots have the same default color (blue in our study). If users identify an interesting session, they may want to obtain"
  },
  {
    "sentence": "The default color used in our study is blue.",
    "subtitle": "6.3.1 Tracking Overall Evolution Patterns",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1773,
    "para_id": 286,
    "paper_id": 4,
    "2d_coord": [
      0.39768922328948975,
      0.8801587820053101
    ],
    "MSU_id": 1773,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Initially, all curves and dots have the same default color (blue in our study). If users identify an interesting session, they may want to obtain"
  },
  {
    "sentence": "Fig. 5D shows the colored Storyline by coloring the sessions highlighted in Fig. 5A1, A2, A3, A4, and A5 with different colors.",
    "subtitle": "6.3.1 Tracking Overall Evolution Patterns",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1787,
    "para_id": 288,
    "paper_id": 4,
    "2d_coord": [
      -0.10846814513206482,
      0.9730327129364014
    ],
    "MSU_id": 1787,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "its geographic distribution and track how the entities evolve over time (G2). To do that, they can pick up a color (Fig. 5E) and click a session to color the entities that are comprised by the clicked session. The dots of these colored entities will also be colored on the geographic map. We provide multiple optional colors, and users can color multiple sessions differently. In this way, users are enabled to establish the geographic distribution of sessions and compare the evolution of different groups of ST series. Fig. 5D shows the colored Storyline from Fig. 5A by mainly coloring the sessions highlighted in Fig. 5A1, A2, A3, A4, and A5 with purple, purple, green, orange, and red, one by one. Fig. 5F shows the geographic distribution of the colored entities."
  },
  {
    "sentence": "Fig. 5F shows the geographic distribution of the colored entities.",
    "subtitle": "6.3.1 Tracking Overall Evolution Patterns",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1788,
    "para_id": 288,
    "paper_id": 4,
    "2d_coord": [
      -0.2856796979904175,
      1.153291940689087
    ],
    "MSU_id": 1788,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "its geographic distribution and track how the entities evolve over time (G2). To do that, they can pick up a color (Fig. 5E) and click a session to color the entities that are comprised by the clicked session. The dots of these colored entities will also be colored on the geographic map. We provide multiple optional colors, and users can color multiple sessions differently. In this way, users are enabled to establish the geographic distribution of sessions and compare the evolution of different groups of ST series. Fig. 5D shows the colored Storyline from Fig. 5A by mainly coloring the sessions highlighted in Fig. 5A1, A2, A3, A4, and A5 with purple, purple, green, orange, and red, one by one. Fig. 5F shows the geographic distribution of the colored entities."
  },
  {
    "sentence": "The map provides an illustration of the geographic distribution for Day 3 as shown in Fig. 6C.",
    "subtitle": "6.3.2 Drilling Down Into Evolution Patterns",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1834,
    "para_id": 295,
    "paper_id": 4,
    "2d_coord": [
      -0.237798810005188,
      1.1532586812973022
    ],
    "MSU_id": 1834,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Investigating evolution patterns in space and time. EvoLens is coordinated with the map (G4). When users hover over a time slice (Day 3 in Fig. 6C), the map displays the geographic distribution of each session in this time slice (Fig. 6B). Specifically, we generate a convex hull on the map for each session to cover the dots the session comprises. The number of sessions in this view is less than in the Storyline so that we can overlay visual elements on the map. When users hover over a line chart, the borders of both the line chart and the hull become thicker. Via the above interactions, users can interactively investigate how ST time series evolve correlatively from a spatiotemporal perspective."
  },
  {
    "sentence": "The number of sessions in this view is less than in the Storyline to allow overlaying of visual elements on the map.",
    "subtitle": "6.3.2 Drilling Down Into Evolution Patterns",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1836,
    "para_id": 295,
    "paper_id": 4,
    "2d_coord": [
      -0.21008431911468506,
      1.145969271659851
    ],
    "MSU_id": 1836,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Investigating evolution patterns in space and time. EvoLens is coordinated with the map (G4). When users hover over a time slice (Day 3 in Fig. 6C), the map displays the geographic distribution of each session in this time slice (Fig. 6B). Specifically, we generate a convex hull on the map for each session to cover the dots the session comprises. The number of sessions in this view is less than in the Storyline so that we can overlay visual elements on the map. When users hover over a line chart, the borders of both the line chart and the hull become thicker. Via the above interactions, users can interactively investigate how ST time series evolve correlatively from a spatiotemporal perspective."
  },
  {
    "sentence": "All parameters are default, as they worked well in our multiple trials.",
    "subtitle": "7 IMPLEMENTATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1845,
    "para_id": 296,
    "paper_id": 4,
    "2d_coord": [
      -0.26380032300949097,
      1.147921085357666
    ],
    "MSU_id": 1845,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "GeoChron is a web- based application with a backend and a frontend. The backend is implemented with Python 3.8. It serves the generation procedures of sessions and Storyline layout. In particular, the backend caches pairwise correlation coefficients among all ST series in every time window. Relation networks thereby can be constructed quickly after receiving the parameters. The Louvain algorithm is supported by the package slnetwork. All parameters are default, as they worked well in our multiple trials (See Sec. 8). We also employ a parallel framework Multiprocessing to detect communities for multiple time slices simultaneously. The frontend is implemented with TypeScript. It provides interactive visualizations for users. The Storyline is rendered on HTML5 canvas rather than HTML5 svg for efficiency."
  },
  {
    "sentence": "GeoChron is evaluated with real-world case studies.",
    "subtitle": "8 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1850,
    "para_id": 297,
    "paper_id": 4,
    "2d_coord": [
      -0.28492122888565063,
      1.0272748470306396
    ],
    "MSU_id": 1850,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "GeoChron is evaluated with real- world case studies, an informal user study, an ablation study, parameter analysis, and running time analysis."
  },
  {
    "sentence": "GeoChron is evaluated with an informal user study.",
    "subtitle": "8 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1851,
    "para_id": 297,
    "paper_id": 4,
    "2d_coord": [
      -0.2608596086502075,
      0.9683884978294373
    ],
    "MSU_id": 1851,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "GeoChron is evaluated with real- world case studies, an informal user study, an ablation study, parameter analysis, and running time analysis."
  },
  {
    "sentence": "GeoChron is evaluated with an ablation study.",
    "subtitle": "8 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1852,
    "para_id": 297,
    "paper_id": 4,
    "2d_coord": [
      -0.28425782918930054,
      1.0887045860290527
    ],
    "MSU_id": 1852,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "GeoChron is evaluated with real- world case studies, an informal user study, an ablation study, parameter analysis, and running time analysis."
  },
  {
    "sentence": "GeoChron is evaluated with parameter analysis.",
    "subtitle": "8 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1853,
    "para_id": 297,
    "paper_id": 4,
    "2d_coord": [
      -0.26359128952026367,
      1.0404269695281982
    ],
    "MSU_id": 1853,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "GeoChron is evaluated with real- world case studies, an informal user study, an ablation study, parameter analysis, and running time analysis."
  },
  {
    "sentence": "GeoChron is evaluated with running time analysis.",
    "subtitle": "8 EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1854,
    "para_id": 297,
    "paper_id": 4,
    "2d_coord": [
      -0.268989622592926,
      1.1124972105026245
    ],
    "MSU_id": 1854,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "GeoChron is evaluated with real- world case studies, an informal user study, an ablation study, parameter analysis, and running time analysis."
  },
  {
    "sentence": "Two experts perform case studies on two real-world datasets using GeoChron in person.",
    "subtitle": "8.1 Case Studies",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1855,
    "para_id": 298,
    "paper_id": 4,
    "2d_coord": [
      -0.27414441108703613,
      0.8954290151596069
    ],
    "MSU_id": 1855,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Two experts together perform case studies on two real- world datasets by using GeoChron in person. The insights gained are confirmed by another expert. Below, \"we\" refers to the two experts."
  },
  {
    "sentence": "Two real-world case studies evaluate GeoChron.",
    "subtitle": "8.1 Case Studies",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1858,
    "para_id": 299,
    "paper_id": 4,
    "2d_coord": [
      -0.2770075798034668,
      0.9928117394447327
    ],
    "MSU_id": 1858,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Two real- world case studies evaluate GeoChron as follows. First, the effectiveness and usability of GeoChron are illustrated. GeoChron enables users to view and analyze large- scale ST series intuitively, which is important in many scenarios, such as data review and real- time monitoring. Initial hypotheses regarding the evolution of spatiotemporal phenomena can also be established. Second, the pattern mining framework is justified as the evolution patterns presented in the cases have correlated trends of spatially close ST series. Third, the Storyline has a readable layout, which shows the heuristic positioning is acceptable."
  },
  {
    "sentence": "In the first case study, we analyzed how the air quality in China evolved.",
    "subtitle": "8.1.1 Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1866,
    "para_id": 300,
    "paper_id": 4,
    "2d_coord": [
      0.0032663345336914062,
      1.458617925643921
    ],
    "MSU_id": 1866,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "In the first case study, we analyzed how the air quality in China evolved. A full demonstration of this case is available in the supplemental video"
  },
  {
    "sentence": "The dataset comprises 448 ST series covering nearly all of China.",
    "subtitle": "8.1.1 Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1868,
    "para_id": 301,
    "paper_id": 4,
    "2d_coord": [
      -0.23651647567749023,
      1.2662127017974854
    ],
    "MSU_id": 1868,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Dataset. The dataset comprises 448 ST series covering nearly all of China. Each ST series records the air quality index (AQI) of a region from January 1 to July 3, 2018, at an hourly granularity. There are 448 (ST series)  $\\times 4,416$  (timestamps) records, ranging from 0 to 500."
  },
  {
    "sentence": "Each ST series records the air quality index (AQI) of a region from January 1 to July 3, 2018, at an hourly granularity.",
    "subtitle": "8.1.1 Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1869,
    "para_id": 301,
    "paper_id": 4,
    "2d_coord": [
      1.34023118019104,
      1.7789034843444824
    ],
    "MSU_id": 1869,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Dataset. The dataset comprises 448 ST series covering nearly all of China. Each ST series records the air quality index (AQI) of a region from January 1 to July 3, 2018, at an hourly granularity. There are 448 (ST series)  $\\times 4,416$  (timestamps) records, ranging from 0 to 500."
  },
  {
    "sentence": "There are 448 ST series times 4,416 timestamps records, ranging from 0 to 500.",
    "subtitle": "8.1.1 Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1870,
    "para_id": 301,
    "paper_id": 4,
    "2d_coord": [
      -0.2407829761505127,
      1.1582624912261963
    ],
    "MSU_id": 1870,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Dataset. The dataset comprises 448 ST series covering nearly all of China. Each ST series records the air quality index (AQI) of a region from January 1 to July 3, 2018, at an hourly granularity. There are 448 (ST series)  $\\times 4,416$  (timestamps) records, ranging from 0 to 500."
  },
  {
    "sentence": "Prior to the analysis, the size of the time slice was set to one day to capture daily patterns.",
    "subtitle": "8.1.1 Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1871,
    "para_id": 302,
    "paper_id": 4,
    "2d_coord": [
      -0.22893762588500977,
      1.1505522727966309
    ],
    "MSU_id": 1871,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. Prior to the analysis, we set the size of the time slice to one day to obtain daily patterns and obtained 184 time slices in total. The values of this dataset had a skewed distribution (Fig. 5B). We adjusted the shade mapping and exploited the shade channel to highlight the serious pollution periods. The final mapping is shown in Fig. 5B. There were five parameters to be tuned interactively to obtain an ideal layout with many aligned sessions and little visual clutter. First,  $th_{d}$  could be determined based on how far the wind can blow in a time slice. Second, a too- large  $th_{r}$  would cause few ST series to be considered correlated and few ST series in the patterns, and vice versa. Third, we focused on the patterns with larger sizes, so we tended to increase  $th_{s}$  more than  $th_{c}$  (See Sec. 8.3 for how  $th_{s}$  and  $th_{c}$  work). Finally, we tuned  $th_{w}$  to reduce clutter, after the layout had been determined. GeoChron can compute layout and render results within seconds (See Sec. 8.4). After several trials, we got satisfactory parameter settings:  $th_{d} = 300\\mathrm{km}$ ,  $th_{r} = 0.7$ ,  $th_{c} = 3$ ,  $th_{s} = 7$ , and  $th_{w} = 140\\mathrm{px}$ ."
  },
  {
    "sentence": "A total of 184 time slices were obtained.",
    "subtitle": "8.1.1 Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1872,
    "para_id": 302,
    "paper_id": 4,
    "2d_coord": [
      -0.24832665920257568,
      1.1662211418151855
    ],
    "MSU_id": 1872,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. Prior to the analysis, we set the size of the time slice to one day to obtain daily patterns and obtained 184 time slices in total. The values of this dataset had a skewed distribution (Fig. 5B). We adjusted the shade mapping and exploited the shade channel to highlight the serious pollution periods. The final mapping is shown in Fig. 5B. There were five parameters to be tuned interactively to obtain an ideal layout with many aligned sessions and little visual clutter. First,  $th_{d}$  could be determined based on how far the wind can blow in a time slice. Second, a too- large  $th_{r}$  would cause few ST series to be considered correlated and few ST series in the patterns, and vice versa. Third, we focused on the patterns with larger sizes, so we tended to increase  $th_{s}$  more than  $th_{c}$  (See Sec. 8.3 for how  $th_{s}$  and  $th_{c}$  work). Finally, we tuned  $th_{w}$  to reduce clutter, after the layout had been determined. GeoChron can compute layout and render results within seconds (See Sec. 8.4). After several trials, we got satisfactory parameter settings:  $th_{d} = 300\\mathrm{km}$ ,  $th_{r} = 0.7$ ,  $th_{c} = 3$ ,  $th_{s} = 7$ , and  $th_{w} = 140\\mathrm{px}$ ."
  },
  {
    "sentence": "The values of the dataset had a skewed distribution.",
    "subtitle": "8.1.1 Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1873,
    "para_id": 302,
    "paper_id": 4,
    "2d_coord": [
      1.8438904285430908,
      0.7613683938980103
    ],
    "MSU_id": 1873,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. Prior to the analysis, we set the size of the time slice to one day to obtain daily patterns and obtained 184 time slices in total. The values of this dataset had a skewed distribution (Fig. 5B). We adjusted the shade mapping and exploited the shade channel to highlight the serious pollution periods. The final mapping is shown in Fig. 5B. There were five parameters to be tuned interactively to obtain an ideal layout with many aligned sessions and little visual clutter. First,  $th_{d}$  could be determined based on how far the wind can blow in a time slice. Second, a too- large  $th_{r}$  would cause few ST series to be considered correlated and few ST series in the patterns, and vice versa. Third, we focused on the patterns with larger sizes, so we tended to increase  $th_{s}$  more than  $th_{c}$  (See Sec. 8.3 for how  $th_{s}$  and  $th_{c}$  work). Finally, we tuned  $th_{w}$  to reduce clutter, after the layout had been determined. GeoChron can compute layout and render results within seconds (See Sec. 8.4). After several trials, we got satisfactory parameter settings:  $th_{d} = 300\\mathrm{km}$ ,  $th_{r} = 0.7$ ,  $th_{c} = 3$ ,  $th_{s} = 7$ , and  $th_{w} = 140\\mathrm{px}$ ."
  },
  {
    "sentence": "In the Storyline (Fig. 5A), we first noticed several sessions with large sizes and dark strokes, denoted as Fig. 5A1-5, respectively.",
    "subtitle": "Tracking Overall Evolution Patterns.",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1886,
    "para_id": 303,
    "paper_id": 4,
    "2d_coord": [
      -0.15010443329811096,
      1.013214349746704
    ],
    "MSU_id": 1886,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Coloring. In the Storyline (Fig. 5A), we first noticed several sessions with large sizes and dark strokes, denoted as Fig. 5A1- 5, respectively. We were interested in their spatial distributions and temporal evolution, and colored them one by one. A1 and A2 are colored purple. A3, A4 and A4 are colored green, red, and black, respectively. Generally, the sessions with more ST series in common tend to receive the same color. The final result was in Fig. 5D, where most of ST series were colored."
  },
  {
    "sentence": "The layout of Fig. 6A was obtained after enforcing the alignment.",
    "subtitle": "Drilling Down into Evolution Patterns.",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1930,
    "para_id": 309,
    "paper_id": 4,
    "2d_coord": [
      -0.1822739839553833,
      1.093181848526001
    ],
    "MSU_id": 1930,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Air Quality in Yangtze River Delta. During the period of Fig. 5I, serious pollution occurred in the Yangtze River Delta and its northern region. We wondered whether there was a propagation process between them. We wanted the orange and purple ST series to be placed closer. Thus, we enforced the alignment on the session of Fig. 5I1 and obtained the layout of Fig. 6A. The sessions with more orange and purple entities were aligned with a higher priority. Fig. 6C shows the details of Fig. 6A."
  },
  {
    "sentence": "We visualized the temperature time series in China in the second case.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1941,
    "para_id": 311,
    "paper_id": 4,
    "2d_coord": [
      -0.2274267077445984,
      1.1765649318695068
    ],
    "MSU_id": 1941,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We visualized the temperature time series in China in the second case. Dataset. The dataset comprises 393 ST series covering nearly all of China. Each series records the temperature of a region from January 1 to December 29, 2020, at a daily granularity. There are 393 (ST series)  $\\times 364$  (timestamps) records, ranging from  $- 37.8^{\\circ}\\mathrm{C}$  to  $43.2^{\\circ}\\mathrm{C}$ ."
  },
  {
    "sentence": "The dataset comprises 393 spatio-temporal (ST) series covering nearly all of China.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1942,
    "para_id": 311,
    "paper_id": 4,
    "2d_coord": [
      -0.26128697395324707,
      1.2648563385009766
    ],
    "MSU_id": 1942,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We visualized the temperature time series in China in the second case. Dataset. The dataset comprises 393 ST series covering nearly all of China. Each series records the temperature of a region from January 1 to December 29, 2020, at a daily granularity. There are 393 (ST series)  $\\times 364$  (timestamps) records, ranging from  $- 37.8^{\\circ}\\mathrm{C}$  to  $43.2^{\\circ}\\mathrm{C}$ ."
  },
  {
    "sentence": "Each series records the temperature of a region from January 1 to December 29, 2020, at a daily granularity.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1943,
    "para_id": 311,
    "paper_id": 4,
    "2d_coord": [
      -0.018174022436141968,
      1.2866458892822266
    ],
    "MSU_id": 1943,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We visualized the temperature time series in China in the second case. Dataset. The dataset comprises 393 ST series covering nearly all of China. Each series records the temperature of a region from January 1 to December 29, 2020, at a daily granularity. There are 393 (ST series)  $\\times 364$  (timestamps) records, ranging from  $- 37.8^{\\circ}\\mathrm{C}$  to  $43.2^{\\circ}\\mathrm{C}$ ."
  },
  {
    "sentence": "There are 393 spatio-temporal series times 364 timestamps records.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1944,
    "para_id": 311,
    "paper_id": 4,
    "2d_coord": [
      -0.31210845708847046,
      1.1850776672363281
    ],
    "MSU_id": 1944,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We visualized the temperature time series in China in the second case. Dataset. The dataset comprises 393 ST series covering nearly all of China. Each series records the temperature of a region from January 1 to December 29, 2020, at a daily granularity. There are 393 (ST series)  $\\times 364$  (timestamps) records, ranging from  $- 37.8^{\\circ}\\mathrm{C}$  to  $43.2^{\\circ}\\mathrm{C}$ ."
  },
  {
    "sentence": "The temperature records range from -37.8°C to 43.2°C.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1945,
    "para_id": 311,
    "paper_id": 4,
    "2d_coord": [
      -0.28550559282302856,
      1.2135555744171143
    ],
    "MSU_id": 1945,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We visualized the temperature time series in China in the second case. Dataset. The dataset comprises 393 ST series covering nearly all of China. Each series records the temperature of a region from January 1 to December 29, 2020, at a daily granularity. There are 393 (ST series)  $\\times 364$  (timestamps) records, ranging from  $- 37.8^{\\circ}\\mathrm{C}$  to  $43.2^{\\circ}\\mathrm{C}$ ."
  },
  {
    "sentence": "We set the size of the time slice to 7 days.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1946,
    "para_id": 312,
    "paper_id": 4,
    "2d_coord": [
      -0.0979967713356018,
      1.1986610889434814
    ],
    "MSU_id": 1946,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. We set the size of the time slice to 7 days. In the analysis of temperature data, one of the most concerning issues is the cold wave [33]. Thus, the shade mapping was adjusted to focus on the range between  $0^{\\circ}\\mathrm{C}$  and  $20^{\\circ}\\mathrm{C}$  (Fig. 7A1). We finally obtained Fig. 7A. We kept  $th_{d}$  as  $300\\mathrm{km}$  in the first case. We increased  $th_{r}$  to 0.9 because the change in temperature is often stable and is less subject to local disturbance. Also because of this, the patterns with small sizes are fewer than in the first case study. We decreased  $th_{s}$  to 4. Other parameters were  $th_{c} = 4$  and  $th_{w} = 280\\mathrm{px}$  after multiple trials."
  },
  {
    "sentence": "The shade mapping was adjusted to focus on the range between 0°C and 20°C.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1948,
    "para_id": 312,
    "paper_id": 4,
    "2d_coord": [
      -0.23341131210327148,
      1.2333495616912842
    ],
    "MSU_id": 1948,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. We set the size of the time slice to 7 days. In the analysis of temperature data, one of the most concerning issues is the cold wave [33]. Thus, the shade mapping was adjusted to focus on the range between  $0^{\\circ}\\mathrm{C}$  and  $20^{\\circ}\\mathrm{C}$  (Fig. 7A1). We finally obtained Fig. 7A. We kept  $th_{d}$  as  $300\\mathrm{km}$  in the first case. We increased  $th_{r}$  to 0.9 because the change in temperature is often stable and is less subject to local disturbance. Also because of this, the patterns with small sizes are fewer than in the first case study. We decreased  $th_{s}$  to 4. Other parameters were  $th_{c} = 4$  and  $th_{w} = 280\\mathrm{px}$  after multiple trials."
  },
  {
    "sentence": "We kept th_d as 300 km in the first case.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1950,
    "para_id": 312,
    "paper_id": 4,
    "2d_coord": [
      -0.24974602460861206,
      1.1008806228637695
    ],
    "MSU_id": 1950,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. We set the size of the time slice to 7 days. In the analysis of temperature data, one of the most concerning issues is the cold wave [33]. Thus, the shade mapping was adjusted to focus on the range between  $0^{\\circ}\\mathrm{C}$  and  $20^{\\circ}\\mathrm{C}$  (Fig. 7A1). We finally obtained Fig. 7A. We kept  $th_{d}$  as  $300\\mathrm{km}$  in the first case. We increased  $th_{r}$  to 0.9 because the change in temperature is often stable and is less subject to local disturbance. Also because of this, the patterns with small sizes are fewer than in the first case study. We decreased  $th_{s}$  to 4. Other parameters were  $th_{c} = 4$  and  $th_{w} = 280\\mathrm{px}$  after multiple trials."
  },
  {
    "sentence": "We increased th_r to 0.9 because the change in temperature is often stable and is less subject to local disturbance.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1951,
    "para_id": 312,
    "paper_id": 4,
    "2d_coord": [
      1.8629543781280518,
      1.1140844821929932
    ],
    "MSU_id": 1951,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. We set the size of the time slice to 7 days. In the analysis of temperature data, one of the most concerning issues is the cold wave [33]. Thus, the shade mapping was adjusted to focus on the range between  $0^{\\circ}\\mathrm{C}$  and  $20^{\\circ}\\mathrm{C}$  (Fig. 7A1). We finally obtained Fig. 7A. We kept  $th_{d}$  as  $300\\mathrm{km}$  in the first case. We increased  $th_{r}$  to 0.9 because the change in temperature is often stable and is less subject to local disturbance. Also because of this, the patterns with small sizes are fewer than in the first case study. We decreased  $th_{s}$  to 4. Other parameters were  $th_{c} = 4$  and  $th_{w} = 280\\mathrm{px}$  after multiple trials."
  },
  {
    "sentence": "We decreased th_s to 4.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1953,
    "para_id": 312,
    "paper_id": 4,
    "2d_coord": [
      -0.09002679586410522,
      1.0696051120758057
    ],
    "MSU_id": 1953,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. We set the size of the time slice to 7 days. In the analysis of temperature data, one of the most concerning issues is the cold wave [33]. Thus, the shade mapping was adjusted to focus on the range between  $0^{\\circ}\\mathrm{C}$  and  $20^{\\circ}\\mathrm{C}$  (Fig. 7A1). We finally obtained Fig. 7A. We kept  $th_{d}$  as  $300\\mathrm{km}$  in the first case. We increased  $th_{r}$  to 0.9 because the change in temperature is often stable and is less subject to local disturbance. Also because of this, the patterns with small sizes are fewer than in the first case study. We decreased  $th_{s}$  to 4. Other parameters were  $th_{c} = 4$  and  $th_{w} = 280\\mathrm{px}$  after multiple trials."
  },
  {
    "sentence": "Other parameters were th_c = 4 and th_w = 280 px after multiple trials.",
    "subtitle": "8.1.2 Temperature in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1954,
    "para_id": 312,
    "paper_id": 4,
    "2d_coord": [
      0.33956393599510193,
      1.174264907836914
    ],
    "MSU_id": 1954,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Parameters. We set the size of the time slice to 7 days. In the analysis of temperature data, one of the most concerning issues is the cold wave [33]. Thus, the shade mapping was adjusted to focus on the range between  $0^{\\circ}\\mathrm{C}$  and  $20^{\\circ}\\mathrm{C}$  (Fig. 7A1). We finally obtained Fig. 7A. We kept  $th_{d}$  as  $300\\mathrm{km}$  in the first case. We increased  $th_{r}$  to 0.9 because the change in temperature is often stable and is less subject to local disturbance. Also because of this, the patterns with small sizes are fewer than in the first case study. We decreased  $th_{s}$  to 4. Other parameters were  $th_{c} = 4$  and  $th_{w} = 280\\mathrm{px}$  after multiple trials."
  },
  {
    "sentence": "We perform an informal user study to evaluate the intuitiveness of the proposed visualizations.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1974,
    "para_id": 316,
    "paper_id": 4,
    "2d_coord": [
      0.043462395668029785,
      1.1143583059310913
    ],
    "MSU_id": 1974,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We perform an informal user study to evaluate the intuitiveness and legibility of the proposed visualizations."
  },
  {
    "sentence": "We perform an informal user study to evaluate the legibility of the proposed visualizations.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1975,
    "para_id": 316,
    "paper_id": 4,
    "2d_coord": [
      -0.17272275686264038,
      1.0971683263778687
    ],
    "MSU_id": 1975,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We perform an informal user study to evaluate the intuitiveness and legibility of the proposed visualizations."
  },
  {
    "sentence": "We recruited six participants (P1-6) from the same school.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1976,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      -0.18327534198760986,
      1.0711908340454102
    ],
    "MSU_id": 1976,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P1 knows both Storyline and spatiotemporal data.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1977,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      -0.24838054180145264,
      1.127104640007019
    ],
    "MSU_id": 1977,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P2 and P3 know Storyline but not spatiotemporal data.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1978,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      -0.21584200859069824,
      1.1646153926849365
    ],
    "MSU_id": 1978,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P4 and P5 know spatiotemporal data but not Storyline.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1979,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      -0.2353065013885498,
      1.229447364807129
    ],
    "MSU_id": 1979,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P6 knows nothing about both Storyline and spatiotemporal data.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1980,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      -0.16736137866973877,
      1.1050870418548584
    ],
    "MSU_id": 1980,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P1-4 are graduates majoring in computer science.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1981,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      0.2884931266307831,
      0.9991182684898376
    ],
    "MSU_id": 1981,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P5 is an undergraduate majoring in geographic information science.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1982,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      0.8758384585380554,
      1.8773467540740967
    ],
    "MSU_id": 1982,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P6 is an undergraduate majoring in agricultural engineering.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1983,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      1.8496098518371582,
      1.222851037979126
    ],
    "MSU_id": 1983,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "P5 and P6 have no visualization expertise.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1984,
    "para_id": 317,
    "paper_id": 4,
    "2d_coord": [
      -0.19497734308242798,
      1.0806097984313965
    ],
    "MSU_id": 1984,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Participants. We recruited six participants (P1- 6) from the same school. P1 knows both Storyline and spatiotemporal data. P2 and P3 know Storyline but not spatiotemporal data. P4 and P5 know spatiotemporal data but not Storyline. P6 knows nothing about both. P1- 4 are graduates majoring in computer science. P5 and P6 are undergraduates majoring in geographic information science and agricultural engineering, respectively, and they have no visualization expertise."
  },
  {
    "sentence": "We then showed each participant the GeoChron of the first case.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1986,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      -0.21192950010299683,
      1.0044670104980469
    ],
    "MSU_id": 1986,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1987,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      -0.22463905811309814,
      1.000887393951416
    ],
    "MSU_id": 1987,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "The participant used GeoChron via desktop in person to finish three tasks.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1988,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      -0.3220289349555969,
      1.1197885274887085
    ],
    "MSU_id": 1988,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "Task 1 was 'Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.'",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1989,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      0.5759415626525879,
      1.665029764175415
    ],
    "MSU_id": 1989,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "Task 2 was 'Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.'",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1990,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      -0.12414824962615967,
      1.36135995388031
    ],
    "MSU_id": 1990,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "Task 3 was 'Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.'",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1991,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      -0.18099427223205566,
      1.2083730697631836
    ],
    "MSU_id": 1991,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "For task 3, participants were only required to describe the objective observations with text.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1992,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      -0.12466961145401001,
      1.1004321575164795
    ],
    "MSU_id": 1992,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "These open-ended tasks required participants to imitate the process of experts seeking information and analyzing ST series.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1993,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      0.8166477084159851,
      1.8842706680297852
    ],
    "MSU_id": 1993,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "Finally, each participant filled out the ICE-T questionnaire to rate GeoChron from Insight, Confidence, Essence, and Satisfaction.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1994,
    "para_id": 318,
    "paper_id": 4,
    "2d_coord": [
      -0.25331956148147583,
      1.1343026161193848
    ],
    "MSU_id": 1994,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Procedure. We first introduced GeoChron's visual encodings and interaction. We then showed each participant the GeoChron of the first case. In particular, GeoChron was colored as Fig. 5D and then was subjected to enforced alignment according to Fig. 511. The participant used GeoChron via desktop in person to finish three tasks: 1) \"Locating the period when the air quality in the red, green, and purple locations are generally correlated with each other.\" 2) \"Locating the period when the air quality in a large area of the Yangtze River Delta Plain deteriorates significantly.\" 3) \"Following task 2, describing how the air quality deteriorates (spatiotemporal trends in the first three days) by days using EvoLens.\" For task 3, they were only required to describe the objective observations with text. These open- ended tasks required participants to imitate the process of experts seeking information and analyzing ST series. Finally, each one filled out the ICE- T questionnaire [57] to rate GeoChron from Insight, Confidence, Essence, and"
  },
  {
    "sentence": "Time perspectives were measured using a 7-point Likert scale.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1996,
    "para_id": 320,
    "paper_id": 4,
    "2d_coord": [
      0.19102820754051208,
      1.4453649520874023
    ],
    "MSU_id": 1996,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Time perspectives (7- point Likert scale). We used think- aloud protocol to collect their feedback. The procedure lasted around 40 minutes."
  },
  {
    "sentence": "We used a think-aloud protocol to collect feedback.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 1997,
    "para_id": 320,
    "paper_id": 4,
    "2d_coord": [
      -0.1786644458770752,
      1.1759411096572876
    ],
    "MSU_id": 1997,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Time perspectives (7- point Likert scale). We used think- aloud protocol to collect their feedback. The procedure lasted around 40 minutes."
  },
  {
    "sentence": "The procedure lasted around 40 minutes.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 1998,
    "para_id": 320,
    "paper_id": 4,
    "2d_coord": [
      -0.23446154594421387,
      1.0814892053604126
    ],
    "MSU_id": 1998,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Time perspectives (7- point Likert scale). We used think- aloud protocol to collect their feedback. The procedure lasted around 40 minutes."
  },
  {
    "sentence": "Their confusion was dispelled during the study after we clarified the encoding of the vertical position again.",
    "subtitle": "8.2 Informal User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2012,
    "para_id": 322,
    "paper_id": 4,
    "2d_coord": [
      0.5025458335876465,
      1.3268485069274902
    ],
    "MSU_id": 2012,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Fig. 8 summarizes the ICE- T scores.  $95\\%$  C.I. are  $6.41\\pm 0.26$  (I),  $5.45\\pm 0.60$  (C),  $6.58\\pm 0.22$  (E), and  $6.27\\pm 0.44$  (T). All participants agreed that GeoChron can provide insights, facilitate exploration, and reveal the essence of data, as the scores of Insight, Essence, and Time are about 6. The Confidence scores are relatively low, which is reasonable. We assume the dataset is cleaned and thus do not design visualizations for data quality. P2 and P6 also commented, \"GeoChron is somehow misleading if ST series that are close in space are not placed together in the Storyline.\" Their confusion was dispelled during the study after we clarified the encoding of the vertical position again."
  },
  {
    "sentence": "We figure out how these strategies affect the layout based on the dataset in Sec. 8.1.1.",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2028,
    "para_id": 325,
    "paper_id": 4,
    "2d_coord": [
      -0.18321830034255981,
      1.277275800704956
    ],
    "MSU_id": 2028,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We refine the traditional Storyline via 1) curve hiding, 2) loose alignment, and 3) session filtering. In addition, we claim the 4) sliding window strategy could improve visual quality in Sec. 4. We figure out how they affect the layout based on the dataset in Sec. 8.1.1."
  },
  {
    "sentence": "We test the curve hiding and sliding windows via ablation studies following the first case.",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2029,
    "para_id": 326,
    "paper_id": 4,
    "2d_coord": [
      -0.22366321086883545,
      1.0406248569488525
    ],
    "MSU_id": 2029,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We test the curve hiding and sliding windows via ablation studies following the first case. First, we set  $th_w = +Infinity$  to disable the curve hiding. Fig. 9A shows a snapshot of the result. The nearly vertical curves bounce up and down on the screen, resulting in visual distractions. Moreover, some aligned sessions are meant to be visually continuous, but this continuity is broken by these curves (e.g., Fig. 9B). Smaller the  $th_w$ , the less clutter. Second, we directly use the correlation coefficients in time slices rather than sliding windows and generate the layout in Fig. 9C with the same parameters in the first case ( $th_s = 7$  and  $th_c = 3$ ). We remove the gradient shade and focus on the layout. Compared with the time window- based results in Fig. 5D, the correlation relationship between ST series is more dynamic. In particular, the dashed ellipses in Fig. 9D and E highlight the unexpected deviation of curves. Entities part suddenly and come back together again, which may be due to the slightly offset time slices, subtle pollution events, or errors. Such deviations lead to visual clusters and prevent users from locating prominent visual patterns. It can be concluded that the sliding window does improve the readability of representations."
  },
  {
    "sentence": "First, we set $th_w = +Infinity$ to disable the curve hiding.",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2030,
    "para_id": 326,
    "paper_id": 4,
    "2d_coord": [
      -0.27132922410964966,
      1.079483985900879
    ],
    "MSU_id": 2030,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We test the curve hiding and sliding windows via ablation studies following the first case. First, we set  $th_w = +Infinity$  to disable the curve hiding. Fig. 9A shows a snapshot of the result. The nearly vertical curves bounce up and down on the screen, resulting in visual distractions. Moreover, some aligned sessions are meant to be visually continuous, but this continuity is broken by these curves (e.g., Fig. 9B). Smaller the  $th_w$ , the less clutter. Second, we directly use the correlation coefficients in time slices rather than sliding windows and generate the layout in Fig. 9C with the same parameters in the first case ( $th_s = 7$  and  $th_c = 3$ ). We remove the gradient shade and focus on the layout. Compared with the time window- based results in Fig. 5D, the correlation relationship between ST series is more dynamic. In particular, the dashed ellipses in Fig. 9D and E highlight the unexpected deviation of curves. Entities part suddenly and come back together again, which may be due to the slightly offset time slices, subtle pollution events, or errors. Such deviations lead to visual clusters and prevent users from locating prominent visual patterns. It can be concluded that the sliding window does improve the readability of representations."
  },
  {
    "sentence": "Second, we directly use the correlation coefficients in time slices rather than sliding windows.",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2035,
    "para_id": 326,
    "paper_id": 4,
    "2d_coord": [
      -0.19778305292129517,
      1.0857248306274414
    ],
    "MSU_id": 2035,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We test the curve hiding and sliding windows via ablation studies following the first case. First, we set  $th_w = +Infinity$  to disable the curve hiding. Fig. 9A shows a snapshot of the result. The nearly vertical curves bounce up and down on the screen, resulting in visual distractions. Moreover, some aligned sessions are meant to be visually continuous, but this continuity is broken by these curves (e.g., Fig. 9B). Smaller the  $th_w$ , the less clutter. Second, we directly use the correlation coefficients in time slices rather than sliding windows and generate the layout in Fig. 9C with the same parameters in the first case ( $th_s = 7$  and  $th_c = 3$ ). We remove the gradient shade and focus on the layout. Compared with the time window- based results in Fig. 5D, the correlation relationship between ST series is more dynamic. In particular, the dashed ellipses in Fig. 9D and E highlight the unexpected deviation of curves. Entities part suddenly and come back together again, which may be due to the slightly offset time slices, subtle pollution events, or errors. Such deviations lead to visual clusters and prevent users from locating prominent visual patterns. It can be concluded that the sliding window does improve the readability of representations."
  },
  {
    "sentence": "We generate the layout in Fig. 9C with the same parameters in the first case ($th_s = 7$ and $th_c = 3$).",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2036,
    "para_id": 326,
    "paper_id": 4,
    "2d_coord": [
      -0.15691852569580078,
      1.057779312133789
    ],
    "MSU_id": 2036,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We test the curve hiding and sliding windows via ablation studies following the first case. First, we set  $th_w = +Infinity$  to disable the curve hiding. Fig. 9A shows a snapshot of the result. The nearly vertical curves bounce up and down on the screen, resulting in visual distractions. Moreover, some aligned sessions are meant to be visually continuous, but this continuity is broken by these curves (e.g., Fig. 9B). Smaller the  $th_w$ , the less clutter. Second, we directly use the correlation coefficients in time slices rather than sliding windows and generate the layout in Fig. 9C with the same parameters in the first case ( $th_s = 7$  and  $th_c = 3$ ). We remove the gradient shade and focus on the layout. Compared with the time window- based results in Fig. 5D, the correlation relationship between ST series is more dynamic. In particular, the dashed ellipses in Fig. 9D and E highlight the unexpected deviation of curves. Entities part suddenly and come back together again, which may be due to the slightly offset time slices, subtle pollution events, or errors. Such deviations lead to visual clusters and prevent users from locating prominent visual patterns. It can be concluded that the sliding window does improve the readability of representations."
  },
  {
    "sentence": "We remove the gradient shade and focus on the layout.",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2037,
    "para_id": 326,
    "paper_id": 4,
    "2d_coord": [
      -0.16334837675094604,
      1.0308263301849365
    ],
    "MSU_id": 2037,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "We test the curve hiding and sliding windows via ablation studies following the first case. First, we set  $th_w = +Infinity$  to disable the curve hiding. Fig. 9A shows a snapshot of the result. The nearly vertical curves bounce up and down on the screen, resulting in visual distractions. Moreover, some aligned sessions are meant to be visually continuous, but this continuity is broken by these curves (e.g., Fig. 9B). Smaller the  $th_w$ , the less clutter. Second, we directly use the correlation coefficients in time slices rather than sliding windows and generate the layout in Fig. 9C with the same parameters in the first case ( $th_s = 7$  and  $th_c = 3$ ). We remove the gradient shade and focus on the layout. Compared with the time window- based results in Fig. 5D, the correlation relationship between ST series is more dynamic. In particular, the dashed ellipses in Fig. 9D and E highlight the unexpected deviation of curves. Entities part suddenly and come back together again, which may be due to the slightly offset time slices, subtle pollution events, or errors. Such deviations lead to visual clusters and prevent users from locating prominent visual patterns. It can be concluded that the sliding window does improve the readability of representations."
  },
  {
    "sentence": "Fig. 9 illustrates the ablation of curve hiding.",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2052,
    "para_id": 328,
    "paper_id": 4,
    "2d_coord": [
      -0.18743371963500977,
      1.0676851272583008
    ],
    "MSU_id": 2052,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Fig. 9: Ablating (A,B) curve hiding and (C,D,E) sliding windows."
  },
  {
    "sentence": "Fig. 9 illustrates the ablation of sliding windows.",
    "subtitle": "8.3 Ablation Study and Parameter Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2053,
    "para_id": 328,
    "paper_id": 4,
    "2d_coord": [
      -0.2049640417098999,
      1.0933771133422852
    ],
    "MSU_id": 2053,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Fig. 9: Ablating (A,B) curve hiding and (C,D,E) sliding windows."
  },
  {
    "sentence": "We report the running times of four backend modules to clarify the fluency of user interaction when refining the layout.",
    "subtitle": "8.4 Running Time Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2055,
    "para_id": 329,
    "paper_id": 4,
    "2d_coord": [
      -0.18574851751327515,
      0.9966716766357422
    ],
    "MSU_id": 2055,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Recall that users may need to refine the layout, e.g., for less clutter, fewer small patterns, or more aligned patterns. We report the running times of four backend modules (evolution pattern detection, ordering aligning, and positioning) to clarify the fluency of user interaction when refining the layout. The experiments were performed on a desktop running Ubuntu 20.04 with Intel Core i7 3.70GHz CPU, and 16 GB RAM. The detection and aligning modules are accelerated via Multiprocessing with 12 pools. Recall that determining correlation does not require high efficiency since the results are cached in advance in the backend."
  },
  {
    "sentence": "The experiments were performed on a desktop running Ubuntu 20.04 with Intel Core i7 3.70GHz CPU, and 16 GB RAM.",
    "subtitle": "8.4 Running Time Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2057,
    "para_id": 329,
    "paper_id": 4,
    "2d_coord": [
      1.2160487174987793,
      -0.08342665433883667
    ],
    "MSU_id": 2057,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Recall that users may need to refine the layout, e.g., for less clutter, fewer small patterns, or more aligned patterns. We report the running times of four backend modules (evolution pattern detection, ordering aligning, and positioning) to clarify the fluency of user interaction when refining the layout. The experiments were performed on a desktop running Ubuntu 20.04 with Intel Core i7 3.70GHz CPU, and 16 GB RAM. The detection and aligning modules are accelerated via Multiprocessing with 12 pools. Recall that determining correlation does not require high efficiency since the results are cached in advance in the backend."
  },
  {
    "sentence": "The running times under different $th_d$ and $th_r$ are reported in Fig. 10H.",
    "subtitle": "8.4 Running Time Analysis",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2061,
    "para_id": 330,
    "paper_id": 4,
    "2d_coord": [
      -0.28066903352737427,
      1.1398316621780396
    ],
    "MSU_id": 2061,
    "paper_info": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "paragraph_info": "Detection and Ordering. Users interact with these two modules when adjusting  $th_d$  and  $th_r$ . We report the running times under different  $th_d$  and  $th_r$  (Fig. 10H). Fig. 10H (left) and (right) are the run times of pattern detection and ordering, respectively. With the increasing of  $th_d$  and decreasing of  $th_r$ , these two modules consume more time because more pairs of ST series are considered correlated. The total running time in the loosest case in Fig. 10H is 12 seconds."
  },
  {
    "sentence": "VolumeSTCube is evaluated through a computational experiment, a real-world case study with one expert, and a controlled user study with twelve non-experts.",
    "subtitle": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2139,
    "para_id": 342,
    "paper_id": 3,
    "2d_coord": [
      1.099666714668274,
      2.017822504043579
    ],
    "MSU_id": 2139,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Abstract- Spatial time series visualization offers scientific research pathways and analytical decision- making tools across various spatiotemporal domains. Despite many advanced methodologies, the seamless integration of temporal and spatial information remains a challenge. The space- time cube (STC) stands out as a promising approach for the synergistic presentation of spatial and temporal information, with successful applications across various spatiotemporal datasets. However, the STC is plagued by well- known issues such as visual occlusion and depth ambiguity, which are further exacerbated when dealing with large- scale spatial time series data. In this study, we introduce a novel technical framework termed VolumeSTCube, designed for continuous spatiotemporal phenomena. It first leverages the concept of the STC to transform discretely distributed spatial time series data into continuously volumetric data. Subsequently, volume rendering and surface rendering techniques are employed to visualize the transformed volumetric data. Volume rendering is utilized to mitigate visual occlusion, while surface rendering provides pattern details by enhanced lighting information. Lastly, we design interactions to facilitate the exploration and analysis from temporal, spatial, and spatiotemporal perspectives. VolumeSTCube is evaluated through a computational experiment, a real- world case study with one expert, and a controlled user study with twelve non- experts, compared against a baseline from prior work, showing its superiority and effectiveness in large- scale spatial time series analysis."
  },
  {
    "sentence": "VolumeSTCube is compared against a baseline from prior work.",
    "subtitle": "Volume-Based Space-Time Cube for Large-Scale Continuous Spatial Time Series",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2140,
    "para_id": 342,
    "paper_id": 3,
    "2d_coord": [
      1.1995511054992676,
      2.0001022815704346
    ],
    "MSU_id": 2140,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Abstract- Spatial time series visualization offers scientific research pathways and analytical decision- making tools across various spatiotemporal domains. Despite many advanced methodologies, the seamless integration of temporal and spatial information remains a challenge. The space- time cube (STC) stands out as a promising approach for the synergistic presentation of spatial and temporal information, with successful applications across various spatiotemporal datasets. However, the STC is plagued by well- known issues such as visual occlusion and depth ambiguity, which are further exacerbated when dealing with large- scale spatial time series data. In this study, we introduce a novel technical framework termed VolumeSTCube, designed for continuous spatiotemporal phenomena. It first leverages the concept of the STC to transform discretely distributed spatial time series data into continuously volumetric data. Subsequently, volume rendering and surface rendering techniques are employed to visualize the transformed volumetric data. Volume rendering is utilized to mitigate visual occlusion, while surface rendering provides pattern details by enhanced lighting information. Lastly, we design interactions to facilitate the exploration and analysis from temporal, spatial, and spatiotemporal perspectives. VolumeSTCube is evaluated through a computational experiment, a real- world case study with one expert, and a controlled user study with twelve non- experts, compared against a baseline from prior work, showing its superiority and effectiveness in large- scale spatial time series analysis."
  },
  {
    "sentence": "VolumeSTCube is evaluated as follows.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2194,
    "para_id": 351,
    "paper_id": 3,
    "2d_coord": [
      1.1420601606369019,
      2.0002620220184326
    ],
    "MSU_id": 2194,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we conducted a case study on a real- world dataset with VolumeSTCube, performed by one expert, to demonstrate its intuitiveness, usefulness, and effectiveness fully. Second, we performed a task- based controlled user study with twelve non- expert participants to compare VolumeSTCube with the prior STC- based ST series visualization [14]. VolumeSTCube achieves better performance and receives positive user feedback regarding the visualization and interaction."
  },
  {
    "sentence": "We conducted a case study on a real-world dataset with VolumeSTCube.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2195,
    "para_id": 351,
    "paper_id": 3,
    "2d_coord": [
      1.125212550163269,
      2.005714178085327
    ],
    "MSU_id": 2195,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we conducted a case study on a real- world dataset with VolumeSTCube, performed by one expert, to demonstrate its intuitiveness, usefulness, and effectiveness fully. Second, we performed a task- based controlled user study with twelve non- expert participants to compare VolumeSTCube with the prior STC- based ST series visualization [14]. VolumeSTCube achieves better performance and receives positive user feedback regarding the visualization and interaction."
  },
  {
    "sentence": "The case study was performed by one expert.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2196,
    "para_id": 351,
    "paper_id": 3,
    "2d_coord": [
      1.4835865497589111,
      1.50455641746521
    ],
    "MSU_id": 2196,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we conducted a case study on a real- world dataset with VolumeSTCube, performed by one expert, to demonstrate its intuitiveness, usefulness, and effectiveness fully. Second, we performed a task- based controlled user study with twelve non- expert participants to compare VolumeSTCube with the prior STC- based ST series visualization [14]. VolumeSTCube achieves better performance and receives positive user feedback regarding the visualization and interaction."
  },
  {
    "sentence": "The case study aimed to demonstrate VolumeSTCube's intuitiveness, usefulness, and effectiveness.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2197,
    "para_id": 351,
    "paper_id": 3,
    "2d_coord": [
      1.12311589717865,
      2.022012710571289
    ],
    "MSU_id": 2197,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we conducted a case study on a real- world dataset with VolumeSTCube, performed by one expert, to demonstrate its intuitiveness, usefulness, and effectiveness fully. Second, we performed a task- based controlled user study with twelve non- expert participants to compare VolumeSTCube with the prior STC- based ST series visualization [14]. VolumeSTCube achieves better performance and receives positive user feedback regarding the visualization and interaction."
  },
  {
    "sentence": "We performed a task-based controlled user study with twelve non-expert participants.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2198,
    "para_id": 351,
    "paper_id": 3,
    "2d_coord": [
      1.0787420272827148,
      1.965561866760254
    ],
    "MSU_id": 2198,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we conducted a case study on a real- world dataset with VolumeSTCube, performed by one expert, to demonstrate its intuitiveness, usefulness, and effectiveness fully. Second, we performed a task- based controlled user study with twelve non- expert participants to compare VolumeSTCube with the prior STC- based ST series visualization [14]. VolumeSTCube achieves better performance and receives positive user feedback regarding the visualization and interaction."
  },
  {
    "sentence": "The user study compared VolumeSTCube with the prior STC-based ST series visualization.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2199,
    "para_id": 351,
    "paper_id": 3,
    "2d_coord": [
      1.0589256286621094,
      1.8666880130767822
    ],
    "MSU_id": 2199,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we conducted a case study on a real- world dataset with VolumeSTCube, performed by one expert, to demonstrate its intuitiveness, usefulness, and effectiveness fully. Second, we performed a task- based controlled user study with twelve non- expert participants to compare VolumeSTCube with the prior STC- based ST series visualization [14]. VolumeSTCube achieves better performance and receives positive user feedback regarding the visualization and interaction."
  },
  {
    "sentence": "Comprehensive evaluations for VolumeSTCube include a computational experiment.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2207,
    "para_id": 352,
    "paper_id": 3,
    "2d_coord": [
      1.1202900409698486,
      1.9669764041900635
    ],
    "MSU_id": 2207,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A visualization technique named VolumeSTCube that incorporates a data transformation framework, volume visualization techniques, and tailored spatiotemporal interactions to visualize large- scale ST series in a spacetime cube effectively. Comprehensive evaluations for VolumeSTCube with a computational experiment, a real- world case study, and a task- based controlled user study."
  },
  {
    "sentence": "Comprehensive evaluations for VolumeSTCube include a real-world case study.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2208,
    "para_id": 352,
    "paper_id": 3,
    "2d_coord": [
      1.1794757843017578,
      1.9691417217254639
    ],
    "MSU_id": 2208,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A visualization technique named VolumeSTCube that incorporates a data transformation framework, volume visualization techniques, and tailored spatiotemporal interactions to visualize large- scale ST series in a spacetime cube effectively. Comprehensive evaluations for VolumeSTCube with a computational experiment, a real- world case study, and a task- based controlled user study."
  },
  {
    "sentence": "Comprehensive evaluations for VolumeSTCube include a task-based controlled user study.",
    "subtitle": "I. INTRODUCTION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2209,
    "para_id": 352,
    "paper_id": 3,
    "2d_coord": [
      1.0051918029785156,
      1.9145660400390625
    ],
    "MSU_id": 2209,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A visualization technique named VolumeSTCube that incorporates a data transformation framework, volume visualization techniques, and tailored spatiotemporal interactions to visualize large- scale ST series in a spacetime cube effectively. Comprehensive evaluations for VolumeSTCube with a computational experiment, a real- world case study, and a task- based controlled user study."
  },
  {
    "sentence": "This section describes the data formats used in this study.",
    "subtitle": "III. BACKGROUND",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2301,
    "para_id": 372,
    "paper_id": 3,
    "2d_coord": [
      1.1110057830810547,
      0.5608910322189331
    ],
    "MSU_id": 2301,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "This section describes the data formats used in this study, and introduces the research problem with a potential solution."
  },
  {
    "sentence": "In the space-time volume in Figure 2B, there is a $3 \times 3$ grid in the geographic space and 3 timestamps, resulting in $3 \times 3 \times 3$ samples or voxels in total.",
    "subtitle": "A.Data Description",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2310,
    "para_id": 373,
    "paper_id": 3,
    "2d_coord": [
      1.216233253479004,
      1.9105560779571533
    ],
    "MSU_id": 2310,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A space- time volume  $\\nu$  is a 3D scalar field or volumetric data. It comprises  $m\\times n\\times T$  samples  $(s,t,v)$  ,where  $s = (x,y)$  is a 2D spatial index,  $t$  is a 1D temporal index, and  $v$  is a real value.  $1\\leq x\\leq m$ $1\\leq y\\leq n$  and  $1\\leq t\\leq T$  .Each sample  $(s,t,v)$  represents the value  $v$  at a 3D location  $(x,y,t)$  ,i.e.,  $v$  is observed at the timestamp  $t$  in the geographic position  $s =$$(x,y)$ . In practical situations, each 3D location is represented by a small hexahedral cube called a voxel. In particular, we use  $\\nu (x_0,y_0, - )$  to denote the ST series at the geographic position  $(x_0,y_0)$  extracted from the space- time volume  $\\nu$ . Taking the space- time volume in Figure 2B as an example, there is a  $3\\times 3$  grid (i.e.,  $m = n = 3$ ) in the geographic space and 3 timestamps (i.e.,  $T = 3$ ), resulting  $3\\times 3\\times 3$  samples or voxels in total. The voxels colored pink denote  $\\nu^{(1,3, - )}$ ."
  },
  {
    "sentence": "The voxels colored pink denote $\nu^{(1,3, - )}$.",
    "subtitle": "A.Data Description",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2311,
    "para_id": 373,
    "paper_id": 3,
    "2d_coord": [
      1.392935872077942,
      1.8259360790252686
    ],
    "MSU_id": 2311,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A space- time volume  $\\nu$  is a 3D scalar field or volumetric data. It comprises  $m\\times n\\times T$  samples  $(s,t,v)$  ,where  $s = (x,y)$  is a 2D spatial index,  $t$  is a 1D temporal index, and  $v$  is a real value.  $1\\leq x\\leq m$ $1\\leq y\\leq n$  and  $1\\leq t\\leq T$  .Each sample  $(s,t,v)$  represents the value  $v$  at a 3D location  $(x,y,t)$  ,i.e.,  $v$  is observed at the timestamp  $t$  in the geographic position  $s =$$(x,y)$ . In practical situations, each 3D location is represented by a small hexahedral cube called a voxel. In particular, we use  $\\nu (x_0,y_0, - )$  to denote the ST series at the geographic position  $(x_0,y_0)$  extracted from the space- time volume  $\\nu$ . Taking the space- time volume in Figure 2B as an example, there is a  $3\\times 3$  grid (i.e.,  $m = n = 3$ ) in the geographic space and 3 timestamps (i.e.,  $T = 3$ ), resulting  $3\\times 3\\times 3$  samples or voxels in total. The voxels colored pink denote  $\\nu^{(1,3, - )}$ ."
  },
  {
    "sentence": "Our implementation of Thakur and Hanson's method is later used as a baseline in the comparative user study.",
    "subtitle": "A.Data Description",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2313,
    "para_id": 374,
    "paper_id": 3,
    "2d_coord": [
      1.1159136295318604,
      1.9635646343231201
    ],
    "MSU_id": 2313,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Fig. 1. Our implementation of Thakur and Hanson's method [14], later used as a baseline in the comparative user study."
  },
  {
    "sentence": "The geographic space in Figure 2A is divided into a $3\\times 3$ grid with 9 cells.",
    "subtitle": "B. Transformation",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2352,
    "para_id": 382,
    "paper_id": 3,
    "2d_coord": [
      1.1204997301101685,
      1.852675437927246
    ],
    "MSU_id": 2352,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "1) Interpolation: First, we divide the geographic space into an  $n\\times m$  grid, resulting in  $n\\times m$  cells denoted as  $C = {c_{1,1},c_{1,2},\\ldots ,c_{n,m}}$ . Each cell is of uniform size and sufficiently small. For example, the geographic space in Figure 2A is divided into a  $3\\times 3$  grid with 9 cells. Second, we divide the ST series with  $T$  timestamps by their timestamps into  $T$  slices. For the  $t$ -th slice of the  $t$  timestamp,  $t\\leq T$ , there are observed data samples  $Z_{t} = {z_{1,t},z_{2,t},\\ldots ,z_{ST}}$ , with  $z_{i,t} = v_{i,t}$  representing the value of the  $i$ -th series at timestamp  $t$ . Afterwards, interpolation techniques, like Kriging and Inverse Distance Weighted, can be employed to predict  $\\hat{z}{c{x,y}}$  for each grid  $c_{x,y}\\in C$  based on observed data samples  $Z_{t}$ , generating a sample  $(s = (x,y),t,v = \\hat{z}{c{x,y}})$  in the spacetime volume. For each slice of each timestamp, we obtain a 2D scalar field with  $n\\times m$  cells. After performing the above operations for every slice, we stack the 2D scalar fields to form a completed space-time volume.\n2) Smoothing: Each generated 2D scalar field is smooth over the geographic space because of the spatial autocorrelation principle. However, due to many reasons, e.g., poor sensor quality, unstable data transmission, and the inherent"
  },
  {
    "sentence": "Assuming we are visualizing the ST series of air pollution concentration, below are some examples.",
    "subtitle": "C. Visualization",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2395,
    "para_id": 390,
    "paper_id": 3,
    "2d_coord": [
      0.7672446966171265,
      1.9138762950897217
    ],
    "MSU_id": 2395,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "In this way, inherent spatiotemporal patterns in the ST series, such as temporal trends, spatiotemporal propagation [56], and spatiotemporal evolution [57], can be easily analyzed based on the cluster of voxels with large values. Assuming we are visualizing the ST series of air pollution concentration, below are some examples: If a voxel cluster extends significantly in the vertical direction and over the x- y plane, it indicates that the duration of poor air quality persists across a vast spatial area (Figure 3A①). If in a vertical cylindrical area in 3D cube space are voxel clusters with equal spacing, the air pollution exhibits periodicity at that location (Figure 3A②). If the voxel cluster exhibits shifts in 3D cube space, it indicates a process of air pollution propagation (Figure 3B and C)."
  },
  {
    "sentence": "The development environment is a desktop running Windows 10.",
    "subtitle": "E. Implementation",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2485,
    "para_id": 409,
    "paper_id": 3,
    "2d_coord": [
      0.9674156904220581,
      0.3499026298522949
    ],
    "MSU_id": 2485,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is a desktop application. We choose Unity as our development platform over Three.js based on WebGL. This decision considers that running in a browser may not meet the memory resource needs for volume rendering due to different browsers' memory management restrictions. The development environment is a desktop running Windows 10 with an Intel Core i7- 13700K 3.40GHz CPU, NVIDIA GeForce RTX 3070 8GB GPU, and 32 GB of RAM."
  },
  {
    "sentence": "The development environment includes an Intel Core i7-13700K 3.40GHz CPU.",
    "subtitle": "E. Implementation",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2486,
    "para_id": 409,
    "paper_id": 3,
    "2d_coord": [
      1.3930203914642334,
      0.8827844858169556
    ],
    "MSU_id": 2486,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is a desktop application. We choose Unity as our development platform over Three.js based on WebGL. This decision considers that running in a browser may not meet the memory resource needs for volume rendering due to different browsers' memory management restrictions. The development environment is a desktop running Windows 10 with an Intel Core i7- 13700K 3.40GHz CPU, NVIDIA GeForce RTX 3070 8GB GPU, and 32 GB of RAM."
  },
  {
    "sentence": "The development environment includes an NVIDIA GeForce RTX 3070 8GB GPU.",
    "subtitle": "E. Implementation",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2487,
    "para_id": 409,
    "paper_id": 3,
    "2d_coord": [
      1.6480381488800049,
      1.1116877794265747
    ],
    "MSU_id": 2487,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is a desktop application. We choose Unity as our development platform over Three.js based on WebGL. This decision considers that running in a browser may not meet the memory resource needs for volume rendering due to different browsers' memory management restrictions. The development environment is a desktop running Windows 10 with an Intel Core i7- 13700K 3.40GHz CPU, NVIDIA GeForce RTX 3070 8GB GPU, and 32 GB of RAM."
  },
  {
    "sentence": "The development environment includes 32 GB of RAM.",
    "subtitle": "E. Implementation",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2488,
    "para_id": 409,
    "paper_id": 3,
    "2d_coord": [
      1.2121466398239136,
      0.22523121535778046
    ],
    "MSU_id": 2488,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is a desktop application. We choose Unity as our development platform over Three.js based on WebGL. This decision considers that running in a browser may not meet the memory resource needs for volume rendering due to different browsers' memory management restrictions. The development environment is a desktop running Windows 10 with an Intel Core i7- 13700K 3.40GHz CPU, NVIDIA GeForce RTX 3070 8GB GPU, and 32 GB of RAM."
  },
  {
    "sentence": "VolumeSTCube is evaluated through a real-world case study.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2489,
    "para_id": 410,
    "paper_id": 3,
    "2d_coord": [
      1.1493220329284668,
      2.0054733753204346
    ],
    "MSU_id": 2489,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we invite a professional analyst (PA) with five years of experience in analyzing nationwide air quality data to perform a real- world case study using VolumeSTCube. Second, we conduct a controlled user study that compares VolumeSTCube with Thakur and Hanson's method [14] to further understand its advantages and disadvantages."
  },
  {
    "sentence": "A professional analyst with five years of experience in analyzing nationwide air quality data performs the case study using VolumeSTCube.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2490,
    "para_id": 410,
    "paper_id": 3,
    "2d_coord": [
      1.0988081693649292,
      2.033538341522217
    ],
    "MSU_id": 2490,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we invite a professional analyst (PA) with five years of experience in analyzing nationwide air quality data to perform a real- world case study using VolumeSTCube. Second, we conduct a controlled user study that compares VolumeSTCube with Thakur and Hanson's method [14] to further understand its advantages and disadvantages."
  },
  {
    "sentence": "A controlled user study is conducted to compare VolumeSTCube with Thakur and Hanson's method.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2491,
    "para_id": 410,
    "paper_id": 3,
    "2d_coord": [
      1.0837258100509644,
      1.9517717361450195
    ],
    "MSU_id": 2491,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we invite a professional analyst (PA) with five years of experience in analyzing nationwide air quality data to perform a real- world case study using VolumeSTCube. Second, we conduct a controlled user study that compares VolumeSTCube with Thakur and Hanson's method [14] to further understand its advantages and disadvantages."
  },
  {
    "sentence": "The user study aims to further understand the advantages and disadvantages of VolumeSTCube.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2492,
    "para_id": 410,
    "paper_id": 3,
    "2d_coord": [
      1.0527753829956055,
      1.9482049942016602
    ],
    "MSU_id": 2492,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube is evaluated as follows. First, we invite a professional analyst (PA) with five years of experience in analyzing nationwide air quality data to perform a real- world case study using VolumeSTCube. Second, we conduct a controlled user study that compares VolumeSTCube with Thakur and Hanson's method [14] to further understand its advantages and disadvantages."
  },
  {
    "sentence": "We have a real-world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2493,
    "para_id": 411,
    "paper_id": 3,
    "2d_coord": [
      1.155981183052063,
      2.029540538787842
    ],
    "MSU_id": 2493,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We have a real- world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China (Figure 5(left)). In the whole evaluation section, the geographic space is divided into a  $350 \\times 350$  grid. The time span is from January 1 to December 20, 2018, and the temporal granularity is one hour. In sum, the dataset comprises 448 (stations)  $\\times 8,472$  (timesteps) values, ranging from 0 to 500. Each value in the dataset is the AQI at the timestamp of a monitoring station. The higher the value, the worse the air quality. In the data transformation procedure, the parameters of the Gaussian model are automatically determined by the PyKridge library. We evaluated the accuracy of the adopted Kriging interpolation on the dataset and found it to be acceptable, ensuring the reliability of subsequent analyses. For detailed results, please refer to Appendix D. The parameters of DBSCAN,  $\\epsilon$  and MinPts, are configured as 10 and 100, respectively, after multiple trials. The window size for smoothing is set as 24 hours."
  },
  {
    "sentence": "The geographic space is divided into a 350 x 350 grid for the evaluation.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2494,
    "para_id": 411,
    "paper_id": 3,
    "2d_coord": [
      1.1969120502471924,
      1.9532606601715088
    ],
    "MSU_id": 2494,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We have a real- world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China (Figure 5(left)). In the whole evaluation section, the geographic space is divided into a  $350 \\times 350$  grid. The time span is from January 1 to December 20, 2018, and the temporal granularity is one hour. In sum, the dataset comprises 448 (stations)  $\\times 8,472$  (timesteps) values, ranging from 0 to 500. Each value in the dataset is the AQI at the timestamp of a monitoring station. The higher the value, the worse the air quality. In the data transformation procedure, the parameters of the Gaussian model are automatically determined by the PyKridge library. We evaluated the accuracy of the adopted Kriging interpolation on the dataset and found it to be acceptable, ensuring the reliability of subsequent analyses. For detailed results, please refer to Appendix D. The parameters of DBSCAN,  $\\epsilon$  and MinPts, are configured as 10 and 100, respectively, after multiple trials. The window size for smoothing is set as 24 hours."
  },
  {
    "sentence": "The time span of the dataset is from January 1 to December 20, 2018, with a temporal granularity of one hour.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2495,
    "para_id": 411,
    "paper_id": 3,
    "2d_coord": [
      0.7709360122680664,
      -0.11566907167434692
    ],
    "MSU_id": 2495,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We have a real- world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China (Figure 5(left)). In the whole evaluation section, the geographic space is divided into a  $350 \\times 350$  grid. The time span is from January 1 to December 20, 2018, and the temporal granularity is one hour. In sum, the dataset comprises 448 (stations)  $\\times 8,472$  (timesteps) values, ranging from 0 to 500. Each value in the dataset is the AQI at the timestamp of a monitoring station. The higher the value, the worse the air quality. In the data transformation procedure, the parameters of the Gaussian model are automatically determined by the PyKridge library. We evaluated the accuracy of the adopted Kriging interpolation on the dataset and found it to be acceptable, ensuring the reliability of subsequent analyses. For detailed results, please refer to Appendix D. The parameters of DBSCAN,  $\\epsilon$  and MinPts, are configured as 10 and 100, respectively, after multiple trials. The window size for smoothing is set as 24 hours."
  },
  {
    "sentence": "The dataset comprises 448 stations and 8,472 timesteps, resulting in values ranging from 0 to 500.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2496,
    "para_id": 411,
    "paper_id": 3,
    "2d_coord": [
      0.8123283982276917,
      1.706430435180664
    ],
    "MSU_id": 2496,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We have a real- world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China (Figure 5(left)). In the whole evaluation section, the geographic space is divided into a  $350 \\times 350$  grid. The time span is from January 1 to December 20, 2018, and the temporal granularity is one hour. In sum, the dataset comprises 448 (stations)  $\\times 8,472$  (timesteps) values, ranging from 0 to 500. Each value in the dataset is the AQI at the timestamp of a monitoring station. The higher the value, the worse the air quality. In the data transformation procedure, the parameters of the Gaussian model are automatically determined by the PyKridge library. We evaluated the accuracy of the adopted Kriging interpolation on the dataset and found it to be acceptable, ensuring the reliability of subsequent analyses. For detailed results, please refer to Appendix D. The parameters of DBSCAN,  $\\epsilon$  and MinPts, are configured as 10 and 100, respectively, after multiple trials. The window size for smoothing is set as 24 hours."
  },
  {
    "sentence": "Each value in the dataset is the AQI at the timestamp of a monitoring station.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2497,
    "para_id": 411,
    "paper_id": 3,
    "2d_coord": [
      1.4402261972427368,
      1.4809761047363281
    ],
    "MSU_id": 2497,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We have a real- world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China (Figure 5(left)). In the whole evaluation section, the geographic space is divided into a  $350 \\times 350$  grid. The time span is from January 1 to December 20, 2018, and the temporal granularity is one hour. In sum, the dataset comprises 448 (stations)  $\\times 8,472$  (timesteps) values, ranging from 0 to 500. Each value in the dataset is the AQI at the timestamp of a monitoring station. The higher the value, the worse the air quality. In the data transformation procedure, the parameters of the Gaussian model are automatically determined by the PyKridge library. We evaluated the accuracy of the adopted Kriging interpolation on the dataset and found it to be acceptable, ensuring the reliability of subsequent analyses. For detailed results, please refer to Appendix D. The parameters of DBSCAN,  $\\epsilon$  and MinPts, are configured as 10 and 100, respectively, after multiple trials. The window size for smoothing is set as 24 hours."
  },
  {
    "sentence": "The parameters of DBSCAN, ε and MinPts, are configured as 10 and 100, respectively, after multiple trials.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2503,
    "para_id": 411,
    "paper_id": 3,
    "2d_coord": [
      0.9419572353363037,
      0.6026136875152588
    ],
    "MSU_id": 2503,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We have a real- world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China (Figure 5(left)). In the whole evaluation section, the geographic space is divided into a  $350 \\times 350$  grid. The time span is from January 1 to December 20, 2018, and the temporal granularity is one hour. In sum, the dataset comprises 448 (stations)  $\\times 8,472$  (timesteps) values, ranging from 0 to 500. Each value in the dataset is the AQI at the timestamp of a monitoring station. The higher the value, the worse the air quality. In the data transformation procedure, the parameters of the Gaussian model are automatically determined by the PyKridge library. We evaluated the accuracy of the adopted Kriging interpolation on the dataset and found it to be acceptable, ensuring the reliability of subsequent analyses. For detailed results, please refer to Appendix D. The parameters of DBSCAN,  $\\epsilon$  and MinPts, are configured as 10 and 100, respectively, after multiple trials. The window size for smoothing is set as 24 hours."
  },
  {
    "sentence": "The window size for smoothing is set as 24 hours.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2504,
    "para_id": 411,
    "paper_id": 3,
    "2d_coord": [
      0.3017764985561371,
      0.7564761638641357
    ],
    "MSU_id": 2504,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We have a real- world AQI (air quality index) ST series dataset, collected from 448 air quality monitoring stations in China (Figure 5(left)). In the whole evaluation section, the geographic space is divided into a  $350 \\times 350$  grid. The time span is from January 1 to December 20, 2018, and the temporal granularity is one hour. In sum, the dataset comprises 448 (stations)  $\\times 8,472$  (timesteps) values, ranging from 0 to 500. Each value in the dataset is the AQI at the timestamp of a monitoring station. The higher the value, the worse the air quality. In the data transformation procedure, the parameters of the Gaussian model are automatically determined by the PyKridge library. We evaluated the accuracy of the adopted Kriging interpolation on the dataset and found it to be acceptable, ensuring the reliability of subsequent analyses. For detailed results, please refer to Appendix D. The parameters of DBSCAN,  $\\epsilon$  and MinPts, are configured as 10 and 100, respectively, after multiple trials. The window size for smoothing is set as 24 hours."
  },
  {
    "sentence": "The dataset is divided equally into two parts according to time.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2505,
    "para_id": 412,
    "paper_id": 3,
    "2d_coord": [
      0.27607065439224243,
      0.12294799089431763
    ],
    "MSU_id": 2505,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "The dataset is divided equally into two parts according to time, and each part is data for half a year. The first dataset will be used in the case study, and both datasets will be used in the controlled user study. Each of the datasets comprises 1.8 million values."
  },
  {
    "sentence": "Each part of the dataset represents data for half a year.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2506,
    "para_id": 412,
    "paper_id": 3,
    "2d_coord": [
      0.30151084065437317,
      0.006819963455200195
    ],
    "MSU_id": 2506,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "The dataset is divided equally into two parts according to time, and each part is data for half a year. The first dataset will be used in the case study, and both datasets will be used in the controlled user study. Each of the datasets comprises 1.8 million values."
  },
  {
    "sentence": "The first dataset will be used in the case study.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2507,
    "para_id": 412,
    "paper_id": 3,
    "2d_coord": [
      1.0328627824783325,
      1.699622631072998
    ],
    "MSU_id": 2507,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "The dataset is divided equally into two parts according to time, and each part is data for half a year. The first dataset will be used in the case study, and both datasets will be used in the controlled user study. Each of the datasets comprises 1.8 million values."
  },
  {
    "sentence": "Both datasets will be used in the controlled user study.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2508,
    "para_id": 412,
    "paper_id": 3,
    "2d_coord": [
      1.2372596263885498,
      1.85691499710083
    ],
    "MSU_id": 2508,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "The dataset is divided equally into two parts according to time, and each part is data for half a year. The first dataset will be used in the case study, and both datasets will be used in the controlled user study. Each of the datasets comprises 1.8 million values."
  },
  {
    "sentence": "Each of the datasets comprises 1.8 million values.",
    "subtitle": "V. EVALUATION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2509,
    "para_id": 412,
    "paper_id": 3,
    "2d_coord": [
      1.5399301052093506,
      0.8866475224494934
    ],
    "MSU_id": 2509,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "The dataset is divided equally into two parts according to time, and each part is data for half a year. The first dataset will be used in the case study, and both datasets will be used in the controlled user study. Each of the datasets comprises 1.8 million values."
  },
  {
    "sentence": "PA analyzed China's air quality in the first half of 2018 using VolumeSTCube.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2511,
    "para_id": 413,
    "paper_id": 3,
    "2d_coord": [
      1.0062172412872314,
      1.915097951889038
    ],
    "MSU_id": 2511,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We first introduced the visual encodings and interactions of VolumeSTCube. Afterward, PA analyzed China's air quality in the first half of 2018 via VolumeSTCube in person. PA started with an overview and performed temporal, spatial, and spatiotemporal analyses."
  },
  {
    "sentence": "During the analysis, PA started with an overview of China's air quality in the specified period.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2512,
    "para_id": 413,
    "paper_id": 3,
    "2d_coord": [
      1.1230963468551636,
      2.001478433609009
    ],
    "MSU_id": 2512,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We first introduced the visual encodings and interactions of VolumeSTCube. Afterward, PA analyzed China's air quality in the first half of 2018 via VolumeSTCube in person. PA started with an overview and performed temporal, spatial, and spatiotemporal analyses."
  },
  {
    "sentence": "PA performed temporal analyses using VolumeSTCube.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2513,
    "para_id": 413,
    "paper_id": 3,
    "2d_coord": [
      0.9880930185317993,
      1.870008945465088
    ],
    "MSU_id": 2513,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We first introduced the visual encodings and interactions of VolumeSTCube. Afterward, PA analyzed China's air quality in the first half of 2018 via VolumeSTCube in person. PA started with an overview and performed temporal, spatial, and spatiotemporal analyses."
  },
  {
    "sentence": "PA conducted spatial analyses using VolumeSTCube.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2514,
    "para_id": 413,
    "paper_id": 3,
    "2d_coord": [
      0.975009560585022,
      1.846142292022705
    ],
    "MSU_id": 2514,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We first introduced the visual encodings and interactions of VolumeSTCube. Afterward, PA analyzed China's air quality in the first half of 2018 via VolumeSTCube in person. PA started with an overview and performed temporal, spatial, and spatiotemporal analyses."
  },
  {
    "sentence": "PA carried out spatiotemporal analyses using VolumeSTCube.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2515,
    "para_id": 413,
    "paper_id": 3,
    "2d_coord": [
      1.0041110515594482,
      1.8674111366271973
    ],
    "MSU_id": 2515,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We first introduced the visual encodings and interactions of VolumeSTCube. Afterward, PA analyzed China's air quality in the first half of 2018 via VolumeSTCube in person. PA started with an overview and performed temporal, spatial, and spatiotemporal analyses."
  },
  {
    "sentence": "After loading the dataset, PA obtained Figure 6A, where the threshold λ was 0.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2516,
    "para_id": 414,
    "paper_id": 3,
    "2d_coord": [
      1.191194772720337,
      1.800619125366211
    ],
    "MSU_id": 2516,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "1) Overview: After loading the dataset, PA obtained Figure 6A, where the threshold  $\\lambda$  was 0. The spatial and temporal variation of air quality could be roughly seen. Some regions were particularly polluted during certain months, for example, the spatiotemporal partitions denoted in Figure 6A1. To make the representation clearer, PA increased the threshold  $\\lambda$  to 150. AQI  $>150$  means the air is moderately polluted, according to China's Ministry of Environmental Protection. In this way, PA could also pay more attention to the occurrences of moderate and severe air pollution."
  },
  {
    "sentence": "PA analyzed the temporal variation of AQI in western China.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2526,
    "para_id": 416,
    "paper_id": 3,
    "2d_coord": [
      1.1953145265579224,
      1.999309778213501
    ],
    "MSU_id": 2526,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "2) Temporal Analysis: PA analyzed the temporal variation of AQI in western China, where PA observed frequent severe pollution, and Beijing-Tianjin-Hebei (BTH) region, the capital economic circle of China."
  },
  {
    "sentence": "PA analyzed the temporal variation of AQI in the Beijing-Tianjin-Hebei region, the capital economic circle of China.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2528,
    "para_id": 416,
    "paper_id": 3,
    "2d_coord": [
      1.3722807168960571,
      1.7111024856567383
    ],
    "MSU_id": 2528,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "2) Temporal Analysis: PA analyzed the temporal variation of AQI in western China, where PA observed frequent severe pollution, and Beijing-Tianjin-Hebei (BTH) region, the capital economic circle of China."
  },
  {
    "sentence": "The region of interest was exactly the Xinjiang.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2531,
    "para_id": 417,
    "paper_id": 3,
    "2d_coord": [
      0.9558988213539124,
      1.9778926372528076
    ],
    "MSU_id": 2531,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Western China. To analyze the air pollution situation in western China further, PA applied the volume highlight tool to select the spatial range of interest. Recall that VolumeSTCube allows us to easily locate the spotlight on the target region by directly pointing to the region on the map. The region was exactly the Xinjiang. PA clearly observed that starting around March, multiple significant air pollution events occurred (Figure 6C). During these events, the air quality in Xinjiang deteriorated notably, possibly due to the poor atmospheric dispersion conditions and the influence of dust storms [65]."
  },
  {
    "sentence": "The BTH region was selected using the volume highlight tool.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2535,
    "para_id": 418,
    "paper_id": 3,
    "2d_coord": [
      1.106156349182129,
      1.9064817428588867
    ],
    "MSU_id": 2535,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "BTH. The BTH region was selected using the volume highlight tool (Figure 6D). Overall, there were only a few episodes of moderate or above pollution in the BTH region, and they did not last very long. Moreover, starting from April, the overall air pollution in the BTH region consistently remained below the moderate level, i.e., AQI  $\\leq 150$"
  },
  {
    "sentence": "PA specified a one-day time range and analyzed the spatial impact of this storm.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2577,
    "para_id": 425,
    "paper_id": 3,
    "2d_coord": [
      1.1428436040878296,
      1.7784194946289062
    ],
    "MSU_id": 2577,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Late May. Figure 6G1 showed the air pollution caused by this dust storm. PA also specified a one- day time range and analyzed the spatial impact of this storm. Figure 6G2 was the top view of the visualization during this time range. Mainly, the regions around the Taklimakan Desert and the Badain Jarah Desert were moderately polluted due to the dust storm. The spatial range of moderate pollution caused by this dust storm is smaller than that caused by the abovementioned dust storm."
  },
  {
    "sentence": "The propagation processes occurred around January 20 and February 3, 2018.",
    "subtitle": "A. Case Study: Air Quality in China",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2615,
    "para_id": 431,
    "paper_id": 3,
    "2d_coord": [
      0.7523020505905151,
      0.5960663557052612
    ],
    "MSU_id": 2615,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "The aforementioned propagation processes occurred around January 20 and February 3, 2018, respectively. Concurrently, China experienced two significant cold waves that resulted in strong cold air moving southward, leading to a substantial drop in temperatures. PA explained these meteorological conditions likely contributed to the observed patterns of air pollution."
  },
  {
    "sentence": "We conducted a controlled, within-subject user study.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2625,
    "para_id": 433,
    "paper_id": 3,
    "2d_coord": [
      1.0994313955307007,
      2.0182101726531982
    ],
    "MSU_id": 2625,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We conducted a controlled, within- subject user study. The study primarily aimed to verify 1) the effectiveness of continuous volume- based visualization compared to column- based visualization and 2) the ease of understanding of volume- based visualization combined with the space- time cube. Besides, we hoped to identify the strengths and weaknesses of VolumeSTCube. While numerous methods, such as 2D map- based estimations or coordinated 2D maps and line charts, are available for comparison, these approaches differ fundamentally in design and interaction principles from STC- based methods. We selected Thakur and Hanson's STC- based method [14] as the baseline, shown in Figure 1. This method, the most recent STC- based visualization for ST series, lacks volumetric representation but serves as a representative of similar methods [15], [16]. Its design allows a focused evaluation of the benefits introduced by volume- based visualization."
  },
  {
    "sentence": "The study primarily aimed to verify the effectiveness of continuous volume-based visualization compared to column-based visualization.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 4,
    "msuid": 2626,
    "para_id": 433,
    "paper_id": 3,
    "2d_coord": [
      1.1271053552627563,
      1.9484264850616455
    ],
    "MSU_id": 2626,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We conducted a controlled, within- subject user study. The study primarily aimed to verify 1) the effectiveness of continuous volume- based visualization compared to column- based visualization and 2) the ease of understanding of volume- based visualization combined with the space- time cube. Besides, we hoped to identify the strengths and weaknesses of VolumeSTCube. While numerous methods, such as 2D map- based estimations or coordinated 2D maps and line charts, are available for comparison, these approaches differ fundamentally in design and interaction principles from STC- based methods. We selected Thakur and Hanson's STC- based method [14] as the baseline, shown in Figure 1. This method, the most recent STC- based visualization for ST series, lacks volumetric representation but serves as a representative of similar methods [15], [16]. Its design allows a focused evaluation of the benefits introduced by volume- based visualization."
  },
  {
    "sentence": "The study primarily aimed to verify the ease of understanding of volume-based visualization combined with the space-time cube.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 4,
    "msuid": 2627,
    "para_id": 433,
    "paper_id": 3,
    "2d_coord": [
      1.1269583702087402,
      1.956916093826294
    ],
    "MSU_id": 2627,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We conducted a controlled, within- subject user study. The study primarily aimed to verify 1) the effectiveness of continuous volume- based visualization compared to column- based visualization and 2) the ease of understanding of volume- based visualization combined with the space- time cube. Besides, we hoped to identify the strengths and weaknesses of VolumeSTCube. While numerous methods, such as 2D map- based estimations or coordinated 2D maps and line charts, are available for comparison, these approaches differ fundamentally in design and interaction principles from STC- based methods. We selected Thakur and Hanson's STC- based method [14] as the baseline, shown in Figure 1. This method, the most recent STC- based visualization for ST series, lacks volumetric representation but serves as a representative of similar methods [15], [16]. Its design allows a focused evaluation of the benefits introduced by volume- based visualization."
  },
  {
    "sentence": "We hoped to identify the strengths and weaknesses of VolumeSTCube.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2628,
    "para_id": 433,
    "paper_id": 3,
    "2d_coord": [
      1.2500855922698975,
      1.7974965572357178
    ],
    "MSU_id": 2628,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We conducted a controlled, within- subject user study. The study primarily aimed to verify 1) the effectiveness of continuous volume- based visualization compared to column- based visualization and 2) the ease of understanding of volume- based visualization combined with the space- time cube. Besides, we hoped to identify the strengths and weaknesses of VolumeSTCube. While numerous methods, such as 2D map- based estimations or coordinated 2D maps and line charts, are available for comparison, these approaches differ fundamentally in design and interaction principles from STC- based methods. We selected Thakur and Hanson's STC- based method [14] as the baseline, shown in Figure 1. This method, the most recent STC- based visualization for ST series, lacks volumetric representation but serves as a representative of similar methods [15], [16]. Its design allows a focused evaluation of the benefits introduced by volume- based visualization."
  },
  {
    "sentence": "We selected Thakur and Hanson's STC-based method as the baseline, shown in Figure 1.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2631,
    "para_id": 433,
    "paper_id": 3,
    "2d_coord": [
      1.2111880779266357,
      1.839658498764038
    ],
    "MSU_id": 2631,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We conducted a controlled, within- subject user study. The study primarily aimed to verify 1) the effectiveness of continuous volume- based visualization compared to column- based visualization and 2) the ease of understanding of volume- based visualization combined with the space- time cube. Besides, we hoped to identify the strengths and weaknesses of VolumeSTCube. While numerous methods, such as 2D map- based estimations or coordinated 2D maps and line charts, are available for comparison, these approaches differ fundamentally in design and interaction principles from STC- based methods. We selected Thakur and Hanson's STC- based method [14] as the baseline, shown in Figure 1. This method, the most recent STC- based visualization for ST series, lacks volumetric representation but serves as a representative of similar methods [15], [16]. Its design allows a focused evaluation of the benefits introduced by volume- based visualization."
  },
  {
    "sentence": "The design of Thakur and Hanson's method allows a focused evaluation of the benefits introduced by volume-based visualization.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2634,
    "para_id": 433,
    "paper_id": 3,
    "2d_coord": [
      1.1387228965759277,
      1.9488420486450195
    ],
    "MSU_id": 2634,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We conducted a controlled, within- subject user study. The study primarily aimed to verify 1) the effectiveness of continuous volume- based visualization compared to column- based visualization and 2) the ease of understanding of volume- based visualization combined with the space- time cube. Besides, we hoped to identify the strengths and weaknesses of VolumeSTCube. While numerous methods, such as 2D map- based estimations or coordinated 2D maps and line charts, are available for comparison, these approaches differ fundamentally in design and interaction principles from STC- based methods. We selected Thakur and Hanson's STC- based method [14] as the baseline, shown in Figure 1. This method, the most recent STC- based visualization for ST series, lacks volumetric representation but serves as a representative of similar methods [15], [16]. Its design allows a focused evaluation of the benefits introduced by volume- based visualization."
  },
  {
    "sentence": "Due to the challenge of recruiting a sufficient number of domain experts, we opted to involve undergraduate students.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2635,
    "para_id": 434,
    "paper_id": 3,
    "2d_coord": [
      0.8107970952987671,
      1.2156367301940918
    ],
    "MSU_id": 2635,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "1) Study Setup: Subjects. Due to the challenge of recruiting a sufficient number of domain experts, we opted to involve undergraduate students. If undergraduate students, who are less familiar with advanced visualization techniques and domain-specific problems, were able to complete the tasks successfully after the introduction or tutorials, it stands to reason that domain experts, with their greater expertise and experience, would be even better equipped to utilize the system effectively."
  },
  {
    "sentence": "Table I presents tasks designed for the user study.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2638,
    "para_id": 435,
    "paper_id": 3,
    "2d_coord": [
      1.152326226234436,
      1.99106764793396
    ],
    "MSU_id": 2638,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "TABLE I TASKS DESIGNED FOR THE USER STUDY, INVOLVING LOOKUP, COMPARISON, AND RELATION-SEEKING AT ELEMENTARY AND SYNOPTIC LEVELS, COVERING SPACE-ORIENTED (LIGHT BLUE BACKGROUND), TIME-ORIENTED (LIGHT RED BACKGROUND), AND SPATIOTEMPORAL PATTERN-ORIENTED (LIGHT GREEN BACKGROUND) ANALYSES."
  },
  {
    "sentence": "The tasks involve lookup, comparison, and relation-seeking at elementary and synoptic levels.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2639,
    "para_id": 435,
    "paper_id": 3,
    "2d_coord": [
      1.0933525562286377,
      1.9377317428588867
    ],
    "MSU_id": 2639,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "TABLE I TASKS DESIGNED FOR THE USER STUDY, INVOLVING LOOKUP, COMPARISON, AND RELATION-SEEKING AT ELEMENTARY AND SYNOPTIC LEVELS, COVERING SPACE-ORIENTED (LIGHT BLUE BACKGROUND), TIME-ORIENTED (LIGHT RED BACKGROUND), AND SPATIOTEMPORAL PATTERN-ORIENTED (LIGHT GREEN BACKGROUND) ANALYSES."
  },
  {
    "sentence": "The tasks cover space-oriented analyses with a light blue background.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2640,
    "para_id": 435,
    "paper_id": 3,
    "2d_coord": [
      0.8745449185371399,
      1.640383243560791
    ],
    "MSU_id": 2640,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "TABLE I TASKS DESIGNED FOR THE USER STUDY, INVOLVING LOOKUP, COMPARISON, AND RELATION-SEEKING AT ELEMENTARY AND SYNOPTIC LEVELS, COVERING SPACE-ORIENTED (LIGHT BLUE BACKGROUND), TIME-ORIENTED (LIGHT RED BACKGROUND), AND SPATIOTEMPORAL PATTERN-ORIENTED (LIGHT GREEN BACKGROUND) ANALYSES."
  },
  {
    "sentence": "The tasks cover time-oriented analyses with a light red background.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2641,
    "para_id": 435,
    "paper_id": 3,
    "2d_coord": [
      0.8421740531921387,
      1.6226253509521484
    ],
    "MSU_id": 2641,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "TABLE I TASKS DESIGNED FOR THE USER STUDY, INVOLVING LOOKUP, COMPARISON, AND RELATION-SEEKING AT ELEMENTARY AND SYNOPTIC LEVELS, COVERING SPACE-ORIENTED (LIGHT BLUE BACKGROUND), TIME-ORIENTED (LIGHT RED BACKGROUND), AND SPATIOTEMPORAL PATTERN-ORIENTED (LIGHT GREEN BACKGROUND) ANALYSES."
  },
  {
    "sentence": "The tasks cover spatiotemporal pattern-oriented analyses with a light green background.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2642,
    "para_id": 435,
    "paper_id": 3,
    "2d_coord": [
      1.000225305557251,
      1.950533151626587
    ],
    "MSU_id": 2642,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "TABLE I TASKS DESIGNED FOR THE USER STUDY, INVOLVING LOOKUP, COMPARISON, AND RELATION-SEEKING AT ELEMENTARY AND SYNOPTIC LEVELS, COVERING SPACE-ORIENTED (LIGHT BLUE BACKGROUND), TIME-ORIENTED (LIGHT RED BACKGROUND), AND SPATIOTEMPORAL PATTERN-ORIENTED (LIGHT GREEN BACKGROUND) ANALYSES."
  },
  {
    "sentence": "We invited twelve undergraduate students as subjects.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2643,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      0.8433763980865479,
      1.5584297180175781
    ],
    "MSU_id": 2643,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "The subjects included six males and six females.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2644,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      0.44695746898651123,
      1.6569745540618896
    ],
    "MSU_id": 2644,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "The subjects' majors include software engineering, business administration, product design, logistics management, industrial design, tourism management, and journalism.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2645,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.1728160381317139,
      2.0093014240264893
    ],
    "MSU_id": 2645,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "Four subjects major in software engineering.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 2646,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.2622733116149902,
      1.921104907989502
    ],
    "MSU_id": 2646,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "Two subjects major in business administration.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 2647,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.3046983480453491,
      1.8669285774230957
    ],
    "MSU_id": 2647,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "Two subjects major in product design.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 2648,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.0754127502441406,
      1.950181007385254
    ],
    "MSU_id": 2648,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "One subject majors in logistics management.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 2649,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.328989028930664,
      1.9010486602783203
    ],
    "MSU_id": 2649,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "One subject majors in industrial design.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 2650,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.1895244121551514,
      1.9495975971221924
    ],
    "MSU_id": 2650,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "One subject majors in tourism management.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 2651,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.2257270812988281,
      1.9505352973937988
    ],
    "MSU_id": 2651,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "One subject majors in journalism.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 1,
    "msuid": 2652,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.1784818172454834,
      2.0002779960632324
    ],
    "MSU_id": 2652,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "The subjects possess a common-sense understanding of air pollution.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2653,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.0168092250823975,
      1.5287442207336426
    ],
    "MSU_id": 2653,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "The subjects have relatively limited visualization and spatiotemporal analysis expertise.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2654,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      1.0266501903533936,
      2.0076582431793213
    ],
    "MSU_id": 2654,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "These subjects are suitable for the purposes of our study.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2655,
    "para_id": 436,
    "paper_id": 3,
    "2d_coord": [
      0.431363046169281,
      1.5014288425445557
    ],
    "MSU_id": 2655,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Finally, we invited twelve undergraduate students (six males and six females) as subjects. Their majors include software engineering (4 subjects), business administration (2), product design (2), logistics management (1), industrial design (1), tourism management (1), and journalism (1). They possess a common- sense understanding of air pollution but relatively limited visualization and spatiotemporal analysis expertise. These subjects are suitable for the purposes of our study."
  },
  {
    "sentence": "Since the subjects were not experts in air quality, the tasks only required them to describe the spatial, temporal, or spatiotemporal phenomena objectively.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2664,
    "para_id": 437,
    "paper_id": 3,
    "2d_coord": [
      1.0571790933609009,
      1.9626679420471191
    ],
    "MSU_id": 2664,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Tasks. Andrienko and Andrienko [17] classified general and basic spatiotemporal analytical tasks into lookup, comparison, and relation- seeking at elementary and synoptic levels. We follow this well- established taxonomy to design concrete tasks, as Thakur and Hanson [14] did. We designed 18 tasks, as shown in Table I with the question form. These tasks cover the three kinds of tasks (i.e., lookup, comparison, and relation- seeking) at two levels (i.e., elementary and synoptic) proposed in Andrienko and Andrienko's taxonomy [17]. Elementary tasks deal with the elements of data, while synoptic tasks are performed on the spatiotemporal pattern rather than the elements. Considering our scenario and dataset, we define patterns as spatiotemporal hotspots and propagation processes. Moreover, we further refine the tasks from the spatial, temporal, and spatiotemporal perspectives, as indicated by the blue, pink, and green backgrounds, respectively. Since the subjects were not experts in air quality, the tasks only required them to describe the spatial, temporal, or spatiotemporal phenomena objectively and did not involve explaining the phenomena, such as how pollutants were generated."
  },
  {
    "sentence": "The tasks did not involve explaining the phenomena, such as how pollutants were generated.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2665,
    "para_id": 437,
    "paper_id": 3,
    "2d_coord": [
      0.9257843494415283,
      0.9027899503707886
    ],
    "MSU_id": 2665,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Tasks. Andrienko and Andrienko [17] classified general and basic spatiotemporal analytical tasks into lookup, comparison, and relation- seeking at elementary and synoptic levels. We follow this well- established taxonomy to design concrete tasks, as Thakur and Hanson [14] did. We designed 18 tasks, as shown in Table I with the question form. These tasks cover the three kinds of tasks (i.e., lookup, comparison, and relation- seeking) at two levels (i.e., elementary and synoptic) proposed in Andrienko and Andrienko's taxonomy [17]. Elementary tasks deal with the elements of data, while synoptic tasks are performed on the spatiotemporal pattern rather than the elements. Considering our scenario and dataset, we define patterns as spatiotemporal hotspots and propagation processes. Moreover, we further refine the tasks from the spatial, temporal, and spatiotemporal perspectives, as indicated by the blue, pink, and green backgrounds, respectively. Since the subjects were not experts in air quality, the tasks only required them to describe the spatial, temporal, or spatiotemporal phenomena objectively and did not involve explaining the phenomena, such as how pollutants were generated."
  },
  {
    "sentence": "The time range selection interaction enables a fair comparison between the two methods.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2679,
    "para_id": 440,
    "paper_id": 3,
    "2d_coord": [
      1.1686837673187256,
      1.2716422080993652
    ],
    "MSU_id": 2679,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We implement the column selection interaction described in Thakur and Hanson's paper [14], which corresponds to our volume spotlight for spatial selection. Additionally, we equip the baseline visualization with the time range selection interaction similar to VolumeSTCube, enabling a fair comparison between the two methods."
  },
  {
    "sentence": "We provide the subjects with a comprehensive introduction to the system's visual encoding and interactions.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2681,
    "para_id": 441,
    "paper_id": 3,
    "2d_coord": [
      1.1146610975265503,
      1.7569098472595215
    ],
    "MSU_id": 2681,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Procedure. Firstly, we introduce the key concepts, including ST series, air quality datasets, common temporal trends, spatial distributions, and prevalent spatiotemporal patterns within air quality data. Subsequently, we provide the subjects with a comprehensive introduction to the system's visual encoding and interactions, followed by a hands- on exploration of a sample dataset using the system. Next, we proceed with the formal experiment section. Each subject analyzed the dataset and answered questions for the first and second halves of the task (denoted as Dataset A and Dataset B, respectively) using two different systems. Upon completion of the experiment, we gather the subject feedback through a brief interview. The procedure for each subject lasted about 1 hour, with a 5- minute break after using the first system."
  },
  {
    "sentence": "Subjects engage in a hands-on exploration of a sample dataset using the system.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2682,
    "para_id": 441,
    "paper_id": 3,
    "2d_coord": [
      1.0183992385864258,
      1.8188867568969727
    ],
    "MSU_id": 2682,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Procedure. Firstly, we introduce the key concepts, including ST series, air quality datasets, common temporal trends, spatial distributions, and prevalent spatiotemporal patterns within air quality data. Subsequently, we provide the subjects with a comprehensive introduction to the system's visual encoding and interactions, followed by a hands- on exploration of a sample dataset using the system. Next, we proceed with the formal experiment section. Each subject analyzed the dataset and answered questions for the first and second halves of the task (denoted as Dataset A and Dataset B, respectively) using two different systems. Upon completion of the experiment, we gather the subject feedback through a brief interview. The procedure for each subject lasted about 1 hour, with a 5- minute break after using the first system."
  },
  {
    "sentence": "We proceed with the formal experiment section.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2683,
    "para_id": 441,
    "paper_id": 3,
    "2d_coord": [
      0.48618578910827637,
      1.2491590976715088
    ],
    "MSU_id": 2683,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Procedure. Firstly, we introduce the key concepts, including ST series, air quality datasets, common temporal trends, spatial distributions, and prevalent spatiotemporal patterns within air quality data. Subsequently, we provide the subjects with a comprehensive introduction to the system's visual encoding and interactions, followed by a hands- on exploration of a sample dataset using the system. Next, we proceed with the formal experiment section. Each subject analyzed the dataset and answered questions for the first and second halves of the task (denoted as Dataset A and Dataset B, respectively) using two different systems. Upon completion of the experiment, we gather the subject feedback through a brief interview. The procedure for each subject lasted about 1 hour, with a 5- minute break after using the first system."
  },
  {
    "sentence": "Each subject analyzed the dataset and answered questions for the first and second halves of the task using two different systems.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2684,
    "para_id": 441,
    "paper_id": 3,
    "2d_coord": [
      0.9628908038139343,
      1.8276948928833008
    ],
    "MSU_id": 2684,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Procedure. Firstly, we introduce the key concepts, including ST series, air quality datasets, common temporal trends, spatial distributions, and prevalent spatiotemporal patterns within air quality data. Subsequently, we provide the subjects with a comprehensive introduction to the system's visual encoding and interactions, followed by a hands- on exploration of a sample dataset using the system. Next, we proceed with the formal experiment section. Each subject analyzed the dataset and answered questions for the first and second halves of the task (denoted as Dataset A and Dataset B, respectively) using two different systems. Upon completion of the experiment, we gather the subject feedback through a brief interview. The procedure for each subject lasted about 1 hour, with a 5- minute break after using the first system."
  },
  {
    "sentence": "The first and second halves of the task are denoted as Dataset A and Dataset B, respectively.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2685,
    "para_id": 441,
    "paper_id": 3,
    "2d_coord": [
      0.49905574321746826,
      0.9342389106750488
    ],
    "MSU_id": 2685,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Procedure. Firstly, we introduce the key concepts, including ST series, air quality datasets, common temporal trends, spatial distributions, and prevalent spatiotemporal patterns within air quality data. Subsequently, we provide the subjects with a comprehensive introduction to the system's visual encoding and interactions, followed by a hands- on exploration of a sample dataset using the system. Next, we proceed with the formal experiment section. Each subject analyzed the dataset and answered questions for the first and second halves of the task (denoted as Dataset A and Dataset B, respectively) using two different systems. Upon completion of the experiment, we gather the subject feedback through a brief interview. The procedure for each subject lasted about 1 hour, with a 5- minute break after using the first system."
  },
  {
    "sentence": "Upon completion of the experiment, we gather the subject feedback through a brief interview.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2686,
    "para_id": 441,
    "paper_id": 3,
    "2d_coord": [
      1.3780055046081543,
      1.783756971359253
    ],
    "MSU_id": 2686,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Procedure. Firstly, we introduce the key concepts, including ST series, air quality datasets, common temporal trends, spatial distributions, and prevalent spatiotemporal patterns within air quality data. Subsequently, we provide the subjects with a comprehensive introduction to the system's visual encoding and interactions, followed by a hands- on exploration of a sample dataset using the system. Next, we proceed with the formal experiment section. Each subject analyzed the dataset and answered questions for the first and second halves of the task (denoted as Dataset A and Dataset B, respectively) using two different systems. Upon completion of the experiment, we gather the subject feedback through a brief interview. The procedure for each subject lasted about 1 hour, with a 5- minute break after using the first system."
  },
  {
    "sentence": "The procedure for each subject lasted about 1 hour, with a 5-minute break after using the first system.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2687,
    "para_id": 441,
    "paper_id": 3,
    "2d_coord": [
      0.6146782636642456,
      1.6911120414733887
    ],
    "MSU_id": 2687,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Procedure. Firstly, we introduce the key concepts, including ST series, air quality datasets, common temporal trends, spatial distributions, and prevalent spatiotemporal patterns within air quality data. Subsequently, we provide the subjects with a comprehensive introduction to the system's visual encoding and interactions, followed by a hands- on exploration of a sample dataset using the system. Next, we proceed with the formal experiment section. Each subject analyzed the dataset and answered questions for the first and second halves of the task (denoted as Dataset A and Dataset B, respectively) using two different systems. Upon completion of the experiment, we gather the subject feedback through a brief interview. The procedure for each subject lasted about 1 hour, with a 5- minute break after using the first system."
  },
  {
    "sentence": "In the experiment section, twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2688,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      1.2627140283584595,
      1.480825662612915
    ],
    "MSU_id": 2688,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "The groups were assigned with systems such as VolumeSTCube with Dataset B and baseline with Dataset A.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2689,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      0.9266119599342346,
      1.8585546016693115
    ],
    "MSU_id": 2689,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2690,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      1.1971274614334106,
      1.8776929378509521
    ],
    "MSU_id": 2690,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "These questions were reorganized according to the exploration process to minimize the workload on the subjects.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2691,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      1.1016379594802856,
      2.033632516860962
    ],
    "MSU_id": 2691,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "Questions that could be answered sequentially were grouped together.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2692,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      0.21401315927505493,
      1.442946434020996
    ],
    "MSU_id": 2692,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "The system would be reset between different question groups, irrespective of which system the subject was utilizing.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2693,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      0.8098227381706238,
      1.8256118297576904
    ],
    "MSU_id": 2693,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "Regardless of which system is used, the order in which the questions appear is the same.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2695,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      -0.03699532151222229,
      1.2971463203430176
    ],
    "MSU_id": 2695,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "When the subjects were conducting the experiment, the questions were displayed on a tablet.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2696,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      1.0564547777175903,
      1.9910774230957031
    ],
    "MSU_id": 2696,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2697,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      1.0313138961791992,
      1.9666860103607178
    ],
    "MSU_id": 2697,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "The response time was recorded from the moment of the confirmation to the moment the answer was provided.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2698,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      0.03696244955062866,
      0.9942580461502075
    ],
    "MSU_id": 2698,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "During the experiment, a think-aloud protocol is employed, encouraging subjects to verbalize their thoughts.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2699,
    "para_id": 442,
    "paper_id": 3,
    "2d_coord": [
      1.113154411315918,
      2.0015523433685303
    ],
    "MSU_id": 2699,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Specifically, in the experiment section, the twelve subjects were randomly assigned into four groups based on the order of system usage and the corresponding dataset (e.g., VolumeSTCube with Dataset B, baseline with Dataset A). 18 questions per dataset were instantiated based on the dataset according to the 18 tasks in Table I. These questions were then reorganized according to the exploration process, grouping together those that could be answered sequentially to minimize the workload on the subjects. The system would be reset between different question groups, irrespective of which system the subject was utilizing. Please refer to Appendix C for the questions, their order and grouping, correct answers,and correctness criteria. Note that regardless of which system you use, the order in which the questions appear is the same. When the subjects were conducting the experiment, the questions were displayed on a tablet. Once the subject confirmed understanding the question, the subject used the system on the desktop for analysis. The response time was recorded from the moment of the confirmation to the moment the answer was provided. During the experiment, a think- aloud protocol is employed, encouraging subjects to verbalize their thoughts."
  },
  {
    "sentence": "The results for VolumeSTCube are represented by soft blue.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2701,
    "para_id": 443,
    "paper_id": 3,
    "2d_coord": [
      1.1006929874420166,
      1.8887357711791992
    ],
    "MSU_id": 2701,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Fig. 8. Results of user study. The results for VolumeSTCube and the baseline are represented by soft blue and soft orange, respectively. The bottom section categorizes the 18 questions into three groups based on their spatial, temporal, and spatiotemporal perspectives. The middle section displays the response times for each question with jittered dot plots, where horizontal markers denote medians. The top section shows the correctness of the answers. Black rectangles highlight instances where either the difference of the correctness is more than 25% or the response time is significantly different. No instances were found where the baseline obviously outperforms VolumeSTCube."
  },
  {
    "sentence": "The results for the baseline are represented by soft orange.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2702,
    "para_id": 443,
    "paper_id": 3,
    "2d_coord": [
      1.0597292184829712,
      1.8700978755950928
    ],
    "MSU_id": 2702,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Fig. 8. Results of user study. The results for VolumeSTCube and the baseline are represented by soft blue and soft orange, respectively. The bottom section categorizes the 18 questions into three groups based on their spatial, temporal, and spatiotemporal perspectives. The middle section displays the response times for each question with jittered dot plots, where horizontal markers denote medians. The top section shows the correctness of the answers. Black rectangles highlight instances where either the difference of the correctness is more than 25% or the response time is significantly different. No instances were found where the baseline obviously outperforms VolumeSTCube."
  },
  {
    "sentence": "The bottom section categorizes the 18 questions into three groups based on their spatial, temporal, and spatiotemporal perspectives.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2703,
    "para_id": 443,
    "paper_id": 3,
    "2d_coord": [
      1.1052563190460205,
      2.015627145767212
    ],
    "MSU_id": 2703,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Fig. 8. Results of user study. The results for VolumeSTCube and the baseline are represented by soft blue and soft orange, respectively. The bottom section categorizes the 18 questions into three groups based on their spatial, temporal, and spatiotemporal perspectives. The middle section displays the response times for each question with jittered dot plots, where horizontal markers denote medians. The top section shows the correctness of the answers. Black rectangles highlight instances where either the difference of the correctness is more than 25% or the response time is significantly different. No instances were found where the baseline obviously outperforms VolumeSTCube."
  },
  {
    "sentence": "The middle section displays the response times for each question with jittered dot plots.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2704,
    "para_id": 443,
    "paper_id": 3,
    "2d_coord": [
      0.2977462410926819,
      1.57989501953125
    ],
    "MSU_id": 2704,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Fig. 8. Results of user study. The results for VolumeSTCube and the baseline are represented by soft blue and soft orange, respectively. The bottom section categorizes the 18 questions into three groups based on their spatial, temporal, and spatiotemporal perspectives. The middle section displays the response times for each question with jittered dot plots, where horizontal markers denote medians. The top section shows the correctness of the answers. Black rectangles highlight instances where either the difference of the correctness is more than 25% or the response time is significantly different. No instances were found where the baseline obviously outperforms VolumeSTCube."
  },
  {
    "sentence": "Horizontal markers in the middle section denote medians.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2705,
    "para_id": 443,
    "paper_id": 3,
    "2d_coord": [
      0.07740741968154907,
      0.9182459712028503
    ],
    "MSU_id": 2705,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Fig. 8. Results of user study. The results for VolumeSTCube and the baseline are represented by soft blue and soft orange, respectively. The bottom section categorizes the 18 questions into three groups based on their spatial, temporal, and spatiotemporal perspectives. The middle section displays the response times for each question with jittered dot plots, where horizontal markers denote medians. The top section shows the correctness of the answers. Black rectangles highlight instances where either the difference of the correctness is more than 25% or the response time is significantly different. No instances were found where the baseline obviously outperforms VolumeSTCube."
  },
  {
    "sentence": "If the subject chose to give up, it was counted as an incorrect answer.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2709,
    "para_id": 444,
    "paper_id": 3,
    "2d_coord": [
      1.5936338901519775,
      1.6339919567108154
    ],
    "MSU_id": 2709,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "2) Results: If the subject chose to give up, it was also counted as an incorrect answer. In addition, response records corresponding to incorrect answers, as well as the user's response records for the same question when using the alternate system, will be excluded from the response time calculations. Figure 8 summarizes the correctness of the subjects' answers and the subjects' response times for every question."
  },
  {
    "sentence": "Response records corresponding to incorrect answers will be excluded from the response time calculations.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2710,
    "para_id": 444,
    "paper_id": 3,
    "2d_coord": [
      1.048076868057251,
      1.8950603008270264
    ],
    "MSU_id": 2710,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "2) Results: If the subject chose to give up, it was also counted as an incorrect answer. In addition, response records corresponding to incorrect answers, as well as the user's response records for the same question when using the alternate system, will be excluded from the response time calculations. Figure 8 summarizes the correctness of the subjects' answers and the subjects' response times for every question."
  },
  {
    "sentence": "User's response records for the same question when using the alternate system will be excluded from the response time calculations.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2711,
    "para_id": 444,
    "paper_id": 3,
    "2d_coord": [
      1.0974804162979126,
      1.9742863178253174
    ],
    "MSU_id": 2711,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "2) Results: If the subject chose to give up, it was also counted as an incorrect answer. In addition, response records corresponding to incorrect answers, as well as the user's response records for the same question when using the alternate system, will be excluded from the response time calculations. Figure 8 summarizes the correctness of the subjects' answers and the subjects' response times for every question."
  },
  {
    "sentence": "Q7, Q8, and Q13 required the subjects to examine the value distribution across the geographic space at a given timestamp.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2720,
    "para_id": 446,
    "paper_id": 3,
    "2d_coord": [
      0.965613603591919,
      1.9406776428222656
    ],
    "MSU_id": 2720,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Q7, Q8, and Q13. These three questions required the subjects to examine the value distribution across the geographic space at a given timestamp. To do that, the slicing interaction was helpful regardless of the system used. Consequently, the response times were typically under 20 seconds, with most being under 10 seconds. However, in the baseline, visualizations were influenced by station density, leading some subjects to mistakenly perceive areas with dense disk density as more polluted, resulting in an accuracy of only  $66.7\\%$  of Q7 and Q8."
  },
  {
    "sentence": "Subjects are required to explore all timestamps across the entire geographic area to answer Q11.",
    "subtitle": "B. User Study",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2727,
    "para_id": 448,
    "paper_id": 3,
    "2d_coord": [
      1.0003886222839355,
      1.964482307434082
    ],
    "MSU_id": 2727,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "Q11. To answer Q11, subjects are required to explore all timestamps across the entire geographic area. Using VolumeSTCube, subjects can examine all voxels without encountering occlusion issues and easily identify the reddest and most opaque ones through simple rotations (only a few seconds). In contrast, the baseline demands subjects repeatedly select time ranges and columns to mitigate occlusion caused by columns, thereby prolonging interaction times."
  },
  {
    "sentence": "In the case study, the expert comprehensively analyzed air quality in China, demonstrating VolumeSTCube's effectiveness.",
    "subtitle": "A. Implications",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2787,
    "para_id": 457,
    "paper_id": 3,
    "2d_coord": [
      1.1176170110702515,
      1.9376695156097412
    ],
    "MSU_id": 2787,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A. ImplicationsThe STC, a form of 3D visualization, has historically seen mixed reception in the visualization community, particularly due to inherent occlusion issues [66]. Nonetheless, our study shows that the STC's effectiveness can be enhanced by reducing occlusion through data transformation combined with volume and surface visualizations. Furthermore, to improve the STC's adaptability to large-scale datasets, we design interactions for users to manipulate the STC from time and space dimensions, corresponding to spatial and temporal selection interactions common in 2D views. In the case study, the expert comprehensively analyzed an quality in China, demonstrating VolumeSTCube's effectiveness. The user study employed carefully designed tasks that required participants to utilize both volume and surface visualizations, alongside interactions such as volume spotlight, slicing, and voxel cluster-based techniques, to complete the analyses. The high accuracy and efficiency observed in task completion indicate that participants mastered VolumeSTCube, further underscoring its usability, effectiveness, and broad applicability."
  },
  {
    "sentence": "The user study employed carefully designed tasks that required participants to utilize both volume and surface visualizations.",
    "subtitle": "A. Implications",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2788,
    "para_id": 457,
    "paper_id": 3,
    "2d_coord": [
      1.1010464429855347,
      1.989546298980713
    ],
    "MSU_id": 2788,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A. ImplicationsThe STC, a form of 3D visualization, has historically seen mixed reception in the visualization community, particularly due to inherent occlusion issues [66]. Nonetheless, our study shows that the STC's effectiveness can be enhanced by reducing occlusion through data transformation combined with volume and surface visualizations. Furthermore, to improve the STC's adaptability to large-scale datasets, we design interactions for users to manipulate the STC from time and space dimensions, corresponding to spatial and temporal selection interactions common in 2D views. In the case study, the expert comprehensively analyzed an quality in China, demonstrating VolumeSTCube's effectiveness. The user study employed carefully designed tasks that required participants to utilize both volume and surface visualizations, alongside interactions such as volume spotlight, slicing, and voxel cluster-based techniques, to complete the analyses. The high accuracy and efficiency observed in task completion indicate that participants mastered VolumeSTCube, further underscoring its usability, effectiveness, and broad applicability."
  },
  {
    "sentence": "Participants used interactions such as volume spotlight, slicing, and voxel cluster-based techniques to complete the analyses.",
    "subtitle": "A. Implications",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2789,
    "para_id": 457,
    "paper_id": 3,
    "2d_coord": [
      1.0510902404785156,
      1.8424949645996094
    ],
    "MSU_id": 2789,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "A. ImplicationsThe STC, a form of 3D visualization, has historically seen mixed reception in the visualization community, particularly due to inherent occlusion issues [66]. Nonetheless, our study shows that the STC's effectiveness can be enhanced by reducing occlusion through data transformation combined with volume and surface visualizations. Furthermore, to improve the STC's adaptability to large-scale datasets, we design interactions for users to manipulate the STC from time and space dimensions, corresponding to spatial and temporal selection interactions common in 2D views. In the case study, the expert comprehensively analyzed an quality in China, demonstrating VolumeSTCube's effectiveness. The user study employed carefully designed tasks that required participants to utilize both volume and surface visualizations, alongside interactions such as volume spotlight, slicing, and voxel cluster-based techniques, to complete the analyses. The high accuracy and efficiency observed in task completion indicate that participants mastered VolumeSTCube, further underscoring its usability, effectiveness, and broad applicability."
  },
  {
    "sentence": "In this study, the air pollution ST series is used to demonstrate.",
    "subtitle": "B. Generalizability",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2798,
    "para_id": 458,
    "paper_id": 3,
    "2d_coord": [
      0.9693009853363037,
      1.9960789680480957
    ],
    "MSU_id": 2798,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube can be generalized to ST series representing natural phenomena in various domains, as they are usually continuous over space and time. Representative phenomena include rainfall, humidity, and temperature, as well as air pollution. The three modules of VolumeSTCube- transformation, visualization, and interaction- are designed to be domainindependent without any domain- specific constraints. As long as phenomena exhibit continuity across both time and space, we can generate volumetric data through interpolation and smoothing, so that our visualizations and interactions can be applied. In this study, the air pollution ST series is used to demonstrate. In Appendix B, we include another example, where we visualize the temperature ST series using VolumeSTCube and briefly describe the observed spatiotemporal patterns. For more details, please refer to Appendix B."
  },
  {
    "sentence": "In Appendix B, we include another example, where we visualize the temperature ST series using VolumeSTCube and briefly describe the observed spatiotemporal patterns.",
    "subtitle": "B. Generalizability",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2799,
    "para_id": 458,
    "paper_id": 3,
    "2d_coord": [
      0.325671911239624,
      1.6204240322113037
    ],
    "MSU_id": 2799,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "VolumeSTCube can be generalized to ST series representing natural phenomena in various domains, as they are usually continuous over space and time. Representative phenomena include rainfall, humidity, and temperature, as well as air pollution. The three modules of VolumeSTCube- transformation, visualization, and interaction- are designed to be domainindependent without any domain- specific constraints. As long as phenomena exhibit continuity across both time and space, we can generate volumetric data through interpolation and smoothing, so that our visualizations and interactions can be applied. In this study, the air pollution ST series is used to demonstrate. In Appendix B, we include another example, where we visualize the temperature ST series using VolumeSTCube and briefly describe the observed spatiotemporal patterns. For more details, please refer to Appendix B."
  },
  {
    "sentence": "The spatial granularity for the visualization is a $350 \times 350$ grid.",
    "subtitle": "C. Scalability",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2808,
    "para_id": 460,
    "paper_id": 3,
    "2d_coord": [
      1.1646443605422974,
      1.9422690868377686
    ],
    "MSU_id": 2808,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "C. ScalabilityThe scalability of VolumeSTCube is primarily constrained by the hardware's capacity to handle a certain number of voxels. Under the hardware conditions mentioned in subsection IV-E, VolumeSTCube can effectively visualize ST series spanning half a year across China, with a spatial granularity of a  $350 \\times 350$  grid and a temporal granularity of hours, totaling over 50 million voxels. In cases where hardware resources are limited, adjustments such as reducing the number of cells or aggregating the time can be implemented to mitigate the number of voxels while maintaining the representation of ST series within the same range."
  },
  {
    "sentence": "The temporal granularity for the visualization is hours.",
    "subtitle": "C. Scalability",
    "category": "EXPERIMENT/SETUP",
    "rank": 2,
    "msuid": 2809,
    "para_id": 460,
    "paper_id": 3,
    "2d_coord": [
      0.4303622841835022,
      1.1484127044677734
    ],
    "MSU_id": 2809,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "C. ScalabilityThe scalability of VolumeSTCube is primarily constrained by the hardware's capacity to handle a certain number of voxels. Under the hardware conditions mentioned in subsection IV-E, VolumeSTCube can effectively visualize ST series spanning half a year across China, with a spatial granularity of a  $350 \\times 350$  grid and a temporal granularity of hours, totaling over 50 million voxels. In cases where hardware resources are limited, adjustments such as reducing the number of cells or aggregating the time can be implemented to mitigate the number of voxels while maintaining the representation of ST series within the same range."
  },
  {
    "sentence": "VolumeSTCube is evaluated with a computation experiment, a real-world case study, and a controlled within-subject user study.",
    "subtitle": "VII. CONCLUSION",
    "category": "EXPERIMENT/SETUP",
    "rank": 3,
    "msuid": 2844,
    "para_id": 467,
    "paper_id": 3,
    "2d_coord": [
      1.086258888244629,
      1.9945704936981201
    ],
    "MSU_id": 2844,
    "paper_info": "Visualizing Large-Scale Spatial Time Series with GeoChron",
    "paragraph_info": "We leverage well- established volume visualization techniques to revisit the space- time cube, proposing a large- scale spatial time (ST) series visualization technique called VolumeSTCube. In particular, we transform large- scale ST series into volumetric data that is subsequently visualized with volume and surface rendering. To enhance users' ability to explore the visualization, we design user- friendly interactions oriented to spatial, temporal, and spatiotemporal patterns of ST series. VolumeSTCube is evaluated with a computation experiment, a real- world case study, and a controlled within- subject user study."
  }
]